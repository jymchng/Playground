{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5860519",
   "metadata": {},
   "source": [
    "# Bayesian Neural Network on the 'Heart Attack' Dataset\n",
    "\n",
    "Author: CHNG Soon Siang ([LinkedIn](https://www.linkedin.com/in/soon-siang-chng/))<br>\n",
    "Dataset: [Heart Attack Dataset](https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)\n",
    "\n",
    "_**Summary**_\n",
    "A typical neural network (acting as a baseline model) and a Bayesian neural network were trained separately on the preprocessed heart attack dataset. Objective is to predict the binary label. The baseline model performs well with a test accuracy of 0.883 whereas the Bayesian neural network (BNN) performs poorly, attaining a test accuracy of 0.567. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c0a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffab165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "0.12.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa514a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data size:  303\n",
      "Sizes for different datasets are: Train 212, Test 45 and Validation 45.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = os.path.join('.', 'data', 'heart.csv')\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "feature_names = df.columns.to_list()[:-1]\n",
    "\n",
    "print(\"Whole data size: \", len(df))\n",
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "val_size = int(0.15 * len(df))\n",
    "test_size = int(0.15 * len(df))\n",
    "\n",
    "print(f\"Sizes for different datasets are: Train {train_size}, Test {test_size} and Validation {val_size}.\")\n",
    "\n",
    "train_dataframe = df[:train_size]\n",
    "test_dataframe = df[train_size:]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682f0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = tf.data.Dataset.from_tensor_slices(dict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628314be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex :  [1 0]\n",
      "cp :  [3 2 1 0]\n",
      "fbs :  [1 0]\n",
      "restecg :  [0 1 2]\n",
      "exng :  [0 1]\n",
      "slp :  [0 2 1]\n",
      "caa :  [0 2 1 3 4]\n",
      "thall :  [1 2 3 0]\n",
      "output :  [1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sex': 2,\n",
       " 'cp': 4,\n",
       " 'fbs': 2,\n",
       " 'restecg': 3,\n",
       " 'exng': 2,\n",
       " 'slp': 3,\n",
       " 'caa': 5,\n",
       " 'thall': 4,\n",
       " 'output': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall', 'output']\n",
    "cat_feat_depth = {k:v for k, v in zip(categorical_features, map(lambda x: len(df[x].unique()), categorical_features))}\n",
    "\n",
    "for cat_feat in categorical_features:\n",
    "    print(cat_feat,': ', df[cat_feat].unique())\n",
    "    \n",
    "cat_feat_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02855bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_x(x):\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        \n",
    "        if feature in categorical_features:\n",
    "            \n",
    "            x[feature] = tf.one_hot(x[feature], depth = cat_feat_depth[feature], dtype = tf.float32)\n",
    "            x[feature] = tf.cast(x[feature], dtype = tf.float32)\n",
    "        else:\n",
    "            x[feature] = tf.cast(x[feature], dtype = tf.float32)\n",
    "    \n",
    "    x['output'] = tf.one_hot(x['output'], depth = cat_feat_depth['output'], dtype = tf.int32)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772a8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.map(transform_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1db823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       " 'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'output': TensorSpec(shape=(2,), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7288138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_feature_label(x):\n",
    "    features = {feature:x[feature] for feature in df.columns.to_list()[:-1]}\n",
    "    return (features, x['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a95213",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.map(map_feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45998cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': {}, 'sex': {}, 'cp': {}, 'trtbps': {}, 'chol': {}, 'fbs': {}, 'restecg': {}, 'thalachh': {}, 'exng': {}, 'oldpeak': {}, 'slp': {}, 'caa': {}, 'thall': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': {'shape': 1, 'dtype': tf.float32},\n",
       " 'sex': {'shape': 2, 'dtype': tf.float32},\n",
       " 'cp': {'shape': 4, 'dtype': tf.float32},\n",
       " 'trtbps': {'shape': 1, 'dtype': tf.float32},\n",
       " 'chol': {'shape': 1, 'dtype': tf.float32},\n",
       " 'fbs': {'shape': 2, 'dtype': tf.float32},\n",
       " 'restecg': {'shape': 3, 'dtype': tf.float32},\n",
       " 'thalachh': {'shape': 1, 'dtype': tf.float32},\n",
       " 'exng': {'shape': 2, 'dtype': tf.float32},\n",
       " 'oldpeak': {'shape': 1, 'dtype': tf.float32},\n",
       " 'slp': {'shape': 3, 'dtype': tf.float32},\n",
       " 'caa': {'shape': 5, 'dtype': tf.float32},\n",
       " 'thall': {'shape': 4, 'dtype': tf.float32}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_shape_dtype = {feature: dict() for feature in feature_names}\n",
    "print(feature_shape_dtype)\n",
    "\n",
    "for x in full_dataset.take(1):\n",
    "    q = x[0]\n",
    "    for feature in feature_names:\n",
    "        feature_shape_dtype[feature]['shape'] = int(cat_feat_depth[feature]) if feature in cat_feat_depth.keys() else 1\n",
    "        feature_shape_dtype[feature]['dtype'] = q[feature].dtype\n",
    "        \n",
    "feature_shape_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283a5d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc75fb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22169811320754718, 0.7783018867924528)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neg_proportion = len(train_dataframe[train_dataframe.output ==0])/len(train_dataframe)\n",
    "num_pos_proportion = len(train_dataframe[train_dataframe.output ==1])/len(train_dataframe)\n",
    "\n",
    "num_neg_proportion, num_pos_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc73b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_train_val_test(dataset, train_size, val_size, test_size):\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size = len(df))\n",
    "    train_dataset = dataset.take(train_size).batch(train_size)\n",
    "    test_dataset = dataset.skip(train_size)\n",
    "    val_dataset = dataset.skip(val_size).batch(val_size)\n",
    "    test_dataset = dataset.take(test_size).batch(test_size)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ae38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset_to_train_val_test(full_dataset,\n",
    "                                                                     train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e544c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(None, 2), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf54b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([44., 59., 58., 67., 44., 62., 56., 60., 57., 58., 62., 45., 38.,\n",
      "       45., 46., 67., 61., 57., 54., 62., 52., 59., 41., 63., 44., 69.,\n",
      "       44., 47., 64., 41., 54., 57., 57., 70., 57., 52., 56., 44., 51.,\n",
      "       56., 64., 42., 62., 44., 41.], dtype=float32)>, 'sex': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.]], dtype=float32)>, 'cp': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.]], dtype=float32)>, 'trtbps': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([120., 160., 140., 125., 130., 120., 130., 140., 150., 136., 150.,\n",
      "       115., 138., 104., 120., 120., 134., 130., 160., 138., 134., 140.,\n",
      "       105., 140., 120., 140., 120., 110., 170., 110., 135., 128., 165.,\n",
      "       160., 110., 118., 130., 108., 100., 120., 130., 130., 128., 140.,\n",
      "       130.], dtype=float32)>, 'chol': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([169., 273., 211., 254., 233., 281., 221., 185., 168., 319., 244.,\n",
      "       260., 175., 208., 249., 229., 234., 131., 201., 294., 201., 177.,\n",
      "       198., 195., 226., 239., 263., 275., 227., 235., 304., 303., 289.,\n",
      "       269., 335., 186., 256., 141., 222., 193., 303., 180., 208., 235.,\n",
      "       204.], dtype=float32)>, 'fbs': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32)>, 'restecg': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.]], dtype=float32)>, 'thalachh': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([144., 125., 165., 163., 179., 103., 163., 155., 174., 152., 154.,\n",
      "       185., 173., 148., 144., 129., 145., 115., 163., 106., 158., 162.,\n",
      "       168., 179., 169., 151., 173., 118., 155., 153., 170., 159., 124.,\n",
      "       112., 143., 190., 142., 175., 143., 162., 122., 150., 140., 180.,\n",
      "       172.], dtype=float32)>, 'exng': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32)>, 'oldpeak': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([2.8, 0. , 0. , 0.2, 0.4, 1.4, 0. , 3. , 1.6, 0. , 1.4, 0. , 0. ,\n",
      "       3. , 0.8, 2.6, 2.6, 1.2, 0. , 1.9, 0.8, 0. , 0. , 0. , 0. , 1.8,\n",
      "       0. , 1. , 0.6, 0. , 0. , 0. , 1. , 2.9, 3. , 0. , 0.6, 0.6, 1.2,\n",
      "       1.9, 2. , 0. , 0. , 0. , 1.4], dtype=float32)>, 'slp': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.]], dtype=float32)>, 'caa': <tf.Tensor: shape=(45, 5), dtype=float32, numpy=\n",
      "array([[1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.]], dtype=float32)>, 'thall': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.]], dtype=float32)>}\n",
      "---------------\n",
      "tf.Tensor(\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]], shape=(45, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_dataset.take(1):\n",
    "    print(x)\n",
    "    print('-'*15)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f363fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "\n",
    "hidden_units = [32, 32, 32]\n",
    "feature_names = ['age',\n",
    "'sex',\n",
    "'cp',\n",
    "'trtbps',\n",
    "'chol',\n",
    "'fbs',\n",
    "'restecg',\n",
    "'thalachh',\n",
    "'exng',\n",
    "'oldpeak',\n",
    "'slp',\n",
    "'caa',\n",
    "'thall',\n",
    "'output']\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcec582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'sex': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'sex')>,\n",
       " 'cp': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'cp')>,\n",
       " 'trtbps': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'trtbps')>,\n",
       " 'chol': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'chol')>,\n",
       " 'fbs': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'fbs')>,\n",
       " 'restecg': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'restecg')>,\n",
       " 'thalachh': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'thalachh')>,\n",
       " 'exng': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'exng')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'oldpeak')>,\n",
       " 'slp': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'slp')>,\n",
       " 'caa': <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'caa')>,\n",
       " 'thall': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'thall')>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model_inputs(feature_names = feature_names): \n",
    "    inputs = {}\n",
    "    for feature_name in feature_names:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(feature_shape_dtype[feature_name]['shape'],),\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n",
    "\n",
    "create_model_inputs(feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f8de85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_and_slab(event_shape, dtype): # Coursera Introduction to Tensorflow 2\n",
    "    distribution = tfd.Mixture(\n",
    "        cat=tfd.Categorical(probs=[0.5, 0.5]),\n",
    "        components=[\n",
    "            tfd.Independent(tfd.Normal(\n",
    "                loc=tf.zeros(event_shape, dtype=dtype), \n",
    "                scale=1.0*tf.ones(event_shape, dtype=dtype)),\n",
    "                            reinterpreted_batch_ndims=1),\n",
    "            tfd.Independent(tfd.Normal(\n",
    "                loc=tf.zeros(event_shape, dtype=dtype), \n",
    "                scale=10.0*tf.ones(event_shape, dtype=dtype)),\n",
    "                            reinterpreted_batch_ndims=1)],\n",
    "    name='spike_and_slab')\n",
    "    return distribution\n",
    "\n",
    "def prior(kernel_size, bias_size, dtype=None): # Coursera Introduction to Tensorflow 2\n",
    "    \n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = keras.Sequential([\n",
    "        tfpl.DistributionLambda(\n",
    "        lambda t : spike_and_slab(n, dtype = dtype)\n",
    "        )\n",
    "    ])\n",
    "    return prior_model\n",
    "\n",
    "# def prior(kernel_size, bias_size, dtype=None):\n",
    "#     n = kernel_size + bias_size\n",
    "#     prior_model = keras.Sequential(\n",
    "#         [\n",
    "#             tfp.layers.DistributionLambda(\n",
    "#                 lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "#                     loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "#                 )\n",
    "#             )\n",
    "#         ]\n",
    "#     )\n",
    "#     return prior_model\n",
    "\n",
    "\n",
    "# Define variational posterior weight distribution as multivariate Gaussian.\n",
    "# Note that the learnable parameters for this distribution are the means,\n",
    "# variances, and covariances.\n",
    "\n",
    "# def posterior(kernel_size, bias_size, dtype=None):\n",
    "#     n = kernel_size + bias_size\n",
    "#     posterior_model = keras.Sequential(\n",
    "#         [\n",
    "#             tfp.layers.VariableLayer(\n",
    "#                 tfp.layers.MultivariateNormalTriL.params_size(n), dtype=dtype\n",
    "#             ),\n",
    "#             tfp.layers.MultivariateNormalTriL(n),\n",
    "#         ]\n",
    "#     )\n",
    "#     return posterior_model\n",
    "\n",
    "def posterior(kernel_size, bias_size, dtype=None): # Coursera Introduction to Tensorflow 2\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential([\n",
    "        tfp.layers.VariableLayer(tfp.layers.IndependentNormal.params_size(n), dtype = dtype),\n",
    "        tfp.layers.IndependentNormal(n)\n",
    "    ])\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b9c1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnn_model(train_size):\n",
    "    \n",
    "    divergence_fn = lambda q, p, _:tfd.kl_divergence(q, p) / train_size\n",
    "    \n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features_ = tfpl.DenseReparameterization(\n",
    "            units = units, activation = 'relu',\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "    \n",
    "    distribution_params = tfpl.DenseReparameterization(\n",
    "            units = tfp.layers.OneHotCategorical.params_size(2), activation = None,\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "\n",
    "    outputs = tfp.layers.OneHotCategorical(2,\n",
    "                                          convert_to_tensor_fn=tfd.Distribution.mode)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70e1df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features_ = tfp.layers.DenseVariational(\n",
    "            units=units,\n",
    "            make_prior_fn=prior,\n",
    "            make_posterior_fn=posterior,\n",
    "            kl_weight=1 / train_size,\n",
    "            activation=\"relu\")(features_)\n",
    "    \n",
    "    distribution_params = tfp.layers.DenseVariational(\n",
    "        units=tfp.layers.OneHotCategorical.params_size(2),\n",
    "        make_prior_fn=prior,\n",
    "        make_posterior_fn=posterior,\n",
    "        kl_weight=1 / train_size,\n",
    "        activation = None\n",
    "    )(features_)\n",
    "\n",
    "    outputs = tfp.layers.OneHotCategorical(2,\n",
    "                                          convert_to_tensor_fn=tfd.Distribution.mode)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d88e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "    \n",
    "    for units in hidden_units:\n",
    "        features_ = tf.keras.layers.Dense(\n",
    "            units=units,\n",
    "            activation = 'relu')(features_)\n",
    "        \n",
    "    outputs = tf.keras.layers.Dense(2,\n",
    "                                    activation = 'softmax')(features_)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d098749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_metric(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "49677cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "def run_experiment(model, loss, train_dataset,val_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics = [tf.keras.metrics.Accuracy(),\n",
    "                  f1_metric],\n",
    "        experimental_run_tf_function=False\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=val_dataset\n",
    "             )\n",
    "    \n",
    "    print(\"Model training finished.\")\n",
    "    \n",
    "    loss, accuracy, f1_score = model.evaluate(train_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Train loss: {round(loss, 3)}, train accuracy: {round(accuracy, 3)} and train f1_score: {round(f1_score, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    loss, accuracy, f1_score = model.evaluate(test_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Test loss: {round(loss, 3)}, test accuracy: {round(accuracy, 3)} and test f1_score: {round(f1_score, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "975f5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_full = create_nn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19173e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7046 - binary_accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 1.0901 - val_binary_accuracy: 0.5698 - val_f1_metric: 0.5687\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6597 - binary_accuracy: 0.6368 - f1_metric: 0.6368 - val_loss: 0.6358 - val_binary_accuracy: 0.6705 - val_f1_metric: 0.6690\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6213 - binary_accuracy: 0.7453 - f1_metric: 0.7453 - val_loss: 0.5551 - val_binary_accuracy: 0.7481 - val_f1_metric: 0.7485\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5926 - binary_accuracy: 0.7925 - f1_metric: 0.7925 - val_loss: 0.5364 - val_binary_accuracy: 0.7481 - val_f1_metric: 0.7471\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5714 - binary_accuracy: 0.8208 - f1_metric: 0.8208 - val_loss: 0.5226 - val_binary_accuracy: 0.7326 - val_f1_metric: 0.7256\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5590 - binary_accuracy: 0.8255 - f1_metric: 0.8255 - val_loss: 0.5363 - val_binary_accuracy: 0.7326 - val_f1_metric: 0.7337\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5174 - binary_accuracy: 0.8585 - f1_metric: 0.8585 - val_loss: 0.5749 - val_binary_accuracy: 0.6899 - val_f1_metric: 0.6848\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.5088 - binary_accuracy: 0.8443 - f1_metric: 0.8443 - val_loss: 0.6200 - val_binary_accuracy: 0.6473 - val_f1_metric: 0.6562\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4843 - binary_accuracy: 0.8821 - f1_metric: 0.8821 - val_loss: 0.6158 - val_binary_accuracy: 0.6357 - val_f1_metric: 0.6438\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4682 - binary_accuracy: 0.8585 - f1_metric: 0.8585 - val_loss: 0.5799 - val_binary_accuracy: 0.6860 - val_f1_metric: 0.6892\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4473 - binary_accuracy: 0.8726 - f1_metric: 0.8726 - val_loss: 0.7523 - val_binary_accuracy: 0.5659 - val_f1_metric: 0.5690\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4305 - binary_accuracy: 0.8915 - f1_metric: 0.8915 - val_loss: 0.6705 - val_binary_accuracy: 0.6008 - val_f1_metric: 0.5970\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4160 - binary_accuracy: 0.8821 - f1_metric: 0.8821 - val_loss: 0.8486 - val_binary_accuracy: 0.5543 - val_f1_metric: 0.5525\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3847 - binary_accuracy: 0.9009 - f1_metric: 0.9009 - val_loss: 0.9451 - val_binary_accuracy: 0.5039 - val_f1_metric: 0.5017\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4028 - binary_accuracy: 0.8821 - f1_metric: 0.8821 - val_loss: 0.8334 - val_binary_accuracy: 0.5620 - val_f1_metric: 0.5640\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3984 - binary_accuracy: 0.8821 - f1_metric: 0.8821 - val_loss: 0.7531 - val_binary_accuracy: 0.6008 - val_f1_metric: 0.6037\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3524 - binary_accuracy: 0.9104 - f1_metric: 0.9104 - val_loss: 0.9993 - val_binary_accuracy: 0.5078 - val_f1_metric: 0.5067\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3736 - binary_accuracy: 0.8774 - f1_metric: 0.8774 - val_loss: 0.7658 - val_binary_accuracy: 0.6163 - val_f1_metric: 0.6104\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3637 - binary_accuracy: 0.8868 - f1_metric: 0.8868 - val_loss: 0.7981 - val_binary_accuracy: 0.6124 - val_f1_metric: 0.6162\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3627 - binary_accuracy: 0.8726 - f1_metric: 0.8726 - val_loss: 0.7692 - val_binary_accuracy: 0.6163 - val_f1_metric: 0.6172\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3055 - binary_accuracy: 0.9198 - f1_metric: 0.9198 - val_loss: 0.8292 - val_binary_accuracy: 0.6085 - val_f1_metric: 0.6125\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3479 - binary_accuracy: 0.8915 - f1_metric: 0.8915 - val_loss: 0.7114 - val_binary_accuracy: 0.6550 - val_f1_metric: 0.6582\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2872 - binary_accuracy: 0.9198 - f1_metric: 0.9198 - val_loss: 0.7361 - val_binary_accuracy: 0.6395 - val_f1_metric: 0.6354\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3182 - binary_accuracy: 0.8868 - f1_metric: 0.8868 - val_loss: 0.7635 - val_binary_accuracy: 0.6434 - val_f1_metric: 0.6418\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2747 - binary_accuracy: 0.9292 - f1_metric: 0.9292 - val_loss: 0.7103 - val_binary_accuracy: 0.6589 - val_f1_metric: 0.6579\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3161 - binary_accuracy: 0.9009 - f1_metric: 0.9009 - val_loss: 0.7817 - val_binary_accuracy: 0.6395 - val_f1_metric: 0.6340\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3078 - binary_accuracy: 0.9009 - f1_metric: 0.9009 - val_loss: 0.9498 - val_binary_accuracy: 0.5814 - val_f1_metric: 0.5798\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3084 - binary_accuracy: 0.8962 - f1_metric: 0.8962 - val_loss: 0.8665 - val_binary_accuracy: 0.6124 - val_f1_metric: 0.6094\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3090 - binary_accuracy: 0.8915 - f1_metric: 0.8915 - val_loss: 0.6291 - val_binary_accuracy: 0.6938 - val_f1_metric: 0.6953\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2621 - binary_accuracy: 0.9387 - f1_metric: 0.9387 - val_loss: 0.6911 - val_binary_accuracy: 0.6512 - val_f1_metric: 0.6492\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2938 - binary_accuracy: 0.9057 - f1_metric: 0.9057 - val_loss: 0.6654 - val_binary_accuracy: 0.6860 - val_f1_metric: 0.6865\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2468 - binary_accuracy: 0.9245 - f1_metric: 0.9245 - val_loss: 0.5047 - val_binary_accuracy: 0.7597 - val_f1_metric: 0.7636\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2713 - binary_accuracy: 0.9057 - f1_metric: 0.9057 - val_loss: 0.7051 - val_binary_accuracy: 0.6744 - val_f1_metric: 0.6768\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2781 - binary_accuracy: 0.9151 - f1_metric: 0.9151 - val_loss: 0.5908 - val_binary_accuracy: 0.7326 - val_f1_metric: 0.7350\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2700 - binary_accuracy: 0.9198 - f1_metric: 0.9198 - val_loss: 0.5768 - val_binary_accuracy: 0.7287 - val_f1_metric: 0.7259\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2691 - binary_accuracy: 0.9151 - f1_metric: 0.9151 - val_loss: 0.5257 - val_binary_accuracy: 0.7558 - val_f1_metric: 0.7545\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2284 - binary_accuracy: 0.9245 - f1_metric: 0.9245 - val_loss: 0.4462 - val_binary_accuracy: 0.7674 - val_f1_metric: 0.7643\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2617 - binary_accuracy: 0.9104 - f1_metric: 0.9104 - val_loss: 0.5489 - val_binary_accuracy: 0.7519 - val_f1_metric: 0.7522\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2534 - binary_accuracy: 0.9198 - f1_metric: 0.9198 - val_loss: 0.5426 - val_binary_accuracy: 0.7519 - val_f1_metric: 0.7522\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2598 - binary_accuracy: 0.9198 - f1_metric: 0.9198 - val_loss: 0.5170 - val_binary_accuracy: 0.7558 - val_f1_metric: 0.7572\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2170 - binary_accuracy: 0.9387 - f1_metric: 0.9387 - val_loss: 0.5014 - val_binary_accuracy: 0.7713 - val_f1_metric: 0.7707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2300 - binary_accuracy: 0.9387 - f1_metric: 0.9387 - val_loss: 0.5376 - val_binary_accuracy: 0.7597 - val_f1_metric: 0.7596\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2256 - binary_accuracy: 0.9245 - f1_metric: 0.9245 - val_loss: 0.4660 - val_binary_accuracy: 0.7829 - val_f1_metric: 0.7818\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2539 - binary_accuracy: 0.9245 - f1_metric: 0.9245 - val_loss: 0.5337 - val_binary_accuracy: 0.7597 - val_f1_metric: 0.7582\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2377 - binary_accuracy: 0.9151 - f1_metric: 0.9151 - val_loss: 0.5958 - val_binary_accuracy: 0.7171 - val_f1_metric: 0.7189\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1930 - binary_accuracy: 0.9387 - f1_metric: 0.9387 - val_loss: 0.6078 - val_binary_accuracy: 0.7364 - val_f1_metric: 0.7374\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2178 - binary_accuracy: 0.9245 - f1_metric: 0.9245 - val_loss: 0.7021 - val_binary_accuracy: 0.6860 - val_f1_metric: 0.6892\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1861 - binary_accuracy: 0.9434 - f1_metric: 0.9434 - val_loss: 0.6014 - val_binary_accuracy: 0.7248 - val_f1_metric: 0.7236\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1787 - binary_accuracy: 0.9575 - f1_metric: 0.9575 - val_loss: 0.5646 - val_binary_accuracy: 0.7442 - val_f1_metric: 0.7461\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1905 - binary_accuracy: 0.9434 - f1_metric: 0.9434 - val_loss: 0.5790 - val_binary_accuracy: 0.7403 - val_f1_metric: 0.7397\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.2203 - binary_accuracy: 0.9340 - f1_metric: 0.9340 - val_loss: 0.6527 - val_binary_accuracy: 0.7209 - val_f1_metric: 0.7253\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.2135 - binary_accuracy: 0.9198 - f1_metric: 0.9198 - val_loss: 0.6307 - val_binary_accuracy: 0.7093 - val_f1_metric: 0.7101\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1941 - binary_accuracy: 0.9387 - f1_metric: 0.9387 - val_loss: 0.5656 - val_binary_accuracy: 0.7442 - val_f1_metric: 0.7434\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.2159 - binary_accuracy: 0.9292 - f1_metric: 0.9292 - val_loss: 0.6449 - val_binary_accuracy: 0.7054 - val_f1_metric: 0.7024\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1684 - binary_accuracy: 0.9528 - f1_metric: 0.9528 - val_loss: 0.4815 - val_binary_accuracy: 0.7674 - val_f1_metric: 0.7657\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1740 - binary_accuracy: 0.9528 - f1_metric: 0.9528 - val_loss: 0.5595 - val_binary_accuracy: 0.7519 - val_f1_metric: 0.7495\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1873 - binary_accuracy: 0.9481 - f1_metric: 0.9481 - val_loss: 0.4890 - val_binary_accuracy: 0.7713 - val_f1_metric: 0.7721\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1715 - binary_accuracy: 0.9528 - f1_metric: 0.9528 - val_loss: 0.4269 - val_binary_accuracy: 0.8023 - val_f1_metric: 0.8044\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1899 - binary_accuracy: 0.9292 - f1_metric: 0.9292 - val_loss: 0.5080 - val_binary_accuracy: 0.7868 - val_f1_metric: 0.7801\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1691 - binary_accuracy: 0.9575 - f1_metric: 0.9575 - val_loss: 0.4797 - val_binary_accuracy: 0.7946 - val_f1_metric: 0.7943\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1534 - binary_accuracy: 0.9575 - f1_metric: 0.9575 - val_loss: 0.4554 - val_binary_accuracy: 0.7946 - val_f1_metric: 0.7997\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1596 - binary_accuracy: 0.9528 - f1_metric: 0.9528 - val_loss: 0.4523 - val_binary_accuracy: 0.7868 - val_f1_metric: 0.7815\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1804 - binary_accuracy: 0.9340 - f1_metric: 0.9340 - val_loss: 0.4981 - val_binary_accuracy: 0.7868 - val_f1_metric: 0.7869\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1870 - binary_accuracy: 0.9434 - f1_metric: 0.9434 - val_loss: 0.4309 - val_binary_accuracy: 0.8140 - val_f1_metric: 0.8141\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1714 - binary_accuracy: 0.9528 - f1_metric: 0.9528 - val_loss: 0.3858 - val_binary_accuracy: 0.8256 - val_f1_metric: 0.8253\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1809 - binary_accuracy: 0.9340 - f1_metric: 0.9340 - val_loss: 0.3986 - val_binary_accuracy: 0.8178 - val_f1_metric: 0.8205\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1137 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.4078 - val_binary_accuracy: 0.7907 - val_f1_metric: 0.7919\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1495 - binary_accuracy: 0.9575 - f1_metric: 0.9575 - val_loss: 0.4149 - val_binary_accuracy: 0.8023 - val_f1_metric: 0.8044\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1550 - binary_accuracy: 0.9575 - f1_metric: 0.9575 - val_loss: 0.3855 - val_binary_accuracy: 0.8178 - val_f1_metric: 0.8152\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1271 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.4205 - val_binary_accuracy: 0.8101 - val_f1_metric: 0.8064\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1420 - binary_accuracy: 0.9623 - f1_metric: 0.9623 - val_loss: 0.4176 - val_binary_accuracy: 0.8062 - val_f1_metric: 0.8054\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1389 - binary_accuracy: 0.9623 - f1_metric: 0.9623 - val_loss: 0.4669 - val_binary_accuracy: 0.8178 - val_f1_metric: 0.8152\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1213 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3928 - val_binary_accuracy: 0.8333 - val_f1_metric: 0.8313\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1545 - binary_accuracy: 0.9623 - f1_metric: 0.9623 - val_loss: 0.4501 - val_binary_accuracy: 0.8140 - val_f1_metric: 0.8128\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1648 - binary_accuracy: 0.9623 - f1_metric: 0.9623 - val_loss: 0.3456 - val_binary_accuracy: 0.8682 - val_f1_metric: 0.8687\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1531 - binary_accuracy: 0.9623 - f1_metric: 0.9623 - val_loss: 0.4044 - val_binary_accuracy: 0.8140 - val_f1_metric: 0.8141\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1501 - binary_accuracy: 0.9575 - f1_metric: 0.9575 - val_loss: 0.4263 - val_binary_accuracy: 0.8101 - val_f1_metric: 0.8118\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1431 - binary_accuracy: 0.9434 - f1_metric: 0.9434 - val_loss: 0.4575 - val_binary_accuracy: 0.8023 - val_f1_metric: 0.8030\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1327 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3387 - val_binary_accuracy: 0.8411 - val_f1_metric: 0.8441\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1041 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.3912 - val_binary_accuracy: 0.8256 - val_f1_metric: 0.8279\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1087 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3883 - val_binary_accuracy: 0.8411 - val_f1_metric: 0.8414\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1281 - binary_accuracy: 0.9670 - f1_metric: 0.9670 - val_loss: 0.4234 - val_binary_accuracy: 0.8140 - val_f1_metric: 0.8168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1200 - binary_accuracy: 0.9670 - f1_metric: 0.9670 - val_loss: 0.4416 - val_binary_accuracy: 0.8217 - val_f1_metric: 0.8162\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1215 - binary_accuracy: 0.9670 - f1_metric: 0.9670 - val_loss: 0.4031 - val_binary_accuracy: 0.8101 - val_f1_metric: 0.8131\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1181 - binary_accuracy: 0.9670 - f1_metric: 0.9670 - val_loss: 0.4044 - val_binary_accuracy: 0.8256 - val_f1_metric: 0.8253\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1273 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.4360 - val_binary_accuracy: 0.8140 - val_f1_metric: 0.8128\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1129 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.3714 - val_binary_accuracy: 0.8333 - val_f1_metric: 0.8300\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1034 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.4205 - val_binary_accuracy: 0.8023 - val_f1_metric: 0.7990\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1037 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.3489 - val_binary_accuracy: 0.8682 - val_f1_metric: 0.8687\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0960 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3525 - val_binary_accuracy: 0.8488 - val_f1_metric: 0.8461\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1073 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3762 - val_binary_accuracy: 0.8295 - val_f1_metric: 0.8263\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1276 - binary_accuracy: 0.9623 - f1_metric: 0.9623 - val_loss: 0.4329 - val_binary_accuracy: 0.8217 - val_f1_metric: 0.8202\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1167 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.4171 - val_binary_accuracy: 0.8333 - val_f1_metric: 0.8327\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1198 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3872 - val_binary_accuracy: 0.8450 - val_f1_metric: 0.8438\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1013 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.3738 - val_binary_accuracy: 0.8333 - val_f1_metric: 0.8327\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0996 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3532 - val_binary_accuracy: 0.8333 - val_f1_metric: 0.8354\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0818 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.3356 - val_binary_accuracy: 0.8566 - val_f1_metric: 0.8549\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0956 - binary_accuracy: 0.9811 - f1_metric: 0.9811 - val_loss: 0.3438 - val_binary_accuracy: 0.8605 - val_f1_metric: 0.8626\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0987 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3513 - val_binary_accuracy: 0.8488 - val_f1_metric: 0.8488\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0943 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.3810 - val_binary_accuracy: 0.8333 - val_f1_metric: 0.8354\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0849 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3102 - val_binary_accuracy: 0.8643 - val_f1_metric: 0.8677\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0706 - binary_accuracy: 0.9811 - f1_metric: 0.9811 - val_loss: 0.4191 - val_binary_accuracy: 0.8295 - val_f1_metric: 0.8343\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0838 - binary_accuracy: 0.9811 - f1_metric: 0.9811 - val_loss: 0.3264 - val_binary_accuracy: 0.8721 - val_f1_metric: 0.8737\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0859 - binary_accuracy: 0.9717 - f1_metric: 0.9717 - val_loss: 0.3208 - val_binary_accuracy: 0.8837 - val_f1_metric: 0.8808\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0935 - binary_accuracy: 0.9811 - f1_metric: 0.9811 - val_loss: 0.3238 - val_binary_accuracy: 0.8450 - val_f1_metric: 0.8451\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0792 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2804 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8811\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0617 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.3596 - val_binary_accuracy: 0.8566 - val_f1_metric: 0.8589\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0682 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3608 - val_binary_accuracy: 0.8566 - val_f1_metric: 0.8589\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0870 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3082 - val_binary_accuracy: 0.8760 - val_f1_metric: 0.8721\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0724 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.3383 - val_binary_accuracy: 0.8721 - val_f1_metric: 0.8751\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0720 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.3722 - val_binary_accuracy: 0.8643 - val_f1_metric: 0.8663\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0765 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3168 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8771\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0641 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2692 - val_binary_accuracy: 0.8992 - val_f1_metric: 0.8983\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0649 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3442 - val_binary_accuracy: 0.8682 - val_f1_metric: 0.8673\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0770 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.4093 - val_binary_accuracy: 0.8295 - val_f1_metric: 0.8263\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0578 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.3119 - val_binary_accuracy: 0.8837 - val_f1_metric: 0.8822\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0794 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3500 - val_binary_accuracy: 0.8527 - val_f1_metric: 0.8539\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0622 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3632 - val_binary_accuracy: 0.8527 - val_f1_metric: 0.8498\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0844 - binary_accuracy: 0.9764 - f1_metric: 0.9764 - val_loss: 0.3613 - val_binary_accuracy: 0.8450 - val_f1_metric: 0.8478\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0717 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2952 - val_binary_accuracy: 0.8760 - val_f1_metric: 0.8747\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0495 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2988 - val_binary_accuracy: 0.8682 - val_f1_metric: 0.8660\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0386 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.3201 - val_binary_accuracy: 0.8721 - val_f1_metric: 0.8751\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0448 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2915 - val_binary_accuracy: 0.8915 - val_f1_metric: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0633 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2971 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8785\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0620 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2901 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8825\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0677 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3276 - val_binary_accuracy: 0.8527 - val_f1_metric: 0.8525\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0587 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.3187 - val_binary_accuracy: 0.8605 - val_f1_metric: 0.8653\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0409 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.3256 - val_binary_accuracy: 0.8605 - val_f1_metric: 0.8586\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0390 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.3140 - val_binary_accuracy: 0.8760 - val_f1_metric: 0.8801\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0394 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.3112 - val_binary_accuracy: 0.8643 - val_f1_metric: 0.8677\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0715 - binary_accuracy: 0.9811 - f1_metric: 0.9811 - val_loss: 0.2870 - val_binary_accuracy: 0.8915 - val_f1_metric: 0.8909\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0700 - binary_accuracy: 0.9811 - f1_metric: 0.9811 - val_loss: 0.3116 - val_binary_accuracy: 0.8760 - val_f1_metric: 0.8747\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0557 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2885 - val_binary_accuracy: 0.8721 - val_f1_metric: 0.8724\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0417 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2690 - val_binary_accuracy: 0.8876 - val_f1_metric: 0.8872\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0583 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3472 - val_binary_accuracy: 0.8605 - val_f1_metric: 0.8626\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0593 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3084 - val_binary_accuracy: 0.8527 - val_f1_metric: 0.8552\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0553 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2758 - val_binary_accuracy: 0.8643 - val_f1_metric: 0.8636\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0549 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3244 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8811\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0607 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.3023 - val_binary_accuracy: 0.8605 - val_f1_metric: 0.8599\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0579 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2613 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8785\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0341 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2674 - val_binary_accuracy: 0.8915 - val_f1_metric: 0.8909\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0341 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2840 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8785\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0339 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2621 - val_binary_accuracy: 0.8760 - val_f1_metric: 0.8761\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0438 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2826 - val_binary_accuracy: 0.8837 - val_f1_metric: 0.8875\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0468 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2866 - val_binary_accuracy: 0.8760 - val_f1_metric: 0.8747\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0562 - binary_accuracy: 0.9811 - f1_metric: 0.9811 - val_loss: 0.2975 - val_binary_accuracy: 0.8643 - val_f1_metric: 0.8609\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0325 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2754 - val_binary_accuracy: 0.8837 - val_f1_metric: 0.8848\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0499 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2534 - val_binary_accuracy: 0.8915 - val_f1_metric: 0.8896\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0489 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2464 - val_binary_accuracy: 0.8953 - val_f1_metric: 0.8919\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0283 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2791 - val_binary_accuracy: 0.8876 - val_f1_metric: 0.8859\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0491 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2431 - val_binary_accuracy: 0.9031 - val_f1_metric: 0.9047\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0416 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2351 - val_binary_accuracy: 0.8953 - val_f1_metric: 0.8919\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0449 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.3161 - val_binary_accuracy: 0.8721 - val_f1_metric: 0.8684\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0564 - binary_accuracy: 0.9858 - f1_metric: 0.9858 - val_loss: 0.2214 - val_binary_accuracy: 0.8953 - val_f1_metric: 0.8946\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0460 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2397 - val_binary_accuracy: 0.8992 - val_f1_metric: 0.8983\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0414 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.1894 - val_binary_accuracy: 0.9186 - val_f1_metric: 0.9182\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0347 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2799 - val_binary_accuracy: 0.8682 - val_f1_metric: 0.8633\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0280 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2517 - val_binary_accuracy: 0.8876 - val_f1_metric: 0.8859\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0392 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2594 - val_binary_accuracy: 0.8837 - val_f1_metric: 0.8875\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0243 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2072 - val_binary_accuracy: 0.9031 - val_f1_metric: 0.9020\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0198 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2424 - val_binary_accuracy: 0.8876 - val_f1_metric: 0.8845\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0218 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2264 - val_binary_accuracy: 0.9109 - val_f1_metric: 0.9094\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0308 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2248 - val_binary_accuracy: 0.8953 - val_f1_metric: 0.8960\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0320 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2037 - val_binary_accuracy: 0.9147 - val_f1_metric: 0.9172\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0176 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2065 - val_binary_accuracy: 0.9109 - val_f1_metric: 0.9121\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0176 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2213 - val_binary_accuracy: 0.9031 - val_f1_metric: 0.9047\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0308 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2543 - val_binary_accuracy: 0.8915 - val_f1_metric: 0.8949\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0338 - binary_accuracy: 0.9906 - f1_metric: 0.990 - 0s 167ms/step - loss: 0.0338 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.2465 - val_binary_accuracy: 0.8798 - val_f1_metric: 0.8852\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0231 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2063 - val_binary_accuracy: 0.9109 - val_f1_metric: 0.9121\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0202 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2258 - val_binary_accuracy: 0.8876 - val_f1_metric: 0.8886\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0323 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2175 - val_binary_accuracy: 0.8876 - val_f1_metric: 0.8886\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0298 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1762 - val_binary_accuracy: 0.9186 - val_f1_metric: 0.9182\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0218 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.2064 - val_binary_accuracy: 0.8953 - val_f1_metric: 0.8960\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0225 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1580 - val_binary_accuracy: 0.9341 - val_f1_metric: 0.9316\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0175 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1709 - val_binary_accuracy: 0.9264 - val_f1_metric: 0.9269\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0170 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1861 - val_binary_accuracy: 0.9147 - val_f1_metric: 0.9185\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0263 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1688 - val_binary_accuracy: 0.9186 - val_f1_metric: 0.9209\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0174 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.2070 - val_binary_accuracy: 0.9031 - val_f1_metric: 0.9047\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0276 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1933 - val_binary_accuracy: 0.9264 - val_f1_metric: 0.9269\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0280 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1810 - val_binary_accuracy: 0.9147 - val_f1_metric: 0.9158\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0150 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1787 - val_binary_accuracy: 0.9109 - val_f1_metric: 0.9108\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0279 - binary_accuracy: 0.9953 - f1_metric: 0.995 - 0s 171ms/step - loss: 0.0279 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1598 - val_binary_accuracy: 0.9419 - val_f1_metric: 0.9431\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0167 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1884 - val_binary_accuracy: 0.9109 - val_f1_metric: 0.9094\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0198 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1452 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9380\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0243 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1579 - val_binary_accuracy: 0.9341 - val_f1_metric: 0.9357\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0152 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1433 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9394\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0139 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1645 - val_binary_accuracy: 0.9225 - val_f1_metric: 0.9259\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0238 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1492 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9367\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0110 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1370 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9354\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0197 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1439 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9380\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0115 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1252 - val_binary_accuracy: 0.9574 - val_f1_metric: 0.9566\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0206 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1433 - val_binary_accuracy: 0.9341 - val_f1_metric: 0.9316\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0100 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1460 - val_binary_accuracy: 0.9264 - val_f1_metric: 0.9242\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0098 - binary_accuracy: 1.0000 - f1_metric: 1.000 - 0s 178ms/step - loss: 0.0098 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9457 - val_f1_metric: 0.9468\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0218 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1414 - val_binary_accuracy: 0.9341 - val_f1_metric: 0.9343\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0123 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9419 - val_f1_metric: 0.9391\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0106 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1321 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9380\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0111 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.1478 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9394\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0239 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0926 - val_binary_accuracy: 0.9651 - val_f1_metric: 0.9626\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0189 - binary_accuracy: 0.9906 - f1_metric: 0.990 - 0s 170ms/step - loss: 0.0189 - binary_accuracy: 0.9906 - f1_metric: 0.9906 - val_loss: 0.1170 - val_binary_accuracy: 0.9535 - val_f1_metric: 0.9529\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0168 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1249 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9354\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0208 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1181 - val_binary_accuracy: 0.9380 - val_f1_metric: 0.9380\n",
      "Epoch 203/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0182 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1226 - val_binary_accuracy: 0.9419 - val_f1_metric: 0.9418\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0137 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1102 - val_binary_accuracy: 0.9496 - val_f1_metric: 0.9465\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0149 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0910 - val_binary_accuracy: 0.9535 - val_f1_metric: 0.9529\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0160 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1290 - val_binary_accuracy: 0.9341 - val_f1_metric: 0.9330\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0123 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1027 - val_binary_accuracy: 0.9496 - val_f1_metric: 0.9492\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0171 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0993 - val_binary_accuracy: 0.9612 - val_f1_metric: 0.9603\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0212 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0943 - val_binary_accuracy: 0.9574 - val_f1_metric: 0.9566\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0138 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0902 - val_binary_accuracy: 0.9612 - val_f1_metric: 0.9616\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0150 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.1033 - val_binary_accuracy: 0.9496 - val_f1_metric: 0.9478\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0154 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0761 - val_binary_accuracy: 0.9651 - val_f1_metric: 0.9667\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0075 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0712 - val_binary_accuracy: 0.9612 - val_f1_metric: 0.9616\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0107 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0792 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9677\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0058 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0745 - val_binary_accuracy: 0.9729 - val_f1_metric: 0.9727\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0108 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0719 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9704\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0063 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0749 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9690\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0082 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0796 - val_binary_accuracy: 0.9612 - val_f1_metric: 0.9630\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0072 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0790 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9704\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0124 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0672 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9677\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0105 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0712 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9704\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0121 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0825 - val_binary_accuracy: 0.9651 - val_f1_metric: 0.9626\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0082 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0700 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9690\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0074 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0743 - val_binary_accuracy: 0.9651 - val_f1_metric: 0.9667\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0099 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0636 - val_binary_accuracy: 0.9729 - val_f1_metric: 0.9714\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0151 - binary_accuracy: 0.9953 - f1_metric: 0.9953 - val_loss: 0.0750 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9690\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0147 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0625 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9690\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0080 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0503 - val_binary_accuracy: 0.9767 - val_f1_metric: 0.9778\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0057 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0599 - val_binary_accuracy: 0.9729 - val_f1_metric: 0.9741\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0082 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0555 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9704\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0073 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0534 - val_binary_accuracy: 0.9767 - val_f1_metric: 0.9778\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0047 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0496 - val_binary_accuracy: 0.9767 - val_f1_metric: 0.9778\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0076 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0530 - val_binary_accuracy: 0.9767 - val_f1_metric: 0.9764\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0076 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0484 - val_binary_accuracy: 0.9767 - val_f1_metric: 0.9764\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0087 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0547 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9875\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0066 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0576 - val_binary_accuracy: 0.9767 - val_f1_metric: 0.9764\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0072 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0538 - val_binary_accuracy: 0.9690 - val_f1_metric: 0.9677\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0060 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0470 - val_binary_accuracy: 0.9806 - val_f1_metric: 0.9815\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0059 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0368 - val_binary_accuracy: 0.9845 - val_f1_metric: 0.9852\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0053 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0387 - val_binary_accuracy: 0.9767 - val_f1_metric: 0.9764\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0057 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0434 - val_binary_accuracy: 0.9845 - val_f1_metric: 0.9838\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0059 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0403 - val_binary_accuracy: 0.9845 - val_f1_metric: 0.9825\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0046 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0346 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0040 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0403 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9875\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0044 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0372 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9889\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0040 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0376 - val_binary_accuracy: 0.9845 - val_f1_metric: 0.9838\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0051 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0256 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0066 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0383 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9889\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0052 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0325 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9926\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0044 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0379 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9875\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0030 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0322 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9875\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0035 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0258 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0043 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0283 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0037 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0257 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9949\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0033 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0275 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0041 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0293 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9889\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0043 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0441 - val_binary_accuracy: 0.9845 - val_f1_metric: 0.9838\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0040 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0248 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9889\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0031 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0222 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0243 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9926\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0031 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0272 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0026 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0245 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9926\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0029 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0211 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9926\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0031 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0216 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0200 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9912\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0033 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0178 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0034 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0190 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0029 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0242 - val_binary_accuracy: 0.9884 - val_f1_metric: 0.9889\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0026 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0142 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0027 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0164 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0042 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0218 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9926\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0034 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0138 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0019 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0140 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0032 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0209 - val_binary_accuracy: 0.9922 - val_f1_metric: 0.9926\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0023 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0157 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0165 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0147 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0121 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0138 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0133 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0104 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0107 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 9.9965e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0111 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0122 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0113 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0102 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0101 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 9.2065e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 8.4770e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 9.5923e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 6.7571e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 8.6082e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0244 - val_binary_accuracy: 0.9845 - val_f1_metric: 0.9852\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0026 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 9.8702e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9961 - val_f1_metric: 0.9963\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 7.6771e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 7.5579e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 9.1402e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 5.8985e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 7.4543e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 9.7884e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 9.7428e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 6.5841e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 5.2571e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 8.7090e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 6.8128e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 7.7944e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.8986e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 7.3736e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.1294e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 8.0400e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 9.4881e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 5.4147e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.6213e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step - loss: 5.6814e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6.9813e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 5.6008e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.8521e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 4.0736e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 3.3509e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 3.9843e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 6.5557e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 7.3806e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.0003e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.6818e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.5840e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.8708e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.5284e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.8411e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.5001e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.6915e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.9664e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.9697e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.6723e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.5760e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.6454e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.9376e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.9708e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.6659e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.2170e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.2750e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.6185e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.6660e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.8211e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.8684e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7863e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.2646e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.3555e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.9911e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0698e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.2757e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.5277e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.8292e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.5311e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.1036e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.3277e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5748e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.0744e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4896e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 3.0556e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.1993e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.5015e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.4928e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.4472e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0263e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.7742e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.4531e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.9376e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.2924e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.9574e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1798e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.3035e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9409e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 9.2399e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.4867e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 9.7311e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7371e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 8.9626e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2258e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 8.3952e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1848e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.0201e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6970e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.5449e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6141e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 1.4793e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7244e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.4449e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.5002e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 2.0516e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.4979e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.1503e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8345e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.3849e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4696e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 9.9279e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7667e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.4754e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8462e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.2372e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4042e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 6.2965e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9604e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 6.8034e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6593e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 5.6255e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5759e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 8.8622e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5569e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 6.3039e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4199e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 5.6392e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2077e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 8.0141e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1067e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.0897e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0769e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.5358e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.2686e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.2410e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1884e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.5127e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.2503e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.1120e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9336e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.4523e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0291e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.0536e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.8940e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.8397e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.4211e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 5.5277e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.7848e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 4.0852e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.9547e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 8.2250e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.8230e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 9.7734e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.8363e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 3.5311e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.1559e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 4.6700e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.1232e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.2405e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4803e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4.4633e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.7608e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step - loss: 4.5498e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4065e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 5.8334e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3534e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 8.4217e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.4272e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 3.8072e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.9264e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.4923e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4006e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.7589e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0062e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 3.4298e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6352e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4.6665e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0568e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 3.3785e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6304e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.3288e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8860e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.4500e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.3513e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.2655e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1506e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.9053e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.2027e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.5922e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7437e-04 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 7.7181e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.2555e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 5.6307e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5404e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.3040e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.2520e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.8395e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6100e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.7863e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.3391e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6.2088e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5654e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.4929e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3085e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3.4327e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1258e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.1340e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5704e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 3.8875e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9347e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.1907e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7136e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.1250e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.0706e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3.9854e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8596e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.6754e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3434e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.9620e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0818e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.7423e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3792e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.0822e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1226e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.6386e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8206e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.3920e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3956e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.1818e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4499e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.9159e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.2385e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.5193e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.2252e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.5317e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0936e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.6154e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1676e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.9636e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4887e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.9712e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8756e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 2.7659e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0782e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.7680e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9149e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.5290e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8140e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.3973e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6756e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.9324e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8312e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.1737e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6403e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 9.1375e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8205e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 8.4548e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8946e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.0228e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7250e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.4489e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4792e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.6847e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7010e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.3660e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5924e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.3762e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6495e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.3083e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8394e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.9824e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8284e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.2373e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2773e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.4189e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2754e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.8246e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3158e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.5248e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1102e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.4675e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.9342e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.6821e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2743e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.0343e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2127e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.1754e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2128e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.3076e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.5126e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.3259e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.5782e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.6790e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.5943e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.6687e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0998e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.4031e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.8482e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.8084e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.1457e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 7.0700e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1863e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 3.4931e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.2746e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.1177e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3571e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.5016e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0896e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 9.4829e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0389e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.2845e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2760e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.4853e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.8534e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 7.7330e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.1026e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 480/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step - loss: 7.2462e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.1393e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 8.6984e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.1351e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 5.8742e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.4422e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 4.7182e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9085e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.1039e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5957e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 7.3968e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6225e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 5.3614e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.1519e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 9.7759e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.6655e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 4.6980e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1897e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.0220e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.3600e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 9.9255e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.7710e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.8293e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7842e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.3098e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.1536e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 8.0673e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.7012e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 4.4516e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.8916e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 7.5176e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0171e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 9.1104e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8347e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 9.1451e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.5885e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 4.1278e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.4200e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 9.7536e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.5899e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 9.3722e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.7997e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 5.1237e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2537e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 2.8818e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1211e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 4.8036e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7801e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.2258e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0355e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.4879e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2964e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.6465e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0677e-05 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.1424e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.3205e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 7.2216e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.7154e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 4.2104e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6195e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 3.8607e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6749e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 4.0455e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.9945e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.5146e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.1382e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 9.9170e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.4287e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 8.1953e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9584e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 3.1673e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7635e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 3.1072e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.2224e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2.9554e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3439e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.5731e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.5602e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2077e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.4715e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 7.2771e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.5828e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.4059e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9062e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 9.5362e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.0176e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 7.0205e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0445e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.7384e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1499e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.1803e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1808e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 4.7104e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.2428e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2.9346e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9286e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.7530e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0589e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.1898e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8893e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 3.9051e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0630e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 2.4972e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6689e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 4.1603e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1609e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 3.5902e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1328e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 2.7636e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4864e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.6051e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7465e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.2627e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8190e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.4131e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8592e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 3.5689e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3533e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 3.0921e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6144e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 9.6271e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.7415e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4.5691e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8507e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.6706e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9618e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.7979e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4578e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.7369e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3570e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.5154e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4171e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.1822e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1884e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.5306e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2688e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.3678e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1399e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.5727e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1279e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.5446e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.9915e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.6149e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0729e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.5604e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.0608e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.2262e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4684e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.8434e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9350e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.3037e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0179e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.6796e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3178e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.4766e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0595e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 558/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 207ms/step - loss: 2.4162e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0803e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.8151e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1306e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.3400e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.9703e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0636e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1676e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 3.1997e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3533e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.5638e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.3010e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.7714e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.7835e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 4.7979e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8636e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.4692e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.8733e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 6.5284e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.6376e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.6312e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.2126e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 9.0081e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3189e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.9478e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.7254e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 9.6660e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9723e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.1820e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.3070e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.7465e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6694e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1145e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.6377e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 9.4523e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.8152e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 8.9237e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6693e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 7.2087e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.3664e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 8.0691e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6713e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.7689e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4236e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 2.8328e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0574e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 7.9172e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.7406e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.5547e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.7406e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.5356e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.7829e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.0835e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.1941e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 9.0081e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.6469e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.2641e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.3367e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5.0832e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.7730e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.0397e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8838e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 6.6183e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.8535e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.0082e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.4654e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.8563e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.7750e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 7.5236e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6687e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 4.5321e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9802e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 5.5275e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1650e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.1874e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.4192e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 5.5331e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.0310e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 8.6257e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2944e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 7.9959e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5531e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 6.9500e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9340e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.0273e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.2191e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 6.4440e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.8350e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 4.0992e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8693e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4.1386e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1208e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.1808e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9617e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 3.2051e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6799e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 4.1329e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8805e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.8968e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6172e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 3.9530e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9221e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 4.6334e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7558e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.4742e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9914e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.8959e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0977e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 6.4777e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2713e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.7082e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0747e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.2151e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6819e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.0204e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.5118e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.0281e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.2654e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.0549e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.9188e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 7.0794e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7815e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.6710e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4304e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.3034e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6449e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 4.2623e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4231e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 3.1039e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6126e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.0196e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3399e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.1471e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5710e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 9.3733e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3261e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 3.8124e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6403e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 3.2220e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2568e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.5688e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3030e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.5913e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2060e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 3.4638e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0489e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 3.0196e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1644e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.8387e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0165e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.0965e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0812e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 7.0680e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2845e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 3.1039e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7493e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 215ms/step - loss: 2.1255e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1320e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 2.6878e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0535e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.4508e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0211e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.2436e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0211e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.5754e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.1783e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.2033e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0304e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.8180e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.6107e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.5472e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1736e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.5949e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0258e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 6.2359e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5201e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.8837e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1967e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.9175e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2568e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.6588e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1135e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.3214e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.9341e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.4620e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0673e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.5801e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.7328e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.6588e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.9176e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.9231e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.2245e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.7938e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.0694e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.0645e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0073e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.3889e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.9935e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 5.7185e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.5479e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.1311e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.0397e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.2933e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.6238e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.0065e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.2080e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.0290e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0529e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.1246e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.0694e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.0410e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.5149e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 5.3419e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.2377e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.6147e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.7625e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.1021e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.5314e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1246e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.8384e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.9287e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.8714e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 7.5349e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7030e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.7609e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.1618e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.1471e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.9605e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 2.0018e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.0232e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 9.4468e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.0232e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.0470e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7294e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.3351e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9683e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 3.4413e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2522e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.3617e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.3334e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.7047e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.0694e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 6.0729e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.9902e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 6.9557e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.4984e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.2371e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.4984e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.4676e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.1750e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 3.1545e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.2971e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 7.9848e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.4192e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.2659e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.5281e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.2659e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.7888e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.0796e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5578e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 7.2029e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.8714e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 4.0823e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.4060e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.3270e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.3598e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.6316e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.2839e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.3419e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5908e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.6813e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1123e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.6372e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5908e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 8.8282e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5908e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.3608e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0364e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.7375e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3268e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.6026e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1123e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.0909e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5578e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 5.1170e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1123e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 7.2538e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1123e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.1865e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 8.3221e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1123e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.3448e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.3301e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.0290e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 7.0851e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3268e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 5.0608e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6799e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 4.7796e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.9736e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 4.1048e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1882e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.0355e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6502e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.8517e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5710e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 4.5001e-05 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.1839e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.6650e-04 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.9341e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 714/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 294ms/step - loss: 1.6082e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2872e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.0515e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.1024e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 9.5592e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0442e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.0605e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.3796e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 8.5187e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.9935e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.9015e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.1321e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.9830e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.8384e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 9.1094e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.4845e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0529e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 6.7477e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.2839e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.4620e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.7459e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.2933e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.6997e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 9.5030e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.1915e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 7.4225e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6370e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.0515e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.6832e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.0796e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 8.8731e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0198e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 8.4964e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8053e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 8.7720e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8053e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.2090e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.4357e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7713e-07 - binary_accuracy: 1.0000 - f1_metric: 1.000 - 0s 175ms/step - loss: 1.7713e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.5281e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 5.7918e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8977e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.2764e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0364e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 5.7466e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.7591e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 7.8161e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0661e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5.8480e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8515e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.0927e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.7591e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 6.5790e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0198e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.8275e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.4357e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 5.9042e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.2971e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.0290e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0661e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 6.7645e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.0495e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 8.1535e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.7426e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.7918e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 7.5349e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.8350e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 9.7841e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3730e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.1752e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.8812e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5.0045e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5578e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.1696e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.8669e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5116e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 8.0410e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5116e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 4.1048e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6040e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.1930e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6040e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.7881e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6040e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 5.7355e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5578e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 5.3700e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0661e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 4.7796e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5578e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5.9605e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.7888e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.2557e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6799e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.1170e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6040e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.4451e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5116e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.9456e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 6.8602e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 6.8039e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1882e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 5.6793e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9571e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.6324e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8647e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 8.3784e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5116e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2.8678e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1419e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.0515e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5116e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 7.8723e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2806e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 3.9362e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.9109e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6.0729e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.5116e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.8237e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3268e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.6316e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8185e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0290e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.0033e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 9.3343e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6799e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.4863e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.5875e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 3.0365e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 8.9407e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7096e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 5.0045e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6337e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 4.0486e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8185e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 7.1975e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0792e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4.3298e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6337e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 5.7918e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4951e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 5.5668e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0330e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 7.8723e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.5413e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 7.7036e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3565e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4.2173e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8482e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 792/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step - loss: 4.2735e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6337e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.8678e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3565e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.9924e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.2641e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 8.7158e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4951e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 7.9848e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.5413e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4.8921e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0792e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 8.2097e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.2641e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 8.2097e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3565e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.4301e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4951e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 9.3343e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1716e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 3.6550e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4951e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 3.1827e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.8515e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 4.5321e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1419e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.2146e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.3495e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8185e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.8799e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6337e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.2614e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1254e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.8725e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0330e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 9.2781e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5710e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.9605e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9868e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 6.6915e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.1716e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2.6428e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.4027e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 5.3982e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7558e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 4.4422e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8020e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 7.9848e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5248e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 3.3738e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9406e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.5866e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8482e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.8480e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9868e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.3327e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.5413e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 9.8404e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6634e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 4.3860e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7558e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.9362e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7096e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 7.9848e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9868e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 4.5547e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5248e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 3.9924e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5710e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.9681e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2475e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.5304e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7096e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 4.1611e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7558e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 8.2097e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8482e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.7553e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1551e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 7.8723e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2937e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 4.1048e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8020e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.9240e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7096e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.9802e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8944e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.7553e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7558e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1086e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.1089e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.1640e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.8647e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 3.7112e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8482e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 5.1170e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9406e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 7.3100e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2013e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.6109e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5248e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 3.9924e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.7790e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 8.6033e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.7558e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.6991e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6634e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.3158e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.9868e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.1170e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3399e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4.5547e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3928e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 4.7796e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2475e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.0365e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.3169e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.3495e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.7790e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.4742e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.5866e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.2090e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.0330e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 5.7355e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.6337e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.4797e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.1882e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 7.9848e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.5710e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 5.1732e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.5745e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8482e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 8.8844e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2475e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.9118e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.4620e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 6.6915e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0165e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2652e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2475e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 8.4346e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.8549e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.0122e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.8549e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.0009e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6172e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.7553e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0165e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.5304e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 870/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 216ms/step - loss: 3.0365e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.2492e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.9681e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.7790e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.9118e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.7790e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2.3055e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.6869e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 2.9802e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.3495e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9308e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 5.4544e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.1930e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.3169e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.5745e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3928e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.1808e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.8549e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.7994e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3928e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.5304e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.4058e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.5304e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.7432e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0826e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 8.4346e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.9681e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0826e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.1246e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.5745e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.6428e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.8556e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0826e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 3.9924e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.2492e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 6.5790e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0165e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.3495e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.9681e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0826e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 9.2781e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4324e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.4551e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.8171e-07 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 4.5208e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.2971e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.4348e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6634e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.9924e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2937e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.0122e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2937e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 9.5592e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2937e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.3495e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2937e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1930e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0627e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.6550e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 8.3169e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0243e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3928e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 6.0167e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0165e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.2371e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.7994e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 6.5790e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.2614e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9308e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 4.8921e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 8.4346e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 8.9969e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9308e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.4058e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 5.0608e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.9118e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.8549e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 6.1854e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9308e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.0365e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9308e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 5.0608e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2371e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5.9605e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.1808e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 4.3298e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 8.3783e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3.8237e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2933e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.6109e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 7.8723e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.4620e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.2933e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.0122e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6964e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 8.4346e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3928e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.4058e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.8549e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.0927e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.0122e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 7.8723e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.4687e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.1808e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0826e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.7553e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.2933e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.0826e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.5304e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.4301e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.3495e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.1368e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.9802e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 948/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 200ms/step - loss: 5.6793e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 8.4346e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 6.1854e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-10 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.5351e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.2410e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.2146e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 6.7477e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.6307e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6964e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.5182e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6964e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 7.8723e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2.5697e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.3268e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6.6406e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.0198e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 7.8723e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0165e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 4.4985e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2937e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.4742e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.3738e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 5.5446e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6.7477e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 7.8723e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 7.8723e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6964e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.1808e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 8.0410e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 8.4346e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.1246e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.0684e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.2933e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 9.5592e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 6.7477e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 6.1854e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.8482e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 5.1732e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 8.4346e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.4742e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.3862e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.2492e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 4.4985e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6.5114e-07 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.4291e-06 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 2.7355e-06 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.6172e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 4.3860e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 9.7031e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1246e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.2013e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.1808e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 1.0627e-08 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4.3860e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3928e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 7.4787e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 7.3928e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.3495e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.0067e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.4058e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 6.9308e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 6.6352e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.6205e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.9118e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 6.1854e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.2933e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.3738e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.5182e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.9362e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.2371e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.7723e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.1930e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 4.1585e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.8556e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 2.3103e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 9.5592e-09 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.6964e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.2492e-08 - binary_accuracy: 1.0000 - f1_metric: 1.0000 - val_loss: 3.2344e-09 - val_binary_accuracy: 1.0000 - val_f1_metric: 1.0000\n",
      "Model training finished.\n",
      "Train loss: 0.0, train accuracy: 1.0 and train f1_score: 1.0\n",
      "Evaluating model performance...\n",
      "Test loss: 0.0, test accuracy: 1.0 and test f1_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "run_experiment(nn_model_full, tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               train_dataset, val_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06c40694",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_model_full = create_bnn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d6dfcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 5s 5s/step - loss: 2272.1023 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2460.9697 - val_accuracy: 0.4535 - val_f1_metric: 0.4603\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4595.7695 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 3638.0073 - val_accuracy: 0.4845 - val_f1_metric: 0.4832\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2059.5466 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2502.9431 - val_accuracy: 0.4845 - val_f1_metric: 0.4805\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 579.2787 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2863.6294 - val_accuracy: 0.5233 - val_f1_metric: 0.5215\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1114.0372 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2175.9846 - val_accuracy: 0.4651 - val_f1_metric: 0.4687\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1553.3831 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 2146.6443 - val_accuracy: 0.4884 - val_f1_metric: 0.4855\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2186.8416 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 2539.6953 - val_accuracy: 0.5194 - val_f1_metric: 0.5152\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5200.3579 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2614.9363 - val_accuracy: 0.4806 - val_f1_metric: 0.4795\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3931.2544 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 3036.3936 - val_accuracy: 0.4767 - val_f1_metric: 0.4825\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 3691.3320 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 2339.4802 - val_accuracy: 0.5233 - val_f1_metric: 0.5162\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 729.8938 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2895.5491 - val_accuracy: 0.4574 - val_f1_metric: 0.4680\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2966.0273 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 3680.7578 - val_accuracy: 0.4884 - val_f1_metric: 0.4936\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2916.5222 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2098.4893 - val_accuracy: 0.5310 - val_f1_metric: 0.5222\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 431.1451 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2953.9749 - val_accuracy: 0.5969 - val_f1_metric: 0.5933\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2125.4124 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2924.3652 - val_accuracy: 0.4651 - val_f1_metric: 0.4660\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5030.1230 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1651.1018 - val_accuracy: 0.5543 - val_f1_metric: 0.5606\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 7572.7603 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 3299.6201 - val_accuracy: 0.4767 - val_f1_metric: 0.4785\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2843.8423 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1500.0486 - val_accuracy: 0.5155 - val_f1_metric: 0.5155\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 523.2149 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 3723.9087 - val_accuracy: 0.5310 - val_f1_metric: 0.5290\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 6333.5576 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 5018.8237 - val_accuracy: 0.4574 - val_f1_metric: 0.4559\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1444.6066 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1250.0355 - val_accuracy: 0.5039 - val_f1_metric: 0.5030\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 920.4370 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1238.0920 - val_accuracy: 0.4845 - val_f1_metric: 0.4899\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2161.5908 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 3111.9468 - val_accuracy: 0.5155 - val_f1_metric: 0.5101\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1371.1627 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 2540.4768 - val_accuracy: 0.4767 - val_f1_metric: 0.4744\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 976.6622 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 3277.5374 - val_accuracy: 0.5233 - val_f1_metric: 0.5215\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 4028.0964 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1964.3169 - val_accuracy: 0.5349 - val_f1_metric: 0.5313\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 9769.0479 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 2328.2769 - val_accuracy: 0.4845 - val_f1_metric: 0.4899\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 13255.2422 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 2392.3650 - val_accuracy: 0.5039 - val_f1_metric: 0.5044\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 296.2501 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1227.4169 - val_accuracy: 0.5155 - val_f1_metric: 0.5195\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2655.2158 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1115.3199 - val_accuracy: 0.5233 - val_f1_metric: 0.5229\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 5961.8843 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 2712.8037 - val_accuracy: 0.5078 - val_f1_metric: 0.5081\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 711.8144 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 3367.4321 - val_accuracy: 0.5233 - val_f1_metric: 0.5215\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 303.7040 - accuracy: 0.3443 - f1_metric: 0.3443 - val_loss: 1473.3199 - val_accuracy: 0.4612 - val_f1_metric: 0.4636\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 7103.1562 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1304.5979 - val_accuracy: 0.4922 - val_f1_metric: 0.4919\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 844.4356 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 3046.1140 - val_accuracy: 0.4884 - val_f1_metric: 0.4882\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 6354.5664 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 2265.7524 - val_accuracy: 0.4690 - val_f1_metric: 0.4657\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1532.0061 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2550.4370 - val_accuracy: 0.4845 - val_f1_metric: 0.4832\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1243.3182 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 3528.6362 - val_accuracy: 0.4922 - val_f1_metric: 0.4946\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 845.1349 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 3518.3403 - val_accuracy: 0.5155 - val_f1_metric: 0.5236\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1367.5745 - accuracy: 0.5047 - f1_metric: 0.5047 - val_loss: 2380.9036 - val_accuracy: 0.5504 - val_f1_metric: 0.5515\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2678.5051 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2402.2229 - val_accuracy: 0.4574 - val_f1_metric: 0.4559\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 3853.6348 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1018.6124 - val_accuracy: 0.5194 - val_f1_metric: 0.5178\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2881.6677 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2371.9370 - val_accuracy: 0.4457 - val_f1_metric: 0.4421\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2510.5386 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1498.1304 - val_accuracy: 0.4884 - val_f1_metric: 0.4869\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1237.6781 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1995.2053 - val_accuracy: 0.4961 - val_f1_metric: 0.4929\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2958.9106 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 3527.2568 - val_accuracy: 0.4729 - val_f1_metric: 0.4707\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2573.7896 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2067.9277 - val_accuracy: 0.4961 - val_f1_metric: 0.5037\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2348.9929 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 4686.3682 - val_accuracy: 0.4264 - val_f1_metric: 0.4236\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 4083.8130 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 2339.2739 - val_accuracy: 0.4884 - val_f1_metric: 0.4896\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 3748.1301 - accuracy: 0.4009 - f1_metric: 0.4009 - val_loss: 1627.1628 - val_accuracy: 0.5078 - val_f1_metric: 0.5081\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1907.7094 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 2548.4360 - val_accuracy: 0.5155 - val_f1_metric: 0.5155\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1579.1721 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2675.5305 - val_accuracy: 0.4845 - val_f1_metric: 0.4872\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 8795.5381 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1301.5004 - val_accuracy: 0.5078 - val_f1_metric: 0.5067\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1455.9271 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 964.5615 - val_accuracy: 0.5155 - val_f1_metric: 0.5168\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 6501.1147 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2762.9180 - val_accuracy: 0.5233 - val_f1_metric: 0.5229\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 819.7384 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1308.5427 - val_accuracy: 0.5000 - val_f1_metric: 0.5007\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 7304.6382 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 3144.3835 - val_accuracy: 0.5271 - val_f1_metric: 0.5293\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6759.3115 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 2110.4131 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2848.5425 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1216.7557 - val_accuracy: 0.4806 - val_f1_metric: 0.4741\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2277.2188 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2153.4319 - val_accuracy: 0.4690 - val_f1_metric: 0.4697\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 482.5636 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 2287.0107 - val_accuracy: 0.4729 - val_f1_metric: 0.4680\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 734.2879 - accuracy: 0.5896 - f1_metric: 0.5896 - val_loss: 2382.6943 - val_accuracy: 0.4961 - val_f1_metric: 0.4983\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 5489.9404 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1486.1587 - val_accuracy: 0.4845 - val_f1_metric: 0.4818\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1755.5161 - accuracy: 0.4009 - f1_metric: 0.4009 - val_loss: 4954.6299 - val_accuracy: 0.5581 - val_f1_metric: 0.5603\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1419.3955 - accuracy: 0.4104 - f1_metric: 0.4104 - val_loss: 3565.4492 - val_accuracy: 0.4496 - val_f1_metric: 0.4539\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1895.1669 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2550.9248 - val_accuracy: 0.4341 - val_f1_metric: 0.4377\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 490.4284 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 1324.2234 - val_accuracy: 0.4845 - val_f1_metric: 0.4859\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3316.2627 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2110.1699 - val_accuracy: 0.5039 - val_f1_metric: 0.5030\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 3720.1567 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 4516.0571 - val_accuracy: 0.5078 - val_f1_metric: 0.5054\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1149.1340 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1899.3259 - val_accuracy: 0.4884 - val_f1_metric: 0.4896\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6508.2148 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2186.7627 - val_accuracy: 0.4884 - val_f1_metric: 0.4815\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 420.9568 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1732.7726 - val_accuracy: 0.4612 - val_f1_metric: 0.4650\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 5165.0713 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2672.7556 - val_accuracy: 0.4845 - val_f1_metric: 0.4872\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 3780.5244 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 2580.1772 - val_accuracy: 0.4845 - val_f1_metric: 0.4926\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 559.8142 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 2897.6533 - val_accuracy: 0.5233 - val_f1_metric: 0.5189\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 266.0817 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 3539.9348 - val_accuracy: 0.5155 - val_f1_metric: 0.5209\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1515.8937 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1332.7061 - val_accuracy: 0.5194 - val_f1_metric: 0.5192\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1173.0383 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2608.6851 - val_accuracy: 0.5271 - val_f1_metric: 0.5212\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 8232.1025 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1385.1821 - val_accuracy: 0.5581 - val_f1_metric: 0.5576\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 775.3654 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1362.7517 - val_accuracy: 0.5078 - val_f1_metric: 0.5121\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2485.8511 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1866.2600 - val_accuracy: 0.5155 - val_f1_metric: 0.5114\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2261.5479 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1692.6752 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2104.1077 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2056.5557 - val_accuracy: 0.5078 - val_f1_metric: 0.5108\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 642.9843 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 2856.6772 - val_accuracy: 0.5155 - val_f1_metric: 0.5195\n",
      "Epoch 85/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 224ms/step - loss: 1073.0671 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2696.4448 - val_accuracy: 0.4806 - val_f1_metric: 0.4808\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 4611.4668 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1383.7632 - val_accuracy: 0.4806 - val_f1_metric: 0.4808\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 5641.1147 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 3289.6738 - val_accuracy: 0.4884 - val_f1_metric: 0.4869\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 513.7769 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2040.5148 - val_accuracy: 0.5000 - val_f1_metric: 0.5007\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 598.8425 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2328.4675 - val_accuracy: 0.5039 - val_f1_metric: 0.5044\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1852.0071 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 2314.0403 - val_accuracy: 0.5736 - val_f1_metric: 0.5751\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2497.9214 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1850.9703 - val_accuracy: 0.5426 - val_f1_metric: 0.5468\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 4610.7729 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2647.0569 - val_accuracy: 0.5000 - val_f1_metric: 0.5020\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2928.4971 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2031.3032 - val_accuracy: 0.5388 - val_f1_metric: 0.5431\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 665.3106 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2942.1497 - val_accuracy: 0.4535 - val_f1_metric: 0.4508\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2044.2488 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1707.0016 - val_accuracy: 0.5581 - val_f1_metric: 0.5576\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 68.5089 - accuracy: 0.6698 - f1_metric: 0.6698 - val_loss: 1441.3068 - val_accuracy: 0.4806 - val_f1_metric: 0.4848\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 619.9861 - accuracy: 0.3774 - f1_metric: 0.3774 - val_loss: 1482.6753 - val_accuracy: 0.5349 - val_f1_metric: 0.5354\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 576.2982 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 2201.5466 - val_accuracy: 0.4767 - val_f1_metric: 0.4663\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1784.6775 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2424.7683 - val_accuracy: 0.4574 - val_f1_metric: 0.4478\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 870.2784 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1112.6947 - val_accuracy: 0.4729 - val_f1_metric: 0.4761\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 4749.6084 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2249.3630 - val_accuracy: 0.4922 - val_f1_metric: 0.4933\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 2925.0903 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 3392.0046 - val_accuracy: 0.4767 - val_f1_metric: 0.4811\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 3623.1270 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2324.3560 - val_accuracy: 0.4496 - val_f1_metric: 0.4471\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2251.6794 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 3054.4619 - val_accuracy: 0.4651 - val_f1_metric: 0.4633\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1007.8714 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1280.0223 - val_accuracy: 0.5155 - val_f1_metric: 0.5141\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1460.5431 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1851.1517 - val_accuracy: 0.4961 - val_f1_metric: 0.4956\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1244.5652 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1945.3173 - val_accuracy: 0.4341 - val_f1_metric: 0.4364\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1087.1691 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2331.7129 - val_accuracy: 0.5155 - val_f1_metric: 0.5195\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 4386.0254 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2221.0071 - val_accuracy: 0.5116 - val_f1_metric: 0.5145\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1888.1104 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2839.7090 - val_accuracy: 0.4884 - val_f1_metric: 0.4855\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2116.5173 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 3146.4570 - val_accuracy: 0.4729 - val_f1_metric: 0.4721\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 171.2053 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 1558.8998 - val_accuracy: 0.5194 - val_f1_metric: 0.5178\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1166.3252 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1505.1244 - val_accuracy: 0.5465 - val_f1_metric: 0.5465\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1488.6024 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1848.4050 - val_accuracy: 0.5465 - val_f1_metric: 0.5492\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 4229.5879 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1641.6954 - val_accuracy: 0.5078 - val_f1_metric: 0.5162\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3771.8433 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 6009.4194 - val_accuracy: 0.4961 - val_f1_metric: 0.4970\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1295.5769 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 2030.7661 - val_accuracy: 0.5116 - val_f1_metric: 0.5104\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 606.8144 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 833.4414 - val_accuracy: 0.4457 - val_f1_metric: 0.4515\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 3564.2263 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2011.5118 - val_accuracy: 0.5155 - val_f1_metric: 0.5182\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 606.4037 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1614.2483 - val_accuracy: 0.5000 - val_f1_metric: 0.4993\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2716.3145 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2363.8406 - val_accuracy: 0.4341 - val_f1_metric: 0.4377\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3989.7390 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 3923.3755 - val_accuracy: 0.4961 - val_f1_metric: 0.5010\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1390.3854 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1978.0896 - val_accuracy: 0.5271 - val_f1_metric: 0.5266\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1368.2385 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2311.1431 - val_accuracy: 0.5504 - val_f1_metric: 0.5502\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 251.1545 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2331.3408 - val_accuracy: 0.5233 - val_f1_metric: 0.5323\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 995.1176 - accuracy: 0.3774 - f1_metric: 0.3774 - val_loss: 1762.9882 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 5472.1572 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 3272.7588 - val_accuracy: 0.4922 - val_f1_metric: 0.4933\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3240.3362 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 2738.0410 - val_accuracy: 0.4806 - val_f1_metric: 0.4835\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 3648.4998 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 4755.2559 - val_accuracy: 0.4729 - val_f1_metric: 0.4707\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2967.6174 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 6337.8413 - val_accuracy: 0.4729 - val_f1_metric: 0.4734\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3156.4924 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 3013.4329 - val_accuracy: 0.5891 - val_f1_metric: 0.5832\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3528.1108 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 4095.6565 - val_accuracy: 0.5349 - val_f1_metric: 0.5354\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 943.2847 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2546.7686 - val_accuracy: 0.5155 - val_f1_metric: 0.5114\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 785.8278 - accuracy: 0.5896 - f1_metric: 0.5896 - val_loss: 2311.6270 - val_accuracy: 0.5310 - val_f1_metric: 0.5303\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3331.7041 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2045.8772 - val_accuracy: 0.4729 - val_f1_metric: 0.4842\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 385.6641 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1823.8185 - val_accuracy: 0.4574 - val_f1_metric: 0.4586\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1983.5715 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2424.7874 - val_accuracy: 0.5659 - val_f1_metric: 0.5636\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 741.3731 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1678.9460 - val_accuracy: 0.5310 - val_f1_metric: 0.5236\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 7346.0264 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1344.0973 - val_accuracy: 0.4767 - val_f1_metric: 0.4758\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 4213.8545 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2324.9026 - val_accuracy: 0.5194 - val_f1_metric: 0.5138\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1023.9008 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2566.7563 - val_accuracy: 0.4651 - val_f1_metric: 0.4687\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1310.5752 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1581.3584 - val_accuracy: 0.4419 - val_f1_metric: 0.4451\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 336.0567 - accuracy: 0.3774 - f1_metric: 0.3774 - val_loss: 2877.9233 - val_accuracy: 0.4845 - val_f1_metric: 0.4818\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4146.6660 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2728.1614 - val_accuracy: 0.5620 - val_f1_metric: 0.5653\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 666.4030 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1770.1748 - val_accuracy: 0.4690 - val_f1_metric: 0.4684\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1745.4263 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 1536.5457 - val_accuracy: 0.5233 - val_f1_metric: 0.5229\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2344.7002 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 2454.6323 - val_accuracy: 0.5310 - val_f1_metric: 0.5316\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 368.6625 - accuracy: 0.3962 - f1_metric: 0.3962 - val_loss: 2262.7136 - val_accuracy: 0.4884 - val_f1_metric: 0.4963\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 410.2896 - accuracy: 0.6085 - f1_metric: 0.6085 - val_loss: 2046.6139 - val_accuracy: 0.4612 - val_f1_metric: 0.4596\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2099.5042 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2854.7642 - val_accuracy: 0.5349 - val_f1_metric: 0.5380\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2223.3528 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2500.8662 - val_accuracy: 0.5116 - val_f1_metric: 0.5131\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2638.7048 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2322.7537 - val_accuracy: 0.5388 - val_f1_metric: 0.5418\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 302.1834 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1737.3331 - val_accuracy: 0.5116 - val_f1_metric: 0.5077\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1540.8772 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2388.3494 - val_accuracy: 0.5426 - val_f1_metric: 0.5428\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1556.4924 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1496.5558 - val_accuracy: 0.5698 - val_f1_metric: 0.5620\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 5511.1260 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1854.0688 - val_accuracy: 0.5116 - val_f1_metric: 0.5131\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2323.4089 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2429.5242 - val_accuracy: 0.4690 - val_f1_metric: 0.4697\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2531.5176 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2819.0017 - val_accuracy: 0.4845 - val_f1_metric: 0.4872\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 7315.5664 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 2804.4021 - val_accuracy: 0.5659 - val_f1_metric: 0.5677\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 529.1827 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 2483.7935 - val_accuracy: 0.5271 - val_f1_metric: 0.5306\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 270.2749 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1505.9617 - val_accuracy: 0.5233 - val_f1_metric: 0.5189\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2060.6521 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1975.5782 - val_accuracy: 0.5233 - val_f1_metric: 0.5283\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1334.4349 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1377.1964 - val_accuracy: 0.4729 - val_f1_metric: 0.4788\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 232.1995 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2416.5852 - val_accuracy: 0.5116 - val_f1_metric: 0.5145\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 180.1115 - accuracy: 0.6274 - f1_metric: 0.6274 - val_loss: 1666.1993 - val_accuracy: 0.5349 - val_f1_metric: 0.5340\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 731.0505 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1955.4341 - val_accuracy: 0.4922 - val_f1_metric: 0.4879\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 5294.3960 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2744.4724 - val_accuracy: 0.5194 - val_f1_metric: 0.5273\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 312.7453 - accuracy: 0.6321 - f1_metric: 0.6321 - val_loss: 4094.8203 - val_accuracy: 0.4729 - val_f1_metric: 0.4761\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step - loss: 1227.7815 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1725.0211 - val_accuracy: 0.5349 - val_f1_metric: 0.5273\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1318.7330 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 3455.0723 - val_accuracy: 0.5000 - val_f1_metric: 0.4980\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2426.5735 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 2440.5034 - val_accuracy: 0.5310 - val_f1_metric: 0.5222\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1005.0695 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1654.2745 - val_accuracy: 0.4806 - val_f1_metric: 0.4822\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 835.0187 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1145.8112 - val_accuracy: 0.4574 - val_f1_metric: 0.4572\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2459.5161 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1978.3507 - val_accuracy: 0.5078 - val_f1_metric: 0.5094\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 187.7969 - accuracy: 0.3585 - f1_metric: 0.3585 - val_loss: 2846.5176 - val_accuracy: 0.5698 - val_f1_metric: 0.5606\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3603.5881 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1307.6833 - val_accuracy: 0.5271 - val_f1_metric: 0.5333\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2175.2910 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 3052.7395 - val_accuracy: 0.5388 - val_f1_metric: 0.5350\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 847.1620 - accuracy: 0.5000 - f1_metric: 0.5000 - val_loss: 2229.4778 - val_accuracy: 0.5155 - val_f1_metric: 0.5101\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3573.5195 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1157.9326 - val_accuracy: 0.5465 - val_f1_metric: 0.5492\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 749.3353 - accuracy: 0.4009 - f1_metric: 0.4009 - val_loss: 1726.2941 - val_accuracy: 0.5736 - val_f1_metric: 0.5724\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 7091.0674 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 3808.3923 - val_accuracy: 0.5581 - val_f1_metric: 0.5576\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2006.3949 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 967.3936 - val_accuracy: 0.4612 - val_f1_metric: 0.4623\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1980.7551 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1967.7327 - val_accuracy: 0.5233 - val_f1_metric: 0.5175\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3862.2378 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 2025.8815 - val_accuracy: 0.4806 - val_f1_metric: 0.4781\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 559.7751 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1629.9152 - val_accuracy: 0.4496 - val_f1_metric: 0.4485\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3037.8833 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2127.0752 - val_accuracy: 0.5194 - val_f1_metric: 0.5232\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 452.3680 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1165.5226 - val_accuracy: 0.5349 - val_f1_metric: 0.5300\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2094.3616 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 2091.8997 - val_accuracy: 0.4806 - val_f1_metric: 0.4822\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2768.6775 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2011.8179 - val_accuracy: 0.4922 - val_f1_metric: 0.4852\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4075.2290 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1707.0884 - val_accuracy: 0.5465 - val_f1_metric: 0.5397\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 1191.0179 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 2504.9402 - val_accuracy: 0.5465 - val_f1_metric: 0.5451\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 4656.5635 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2944.9512 - val_accuracy: 0.4690 - val_f1_metric: 0.4684\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 718.3345 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 2471.4380 - val_accuracy: 0.4612 - val_f1_metric: 0.4636\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 650.0607 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1664.6602 - val_accuracy: 0.5426 - val_f1_metric: 0.5414\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1010.6799 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 3284.3215 - val_accuracy: 0.4651 - val_f1_metric: 0.4633\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 4077.1858 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1539.3359 - val_accuracy: 0.5039 - val_f1_metric: 0.5125\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2804.5776 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 3506.2886 - val_accuracy: 0.4574 - val_f1_metric: 0.4613\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2377.8240 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2059.5508 - val_accuracy: 0.5271 - val_f1_metric: 0.5226\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 389.7292 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2463.2791 - val_accuracy: 0.4961 - val_f1_metric: 0.5064\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1019.6556 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2889.4531 - val_accuracy: 0.4922 - val_f1_metric: 0.4919\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 7326.6509 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1425.5427 - val_accuracy: 0.5465 - val_f1_metric: 0.5465\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3173.6113 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2955.5701 - val_accuracy: 0.5349 - val_f1_metric: 0.5354\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1784.7449 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2646.8169 - val_accuracy: 0.5039 - val_f1_metric: 0.5030\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2731.4668 - accuracy: 0.4104 - f1_metric: 0.4104 - val_loss: 2349.0015 - val_accuracy: 0.5233 - val_f1_metric: 0.5175\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2265.2407 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1543.2175 - val_accuracy: 0.5000 - val_f1_metric: 0.4953\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 89.4672 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 1655.2904 - val_accuracy: 0.4729 - val_f1_metric: 0.4747\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 271.6600 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 3858.7466 - val_accuracy: 0.5349 - val_f1_metric: 0.5367\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 546.9457 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1161.7738 - val_accuracy: 0.5426 - val_f1_metric: 0.5428\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 865.1253 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 3193.8228 - val_accuracy: 0.4457 - val_f1_metric: 0.4407\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1171.1270 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 4375.5181 - val_accuracy: 0.5659 - val_f1_metric: 0.5717\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3325.1113 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1964.9058 - val_accuracy: 0.4612 - val_f1_metric: 0.4650\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 383.5439 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2598.6807 - val_accuracy: 0.5349 - val_f1_metric: 0.5313\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 3629.7073 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 1364.7185 - val_accuracy: 0.4961 - val_f1_metric: 0.4916\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 8522.9189 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2349.0891 - val_accuracy: 0.5000 - val_f1_metric: 0.5020\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 663.8398 - accuracy: 0.6038 - f1_metric: 0.6038 - val_loss: 2097.7793 - val_accuracy: 0.4651 - val_f1_metric: 0.4700\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 652.9562 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1669.5635 - val_accuracy: 0.5194 - val_f1_metric: 0.5192\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1358.1514 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2402.7046 - val_accuracy: 0.5271 - val_f1_metric: 0.5226\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2651.2412 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2910.8337 - val_accuracy: 0.5039 - val_f1_metric: 0.4990\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 365.8703 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2231.1748 - val_accuracy: 0.5426 - val_f1_metric: 0.5455\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2081.7314 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1767.0876 - val_accuracy: 0.4574 - val_f1_metric: 0.4519\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3009.5154 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 2439.3982 - val_accuracy: 0.5504 - val_f1_metric: 0.5556\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 908.0602 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 2506.4707 - val_accuracy: 0.5930 - val_f1_metric: 0.5936\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1653.7955 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1488.3546 - val_accuracy: 0.4651 - val_f1_metric: 0.4687\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1935.7026 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1879.3931 - val_accuracy: 0.4651 - val_f1_metric: 0.4633\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 550.5596 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1909.4286 - val_accuracy: 0.5116 - val_f1_metric: 0.5158\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 6126.3584 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1573.1885 - val_accuracy: 0.5039 - val_f1_metric: 0.5030\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1176.8011 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 3767.0198 - val_accuracy: 0.4845 - val_f1_metric: 0.4859\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2121.5566 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 3785.2483 - val_accuracy: 0.4535 - val_f1_metric: 0.4562\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 181.1928 - accuracy: 0.6179 - f1_metric: 0.6179 - val_loss: 2683.4910 - val_accuracy: 0.5194 - val_f1_metric: 0.5178\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1175.0251 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2531.4597 - val_accuracy: 0.4535 - val_f1_metric: 0.4535\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1872.3329 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 3126.6531 - val_accuracy: 0.4419 - val_f1_metric: 0.4397\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2364.1614 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2268.0820 - val_accuracy: 0.4806 - val_f1_metric: 0.4754\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 256.9705 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1524.6775 - val_accuracy: 0.5969 - val_f1_metric: 0.5987\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 950.5462 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 890.0605 - val_accuracy: 0.5620 - val_f1_metric: 0.5694\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3490.8135 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 4546.8228 - val_accuracy: 0.4961 - val_f1_metric: 0.4970\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 894.6774 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1703.2799 - val_accuracy: 0.5581 - val_f1_metric: 0.5630\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2976.4504 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 3849.7424 - val_accuracy: 0.4884 - val_f1_metric: 0.4842\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3052.6787 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1757.9922 - val_accuracy: 0.5194 - val_f1_metric: 0.5178\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1136.0643 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 3723.8838 - val_accuracy: 0.5349 - val_f1_metric: 0.5340\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1279.3514 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1324.2151 - val_accuracy: 0.4729 - val_f1_metric: 0.4734\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1308.3740 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 3761.2986 - val_accuracy: 0.5620 - val_f1_metric: 0.5626\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 3226.4167 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 3227.0886 - val_accuracy: 0.4651 - val_f1_metric: 0.4620\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 7392.6997 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 1550.4921 - val_accuracy: 0.4729 - val_f1_metric: 0.4747\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1613.5244 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1953.2726 - val_accuracy: 0.5814 - val_f1_metric: 0.5798\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2690.7466 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 2514.1670 - val_accuracy: 0.5078 - val_f1_metric: 0.5000\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1831.8616 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 2045.2655 - val_accuracy: 0.5039 - val_f1_metric: 0.5003\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3480.5857 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2572.9138 - val_accuracy: 0.4767 - val_f1_metric: 0.4838\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 878.9385 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 3727.9473 - val_accuracy: 0.4574 - val_f1_metric: 0.4505\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2220.8679 - accuracy: 0.5849 - f1_metric: 0.5849 - val_loss: 3394.9905 - val_accuracy: 0.5000 - val_f1_metric: 0.5061\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 123.5032 - accuracy: 0.3868 - f1_metric: 0.3868 - val_loss: 1694.6423 - val_accuracy: 0.4457 - val_f1_metric: 0.4448\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1331.2786 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1272.3314 - val_accuracy: 0.4884 - val_f1_metric: 0.4882\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3051.5571 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2960.7004 - val_accuracy: 0.4884 - val_f1_metric: 0.4801\n",
      "Epoch 253/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 193ms/step - loss: 352.4849 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1139.0420 - val_accuracy: 0.5775 - val_f1_metric: 0.5721\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 6050.2642 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1279.5398 - val_accuracy: 0.4690 - val_f1_metric: 0.4643\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 122.5360 - accuracy: 0.6462 - f1_metric: 0.6462 - val_loss: 1401.7593 - val_accuracy: 0.5349 - val_f1_metric: 0.5340\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2279.3828 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1831.7773 - val_accuracy: 0.4302 - val_f1_metric: 0.4300\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2032.3859 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1154.0750 - val_accuracy: 0.5000 - val_f1_metric: 0.5047\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 897.7886 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 3183.0156 - val_accuracy: 0.4806 - val_f1_metric: 0.4889\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 72.9909 - accuracy: 0.6604 - f1_metric: 0.6604 - val_loss: 3227.4192 - val_accuracy: 0.4574 - val_f1_metric: 0.4599\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 666.3837 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 2529.6436 - val_accuracy: 0.5581 - val_f1_metric: 0.5603\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1121.5913 - accuracy: 0.5849 - f1_metric: 0.5849 - val_loss: 1533.1465 - val_accuracy: 0.5426 - val_f1_metric: 0.5535\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1892.0143 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1566.5625 - val_accuracy: 0.5233 - val_f1_metric: 0.5202\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2034.5912 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1766.3153 - val_accuracy: 0.4767 - val_f1_metric: 0.4744\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3873.5779 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1556.3810 - val_accuracy: 0.5000 - val_f1_metric: 0.5007\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 629.4409 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1300.2012 - val_accuracy: 0.5000 - val_f1_metric: 0.5020\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2897.7974 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1005.6964 - val_accuracy: 0.4767 - val_f1_metric: 0.4704\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1814.5455 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 2455.7686 - val_accuracy: 0.5155 - val_f1_metric: 0.5155\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 428.1450 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 3279.8320 - val_accuracy: 0.4961 - val_f1_metric: 0.4943\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3683.8306 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1185.3223 - val_accuracy: 0.4574 - val_f1_metric: 0.4626\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 3153.7974 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1386.1182 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 7569.0596 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2391.1538 - val_accuracy: 0.4884 - val_f1_metric: 0.4896\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 880.1706 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1731.0527 - val_accuracy: 0.4767 - val_f1_metric: 0.4758\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 200.4130 - accuracy: 0.6274 - f1_metric: 0.6274 - val_loss: 2465.3906 - val_accuracy: 0.5504 - val_f1_metric: 0.5502\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1931.0842 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2154.4839 - val_accuracy: 0.4884 - val_f1_metric: 0.4963\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1862.7908 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2012.5978 - val_accuracy: 0.4690 - val_f1_metric: 0.4710\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2714.4028 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 3472.6763 - val_accuracy: 0.4884 - val_f1_metric: 0.4909\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5200.0928 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 822.4718 - val_accuracy: 0.5000 - val_f1_metric: 0.4980\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1529.5951 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1502.0223 - val_accuracy: 0.5039 - val_f1_metric: 0.5057\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 4502.2197 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2848.0840 - val_accuracy: 0.4729 - val_f1_metric: 0.4667\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2032.6320 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1828.8706 - val_accuracy: 0.5194 - val_f1_metric: 0.5192\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1990.4567 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 2219.1304 - val_accuracy: 0.5155 - val_f1_metric: 0.5074\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 8149.4824 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1669.2227 - val_accuracy: 0.4961 - val_f1_metric: 0.4929\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 209.6241 - accuracy: 0.6462 - f1_metric: 0.6462 - val_loss: 3646.1777 - val_accuracy: 0.4690 - val_f1_metric: 0.4684\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 4277.8184 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1393.8411 - val_accuracy: 0.5388 - val_f1_metric: 0.5418\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2371.1377 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1637.8922 - val_accuracy: 0.5116 - val_f1_metric: 0.5104\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1577.8317 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1739.5281 - val_accuracy: 0.4651 - val_f1_metric: 0.4660\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3721.5815 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 2666.1719 - val_accuracy: 0.5155 - val_f1_metric: 0.5182\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1604.4133 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1674.4366 - val_accuracy: 0.4535 - val_f1_metric: 0.4535\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2840.7339 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1679.9509 - val_accuracy: 0.4651 - val_f1_metric: 0.4660\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2335.5916 - accuracy: 0.5943 - f1_metric: 0.5943 - val_loss: 1378.2417 - val_accuracy: 0.4961 - val_f1_metric: 0.4956\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 700.2411 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2948.9551 - val_accuracy: 0.4806 - val_f1_metric: 0.4822\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1431.3020 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1552.2510 - val_accuracy: 0.4961 - val_f1_metric: 0.4943\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1540.5312 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 3100.0164 - val_accuracy: 0.4922 - val_f1_metric: 0.4892\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 492.4211 - accuracy: 0.3868 - f1_metric: 0.3868 - val_loss: 2128.4714 - val_accuracy: 0.5039 - val_f1_metric: 0.5044\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1287.0951 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1368.9845 - val_accuracy: 0.5039 - val_f1_metric: 0.5030\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 621.4946 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 3069.1599 - val_accuracy: 0.5116 - val_f1_metric: 0.5158\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2095.6775 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1383.8430 - val_accuracy: 0.5349 - val_f1_metric: 0.5367\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 794.6606 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1354.3185 - val_accuracy: 0.4651 - val_f1_metric: 0.4687\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 253.6726 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1151.0104 - val_accuracy: 0.4922 - val_f1_metric: 0.4892\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 7268.1675 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2589.2993 - val_accuracy: 0.4729 - val_f1_metric: 0.4761\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 4938.2612 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2899.7668 - val_accuracy: 0.4186 - val_f1_metric: 0.4229\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1310.4781 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2320.6245 - val_accuracy: 0.4884 - val_f1_metric: 0.4842\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1344.3352 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 3335.9775 - val_accuracy: 0.5155 - val_f1_metric: 0.5141\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1882.5137 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1072.2139 - val_accuracy: 0.5233 - val_f1_metric: 0.5256\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2321.4797 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 1256.5571 - val_accuracy: 0.5155 - val_f1_metric: 0.5155\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1409.2322 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 2024.9143 - val_accuracy: 0.4651 - val_f1_metric: 0.4687\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1952.6780 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1606.4547 - val_accuracy: 0.5194 - val_f1_metric: 0.5219\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 512.4557 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 2135.9580 - val_accuracy: 0.4457 - val_f1_metric: 0.4529\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 8138.6147 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1793.6945 - val_accuracy: 0.5116 - val_f1_metric: 0.5145\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2725.8982 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1861.8805 - val_accuracy: 0.4690 - val_f1_metric: 0.4684\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1392.7694 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1772.5388 - val_accuracy: 0.5426 - val_f1_metric: 0.5401\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3361.4690 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2042.7301 - val_accuracy: 0.4302 - val_f1_metric: 0.4259\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2824.9585 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1223.2815 - val_accuracy: 0.5426 - val_f1_metric: 0.5441\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1512.5729 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2184.3367 - val_accuracy: 0.4651 - val_f1_metric: 0.4700\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3202.8201 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2094.0420 - val_accuracy: 0.5504 - val_f1_metric: 0.5488\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 306.8228 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1899.1780 - val_accuracy: 0.5465 - val_f1_metric: 0.5465\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2699.9929 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1398.6449 - val_accuracy: 0.4961 - val_f1_metric: 0.4929\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 539.0237 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 1092.6233 - val_accuracy: 0.5233 - val_f1_metric: 0.5175\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1081.7041 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2339.0757 - val_accuracy: 0.5271 - val_f1_metric: 0.5320\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1127.1566 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2121.4817 - val_accuracy: 0.5233 - val_f1_metric: 0.5202\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2157.3584 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 901.2643 - val_accuracy: 0.4884 - val_f1_metric: 0.4855\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 6294.1304 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2923.3684 - val_accuracy: 0.5233 - val_f1_metric: 0.5242\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1034.1007 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1613.1312 - val_accuracy: 0.5504 - val_f1_metric: 0.5542\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 648.1943 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1890.0278 - val_accuracy: 0.4922 - val_f1_metric: 0.4919\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1388.8038 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2150.9719 - val_accuracy: 0.5388 - val_f1_metric: 0.5391\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 11148.8770 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2685.8906 - val_accuracy: 0.4690 - val_f1_metric: 0.4724\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5896.9009 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 1078.3932 - val_accuracy: 0.5000 - val_f1_metric: 0.4993\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 4561.9844 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1286.0292 - val_accuracy: 0.5814 - val_f1_metric: 0.5852\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1809.5084 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2020.7401 - val_accuracy: 0.4922 - val_f1_metric: 0.4933\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2551.6699 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2599.6301 - val_accuracy: 0.4690 - val_f1_metric: 0.4724\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 3807.2590 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2272.0488 - val_accuracy: 0.4729 - val_f1_metric: 0.4694\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 281.7934 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2955.3748 - val_accuracy: 0.5000 - val_f1_metric: 0.4980\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 6677.8457 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1413.8313 - val_accuracy: 0.4961 - val_f1_metric: 0.4983\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3249.2327 - accuracy: 0.5849 - f1_metric: 0.5849 - val_loss: 895.5939 - val_accuracy: 0.4690 - val_f1_metric: 0.4684\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1711.6940 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1342.0349 - val_accuracy: 0.5233 - val_f1_metric: 0.5189\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1731.5140 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1852.7632 - val_accuracy: 0.5620 - val_f1_metric: 0.5572\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 195ms/step - loss: 1265.9984 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 2448.1479 - val_accuracy: 0.4535 - val_f1_metric: 0.4562\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 5186.1069 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 3355.9255 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 995.5316 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 2350.1292 - val_accuracy: 0.5116 - val_f1_metric: 0.5091\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 905.7946 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 3014.2344 - val_accuracy: 0.4961 - val_f1_metric: 0.4970\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3475.5566 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2870.2239 - val_accuracy: 0.4690 - val_f1_metric: 0.4657\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 4849.9580 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 805.6877 - val_accuracy: 0.5271 - val_f1_metric: 0.5306\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2952.8547 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1340.5830 - val_accuracy: 0.5310 - val_f1_metric: 0.5330\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1584.4674 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2269.3821 - val_accuracy: 0.5814 - val_f1_metric: 0.5852\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1847.7271 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2630.1182 - val_accuracy: 0.4690 - val_f1_metric: 0.4737\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1209.8983 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2022.8748 - val_accuracy: 0.4690 - val_f1_metric: 0.4616\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4247.5688 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 3370.1570 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 131.0418 - accuracy: 0.4057 - f1_metric: 0.4057 - val_loss: 1233.7085 - val_accuracy: 0.4884 - val_f1_metric: 0.4882\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 984.7428 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2311.9089 - val_accuracy: 0.5349 - val_f1_metric: 0.5313\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 769.1743 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 976.3505 - val_accuracy: 0.4961 - val_f1_metric: 0.5051\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 108.5559 - accuracy: 0.5849 - f1_metric: 0.5849 - val_loss: 1262.7675 - val_accuracy: 0.4729 - val_f1_metric: 0.4761\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2059.5720 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1315.2526 - val_accuracy: 0.4302 - val_f1_metric: 0.4219\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 517.6338 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 1384.9270 - val_accuracy: 0.5000 - val_f1_metric: 0.4939\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2537.3655 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 3387.4463 - val_accuracy: 0.4806 - val_f1_metric: 0.4822\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1893.9786 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2321.6313 - val_accuracy: 0.4690 - val_f1_metric: 0.4603\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1681.5189 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2020.8295 - val_accuracy: 0.5775 - val_f1_metric: 0.5721\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 728.9363 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1816.2112 - val_accuracy: 0.5039 - val_f1_metric: 0.5044\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1624.7977 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1341.3407 - val_accuracy: 0.5310 - val_f1_metric: 0.5411\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 7447.8042 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1791.8323 - val_accuracy: 0.4690 - val_f1_metric: 0.4724\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2269.4871 - accuracy: 0.5000 - f1_metric: 0.5000 - val_loss: 1007.4326 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1567.1812 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2039.8854 - val_accuracy: 0.5000 - val_f1_metric: 0.5047\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 209.4850 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 2032.7357 - val_accuracy: 0.4845 - val_f1_metric: 0.4859\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 371.4963 - accuracy: 0.3632 - f1_metric: 0.3632 - val_loss: 1819.6895 - val_accuracy: 0.5233 - val_f1_metric: 0.5283\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 73.3814 - accuracy: 0.5991 - f1_metric: 0.5991 - val_loss: 1737.8588 - val_accuracy: 0.4961 - val_f1_metric: 0.4997\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 425.4843 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1094.6127 - val_accuracy: 0.5078 - val_f1_metric: 0.5121\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2197.3203 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2585.7654 - val_accuracy: 0.4729 - val_f1_metric: 0.4801\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 595.6437 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2407.8052 - val_accuracy: 0.5233 - val_f1_metric: 0.5269\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 403.3248 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1963.1434 - val_accuracy: 0.4845 - val_f1_metric: 0.4845\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 222.0368 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1876.4257 - val_accuracy: 0.4419 - val_f1_metric: 0.4397\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 258.4341 - accuracy: 0.3821 - f1_metric: 0.3821 - val_loss: 1189.0377 - val_accuracy: 0.5388 - val_f1_metric: 0.5404\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2020.5182 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1302.5078 - val_accuracy: 0.4457 - val_f1_metric: 0.4475\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1006.7669 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1646.6863 - val_accuracy: 0.5233 - val_f1_metric: 0.5242\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 2786.8450 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1355.0529 - val_accuracy: 0.4612 - val_f1_metric: 0.4569\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3521.5347 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1209.1049 - val_accuracy: 0.4806 - val_f1_metric: 0.4848\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2770.9719 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1075.4496 - val_accuracy: 0.5233 - val_f1_metric: 0.5189\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1909.5999 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2096.5195 - val_accuracy: 0.5155 - val_f1_metric: 0.5061\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 707.1403 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2163.0303 - val_accuracy: 0.4535 - val_f1_metric: 0.4535\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 3065.5786 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1519.4880 - val_accuracy: 0.4690 - val_f1_metric: 0.4764\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2868.9102 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1167.8506 - val_accuracy: 0.5388 - val_f1_metric: 0.5364\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 6978.4766 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2042.9060 - val_accuracy: 0.4535 - val_f1_metric: 0.4495\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 855.9155 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1449.6267 - val_accuracy: 0.5310 - val_f1_metric: 0.5316\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 4039.4749 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 850.5192 - val_accuracy: 0.5155 - val_f1_metric: 0.5141\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 728.2204 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1968.2343 - val_accuracy: 0.5426 - val_f1_metric: 0.5468\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1463.2959 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1579.9692 - val_accuracy: 0.5465 - val_f1_metric: 0.5532\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 318.4228 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2926.5503 - val_accuracy: 0.4496 - val_f1_metric: 0.4512\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5003.4194 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1259.9791 - val_accuracy: 0.4961 - val_f1_metric: 0.4943\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1895.2285 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1759.8634 - val_accuracy: 0.5349 - val_f1_metric: 0.5394\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 716.2446 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1625.0769 - val_accuracy: 0.5155 - val_f1_metric: 0.5222\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1596.6510 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 1432.0184 - val_accuracy: 0.4535 - val_f1_metric: 0.4576\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 2465.4846 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1375.2014 - val_accuracy: 0.5000 - val_f1_metric: 0.4993\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 3870.1575 - accuracy: 0.5000 - f1_metric: 0.5000 - val_loss: 2885.4897 - val_accuracy: 0.4612 - val_f1_metric: 0.4623\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1847.8531 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2122.1438 - val_accuracy: 0.4574 - val_f1_metric: 0.4532\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 196.6278 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2093.7637 - val_accuracy: 0.5504 - val_f1_metric: 0.5582\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 5543.4780 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2180.3005 - val_accuracy: 0.5620 - val_f1_metric: 0.5545\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5398.0615 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 2665.8818 - val_accuracy: 0.4806 - val_f1_metric: 0.4795\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2246.4231 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1395.8821 - val_accuracy: 0.5233 - val_f1_metric: 0.5256\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2830.2532 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1774.1672 - val_accuracy: 0.5504 - val_f1_metric: 0.5475\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1965.7328 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1157.9724 - val_accuracy: 0.4806 - val_f1_metric: 0.4741\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1374.1316 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 2664.7664 - val_accuracy: 0.5310 - val_f1_metric: 0.5397\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 985.4761 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 2506.3843 - val_accuracy: 0.4535 - val_f1_metric: 0.4495\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 902.3824 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1375.7418 - val_accuracy: 0.5581 - val_f1_metric: 0.5562\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 973.4180 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2247.5996 - val_accuracy: 0.4574 - val_f1_metric: 0.4559\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 646.1664 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1229.7639 - val_accuracy: 0.4884 - val_f1_metric: 0.4815\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1545.9307 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1696.6162 - val_accuracy: 0.4264 - val_f1_metric: 0.4290\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1368.6823 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1251.1368 - val_accuracy: 0.4961 - val_f1_metric: 0.4970\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 4550.2656 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1626.5356 - val_accuracy: 0.5271 - val_f1_metric: 0.5253\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3664.5208 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 2073.6204 - val_accuracy: 0.5116 - val_f1_metric: 0.5158\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 3364.7036 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1675.1416 - val_accuracy: 0.5426 - val_f1_metric: 0.5441\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1495.1240 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 2145.3494 - val_accuracy: 0.5349 - val_f1_metric: 0.5367\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 356.0885 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1393.1904 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2474.5342 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 921.0578 - val_accuracy: 0.4845 - val_f1_metric: 0.4872\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 4747.1982 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 1263.1677 - val_accuracy: 0.4961 - val_f1_metric: 0.4997\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 499.9079 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 2167.1216 - val_accuracy: 0.5465 - val_f1_metric: 0.5478\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5854.1445 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1321.8496 - val_accuracy: 0.5388 - val_f1_metric: 0.5364\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1705.2233 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1804.7067 - val_accuracy: 0.5233 - val_f1_metric: 0.5229\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2320.3542 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2139.0532 - val_accuracy: 0.4922 - val_f1_metric: 0.4879\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1565.0356 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1629.4719 - val_accuracy: 0.4612 - val_f1_metric: 0.4663\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1375.5680 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 975.1016 - val_accuracy: 0.5271 - val_f1_metric: 0.5306\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2554.8042 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1770.8356 - val_accuracy: 0.5000 - val_f1_metric: 0.5007\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1692.0284 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 3504.6152 - val_accuracy: 0.4612 - val_f1_metric: 0.4596\n",
      "Epoch 421/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step - loss: 2248.4634 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1810.2573 - val_accuracy: 0.4496 - val_f1_metric: 0.4498\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 268.9067 - accuracy: 0.3726 - f1_metric: 0.3726 - val_loss: 1952.2086 - val_accuracy: 0.4884 - val_f1_metric: 0.4828\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1189.9420 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2239.5425 - val_accuracy: 0.4922 - val_f1_metric: 0.4892\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1297.3849 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1756.4640 - val_accuracy: 0.4574 - val_f1_metric: 0.4572\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2658.9819 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 1877.6564 - val_accuracy: 0.4961 - val_f1_metric: 0.4956\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 155.7018 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1963.7897 - val_accuracy: 0.5271 - val_f1_metric: 0.5212\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 556.0441 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1347.9794 - val_accuracy: 0.4574 - val_f1_metric: 0.4626\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 66.4377 - accuracy: 0.6038 - f1_metric: 0.603 - 0s 179ms/step - loss: 66.4377 - accuracy: 0.6038 - f1_metric: 0.6038 - val_loss: 1140.8900 - val_accuracy: 0.5233 - val_f1_metric: 0.5256\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 331.5583 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1865.7223 - val_accuracy: 0.5310 - val_f1_metric: 0.5330\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 194.5553 - accuracy: 0.3538 - f1_metric: 0.3538 - val_loss: 1284.6864 - val_accuracy: 0.5310 - val_f1_metric: 0.5330\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 7066.0405 - accuracy: 0.4811 - f1_metric: 0.481 - 0s 174ms/step - loss: 7066.0405 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1648.1086 - val_accuracy: 0.4612 - val_f1_metric: 0.4609\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2098.4810 - accuracy: 0.4104 - f1_metric: 0.4104 - val_loss: 708.7533 - val_accuracy: 0.4961 - val_f1_metric: 0.4997\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 971.5521 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2571.6133 - val_accuracy: 0.4690 - val_f1_metric: 0.4697\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2060.4053 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1848.2334 - val_accuracy: 0.4806 - val_f1_metric: 0.4741\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1686.6053 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 3735.9541 - val_accuracy: 0.5039 - val_f1_metric: 0.5044\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1045.4821 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2279.8679 - val_accuracy: 0.5775 - val_f1_metric: 0.5774\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 204.5274 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1626.8501 - val_accuracy: 0.4922 - val_f1_metric: 0.4811\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1113.3026 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2509.8147 - val_accuracy: 0.4690 - val_f1_metric: 0.4630\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1096.0670 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 2315.9844 - val_accuracy: 0.4729 - val_f1_metric: 0.4694\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 746.0874 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2194.3875 - val_accuracy: 0.5078 - val_f1_metric: 0.5121\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 435.6497 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 2361.1719 - val_accuracy: 0.5426 - val_f1_metric: 0.5441\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1107.5845 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 990.4348 - val_accuracy: 0.5504 - val_f1_metric: 0.5475\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 778.0941 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1386.7086 - val_accuracy: 0.5155 - val_f1_metric: 0.5168\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1991.0122 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2754.4541 - val_accuracy: 0.5078 - val_f1_metric: 0.5108\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 435.6876 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 2167.5110 - val_accuracy: 0.5310 - val_f1_metric: 0.5303\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1926.9021 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 4094.1328 - val_accuracy: 0.4651 - val_f1_metric: 0.4700\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4237.8535 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2480.0496 - val_accuracy: 0.5116 - val_f1_metric: 0.5077\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1203.7723 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2578.0620 - val_accuracy: 0.4845 - val_f1_metric: 0.4859\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 381.2775 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1666.3868 - val_accuracy: 0.5078 - val_f1_metric: 0.5054\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2830.5366 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1437.4601 - val_accuracy: 0.4922 - val_f1_metric: 0.4946\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 538.3869 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2177.0176 - val_accuracy: 0.3915 - val_f1_metric: 0.3997\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 741.5729 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 998.4445 - val_accuracy: 0.4961 - val_f1_metric: 0.4943\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 285.7487 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1591.2306 - val_accuracy: 0.4729 - val_f1_metric: 0.4734\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 152.5130 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2373.5474 - val_accuracy: 0.5698 - val_f1_metric: 0.5646\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 189.9700 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 2563.5464 - val_accuracy: 0.5155 - val_f1_metric: 0.5195\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 350.1642 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 647.9174 - val_accuracy: 0.5271 - val_f1_metric: 0.5253\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1519.1494 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 677.5264 - val_accuracy: 0.5698 - val_f1_metric: 0.5646\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 179.5772 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 2248.1350 - val_accuracy: 0.5698 - val_f1_metric: 0.5714\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2222.1125 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2970.9958 - val_accuracy: 0.4574 - val_f1_metric: 0.4505\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1038.6422 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 1467.2051 - val_accuracy: 0.5078 - val_f1_metric: 0.5121\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2233.2700 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1878.0851 - val_accuracy: 0.4341 - val_f1_metric: 0.4283\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3422.2627 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 955.2474 - val_accuracy: 0.5465 - val_f1_metric: 0.5438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 703.8622 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 963.9897 - val_accuracy: 0.4651 - val_f1_metric: 0.4566\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 116.1888 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1895.2745 - val_accuracy: 0.5426 - val_f1_metric: 0.5428\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2372.5305 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2563.9902 - val_accuracy: 0.5271 - val_f1_metric: 0.5306\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 691.4079 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 2357.7017 - val_accuracy: 0.4922 - val_f1_metric: 0.4838\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 7045.3921 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 1281.0974 - val_accuracy: 0.5349 - val_f1_metric: 0.5273\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 450.8643 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1360.6437 - val_accuracy: 0.4535 - val_f1_metric: 0.4576\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1105.7050 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1684.6521 - val_accuracy: 0.4845 - val_f1_metric: 0.4872\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 211.7787 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1720.4155 - val_accuracy: 0.5388 - val_f1_metric: 0.5337\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1169.5251 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1009.8991 - val_accuracy: 0.5194 - val_f1_metric: 0.5219\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 744.2674 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1616.6727 - val_accuracy: 0.4651 - val_f1_metric: 0.4687\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2173.1501 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1562.7628 - val_accuracy: 0.5116 - val_f1_metric: 0.5104\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2474.9729 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 2138.0552 - val_accuracy: 0.5039 - val_f1_metric: 0.5057\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1051.0677 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1384.1099 - val_accuracy: 0.5310 - val_f1_metric: 0.5384\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 917.1730 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 1600.3788 - val_accuracy: 0.4264 - val_f1_metric: 0.4209\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 645.1102 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1292.3735 - val_accuracy: 0.4922 - val_f1_metric: 0.4987\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 9114.0127 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1562.7212 - val_accuracy: 0.5039 - val_f1_metric: 0.5003\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 856.4368 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1228.4823 - val_accuracy: 0.4612 - val_f1_metric: 0.4663\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 975.0912 - accuracy: 0.3915 - f1_metric: 0.3915 - val_loss: 1704.0527 - val_accuracy: 0.5543 - val_f1_metric: 0.5606\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 111.9737 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2788.2798 - val_accuracy: 0.5155 - val_f1_metric: 0.5195\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 720.0717 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 2306.9448 - val_accuracy: 0.5271 - val_f1_metric: 0.5320\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1496.6927 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2426.0618 - val_accuracy: 0.5078 - val_f1_metric: 0.5000\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1979.2854 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 2574.9829 - val_accuracy: 0.4806 - val_f1_metric: 0.4714\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1107.1182 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 1840.3357 - val_accuracy: 0.5078 - val_f1_metric: 0.5108\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1504.8060 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1047.7091 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2022.7367 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2572.3291 - val_accuracy: 0.4845 - val_f1_metric: 0.4778\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 879.1604 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1041.4061 - val_accuracy: 0.5504 - val_f1_metric: 0.5515\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1230.4658 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1509.7363 - val_accuracy: 0.5620 - val_f1_metric: 0.5667\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 337.6111 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1244.7401 - val_accuracy: 0.4496 - val_f1_metric: 0.4552\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2559.9583 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1008.1804 - val_accuracy: 0.5039 - val_f1_metric: 0.5071\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3238.0056 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1139.1647 - val_accuracy: 0.4380 - val_f1_metric: 0.4306\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2040.0425 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 976.6742 - val_accuracy: 0.5271 - val_f1_metric: 0.5266\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1792.3325 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1231.5889 - val_accuracy: 0.4690 - val_f1_metric: 0.4643\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 520.2767 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1973.0488 - val_accuracy: 0.4767 - val_f1_metric: 0.4744\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 999.1306 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1488.2557 - val_accuracy: 0.5426 - val_f1_metric: 0.5387\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1497.0104 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2227.2505 - val_accuracy: 0.4922 - val_f1_metric: 0.4919\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2277.3516 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2007.0270 - val_accuracy: 0.4496 - val_f1_metric: 0.4471\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 519.0707 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 843.4097 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3303.4856 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2472.0095 - val_accuracy: 0.5271 - val_f1_metric: 0.5212\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 350.3939 - accuracy: 0.5377 - f1_metric: 0.53 - 0s 174ms/step - loss: 350.3939 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1428.1255 - val_accuracy: 0.4457 - val_f1_metric: 0.4394\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 184.6108 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 2329.3430 - val_accuracy: 0.5116 - val_f1_metric: 0.5091\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 565.9403 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2526.8623 - val_accuracy: 0.4961 - val_f1_metric: 0.4970\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1247.3014 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 923.4204 - val_accuracy: 0.5155 - val_f1_metric: 0.5155\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 173ms/step - loss: 2505.7688 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1262.4299 - val_accuracy: 0.5194 - val_f1_metric: 0.5178\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 7703.6074 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1857.2792 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2656.3413 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 867.3848 - val_accuracy: 0.5194 - val_f1_metric: 0.5205\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1800.5068 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1202.2805 - val_accuracy: 0.5271 - val_f1_metric: 0.5226\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 6806.7563 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2419.1682 - val_accuracy: 0.5078 - val_f1_metric: 0.5121\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 592.5970 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1629.8680 - val_accuracy: 0.4496 - val_f1_metric: 0.4471\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 800.2679 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1331.3063 - val_accuracy: 0.4729 - val_f1_metric: 0.4747\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 423.6586 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1303.9722 - val_accuracy: 0.4341 - val_f1_metric: 0.4391\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 3027.5737 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1784.6943 - val_accuracy: 0.4729 - val_f1_metric: 0.4707\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 447.7571 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1933.4197 - val_accuracy: 0.4186 - val_f1_metric: 0.4175\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1767.9045 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1168.8459 - val_accuracy: 0.5930 - val_f1_metric: 0.5949\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1178.2267 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1442.5029 - val_accuracy: 0.5504 - val_f1_metric: 0.5475\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 971.8148 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2120.4072 - val_accuracy: 0.5078 - val_f1_metric: 0.5027\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2116.4150 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1122.5963 - val_accuracy: 0.4767 - val_f1_metric: 0.4717\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1693.3730 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 3207.3049 - val_accuracy: 0.5271 - val_f1_metric: 0.5266\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2118.3225 - accuracy: 0.5047 - f1_metric: 0.5047 - val_loss: 2147.6382 - val_accuracy: 0.4884 - val_f1_metric: 0.4923\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 399.6252 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1263.8651 - val_accuracy: 0.5388 - val_f1_metric: 0.5350\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1308.4338 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1650.3470 - val_accuracy: 0.5388 - val_f1_metric: 0.5458\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 263.6118 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1077.4686 - val_accuracy: 0.4922 - val_f1_metric: 0.4933\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2617.5295 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1747.0258 - val_accuracy: 0.5349 - val_f1_metric: 0.5327\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1983.7322 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1469.6771 - val_accuracy: 0.5543 - val_f1_metric: 0.5471\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3908.1150 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1809.5468 - val_accuracy: 0.5116 - val_f1_metric: 0.5131\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 758.3153 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1321.0251 - val_accuracy: 0.4535 - val_f1_metric: 0.4522\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 338.6193 - accuracy: 0.5849 - f1_metric: 0.5849 - val_loss: 1179.3739 - val_accuracy: 0.5736 - val_f1_metric: 0.5805\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1652.6486 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1780.9039 - val_accuracy: 0.4729 - val_f1_metric: 0.4707\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 609.8430 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 983.6851 - val_accuracy: 0.5155 - val_f1_metric: 0.5088\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1429.8424 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 3227.3396 - val_accuracy: 0.5039 - val_f1_metric: 0.5071\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1054.0195 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1863.9467 - val_accuracy: 0.5233 - val_f1_metric: 0.5148\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 986.7087 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1682.0198 - val_accuracy: 0.5349 - val_f1_metric: 0.5394\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 4453.9658 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2201.4993 - val_accuracy: 0.5388 - val_f1_metric: 0.5471\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1136.9713 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1418.8911 - val_accuracy: 0.4457 - val_f1_metric: 0.4475\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 3894.0801 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1349.9331 - val_accuracy: 0.5155 - val_f1_metric: 0.5088\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1468.0095 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 3059.8333 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 323.8403 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1333.7980 - val_accuracy: 0.5271 - val_f1_metric: 0.5253\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3219.8923 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 2372.6724 - val_accuracy: 0.4961 - val_f1_metric: 0.4983\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 500.9278 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1530.7063 - val_accuracy: 0.5930 - val_f1_metric: 0.5855\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1367.3219 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1774.5010 - val_accuracy: 0.5349 - val_f1_metric: 0.5300\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3984.9365 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2189.4751 - val_accuracy: 0.4922 - val_f1_metric: 0.4865\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 770.5191 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2803.9407 - val_accuracy: 0.4884 - val_f1_metric: 0.4882\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2608.2310 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1991.2913 - val_accuracy: 0.5155 - val_f1_metric: 0.5088\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1185.0376 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2902.9143 - val_accuracy: 0.5000 - val_f1_metric: 0.5088\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 3785.1160 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1751.8542 - val_accuracy: 0.5581 - val_f1_metric: 0.5535\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1448.8206 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1419.5927 - val_accuracy: 0.4574 - val_f1_metric: 0.4559\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1670.2065 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2212.5522 - val_accuracy: 0.4961 - val_f1_metric: 0.4916\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4215.9497 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2065.8276 - val_accuracy: 0.4690 - val_f1_metric: 0.4710\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2646.1318 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1220.8047 - val_accuracy: 0.5620 - val_f1_metric: 0.5626\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2297.5500 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 1809.4875 - val_accuracy: 0.4341 - val_f1_metric: 0.4431\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3755.2651 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 813.2289 - val_accuracy: 0.5388 - val_f1_metric: 0.5444\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 4395.3853 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 683.1407 - val_accuracy: 0.6085 - val_f1_metric: 0.6111\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2187.9067 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2949.2397 - val_accuracy: 0.5465 - val_f1_metric: 0.5465\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1690.2100 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1223.9490 - val_accuracy: 0.4457 - val_f1_metric: 0.4475\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 6696.0112 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 2512.8193 - val_accuracy: 0.5233 - val_f1_metric: 0.5202\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2741.5388 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1596.5552 - val_accuracy: 0.5543 - val_f1_metric: 0.5579\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5367.5586 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 1780.2559 - val_accuracy: 0.5078 - val_f1_metric: 0.5067\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2891.9250 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 750.1218 - val_accuracy: 0.4690 - val_f1_metric: 0.4724\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3292.5891 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2197.8457 - val_accuracy: 0.4651 - val_f1_metric: 0.4606\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1230.9229 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2127.4922 - val_accuracy: 0.4845 - val_f1_metric: 0.4859\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 93.1084 - accuracy: 0.6038 - f1_metric: 0.6038 - val_loss: 1188.1844 - val_accuracy: 0.4961 - val_f1_metric: 0.5024\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 232.0258 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 2709.3479 - val_accuracy: 0.3953 - val_f1_metric: 0.3926\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 824.4701 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1224.3829 - val_accuracy: 0.5388 - val_f1_metric: 0.5404\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 572.6635 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2202.2185 - val_accuracy: 0.4690 - val_f1_metric: 0.4684\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 622.8220 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1877.8286 - val_accuracy: 0.5543 - val_f1_metric: 0.5566\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1098.0972 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1712.6285 - val_accuracy: 0.5000 - val_f1_metric: 0.5034\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 567.7667 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1458.6902 - val_accuracy: 0.5000 - val_f1_metric: 0.4993\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 52.5752 - accuracy: 0.6038 - f1_metric: 0.6038 - val_loss: 1386.4926 - val_accuracy: 0.5194 - val_f1_metric: 0.5192\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1385.9110 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1269.6958 - val_accuracy: 0.4884 - val_f1_metric: 0.4842\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2554.1167 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2227.3342 - val_accuracy: 0.4922 - val_f1_metric: 0.4933\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1737.4938 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1361.4082 - val_accuracy: 0.4651 - val_f1_metric: 0.4673\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 280.9633 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1386.2488 - val_accuracy: 0.5233 - val_f1_metric: 0.5202\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4839.3599 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1446.2472 - val_accuracy: 0.5039 - val_f1_metric: 0.5098\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 510.0960 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1212.2791 - val_accuracy: 0.5039 - val_f1_metric: 0.5084\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 205.2714 - accuracy: 0.3774 - f1_metric: 0.3774 - val_loss: 1376.8507 - val_accuracy: 0.5698 - val_f1_metric: 0.5700\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 210.4712 - accuracy: 0.6651 - f1_metric: 0.6651 - val_loss: 1436.7300 - val_accuracy: 0.5271 - val_f1_metric: 0.5253\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1369.7943 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1309.7892 - val_accuracy: 0.5039 - val_f1_metric: 0.5044\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1677.6124 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1580.1689 - val_accuracy: 0.5736 - val_f1_metric: 0.5764\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2196.4863 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1685.6881 - val_accuracy: 0.5426 - val_f1_metric: 0.5414\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1426.5857 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1842.0273 - val_accuracy: 0.5078 - val_f1_metric: 0.5054\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 1045.7124 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1112.1010 - val_accuracy: 0.5310 - val_f1_metric: 0.5316\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1444.4396 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 3037.0786 - val_accuracy: 0.5078 - val_f1_metric: 0.5148\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3078.8191 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 969.9998 - val_accuracy: 0.4729 - val_f1_metric: 0.4734\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 343.0983 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1718.4259 - val_accuracy: 0.5310 - val_f1_metric: 0.5303\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 417.5159 - accuracy: 0.5896 - f1_metric: 0.5896 - val_loss: 1557.2960 - val_accuracy: 0.5078 - val_f1_metric: 0.5027\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1876.1093 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1271.4583 - val_accuracy: 0.5775 - val_f1_metric: 0.5788\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1108.5729 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1376.5071 - val_accuracy: 0.4767 - val_f1_metric: 0.4798\n",
      "Epoch 589/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step - loss: 1293.0009 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1725.7427 - val_accuracy: 0.5000 - val_f1_metric: 0.4953\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1907.1615 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 2838.0127 - val_accuracy: 0.4457 - val_f1_metric: 0.4488\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3361.3298 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2155.1323 - val_accuracy: 0.4806 - val_f1_metric: 0.4822\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3566.6809 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1171.8419 - val_accuracy: 0.4884 - val_f1_metric: 0.4949\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 9971.6328 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1355.8597 - val_accuracy: 0.5271 - val_f1_metric: 0.5293\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 579.1719 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1066.2921 - val_accuracy: 0.5039 - val_f1_metric: 0.5057\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 876.9775 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2165.5698 - val_accuracy: 0.5698 - val_f1_metric: 0.5700\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 809.9459 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1110.0771 - val_accuracy: 0.4729 - val_f1_metric: 0.4694\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 2874.9370 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 2140.3474 - val_accuracy: 0.5078 - val_f1_metric: 0.5067\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 203.1161 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 327.2435 - val_accuracy: 0.5388 - val_f1_metric: 0.5377\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 414.1184 - accuracy: 0.6368 - f1_metric: 0.6368 - val_loss: 2118.0474 - val_accuracy: 0.5000 - val_f1_metric: 0.4939\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 590.6068 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1658.7410 - val_accuracy: 0.5155 - val_f1_metric: 0.5209\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 551.5107 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1761.2452 - val_accuracy: 0.5194 - val_f1_metric: 0.5192\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2003.3660 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1929.9233 - val_accuracy: 0.5194 - val_f1_metric: 0.5098\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 452.9511 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1620.4705 - val_accuracy: 0.5349 - val_f1_metric: 0.5380\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1255.5225 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2572.6714 - val_accuracy: 0.4845 - val_f1_metric: 0.4872\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 155.3295 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 2718.0698 - val_accuracy: 0.4729 - val_f1_metric: 0.4680\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 540.3829 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2182.1882 - val_accuracy: 0.4690 - val_f1_metric: 0.4616\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 328.3579 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1232.3937 - val_accuracy: 0.4767 - val_f1_metric: 0.4798\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2291.7478 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1804.5460 - val_accuracy: 0.4535 - val_f1_metric: 0.4522\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 331.1627 - accuracy: 0.3962 - f1_metric: 0.3962 - val_loss: 1534.6118 - val_accuracy: 0.4884 - val_f1_metric: 0.4896\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1909.8204 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2771.9607 - val_accuracy: 0.4729 - val_f1_metric: 0.4747\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5871.5259 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1625.2944 - val_accuracy: 0.5155 - val_f1_metric: 0.5195\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3919.0444 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 696.4788 - val_accuracy: 0.4884 - val_f1_metric: 0.4896\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2820.1880 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1564.8475 - val_accuracy: 0.4845 - val_f1_metric: 0.4886\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1410.3593 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1737.2793 - val_accuracy: 0.5736 - val_f1_metric: 0.5764\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2077.4319 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1066.0920 - val_accuracy: 0.5698 - val_f1_metric: 0.5727\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2434.6670 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1156.7878 - val_accuracy: 0.5000 - val_f1_metric: 0.5047\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 601.5981 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1712.4374 - val_accuracy: 0.5388 - val_f1_metric: 0.5418\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1652.0756 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1524.2069 - val_accuracy: 0.5426 - val_f1_metric: 0.5428\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 313.3036 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 689.6785 - val_accuracy: 0.5349 - val_f1_metric: 0.5394\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3689.7935 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1207.7296 - val_accuracy: 0.5465 - val_f1_metric: 0.5478\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2153.5344 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1718.1749 - val_accuracy: 0.4341 - val_f1_metric: 0.4323\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 993.2546 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1683.8771 - val_accuracy: 0.4496 - val_f1_metric: 0.4485\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1918.3993 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1534.6639 - val_accuracy: 0.5388 - val_f1_metric: 0.5404\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 766.3367 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1470.3698 - val_accuracy: 0.5388 - val_f1_metric: 0.5418\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 876.5032 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2046.4891 - val_accuracy: 0.5000 - val_f1_metric: 0.4953\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 716.9811 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 2266.9680 - val_accuracy: 0.4961 - val_f1_metric: 0.4983\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1732.5127 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 2305.3892 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 305.4711 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1931.9692 - val_accuracy: 0.5155 - val_f1_metric: 0.5114\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2259.9463 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 959.5230 - val_accuracy: 0.4806 - val_f1_metric: 0.4795\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1199.3680 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1185.4285 - val_accuracy: 0.5504 - val_f1_metric: 0.5488\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 350.1291 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 976.4181 - val_accuracy: 0.4961 - val_f1_metric: 0.4889\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 861.4788 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1144.1331 - val_accuracy: 0.5581 - val_f1_metric: 0.5589\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2187.8079 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1854.7603 - val_accuracy: 0.5155 - val_f1_metric: 0.5128\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 500.8557 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2259.2656 - val_accuracy: 0.5194 - val_f1_metric: 0.5125\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 254.9783 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1495.3684 - val_accuracy: 0.5775 - val_f1_metric: 0.5842\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1926.9600 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 866.9803 - val_accuracy: 0.4651 - val_f1_metric: 0.4633\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1221.7155 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 2569.4954 - val_accuracy: 0.5078 - val_f1_metric: 0.5081\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3394.9441 - accuracy: 0.5991 - f1_metric: 0.5991 - val_loss: 1224.7522 - val_accuracy: 0.5543 - val_f1_metric: 0.5525\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1685.3064 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1001.2321 - val_accuracy: 0.4496 - val_f1_metric: 0.4431\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3445.7412 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1200.1525 - val_accuracy: 0.4147 - val_f1_metric: 0.4152\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 700.6810 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1219.9203 - val_accuracy: 0.4884 - val_f1_metric: 0.4828\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 649.9656 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 635.6324 - val_accuracy: 0.4884 - val_f1_metric: 0.4923\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1579.8916 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1501.6624 - val_accuracy: 0.4574 - val_f1_metric: 0.4613\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 496.9519 - accuracy: 0.3962 - f1_metric: 0.3962 - val_loss: 1274.6874 - val_accuracy: 0.5426 - val_f1_metric: 0.5428\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1739.8260 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1086.8594 - val_accuracy: 0.5271 - val_f1_metric: 0.5293\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2035.0758 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1115.3884 - val_accuracy: 0.5233 - val_f1_metric: 0.5215\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 519.4886 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 692.4279 - val_accuracy: 0.5698 - val_f1_metric: 0.5795\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2500.8367 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1651.8573 - val_accuracy: 0.5233 - val_f1_metric: 0.5256\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1518.7240 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 951.0316 - val_accuracy: 0.5310 - val_f1_metric: 0.5303\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1446.6752 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2084.3000 - val_accuracy: 0.4574 - val_f1_metric: 0.4599\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 490.4003 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1069.6573 - val_accuracy: 0.5116 - val_f1_metric: 0.5145\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1359.5399 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 1958.3080 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 677.1492 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 585.3564 - val_accuracy: 0.5233 - val_f1_metric: 0.5189\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3634.7544 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2867.8013 - val_accuracy: 0.4302 - val_f1_metric: 0.4286\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1142.2759 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1343.0720 - val_accuracy: 0.4457 - val_f1_metric: 0.4461\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 410.5019 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1436.2954 - val_accuracy: 0.5271 - val_f1_metric: 0.5266\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1162.4332 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1953.2314 - val_accuracy: 0.5426 - val_f1_metric: 0.5468\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1176.6097 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1278.8181 - val_accuracy: 0.5155 - val_f1_metric: 0.5155\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1897.5924 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1318.7679 - val_accuracy: 0.4109 - val_f1_metric: 0.4101\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 8845.2256 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1682.8684 - val_accuracy: 0.5465 - val_f1_metric: 0.5478\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 272.6885 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1283.0046 - val_accuracy: 0.5000 - val_f1_metric: 0.4926\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 694.2505 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1221.7671 - val_accuracy: 0.4961 - val_f1_metric: 0.4875\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 283.5262 - accuracy: 0.3774 - f1_metric: 0.3774 - val_loss: 1031.6776 - val_accuracy: 0.5039 - val_f1_metric: 0.5084\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1104.6034 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1498.9398 - val_accuracy: 0.5930 - val_f1_metric: 0.5949\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1059.4302 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 645.2639 - val_accuracy: 0.5504 - val_f1_metric: 0.5461\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3808.0486 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1478.5178 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 472.8862 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 2247.5481 - val_accuracy: 0.4690 - val_f1_metric: 0.4643\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 287.1318 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1787.5261 - val_accuracy: 0.4186 - val_f1_metric: 0.4067\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2262.6599 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 933.1198 - val_accuracy: 0.5039 - val_f1_metric: 0.5084\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 4290.4980 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 2019.8612 - val_accuracy: 0.4961 - val_f1_metric: 0.4916\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 500.8494 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2007.8575 - val_accuracy: 0.5465 - val_f1_metric: 0.5451\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3765.8542 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1670.5837 - val_accuracy: 0.5155 - val_f1_metric: 0.5155\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step - loss: 6792.8491 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1476.4624 - val_accuracy: 0.5620 - val_f1_metric: 0.5599\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1966.8884 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1344.9064 - val_accuracy: 0.5465 - val_f1_metric: 0.5411\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2999.8191 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1061.3481 - val_accuracy: 0.5310 - val_f1_metric: 0.5343\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1763.7886 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1450.3286 - val_accuracy: 0.4612 - val_f1_metric: 0.4636\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 542.1374 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 1675.3759 - val_accuracy: 0.5310 - val_f1_metric: 0.5303\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 823.2131 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1209.4102 - val_accuracy: 0.4380 - val_f1_metric: 0.4347\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 657.2597 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1090.1766 - val_accuracy: 0.4651 - val_f1_metric: 0.4660\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1525.1089 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1594.0599 - val_accuracy: 0.4922 - val_f1_metric: 0.4973\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 3649.6333 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 1173.5739 - val_accuracy: 0.4767 - val_f1_metric: 0.4731\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2223.7041 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1478.3359 - val_accuracy: 0.5000 - val_f1_metric: 0.5074\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 128.9148 - accuracy: 0.3679 - f1_metric: 0.3679 - val_loss: 2023.9993 - val_accuracy: 0.5039 - val_f1_metric: 0.5084\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 809.2964 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 842.7582 - val_accuracy: 0.4535 - val_f1_metric: 0.4522\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3315.9954 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1816.6604 - val_accuracy: 0.5116 - val_f1_metric: 0.5077\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1982.5826 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 3195.0378 - val_accuracy: 0.4767 - val_f1_metric: 0.4785\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1586.4919 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1992.2781 - val_accuracy: 0.4922 - val_f1_metric: 0.4838\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1774.6621 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 640.9626 - val_accuracy: 0.5116 - val_f1_metric: 0.5158\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 622.1827 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 974.0595 - val_accuracy: 0.5233 - val_f1_metric: 0.5323\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2550.6689 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1799.9274 - val_accuracy: 0.4845 - val_f1_metric: 0.4832\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 975.1426 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1393.6979 - val_accuracy: 0.5349 - val_f1_metric: 0.5313\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4963.3760 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1188.2820 - val_accuracy: 0.4574 - val_f1_metric: 0.4532\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3060.1396 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 1932.6991 - val_accuracy: 0.4612 - val_f1_metric: 0.4609\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 975.0112 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 2147.5281 - val_accuracy: 0.4961 - val_f1_metric: 0.4929\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1960.7261 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1071.9784 - val_accuracy: 0.4884 - val_f1_metric: 0.4923\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 637.5035 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1125.0089 - val_accuracy: 0.5349 - val_f1_metric: 0.5327\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 879.2852 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1488.9452 - val_accuracy: 0.5039 - val_f1_metric: 0.5044\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2417.2605 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 868.7891 - val_accuracy: 0.5620 - val_f1_metric: 0.5572\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 624.4832 - accuracy: 0.3491 - f1_metric: 0.3491 - val_loss: 1016.1385 - val_accuracy: 0.4612 - val_f1_metric: 0.4582\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 4317.1313 - accuracy: 0.4151 - f1_metric: 0.4151 - val_loss: 1952.4637 - val_accuracy: 0.5039 - val_f1_metric: 0.4976\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3424.1458 - accuracy: 0.5047 - f1_metric: 0.5047 - val_loss: 1851.1207 - val_accuracy: 0.5271 - val_f1_metric: 0.5293\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3284.3794 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2428.0500 - val_accuracy: 0.4961 - val_f1_metric: 0.4902\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 4080.6772 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 938.4852 - val_accuracy: 0.4767 - val_f1_metric: 0.4731\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 806.4294 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 876.4162 - val_accuracy: 0.5504 - val_f1_metric: 0.5542\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1275.0540 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1006.7368 - val_accuracy: 0.4535 - val_f1_metric: 0.4508\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 99.0079 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1562.1321 - val_accuracy: 0.4806 - val_f1_metric: 0.4835\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1999.3514 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1343.4927 - val_accuracy: 0.5349 - val_f1_metric: 0.5354\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 587.4519 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1185.2542 - val_accuracy: 0.5310 - val_f1_metric: 0.5290\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 384.7543 - accuracy: 0.3632 - f1_metric: 0.3632 - val_loss: 2270.9177 - val_accuracy: 0.5000 - val_f1_metric: 0.4993\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1869.6600 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1086.5121 - val_accuracy: 0.4767 - val_f1_metric: 0.4731\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2322.7231 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2571.0427 - val_accuracy: 0.4961 - val_f1_metric: 0.5010\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 546.3413 - accuracy: 0.4057 - f1_metric: 0.4057 - val_loss: 1393.7583 - val_accuracy: 0.4806 - val_f1_metric: 0.4835\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 4456.3179 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 2274.4041 - val_accuracy: 0.4884 - val_f1_metric: 0.4923\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 316.9616 - accuracy: 0.3915 - f1_metric: 0.3915 - val_loss: 1766.2839 - val_accuracy: 0.5233 - val_f1_metric: 0.5283\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1104.0422 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 666.2668 - val_accuracy: 0.5426 - val_f1_metric: 0.5468\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1128.7203 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2416.1526 - val_accuracy: 0.4651 - val_f1_metric: 0.4593\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 677.8370 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 989.8607 - val_accuracy: 0.5581 - val_f1_metric: 0.5616\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 2700.3481 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1555.4298 - val_accuracy: 0.5349 - val_f1_metric: 0.5286\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2091.4600 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 1472.7319 - val_accuracy: 0.5155 - val_f1_metric: 0.5168\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1500.0338 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 1802.6768 - val_accuracy: 0.6124 - val_f1_metric: 0.6135\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1336.9893 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1368.5792 - val_accuracy: 0.4690 - val_f1_metric: 0.4724\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 236.5394 - accuracy: 0.5047 - f1_metric: 0.5047 - val_loss: 940.9978 - val_accuracy: 0.4922 - val_f1_metric: 0.4973\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 234.9583 - accuracy: 0.3868 - f1_metric: 0.3868 - val_loss: 3311.7637 - val_accuracy: 0.4884 - val_f1_metric: 0.4855\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1168.5496 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1173.3197 - val_accuracy: 0.4419 - val_f1_metric: 0.4438\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 581.9973 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 2563.8594 - val_accuracy: 0.5271 - val_f1_metric: 0.5306\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3894.8926 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1127.6995 - val_accuracy: 0.4961 - val_f1_metric: 0.4956\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 226.0721 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1473.9257 - val_accuracy: 0.4690 - val_f1_metric: 0.4684\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 5441.1694 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 2288.3206 - val_accuracy: 0.5349 - val_f1_metric: 0.5300\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3317.3184 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1363.3895 - val_accuracy: 0.4884 - val_f1_metric: 0.4855\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3971.4519 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1552.0283 - val_accuracy: 0.5155 - val_f1_metric: 0.5182\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3290.4810 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 632.3468 - val_accuracy: 0.5814 - val_f1_metric: 0.5798\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 105.7314 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1685.6898 - val_accuracy: 0.4612 - val_f1_metric: 0.4529\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4128.2617 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 919.2139 - val_accuracy: 0.5271 - val_f1_metric: 0.5374\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 570.4220 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 748.7895 - val_accuracy: 0.5581 - val_f1_metric: 0.5576\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1995.0095 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1442.9441 - val_accuracy: 0.4729 - val_f1_metric: 0.4774\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2521.6855 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 903.1277 - val_accuracy: 0.5155 - val_f1_metric: 0.5168\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 445.9292 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1984.3420 - val_accuracy: 0.4690 - val_f1_metric: 0.4697\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1135.4073 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1071.3459 - val_accuracy: 0.5775 - val_f1_metric: 0.5801\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1188.1349 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 744.2611 - val_accuracy: 0.5426 - val_f1_metric: 0.5455\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 651.5281 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 617.7064 - val_accuracy: 0.5233 - val_f1_metric: 0.5202\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 857.4197 - accuracy: 0.5896 - f1_metric: 0.5896 - val_loss: 1324.3700 - val_accuracy: 0.5078 - val_f1_metric: 0.5067\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 906.4279 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 2257.9297 - val_accuracy: 0.4922 - val_f1_metric: 0.4933\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 413.7663 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1573.6919 - val_accuracy: 0.5388 - val_f1_metric: 0.5418\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 901.4110 - accuracy: 0.4009 - f1_metric: 0.4009 - val_loss: 1694.3384 - val_accuracy: 0.5388 - val_f1_metric: 0.5391\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 353.1846 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 1541.4858 - val_accuracy: 0.5116 - val_f1_metric: 0.5077\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1278.4827 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1118.2087 - val_accuracy: 0.5504 - val_f1_metric: 0.5461\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 431.5419 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1184.1283 - val_accuracy: 0.5116 - val_f1_metric: 0.5145\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 332.3538 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 663.7975 - val_accuracy: 0.5039 - val_f1_metric: 0.4976\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4098.9805 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 874.3909 - val_accuracy: 0.5155 - val_f1_metric: 0.5209\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 810.2462 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1320.3760 - val_accuracy: 0.5116 - val_f1_metric: 0.5051\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 323.4268 - accuracy: 0.5943 - f1_metric: 0.5943 - val_loss: 1407.0420 - val_accuracy: 0.5233 - val_f1_metric: 0.5175\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 556.8615 - accuracy: 0.3774 - f1_metric: 0.3774 - val_loss: 1265.9230 - val_accuracy: 0.4845 - val_f1_metric: 0.4899\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 397.1953 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1340.8896 - val_accuracy: 0.4884 - val_f1_metric: 0.4896\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1653.8188 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2695.3906 - val_accuracy: 0.4767 - val_f1_metric: 0.4704\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1848.2665 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1451.6385 - val_accuracy: 0.5000 - val_f1_metric: 0.5020\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1100.0546 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1364.5978 - val_accuracy: 0.4574 - val_f1_metric: 0.4559\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 198ms/step - loss: 2027.2971 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1054.3358 - val_accuracy: 0.4496 - val_f1_metric: 0.4525\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 343.2914 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1433.7439 - val_accuracy: 0.4806 - val_f1_metric: 0.4795\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1219.5201 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1692.8441 - val_accuracy: 0.4612 - val_f1_metric: 0.4677\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1510.9637 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2085.5081 - val_accuracy: 0.4651 - val_f1_metric: 0.4687\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1563.4514 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1019.9118 - val_accuracy: 0.5543 - val_f1_metric: 0.5512\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 372.8762 - accuracy: 0.5943 - f1_metric: 0.5943 - val_loss: 1863.0360 - val_accuracy: 0.5078 - val_f1_metric: 0.5094\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1843.4014 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1519.7460 - val_accuracy: 0.4574 - val_f1_metric: 0.4572\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1819.0720 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1301.1290 - val_accuracy: 0.5000 - val_f1_metric: 0.5034\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 307.0401 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1270.2822 - val_accuracy: 0.5194 - val_f1_metric: 0.5192\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1453.8220 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 552.1902 - val_accuracy: 0.5659 - val_f1_metric: 0.5704\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 282.0341 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1695.3152 - val_accuracy: 0.5000 - val_f1_metric: 0.4980\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1051.4060 - accuracy: 0.4057 - f1_metric: 0.4057 - val_loss: 1998.2588 - val_accuracy: 0.4729 - val_f1_metric: 0.4721\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1917.5592 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 710.5991 - val_accuracy: 0.5349 - val_f1_metric: 0.5327\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1918.2111 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1652.7144 - val_accuracy: 0.4457 - val_f1_metric: 0.4502\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 532.3676 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1832.7057 - val_accuracy: 0.5388 - val_f1_metric: 0.5350\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 4270.8154 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1310.5256 - val_accuracy: 0.4922 - val_f1_metric: 0.4865\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1098.3186 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1410.2052 - val_accuracy: 0.5581 - val_f1_metric: 0.5603\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 678.2722 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 1313.7861 - val_accuracy: 0.5194 - val_f1_metric: 0.5219\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5068.2495 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1336.5946 - val_accuracy: 0.4729 - val_f1_metric: 0.4667\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1239.6344 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1313.1592 - val_accuracy: 0.4574 - val_f1_metric: 0.4653\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 4104.1729 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1245.8813 - val_accuracy: 0.4845 - val_f1_metric: 0.4832\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 343.7953 - accuracy: 0.6085 - f1_metric: 0.6085 - val_loss: 2179.7856 - val_accuracy: 0.4845 - val_f1_metric: 0.4872\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 68.7421 - accuracy: 0.6132 - f1_metric: 0.6132 - val_loss: 847.5701 - val_accuracy: 0.5039 - val_f1_metric: 0.5017\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1934.8942 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1939.8878 - val_accuracy: 0.5000 - val_f1_metric: 0.5020\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 227.4355 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1398.9924 - val_accuracy: 0.4690 - val_f1_metric: 0.4670\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 953.0936 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1543.8960 - val_accuracy: 0.5465 - val_f1_metric: 0.5505\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 701.4020 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1155.0626 - val_accuracy: 0.5116 - val_f1_metric: 0.5104\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 591.2769 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1388.6788 - val_accuracy: 0.5465 - val_f1_metric: 0.5505\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 879.4676 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 879.9642 - val_accuracy: 0.4535 - val_f1_metric: 0.4549\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1343.4373 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1333.5100 - val_accuracy: 0.4651 - val_f1_metric: 0.4700\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 126.3098 - accuracy: 0.5802 - f1_metric: 0.5802 - val_loss: 2188.7532 - val_accuracy: 0.5078 - val_f1_metric: 0.5027\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 661.2821 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 2599.7690 - val_accuracy: 0.4535 - val_f1_metric: 0.4549\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 886.4891 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1063.4097 - val_accuracy: 0.4884 - val_f1_metric: 0.4869\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1263.3290 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 839.6523 - val_accuracy: 0.5271 - val_f1_metric: 0.5333\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 521.0103 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1206.5234 - val_accuracy: 0.5116 - val_f1_metric: 0.5037\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 972.6516 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1145.6449 - val_accuracy: 0.4845 - val_f1_metric: 0.4791\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 775.2216 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1604.4814 - val_accuracy: 0.3992 - val_f1_metric: 0.3976\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 601.8832 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 982.0241 - val_accuracy: 0.4419 - val_f1_metric: 0.4451\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 122.7890 - accuracy: 0.3679 - f1_metric: 0.3679 - val_loss: 1081.5271 - val_accuracy: 0.5388 - val_f1_metric: 0.5337\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 4056.7083 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 870.9629 - val_accuracy: 0.4961 - val_f1_metric: 0.4970\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1683.9720 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1355.9882 - val_accuracy: 0.4806 - val_f1_metric: 0.4848\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 932.1792 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 853.9412 - val_accuracy: 0.4729 - val_f1_metric: 0.4694\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 6024.2461 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 565.8682 - val_accuracy: 0.5000 - val_f1_metric: 0.5020\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2444.5500 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1344.2023 - val_accuracy: 0.5116 - val_f1_metric: 0.5064\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 159.8807 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1631.7227 - val_accuracy: 0.5504 - val_f1_metric: 0.5488\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 793.8212 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1320.4260 - val_accuracy: 0.4922 - val_f1_metric: 0.4906\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4435.0190 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1079.4966 - val_accuracy: 0.5271 - val_f1_metric: 0.5293\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1492.7311 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2389.8567 - val_accuracy: 0.5543 - val_f1_metric: 0.5566\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2362.6780 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 610.1532 - val_accuracy: 0.5233 - val_f1_metric: 0.5242\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 191.6418 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 2151.7344 - val_accuracy: 0.4651 - val_f1_metric: 0.4620\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3360.9644 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1425.2350 - val_accuracy: 0.4109 - val_f1_metric: 0.4128\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 3494.9561 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 2203.7971 - val_accuracy: 0.5078 - val_f1_metric: 0.5094\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 658.8755 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 722.5934 - val_accuracy: 0.4922 - val_f1_metric: 0.4946\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 645.8759 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1048.5409 - val_accuracy: 0.5194 - val_f1_metric: 0.5138\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 899.0433 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1750.1425 - val_accuracy: 0.4729 - val_f1_metric: 0.4761\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 5602.1665 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 517.6392 - val_accuracy: 0.5000 - val_f1_metric: 0.4993\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 314.1344 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 567.0255 - val_accuracy: 0.5504 - val_f1_metric: 0.5448\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 215.1337 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2342.8923 - val_accuracy: 0.4612 - val_f1_metric: 0.4636\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 821.5443 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1651.6342 - val_accuracy: 0.5388 - val_f1_metric: 0.5431\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 1166.3652 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 2111.1748 - val_accuracy: 0.4535 - val_f1_metric: 0.4508\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2368.9539 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1023.0405 - val_accuracy: 0.5349 - val_f1_metric: 0.5354\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 637.0867 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 406.8691 - val_accuracy: 0.5194 - val_f1_metric: 0.5152\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 5159.0703 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1117.5264 - val_accuracy: 0.5000 - val_f1_metric: 0.4966\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 566.8347 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 2314.2910 - val_accuracy: 0.5039 - val_f1_metric: 0.5125\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1319.2352 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1588.1554 - val_accuracy: 0.4690 - val_f1_metric: 0.4724\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 102.7305 - accuracy: 0.6226 - f1_metric: 0.6226 - val_loss: 1110.6407 - val_accuracy: 0.4690 - val_f1_metric: 0.4737\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3731.0386 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 687.3351 - val_accuracy: 0.4961 - val_f1_metric: 0.4929\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1664.5358 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 888.1717 - val_accuracy: 0.5078 - val_f1_metric: 0.5094\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1089.2594 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1487.4653 - val_accuracy: 0.4806 - val_f1_metric: 0.4808\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 886.1440 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1806.8619 - val_accuracy: 0.4574 - val_f1_metric: 0.4572\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 429.0355 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1175.0947 - val_accuracy: 0.4690 - val_f1_metric: 0.4710\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 551.5969 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 820.7890 - val_accuracy: 0.5116 - val_f1_metric: 0.5091\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1829.9147 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 593.7471 - val_accuracy: 0.4419 - val_f1_metric: 0.4397\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 527.0819 - accuracy: 0.4009 - f1_metric: 0.4009 - val_loss: 1519.4832 - val_accuracy: 0.4574 - val_f1_metric: 0.4532\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 793.0087 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 798.7888 - val_accuracy: 0.5465 - val_f1_metric: 0.5451\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 600.5538 - accuracy: 0.5896 - f1_metric: 0.5896 - val_loss: 1916.5636 - val_accuracy: 0.4225 - val_f1_metric: 0.4266\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1950.6376 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1367.0266 - val_accuracy: 0.5116 - val_f1_metric: 0.5091\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 4357.2129 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1714.5715 - val_accuracy: 0.4612 - val_f1_metric: 0.4636\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1366.7850 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 2574.3333 - val_accuracy: 0.4457 - val_f1_metric: 0.4434\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1485.7709 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1346.7599 - val_accuracy: 0.5233 - val_f1_metric: 0.5175\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 926.3386 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1917.0850 - val_accuracy: 0.4380 - val_f1_metric: 0.4468\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 8247.3984 - accuracy: 0.4104 - f1_metric: 0.4104 - val_loss: 1148.0045 - val_accuracy: 0.5194 - val_f1_metric: 0.5219\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 110.2463 - accuracy: 0.5991 - f1_metric: 0.5991 - val_loss: 2465.8257 - val_accuracy: 0.4574 - val_f1_metric: 0.4626\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3603.1296 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1060.9619 - val_accuracy: 0.5543 - val_f1_metric: 0.5525\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step - loss: 1480.0892 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 1766.4642 - val_accuracy: 0.5620 - val_f1_metric: 0.5680\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 516.4072 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1562.6274 - val_accuracy: 0.5194 - val_f1_metric: 0.5178\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 5655.3174 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1180.3481 - val_accuracy: 0.5116 - val_f1_metric: 0.5158\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1888.8267 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 994.4071 - val_accuracy: 0.4535 - val_f1_metric: 0.4576\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 779.4046 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 566.0912 - val_accuracy: 0.5116 - val_f1_metric: 0.5172\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1283.3291 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1059.6992 - val_accuracy: 0.5116 - val_f1_metric: 0.5172\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 379.7160 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1577.9099 - val_accuracy: 0.5271 - val_f1_metric: 0.5266\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4944.7227 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1068.0330 - val_accuracy: 0.4884 - val_f1_metric: 0.4842\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 291.4460 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1467.8378 - val_accuracy: 0.5543 - val_f1_metric: 0.5566\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 811.3480 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1445.4025 - val_accuracy: 0.5233 - val_f1_metric: 0.5229\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1561.9869 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 934.1433 - val_accuracy: 0.5388 - val_f1_metric: 0.5377\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2514.5635 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1401.3896 - val_accuracy: 0.4302 - val_f1_metric: 0.4313\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1704.4969 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 734.5913 - val_accuracy: 0.4922 - val_f1_metric: 0.4906\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 697.8610 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1063.5719 - val_accuracy: 0.4806 - val_f1_metric: 0.4808\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 534.7914 - accuracy: 0.4009 - f1_metric: 0.4009 - val_loss: 825.7169 - val_accuracy: 0.5000 - val_f1_metric: 0.5047\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 223.7578 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 968.3311 - val_accuracy: 0.5504 - val_f1_metric: 0.5529\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 341.4462 - accuracy: 0.4198 - f1_metric: 0.4198 - val_loss: 641.4963 - val_accuracy: 0.5233 - val_f1_metric: 0.5229\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 617.0319 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 915.9829 - val_accuracy: 0.5349 - val_f1_metric: 0.5286\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1136.4879 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2412.9597 - val_accuracy: 0.4574 - val_f1_metric: 0.4559\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1096.7650 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2609.5635 - val_accuracy: 0.4380 - val_f1_metric: 0.4347\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 661.6683 - accuracy: 0.4811 - f1_metric: 0.4811 - val_loss: 1341.0753 - val_accuracy: 0.4690 - val_f1_metric: 0.4670\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 748.7588 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 2673.3899 - val_accuracy: 0.4767 - val_f1_metric: 0.4798\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 67.5145 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1055.1693 - val_accuracy: 0.5310 - val_f1_metric: 0.5303\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2546.5217 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1177.5486 - val_accuracy: 0.4806 - val_f1_metric: 0.4835\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 4436.2153 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1036.1511 - val_accuracy: 0.5078 - val_f1_metric: 0.5121\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 692.8864 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1515.5020 - val_accuracy: 0.5349 - val_f1_metric: 0.5380\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 477.7433 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1468.3807 - val_accuracy: 0.5736 - val_f1_metric: 0.5684\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 695.6636 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 903.6192 - val_accuracy: 0.5659 - val_f1_metric: 0.5582\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2416.6995 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1203.8213 - val_accuracy: 0.4729 - val_f1_metric: 0.4734\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 77.9632 - accuracy: 0.6038 - f1_metric: 0.6038 - val_loss: 1475.7230 - val_accuracy: 0.5078 - val_f1_metric: 0.5013\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1877.8383 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2868.6357 - val_accuracy: 0.4729 - val_f1_metric: 0.4774\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 260.8886 - accuracy: 0.3726 - f1_metric: 0.3726 - val_loss: 737.7381 - val_accuracy: 0.5078 - val_f1_metric: 0.5040\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1016.1481 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 763.3132 - val_accuracy: 0.5388 - val_f1_metric: 0.5404\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1403.3174 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1485.1470 - val_accuracy: 0.5039 - val_f1_metric: 0.5125\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1279.2850 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1244.4523 - val_accuracy: 0.4651 - val_f1_metric: 0.4646\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 541.1865 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 2548.2437 - val_accuracy: 0.4496 - val_f1_metric: 0.4525\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 200.9046 - accuracy: 0.6415 - f1_metric: 0.6415 - val_loss: 504.0040 - val_accuracy: 0.5891 - val_f1_metric: 0.5899\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1175.0309 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 800.8214 - val_accuracy: 0.4884 - val_f1_metric: 0.4896\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1700.1627 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1212.1279 - val_accuracy: 0.4806 - val_f1_metric: 0.4781\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2680.6128 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 2582.5266 - val_accuracy: 0.4767 - val_f1_metric: 0.4811\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1112.9058 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1466.9954 - val_accuracy: 0.4922 - val_f1_metric: 0.4960\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 733.3807 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1305.1066 - val_accuracy: 0.5194 - val_f1_metric: 0.5232\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 3113.6602 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 2781.0215 - val_accuracy: 0.5271 - val_f1_metric: 0.5279\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 829.6496 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1544.4098 - val_accuracy: 0.5349 - val_f1_metric: 0.5367\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 828.6780 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 902.1572 - val_accuracy: 0.5194 - val_f1_metric: 0.5111\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1298.4551 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1083.7126 - val_accuracy: 0.5388 - val_f1_metric: 0.5364\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 697.2466 - accuracy: 0.5755 - f1_metric: 0.5755 - val_loss: 867.0272 - val_accuracy: 0.5116 - val_f1_metric: 0.5037\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 250.9798 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 967.2021 - val_accuracy: 0.5736 - val_f1_metric: 0.5778\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1346.2275 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1111.1984 - val_accuracy: 0.5581 - val_f1_metric: 0.5562\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1462.6356 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 2329.8037 - val_accuracy: 0.4457 - val_f1_metric: 0.4475\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 771.5794 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1171.9934 - val_accuracy: 0.5116 - val_f1_metric: 0.5158\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 755.5668 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1553.5197 - val_accuracy: 0.5426 - val_f1_metric: 0.5428\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 295.0018 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 660.0938 - val_accuracy: 0.5271 - val_f1_metric: 0.5239\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2057.0046 - accuracy: 0.5047 - f1_metric: 0.5047 - val_loss: 916.2015 - val_accuracy: 0.5504 - val_f1_metric: 0.5461\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1768.0280 - accuracy: 0.4528 - f1_metric: 0.4528 - val_loss: 1712.7019 - val_accuracy: 0.4806 - val_f1_metric: 0.4848\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1238.5585 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1470.3542 - val_accuracy: 0.4341 - val_f1_metric: 0.4404\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2129.6638 - accuracy: 0.5000 - f1_metric: 0.5000 - val_loss: 912.6158 - val_accuracy: 0.5698 - val_f1_metric: 0.5646\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1973.2815 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1552.8573 - val_accuracy: 0.5194 - val_f1_metric: 0.5152\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 837.3525 - accuracy: 0.5047 - f1_metric: 0.5047 - val_loss: 1803.6174 - val_accuracy: 0.4961 - val_f1_metric: 0.4902\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 786.3503 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 883.2305 - val_accuracy: 0.4884 - val_f1_metric: 0.4882\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1083.6442 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 891.2406 - val_accuracy: 0.4806 - val_f1_metric: 0.4808\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2969.7051 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 890.6359 - val_accuracy: 0.5620 - val_f1_metric: 0.5626\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1041.4252 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1430.4167 - val_accuracy: 0.4845 - val_f1_metric: 0.4886\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3106.4536 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 1103.0900 - val_accuracy: 0.4651 - val_f1_metric: 0.4660\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1571.3098 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 831.4409 - val_accuracy: 0.5078 - val_f1_metric: 0.5081\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 737.4097 - accuracy: 0.5000 - f1_metric: 0.5000 - val_loss: 1542.8932 - val_accuracy: 0.5194 - val_f1_metric: 0.5165\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 324.0043 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 834.9553 - val_accuracy: 0.5465 - val_f1_metric: 0.5438\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1832.9766 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1580.5150 - val_accuracy: 0.4845 - val_f1_metric: 0.4845\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1307.2839 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1134.9957 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 650.1163 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1227.4098 - val_accuracy: 0.4767 - val_f1_metric: 0.4771\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 826.8349 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1836.7792 - val_accuracy: 0.5310 - val_f1_metric: 0.5290\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1876.8632 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 863.7820 - val_accuracy: 0.4496 - val_f1_metric: 0.4525\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2973.1245 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 925.6387 - val_accuracy: 0.5194 - val_f1_metric: 0.5205\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 2140.3262 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1341.1353 - val_accuracy: 0.4922 - val_f1_metric: 0.4960\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 740.2961 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1506.2273 - val_accuracy: 0.4612 - val_f1_metric: 0.4542\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1355.4392 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 1907.7194 - val_accuracy: 0.5736 - val_f1_metric: 0.5737\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4912.2598 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 898.0381 - val_accuracy: 0.4729 - val_f1_metric: 0.4788\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1207.7786 - accuracy: 0.5991 - f1_metric: 0.5991 - val_loss: 1453.7368 - val_accuracy: 0.4380 - val_f1_metric: 0.4320\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 756.7010 - accuracy: 0.4340 - f1_metric: 0.4340 - val_loss: 1584.8689 - val_accuracy: 0.5194 - val_f1_metric: 0.5192\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2482.5608 - accuracy: 0.5236 - f1_metric: 0.5236 - val_loss: 858.8308 - val_accuracy: 0.5310 - val_f1_metric: 0.5263\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 169.1247 - accuracy: 0.5991 - f1_metric: 0.5991 - val_loss: 1056.3344 - val_accuracy: 0.5271 - val_f1_metric: 0.5333\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 819.4981 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 797.4277 - val_accuracy: 0.5310 - val_f1_metric: 0.5370\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 230.7393 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1862.8398 - val_accuracy: 0.4767 - val_f1_metric: 0.4758\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1195.6917 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1777.7355 - val_accuracy: 0.5349 - val_f1_metric: 0.5354\n",
      "Epoch 925/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 193ms/step - loss: 1542.4673 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 998.3724 - val_accuracy: 0.4806 - val_f1_metric: 0.4835\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 884.7108 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1854.2239 - val_accuracy: 0.4922 - val_f1_metric: 0.4865\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 992.0402 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1390.6501 - val_accuracy: 0.5155 - val_f1_metric: 0.5101\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1469.1194 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 1122.5341 - val_accuracy: 0.3760 - val_f1_metric: 0.3781\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2374.7129 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1040.9119 - val_accuracy: 0.4845 - val_f1_metric: 0.4845\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 2044.6326 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 467.8408 - val_accuracy: 0.4845 - val_f1_metric: 0.4832\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 285.5771 - accuracy: 0.4953 - f1_metric: 0.4953 - val_loss: 1359.5107 - val_accuracy: 0.4690 - val_f1_metric: 0.4724\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1441.9832 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 891.1380 - val_accuracy: 0.4961 - val_f1_metric: 0.4929\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1070.4377 - accuracy: 0.5330 - f1_metric: 0.5330 - val_loss: 1209.0975 - val_accuracy: 0.4961 - val_f1_metric: 0.4943\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2378.0237 - accuracy: 0.5283 - f1_metric: 0.5283 - val_loss: 1093.9424 - val_accuracy: 0.5000 - val_f1_metric: 0.5020\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1498.6515 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 836.9235 - val_accuracy: 0.5271 - val_f1_metric: 0.5226\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 938.7253 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1941.8850 - val_accuracy: 0.5310 - val_f1_metric: 0.5303\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 804.2333 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1186.7169 - val_accuracy: 0.5620 - val_f1_metric: 0.5599\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 877.9809 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 1066.3517 - val_accuracy: 0.4690 - val_f1_metric: 0.4616\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 135.7146 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 2318.9624 - val_accuracy: 0.5233 - val_f1_metric: 0.5242\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 300.6866 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 960.5886 - val_accuracy: 0.5659 - val_f1_metric: 0.5623\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 365.4271 - accuracy: 0.3726 - f1_metric: 0.37 - 0s 201ms/step - loss: 365.4271 - accuracy: 0.3726 - f1_metric: 0.3726 - val_loss: 1603.0121 - val_accuracy: 0.5388 - val_f1_metric: 0.5418\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 204.0560 - accuracy: 0.5708 - f1_metric: 0.5708 - val_loss: 691.1776 - val_accuracy: 0.4884 - val_f1_metric: 0.4828\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 473.3043 - accuracy: 0.4009 - f1_metric: 0.4009 - val_loss: 1967.0792 - val_accuracy: 0.4651 - val_f1_metric: 0.4727\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 212.9261 - accuracy: 0.5142 - f1_metric: 0.5142 - val_loss: 886.2194 - val_accuracy: 0.4884 - val_f1_metric: 0.4909\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 605.1285 - accuracy: 0.5566 - f1_metric: 0.5566 - val_loss: 896.7073 - val_accuracy: 0.4535 - val_f1_metric: 0.4589\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 297.4033 - accuracy: 0.3868 - f1_metric: 0.3868 - val_loss: 966.2161 - val_accuracy: 0.5000 - val_f1_metric: 0.5047\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 716.8898 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 2460.0630 - val_accuracy: 0.5426 - val_f1_metric: 0.5360\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 187.8265 - accuracy: 0.4764 - f1_metric: 0.4764 - val_loss: 1450.0712 - val_accuracy: 0.5698 - val_f1_metric: 0.5727\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1425.2764 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1517.3358 - val_accuracy: 0.4884 - val_f1_metric: 0.4923\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 201.7213 - accuracy: 0.6038 - f1_metric: 0.6038 - val_loss: 913.7238 - val_accuracy: 0.5504 - val_f1_metric: 0.5556\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1748.3357 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1099.9084 - val_accuracy: 0.4806 - val_f1_metric: 0.4835\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3914.5325 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1506.1254 - val_accuracy: 0.4651 - val_f1_metric: 0.4620\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1397.3080 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 1028.5278 - val_accuracy: 0.5000 - val_f1_metric: 0.5034\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 486.8774 - accuracy: 0.5094 - f1_metric: 0.5094 - val_loss: 1286.1606 - val_accuracy: 0.5543 - val_f1_metric: 0.5525\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1358.6816 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 589.0088 - val_accuracy: 0.4341 - val_f1_metric: 0.4242\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2072.0278 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1266.4871 - val_accuracy: 0.5039 - val_f1_metric: 0.5030\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2562.7395 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1410.9183 - val_accuracy: 0.5155 - val_f1_metric: 0.5101\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 440.1964 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1530.3800 - val_accuracy: 0.5271 - val_f1_metric: 0.5306\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1209.9775 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 361.4326 - val_accuracy: 0.5233 - val_f1_metric: 0.5242\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 3706.2036 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 687.4617 - val_accuracy: 0.5543 - val_f1_metric: 0.5525\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 649.6328 - accuracy: 0.4717 - f1_metric: 0.4717 - val_loss: 1471.6530 - val_accuracy: 0.5504 - val_f1_metric: 0.5488\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2152.7698 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 886.5918 - val_accuracy: 0.4806 - val_f1_metric: 0.4822\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1158.6031 - accuracy: 0.4245 - f1_metric: 0.4245 - val_loss: 1712.4235 - val_accuracy: 0.5426 - val_f1_metric: 0.5414\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 442.6956 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1163.1112 - val_accuracy: 0.4767 - val_f1_metric: 0.4717\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 2207.3682 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1737.4979 - val_accuracy: 0.4690 - val_f1_metric: 0.4657\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5020.2505 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 790.8866 - val_accuracy: 0.5194 - val_f1_metric: 0.5125\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3002.6543 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 824.9786 - val_accuracy: 0.5116 - val_f1_metric: 0.5172\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 164.9204 - accuracy: 0.5047 - f1_metric: 0.5047 - val_loss: 1531.1715 - val_accuracy: 0.5078 - val_f1_metric: 0.4973\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 276.3723 - accuracy: 0.5991 - f1_metric: 0.5991 - val_loss: 1706.8062 - val_accuracy: 0.4729 - val_f1_metric: 0.4734\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1244.1912 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 865.8932 - val_accuracy: 0.4341 - val_f1_metric: 0.4350\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 177.3253 - accuracy: 0.5189 - f1_metric: 0.5189 - val_loss: 973.6358 - val_accuracy: 0.5620 - val_f1_metric: 0.5626\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1505.3865 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1197.8412 - val_accuracy: 0.5465 - val_f1_metric: 0.5397\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 319.3990 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 1208.4242 - val_accuracy: 0.5426 - val_f1_metric: 0.5387\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 220.8365 - accuracy: 0.5519 - f1_metric: 0.5519 - val_loss: 1096.4812 - val_accuracy: 0.4496 - val_f1_metric: 0.4485\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 995.9351 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1638.1681 - val_accuracy: 0.4806 - val_f1_metric: 0.4835\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1448.9249 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1346.8004 - val_accuracy: 0.4729 - val_f1_metric: 0.4707\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1196.6240 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1434.7554 - val_accuracy: 0.4961 - val_f1_metric: 0.4916\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 113.2096 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 1554.1855 - val_accuracy: 0.5426 - val_f1_metric: 0.5468\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 841.8870 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 868.7818 - val_accuracy: 0.5155 - val_f1_metric: 0.5114\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 136.3754 - accuracy: 0.5991 - f1_metric: 0.5991 - val_loss: 608.3290 - val_accuracy: 0.4922 - val_f1_metric: 0.4987\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 871.7261 - accuracy: 0.4387 - f1_metric: 0.4387 - val_loss: 620.2297 - val_accuracy: 0.5388 - val_f1_metric: 0.5391\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 788.8336 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 781.5096 - val_accuracy: 0.5310 - val_f1_metric: 0.5249\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 388.9782 - accuracy: 0.4858 - f1_metric: 0.4858 - val_loss: 1058.8260 - val_accuracy: 0.5116 - val_f1_metric: 0.5118\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1719.1595 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 1521.7444 - val_accuracy: 0.4884 - val_f1_metric: 0.4923\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1445.3976 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 1171.0748 - val_accuracy: 0.4806 - val_f1_metric: 0.4848\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 5085.6978 - accuracy: 0.4906 - f1_metric: 0.4906 - val_loss: 715.1403 - val_accuracy: 0.5465 - val_f1_metric: 0.5545\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2386.9800 - accuracy: 0.4481 - f1_metric: 0.4481 - val_loss: 1781.8058 - val_accuracy: 0.4884 - val_f1_metric: 0.4828\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1362.4067 - accuracy: 0.4670 - f1_metric: 0.4670 - val_loss: 1362.7540 - val_accuracy: 0.5039 - val_f1_metric: 0.5017\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1759.2526 - accuracy: 0.4575 - f1_metric: 0.4575 - val_loss: 616.0524 - val_accuracy: 0.4806 - val_f1_metric: 0.4822\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 414.9536 - accuracy: 0.4434 - f1_metric: 0.4434 - val_loss: 1710.2339 - val_accuracy: 0.5233 - val_f1_metric: 0.5215\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1898.9518 - accuracy: 0.5425 - f1_metric: 0.5425 - val_loss: 914.3438 - val_accuracy: 0.5039 - val_f1_metric: 0.5003\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1119.1244 - accuracy: 0.5660 - f1_metric: 0.5660 - val_loss: 909.4656 - val_accuracy: 0.5000 - val_f1_metric: 0.4993\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 110.7396 - accuracy: 0.5896 - f1_metric: 0.5896 - val_loss: 1619.7980 - val_accuracy: 0.5116 - val_f1_metric: 0.5131\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1435.8586 - accuracy: 0.5613 - f1_metric: 0.5613 - val_loss: 934.7668 - val_accuracy: 0.4961 - val_f1_metric: 0.4983\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 368.9111 - accuracy: 0.4292 - f1_metric: 0.4292 - val_loss: 1276.3130 - val_accuracy: 0.4884 - val_f1_metric: 0.4949\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1184.9259 - accuracy: 0.5472 - f1_metric: 0.5472 - val_loss: 793.1672 - val_accuracy: 0.5581 - val_f1_metric: 0.5549\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1001.0317 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1458.3108 - val_accuracy: 0.4496 - val_f1_metric: 0.4525\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2269.0649 - accuracy: 0.4623 - f1_metric: 0.4623 - val_loss: 1714.0206 - val_accuracy: 0.5310 - val_f1_metric: 0.5290\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 564.6938 - accuracy: 0.5377 - f1_metric: 0.5377 - val_loss: 1448.9474 - val_accuracy: 0.4729 - val_f1_metric: 0.4721\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 533.6191 - accuracy: 0.4104 - f1_metric: 0.4104 - val_loss: 760.8371 - val_accuracy: 0.5271 - val_f1_metric: 0.5293\n",
      "Model training finished.\n",
      "Train loss: 512.343, train accuracy: 0.434 and train f1_score: 0.434\n",
      "Evaluating model performance...\n",
      "Test loss: 522.084, test accuracy: 0.422 and test f1_score: 0.422\n"
     ]
    }
   ],
   "source": [
    "run_experiment(bnn_model_full,\n",
    "               nll,\n",
    "               train_dataset,\n",
    "               val_dataset,\n",
    "               test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cab01c68",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <TakeDataset shapes: ({age: (None,), sex: (None, 2), cp: (None, 4), trtbps: (None,), chol: (None,), fbs: (None, 2), restecg: (None, 3), thalachh: (None,), exng: (None, 2), oldpeak: (None,), slp: (None, 3), caa: (None, 5), thall: (None, 4)}, (None, 2)), types: ({age: tf.float32, sex: tf.float32, cp: tf.float32, trtbps: tf.float32, chol: tf.float32, fbs: tf.float32, restecg: tf.float32, thalachh: tf.float32, exng: tf.float32, oldpeak: tf.float32, slp: tf.float32, caa: tf.float32, thall: tf.float32}, tf.int32)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-0b62fceb0bde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbnn_model_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# have a `shape` attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Inputs to a layer should be tensors. Got: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <TakeDataset shapes: ({age: (None,), sex: (None, 2), cp: (None, 4), trtbps: (None,), chol: (None,), fbs: (None, 2), restecg: (None, 3), thalachh: (None,), exng: (None, 2), oldpeak: (None,), slp: (None, 3), caa: (None, 5), thall: (None, 4)}, (None, 2)), types: ({age: tf.float32, sex: tf.float32, cp: tf.float32, trtbps: tf.float32, chol: tf.float32, fbs: tf.float32, restecg: tf.float32, thalachh: tf.float32, exng: tf.float32, oldpeak: tf.float32, slp: tf.float32, caa: tf.float32, thall: tf.float32}, tf.int32)>"
     ]
    }
   ],
   "source": [
    "bnn_model_full(test_dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "64d89c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_bnn = bnn_model_full.predict(test_dataset)\n",
    "test_predictions_nn = nn_model_full.predict(test_dataset)\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3de47f2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "x and y must have the same dtype, got tf.float64 != tf.float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             \u001b[0mr_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__r%s__\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1507\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   1508\u001b[0m           \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(), dtype=float64, numpy=25.0>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-7b1b1363718a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf1_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predictions_nn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-c4ed4ea9ad60>\u001b[0m in \u001b[0;36mf1_metric\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpredicted_positives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted_positives\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_positives\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpossible_positives\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m   \"\"\"\n\u001b[1;32m-> 1336\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     \u001b[0my_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m       raise TypeError(\"x and y must have the same dtype, got %r != %r\" %\n\u001b[0m\u001b[0;32m   1267\u001b[0m                       (x_dtype, y_dtype))\n\u001b[0;32m   1268\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: x and y must have the same dtype, got tf.float64 != tf.float32"
     ]
    }
   ],
   "source": [
    "f1_metric(true_labels, test_predictions_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "708ca576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\bnn_model_full\\assets\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join('.','bnn_model_full')\n",
    "\n",
    "tf.saved_model.save(\n",
    "    bnn_model_full, export_dir = save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d56b9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predictions_probabilities(model, test_dataset = test_dataset):\n",
    "    \n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    entropies = []\n",
    "    i = 1\n",
    "\n",
    "    for x, y in test_dataset.unbatch().batch(1).take(-1):\n",
    "        \n",
    "        output_dist = model(x)\n",
    "        \n",
    "        # prediction\n",
    "        [prediction] = highest_prob = output_dist.mode()\n",
    "        prediction = np.argmax(prediction)\n",
    "        \n",
    "        # probability of this prediction\n",
    "        probability = output_dist.prob(highest_prob).numpy().squeeze()\n",
    "        \n",
    "        # true label of test example\n",
    "        true_label = np.argmax(y.numpy().squeeze())\n",
    "        \n",
    "        # entropy\n",
    "        [entropy] = output_dist.entropy().numpy()\n",
    "        \n",
    "        print(f\"Test Example: {i}\")\n",
    "        print(f\"Test Prediction: {prediction}, probability of this prediction: {probability} and entropy: {entropy}\")\n",
    "        print(f\"True Label: {true_label}\")\n",
    "        print(\"=\"*15)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "        true_labels.append(true_label)\n",
    "        probabilities.append(probability)\n",
    "        entropies.append(entropy)\n",
    "        \n",
    "    return predictions, true_labels, probabilities, entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34dbca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Example: 1\n",
      "Test Prediction: 0, probability of this prediction: 0.9995660185813904 and entropy: 0.0037937164306640625\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 2\n",
      "Test Prediction: 0, probability of this prediction: 0.9999384880065918 and entropy: 0.0006580352783203125\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 3\n",
      "Test Prediction: 0, probability of this prediction: 0.9998884201049805 and entropy: 0.0011272430419921875\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 4\n",
      "Test Prediction: 1, probability of this prediction: 0.9483664035797119 and entropy: 0.20329749584197998\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 5\n",
      "Test Prediction: 1, probability of this prediction: 0.9236447215080261 and entropy: 0.2697761654853821\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 6\n",
      "Test Prediction: 1, probability of this prediction: 0.9105547666549683 and entropy: 0.3012523055076599\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 7\n",
      "Test Prediction: 0, probability of this prediction: 0.653389036655426 and entropy: 0.6453234553337097\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 8\n",
      "Test Prediction: 0, probability of this prediction: 0.9887762665748596 and entropy: 0.06155204772949219\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 9\n",
      "Test Prediction: 0, probability of this prediction: 0.9998379945755005 and entropy: 0.0015764236450195312\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 10\n",
      "Test Prediction: 1, probability of this prediction: 0.9832642674446106 and entropy: 0.08504748344421387\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 11\n",
      "Test Prediction: 0, probability of this prediction: 0.9868863224983215 and entropy: 0.06986308097839355\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 12\n",
      "Test Prediction: 1, probability of this prediction: 0.803392231464386 and entropy: 0.49566370248794556\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 13\n",
      "Test Prediction: 0, probability of this prediction: 0.5805960297584534 and entropy: 0.6800988912582397\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 14\n",
      "Test Prediction: 1, probability of this prediction: 0.9854112863540649 and entropy: 0.0761556625366211\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 15\n",
      "Test Prediction: 0, probability of this prediction: 0.9605648517608643 and entropy: 0.16614484786987305\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 16\n",
      "Test Prediction: 1, probability of this prediction: 0.9998409748077393 and entropy: 0.0015494823455810547\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 17\n",
      "Test Prediction: 0, probability of this prediction: 0.9937422871589661 and entropy: 0.03798937797546387\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 18\n",
      "Test Prediction: 0, probability of this prediction: 0.8996075391769409 and entropy: 0.32594454288482666\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 19\n",
      "Test Prediction: 1, probability of this prediction: 0.5750620365142822 and entropy: 0.6818358302116394\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 20\n",
      "Test Prediction: 1, probability of this prediction: 0.9953515529632568 and entropy: 0.02960515022277832\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 21\n",
      "Test Prediction: 1, probability of this prediction: 0.9941060543060303 and entropy: 0.036134958267211914\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 22\n",
      "Test Prediction: 0, probability of this prediction: 0.9998693466186523 and entropy: 0.0012989044189453125\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 23\n",
      "Test Prediction: 0, probability of this prediction: 0.9956846237182617 and entropy: 0.027805805206298828\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 24\n",
      "Test Prediction: 1, probability of this prediction: 0.9999215602874756 and entropy: 0.0008196830749511719\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 25\n",
      "Test Prediction: 1, probability of this prediction: 0.9992074370384216 and entropy: 0.006451845169067383\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 26\n",
      "Test Prediction: 0, probability of this prediction: 0.8485532999038696 and entropy: 0.42521029710769653\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 27\n",
      "Test Prediction: 0, probability of this prediction: 0.9773764610290527 and entropy: 0.10808110237121582\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 28\n",
      "Test Prediction: 0, probability of this prediction: 0.9985520243644714 and entropy: 0.010913372039794922\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 29\n",
      "Test Prediction: 1, probability of this prediction: 0.9857783317565918 and entropy: 0.07460451126098633\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 30\n",
      "Test Prediction: 0, probability of this prediction: 0.9981682300567627 and entropy: 0.013374567031860352\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 31\n",
      "Test Prediction: 0, probability of this prediction: 0.9877382516860962 and entropy: 0.06615352630615234\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 32\n",
      "Test Prediction: 1, probability of this prediction: 0.8756977319717407 and entropy: 0.375410258769989\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 33\n",
      "Test Prediction: 1, probability of this prediction: 0.9478583335876465 and entropy: 0.20477354526519775\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 34\n",
      "Test Prediction: 0, probability of this prediction: 0.995311975479126 and entropy: 0.029817581176757812\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 35\n",
      "Test Prediction: 1, probability of this prediction: 0.9995988011360168 and entropy: 0.0035390853881835938\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 36\n",
      "Test Prediction: 0, probability of this prediction: 0.9679858684539795 and entropy: 0.14167511463165283\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 37\n",
      "Test Prediction: 0, probability of this prediction: 0.9643919467926025 and entropy: 0.15372586250305176\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 38\n",
      "Test Prediction: 1, probability of this prediction: 0.9983001351356506 and entropy: 0.012539148330688477\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 39\n",
      "Test Prediction: 0, probability of this prediction: 0.9999974966049194 and entropy: 3.4332275390625e-05\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 40\n",
      "Test Prediction: 0, probability of this prediction: 0.5923390984535217 and entropy: 0.6759958267211914\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 41\n",
      "Test Prediction: 1, probability of this prediction: 0.9997754693031311 and entropy: 0.0021109580993652344\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 42\n",
      "Test Prediction: 0, probability of this prediction: 0.8129138350486755 and entropy: 0.4819702208042145\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 43\n",
      "Test Prediction: 1, probability of this prediction: 0.9481161236763 and entropy: 0.20402538776397705\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 44\n",
      "Test Prediction: 0, probability of this prediction: 0.9998389482498169 and entropy: 0.0015673637390136719\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 45\n",
      "Test Prediction: 1, probability of this prediction: 0.985249936580658 and entropy: 0.07683444023132324\n",
      "True Label: 1\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels, probabilities, entropies = output_predictions_probabilities(bnn_model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfd893b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>entropies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999566</td>\n",
       "      <td>0.003794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999385</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9998884</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9483664</td>\n",
       "      <td>0.203297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9236447</td>\n",
       "      <td>0.269776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91055477</td>\n",
       "      <td>0.301252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65338904</td>\n",
       "      <td>0.645323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98877627</td>\n",
       "      <td>0.061552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98326427</td>\n",
       "      <td>0.085047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9868863</td>\n",
       "      <td>0.069863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80339223</td>\n",
       "      <td>0.495664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580596</td>\n",
       "      <td>0.680099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9854113</td>\n",
       "      <td>0.076156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96056485</td>\n",
       "      <td>0.166145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.001549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9937423</td>\n",
       "      <td>0.037989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89960754</td>\n",
       "      <td>0.325945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57506204</td>\n",
       "      <td>0.681836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99535155</td>\n",
       "      <td>0.029605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99410605</td>\n",
       "      <td>0.036135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99986935</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9956846</td>\n",
       "      <td>0.027806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99992156</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99920744</td>\n",
       "      <td>0.006452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8485533</td>\n",
       "      <td>0.425210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97737646</td>\n",
       "      <td>0.108081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998552</td>\n",
       "      <td>0.010913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98577833</td>\n",
       "      <td>0.074605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99816823</td>\n",
       "      <td>0.013375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98773825</td>\n",
       "      <td>0.066154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87569773</td>\n",
       "      <td>0.375410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94785833</td>\n",
       "      <td>0.204774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.029818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9995988</td>\n",
       "      <td>0.003539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96798587</td>\n",
       "      <td>0.141675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96439195</td>\n",
       "      <td>0.153726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99830014</td>\n",
       "      <td>0.012539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999975</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5923391</td>\n",
       "      <td>0.675996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99977547</td>\n",
       "      <td>0.002111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81291384</td>\n",
       "      <td>0.481970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9481161</td>\n",
       "      <td>0.204025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99983895</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98524994</td>\n",
       "      <td>0.076834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions  true_labels probabilities  entropies\n",
       "0             0            0      0.999566   0.003794\n",
       "1             0            0     0.9999385   0.000658\n",
       "2             0            0     0.9998884   0.001127\n",
       "3             1            1     0.9483664   0.203297\n",
       "4             1            1     0.9236447   0.269776\n",
       "5             1            1    0.91055477   0.301252\n",
       "6             0            1    0.65338904   0.645323\n",
       "7             0            0    0.98877627   0.061552\n",
       "8             0            0      0.999838   0.001576\n",
       "9             1            1    0.98326427   0.085047\n",
       "10            0            0     0.9868863   0.069863\n",
       "11            1            1    0.80339223   0.495664\n",
       "12            0            0      0.580596   0.680099\n",
       "13            1            1     0.9854113   0.076156\n",
       "14            0            0    0.96056485   0.166145\n",
       "15            1            1      0.999841   0.001549\n",
       "16            0            0     0.9937423   0.037989\n",
       "17            0            0    0.89960754   0.325945\n",
       "18            1            1    0.57506204   0.681836\n",
       "19            1            1    0.99535155   0.029605\n",
       "20            1            0    0.99410605   0.036135\n",
       "21            0            0    0.99986935   0.001299\n",
       "22            0            0     0.9956846   0.027806\n",
       "23            1            1    0.99992156   0.000820\n",
       "24            1            1    0.99920744   0.006452\n",
       "25            0            0     0.8485533   0.425210\n",
       "26            0            0    0.97737646   0.108081\n",
       "27            0            0      0.998552   0.010913\n",
       "28            1            1    0.98577833   0.074605\n",
       "29            0            0    0.99816823   0.013375\n",
       "30            0            0    0.98773825   0.066154\n",
       "31            1            1    0.87569773   0.375410\n",
       "32            1            1    0.94785833   0.204774\n",
       "33            0            0      0.995312   0.029818\n",
       "34            1            1     0.9995988   0.003539\n",
       "35            0            0    0.96798587   0.141675\n",
       "36            0            0    0.96439195   0.153726\n",
       "37            1            1    0.99830014   0.012539\n",
       "38            0            0     0.9999975   0.000034\n",
       "39            0            1     0.5923391   0.675996\n",
       "40            1            1    0.99977547   0.002111\n",
       "41            0            0    0.81291384   0.481970\n",
       "42            1            1     0.9481161   0.204025\n",
       "43            0            0    0.99983895   0.001567\n",
       "44            1            1    0.98524994   0.076834"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_result_dict = {k: v for k, v in zip(['predictions', 'true_labels', 'probabilities', 'entropies'],\n",
    "                                                [predictions, true_labels, probabilities, entropies])}\n",
    "\n",
    "test_dataset_result_df = pd.DataFrame(test_dataset_result_dict)\n",
    "test_dataset_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3344d3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correctly Predicted')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_entropies = test_dataset_result_df[test_dataset_result_df.predictions == test_dataset_result_df.true_labels]['entropies']\n",
    "density = gaussian_kde(correct_entropies.to_numpy())\n",
    "plt.plot(np.linspace(0,1,100), density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Correctly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff72add7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Wrongly Predicted')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_entropies = test_dataset_result_df[test_dataset_result_df.predictions != test_dataset_result_df.true_labels]['entropies']\n",
    "density = gaussian_kde(wrong_entropies.to_numpy())\n",
    "plt.plot(np.linspace(0,1,100), density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Wrongly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21092f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
