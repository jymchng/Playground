{
 "cells": [
  {
   "attachments": {
    "entropies.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "79c3c53f",
   "metadata": {},
   "source": [
    "<img src=\"assets/uriel-sc-11KDtiUWRq4-unsplash.jpg\" width=400 height=400 />\n",
    "\n",
    "<center> <a href=\"https://unsplash.com/photos/11KDtiUWRq4\">Source</a> </center>\n",
    "\n",
    "# Bayesian Neural Network on the 'Heart Disease' Dataset\n",
    "\n",
    "Author: CHNG Soon Siang ([LinkedIn](https://www.linkedin.com/in/soon-siang-chng/))<br>\n",
    "Dataset: [Heart Disease Dataset](https://www.kaggle.com/ronitf/heart-disease-uci)\n",
    "\n",
    "Date last updated: 11 July 2021\n",
    "\n",
    "_**Summary**_    \n",
    "In applications where the size of the data collected is small and the outcome to be predicted is of great importance, one would require a probabilistic model to quantify the uncertainty of its predictions. This is often encountered in healthcare, engineering, academia, and other industries. In this exercise, a deterministic neural network (DNN) (acting as a baseline model) and a Bayesian neural network (BNN) were trained separately on the preprocessed heart attack dataset. The objective is to predict if heart disease is present in a patient. The accuracies attained by both models are tabulated below. Both models attained similar accuracy on the test dataset, however, in this context, the BNN model is advantageous as it quantifies the uncertainty, using entropy, associated with its prediction.\n",
    "\n",
    "<center>Table of Accuracies for the 2 Networks</center>\n",
    "\n",
    "|                   | Deterministic NN | Bayesian NN |\n",
    "|-------------------|------------------|-------------|\n",
    "| Training Accuracy |1.000             |0.92         |\n",
    "| Test Accuracy     |1.000             |0.933    |\n",
    "\n",
    "![entropies.png](attachment:entropies.png)\n",
    "<center>(Left) Entropies associated with correct predictions. (Right) Entropies associated with wrong predictions.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e770e",
   "metadata": {},
   "source": [
    "<a name = 'background'></a>\n",
    "## Background\n",
    "\n",
    "* The power of neural network lies in its capability as a Universal Function Approximator ([Universal Approximation Theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem)).\n",
    "* Data (collected through sampling) is a representation of the phenomenon we wish to model. Given a small dataset, a **fundamental** limitation is that the dataset is highly **unlikely** to be **representative** of the underlying distribution of data points associated with the phenomenon.\n",
    "* Consequently, any model attempting to approximate the distribution output 'I don't know' to an input with which it is unable to give a good prediction ('good' as quantified by the uncertainty of the prediction, i.e. how 'confident' a model is in giving this prediction).\n",
    "* In practice, this allows a user of the model to determine if he should trust (and subsequently, use) the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be59869",
   "metadata": {},
   "source": [
    "<a name = 'agenda'></a>\n",
    "## Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b0458",
   "metadata": {},
   "source": [
    "In this exercise, the following agendas are fulfilled:\n",
    "\n",
    "1. Pre-processing of the heart disease dataset.\n",
    "2. Tuning of BNN using Keras Tuner.\n",
    "3. Training of both DNN and BNN with DNN serving as a baseline model.\n",
    "4. Evaluation of BNN's predictive capability using entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcea3919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:32.248674Z",
     "start_time": "2021-07-09T12:47:16.877371Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cloudpickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_probability as tfp\n",
    "import keras_tuner as kt\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fbfe87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:32.279230Z",
     "start_time": "2021-07-09T12:47:32.254470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469aa5b4",
   "metadata": {},
   "source": [
    "Steps in the intial-preprocessing of the data.\n",
    "\n",
    "* First, we specify the path to the CSV containing the dataset.\n",
    "* Then, we read it as a Pandas DataFrame object.\n",
    "* Finally, we split the dataframe into train and test dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dc4879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:32.355028Z",
     "start_time": "2021-07-09T12:47:32.283223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data size:  303\n",
      "Sizes for different datasets are: Train 212, Test 45 and Validation 45.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the csv.\n",
    "csv_file = os.path.join('.','data','heart.csv')\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "feature_names = df.columns.to_list()[:-1]\n",
    "\n",
    "print(\"Whole data size: \", len(df))\n",
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "val_size = int(0.15 * len(df))\n",
    "test_size = int(0.15 * len(df))\n",
    "\n",
    "print(f\"Sizes for different datasets are: Train {train_size}, Test {test_size} and Validation {val_size}.\")\n",
    "\n",
    "train_dataframe = df[:train_size]\n",
    "test_dataframe = df[train_size:]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ed463",
   "metadata": {},
   "source": [
    "<a name = 'preprocessing'></a>\n",
    "\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ce651",
   "metadata": {},
   "source": [
    "* We first look at the features of the dataset and its description, i.e. the metadata.\n",
    "* Next, we determine which features are categorical features and which are numerical features.\n",
    "* For categorical features, we will use One-Hot encoding to represent its values and for numerical features, we will normalize it within the model.\n",
    "* The dataset is demarcated into (features, label) tuple.\n",
    "* Finally, the dataset is splitted into train-validation-test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f54461",
   "metadata": {},
   "source": [
    "## The features of the dataset and its respective description\n",
    "\n",
    "| Feature  | Description                                                    |\n",
    "|----------|----------------------------------------------------------------|\n",
    "| age      | age in years                                                   |\n",
    "| sex      | (1 = male; 0 = female)                                         |\n",
    "| cp       | chest pain type                                                |\n",
    "| trtbps   | resting blood pressure (in mm Hg on admission to the hospital) |\n",
    "| chol     | serum cholestoral in mg/dl                                     |\n",
    "| fbs      | (fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)     |\n",
    "| restecg  | resting electrocardiographic results                           |\n",
    "| thalachh | maximum heart rate achieved                                    |\n",
    "| exng     | exercise induced angina (1 = yes; 0 = no)                      |\n",
    "| oldpeak  | ST depression induced by exercise relative to rest             |\n",
    "| slp      | the slope of the peak exercise ST segment                      |\n",
    "| caa      | number of major vessels (0-3) colored by flourosopy            |\n",
    "| thall    | 3 = normal; 6 = fixed defect; 7 = reversable defect            |\n",
    "| output   | 1 (heart disease) or 0                                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500476a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:32.960890Z",
     "start_time": "2021-07-09T12:47:32.362016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use method `from_tensor_slices` to convert the dataframe into a tf.data.Dataset object.\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(dict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29496d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.006714Z",
     "start_time": "2021-07-09T12:47:32.965826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex :  [1 0]\n",
      "cp :  [3 2 1 0]\n",
      "fbs :  [1 0]\n",
      "restecg :  [0 1 2]\n",
      "exng :  [0 1]\n",
      "slp :  [0 2 1]\n",
      "caa :  [0 2 1 3 4]\n",
      "thall :  [1 2 3 0]\n",
      "output :  [1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sex': 2,\n",
       " 'cp': 4,\n",
       " 'fbs': 2,\n",
       " 'restecg': 3,\n",
       " 'exng': 2,\n",
       " 'slp': 3,\n",
       " 'caa': 5,\n",
       " 'thall': 4,\n",
       " 'output': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List out all the categorical features\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall', 'output']\n",
    "\n",
    "# For each of the categorical feature, we find out what are its unique values,\n",
    "# e.g. 'caa' is encoding with integers: 0, 1, 2, 3 and 4.\n",
    "# We will be able to use this information to specify the shape of the input tensor to the model later on.\n",
    "cat_feat_depth = {k:v for k, v in zip(categorical_features,\n",
    "                                      map(lambda x: len(df[x].unique()),\n",
    "                                          categorical_features))}\n",
    "\n",
    "for cat_feat in categorical_features:\n",
    "    print(cat_feat,': ', df[cat_feat].unique())\n",
    "    \n",
    "cat_feat_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c38ec3",
   "metadata": {},
   "source": [
    "## Transform the dataset\n",
    "\n",
    "* Categorical features are transformed using one-hot encoding, numerical features are not transformed (will be transformed within the model itself using the BatchNormalization layer).\n",
    "* The dataset is demarcated into the features and label tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad6df4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.021675Z",
     "start_time": "2021-07-09T12:47:33.008709Z"
    }
   },
   "outputs": [],
   "source": [
    "# We use a function that takes in a slice of tf.data.Dataset object and transform it according to the feature names.\n",
    "def transform_x(x):\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        \n",
    "        if feature in categorical_features:\n",
    "            # For categorical features, we one-hot encode it and the depth is specified by\n",
    "            # the 'cat_feat_depth' dictionary defined earlier.\n",
    "            x[feature] = tf.one_hot(x[feature],\n",
    "                                    depth=cat_feat_depth[feature],\n",
    "                                    dtype=tf.float32)\n",
    "            \n",
    "            x[feature] = tf.cast(x[feature],\n",
    "                                 dtype=tf.float32)\n",
    "            \n",
    "        else:\n",
    "            # For numerical feature, we leave it as it is.\n",
    "            # BatchNormalization layer defined in the model will normalize it.\n",
    "            x[feature] = tf.cast(x[feature],\n",
    "                                 dtype=tf.float32)\n",
    "    \n",
    "    # We apply one-hot encoding to the output as well.\n",
    "    x['output'] = tf.one_hot(x['output'],\n",
    "                             depth=cat_feat_depth['output'],\n",
    "                             dtype=tf.int32)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80152cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.549907Z",
     "start_time": "2021-07-09T12:47:33.024667Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using the 'map' method, we are able to transform the dataset.\n",
    "full_dataset = full_dataset.map(transform_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff9b157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.580823Z",
     "start_time": "2021-07-09T12:47:33.559072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       " 'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'output': TensorSpec(shape=(2,), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The method 'element_spec' will show us the properties of the dataset.\n",
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce74efcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.596919Z",
     "start_time": "2021-07-09T12:47:33.583815Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_feature_label(x):\n",
    "    features = {feature:x[feature] for feature in feature_names}\n",
    "    return (features, x['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7379c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.787129Z",
     "start_time": "2021-07-09T12:47:33.599771Z"
    }
   },
   "outputs": [],
   "source": [
    "# This line of code is to separate the features from the target label within the dataset.\n",
    "full_dataset = full_dataset.map(map_feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eda3cd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.925715Z",
     "start_time": "2021-07-09T12:47:33.790007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': {}, 'sex': {}, 'cp': {}, 'trtbps': {}, 'chol': {}, 'fbs': {}, 'restecg': {}, 'thalachh': {}, 'exng': {}, 'oldpeak': {}, 'slp': {}, 'caa': {}, 'thall': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': {'shape': 1, 'dtype': tf.float32},\n",
       " 'sex': {'shape': 2, 'dtype': tf.float32},\n",
       " 'cp': {'shape': 4, 'dtype': tf.float32},\n",
       " 'trtbps': {'shape': 1, 'dtype': tf.float32},\n",
       " 'chol': {'shape': 1, 'dtype': tf.float32},\n",
       " 'fbs': {'shape': 2, 'dtype': tf.float32},\n",
       " 'restecg': {'shape': 3, 'dtype': tf.float32},\n",
       " 'thalachh': {'shape': 1, 'dtype': tf.float32},\n",
       " 'exng': {'shape': 2, 'dtype': tf.float32},\n",
       " 'oldpeak': {'shape': 1, 'dtype': tf.float32},\n",
       " 'slp': {'shape': 3, 'dtype': tf.float32},\n",
       " 'caa': {'shape': 5, 'dtype': tf.float32},\n",
       " 'thall': {'shape': 4, 'dtype': tf.float32}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 'feature_shape_dtype' is a dictionary which is prepared for later use in the create_model_inputs function\n",
    "# which will create the Input layers corresponding to each feature to the model.\n",
    "feature_shape_dtype = {feature: dict() for feature in feature_names}\n",
    "print(feature_shape_dtype)\n",
    "\n",
    "for x in full_dataset.take(1):\n",
    "    \n",
    "    q = x[0]\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        \n",
    "        feature_shape_dtype[feature]['shape'] = int(cat_feat_depth[feature]) if feature in cat_feat_depth.keys() else 1\n",
    "        feature_shape_dtype[feature]['dtype'] = q[feature].dtype\n",
    "        \n",
    "feature_shape_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1835b3b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:33.956636Z",
     "start_time": "2021-07-09T12:47:33.930704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87567335",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train-validation-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d270db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:34.033429Z",
     "start_time": "2021-07-09T12:47:34.010490Z"
    }
   },
   "outputs": [],
   "source": [
    "# A convenient function to split the entire dataset into train-test-validation sets using their corresponding sizes.\n",
    "def dataset_to_train_val_test(dataset, train_size, val_size, test_size):\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size = len(df))\n",
    "    train_dataset = dataset.take(train_size).batch(train_size)\n",
    "    test_dataset = dataset.skip(train_size)\n",
    "    val_dataset = dataset.skip(val_size).batch(val_size)\n",
    "    test_dataset = dataset.take(test_size).batch(test_size)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b366d1fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:34.049477Z",
     "start_time": "2021-07-09T12:47:34.036420Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset_to_train_val_test(full_dataset,\n",
    "                                                                     train_size,\n",
    "                                                                     val_size,\n",
    "                                                                     test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5293ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:34.064948Z",
     "start_time": "2021-07-09T12:47:34.051381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(None, 2), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f6ab0",
   "metadata": {},
   "source": [
    "The following codes help one to visually inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea7f9311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:34.252192Z",
     "start_time": "2021-07-09T12:47:34.069880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([62., 58., 42., 60., 55., 58., 77., 58., 63., 44., 54., 61., 51.,\n",
      "       58., 47., 45., 56., 59., 54., 60., 57., 45., 55., 57., 52., 58.,\n",
      "       56., 57., 43., 63., 58., 39., 59., 57., 71., 44., 59., 46., 62.,\n",
      "       63., 51., 57., 41., 35., 34.], dtype=float32)>, 'sex': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.]], dtype=float32)>, 'cp': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.]], dtype=float32)>, 'trtbps': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([120., 112., 120., 102., 132., 100., 125., 114., 145., 120., 108.,\n",
      "       130., 110., 120., 112., 115., 125., 150., 150., 125., 128., 110.,\n",
      "       130., 120., 120., 100., 130., 110., 120., 108., 146., 118., 138.,\n",
      "       150., 112., 120., 160., 150., 130., 130., 140., 150., 120., 122.,\n",
      "       118.], dtype=float32)>, 'chol': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([267., 230., 209., 318., 342., 234., 304., 318., 233., 263., 267.,\n",
      "       330., 175., 340., 204., 260., 249., 212., 232., 258., 303., 264.,\n",
      "       262., 354., 325., 248., 221., 335., 177., 269., 218., 219., 271.,\n",
      "       126., 149., 169., 273., 231., 231., 254., 298., 168., 157., 192.,\n",
      "       182.], dtype=float32)>, 'fbs': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32)>, 'restecg': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.]], dtype=float32)>, 'thalachh': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([ 99., 165., 173., 160., 166., 156., 162., 140., 150., 173., 167.,\n",
      "       169., 123., 172., 143., 185., 144., 157., 165., 141., 159., 132.,\n",
      "       155., 163., 172., 122., 163., 143., 120., 169., 105., 140., 182.,\n",
      "       173., 125., 144., 125., 147., 146., 147., 122., 174., 182., 174.,\n",
      "       174.], dtype=float32)>, 'exng': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32)>, 'oldpeak': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([1.8, 2.5, 0. , 0. , 1.2, 0.1, 0. , 4.4, 2.3, 0. , 0. , 0. , 0.6,\n",
      "       0. , 0.1, 0. , 1.2, 1.6, 1.6, 2.8, 0. , 1.2, 0. , 0.6, 0.2, 1. ,\n",
      "       0. , 3. , 2.5, 1.8, 2. , 1.2, 0. , 0.2, 1.6, 2.8, 0. , 3.6, 1.8,\n",
      "       1.4, 4.2, 1.6, 0. , 0. , 0. ], dtype=float32)>, 'slp': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.]], dtype=float32)>, 'caa': <tf.Tensor: shape=(45, 5), dtype=float32, numpy=\n",
      "array([[0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.]], dtype=float32)>, 'thall': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.]], dtype=float32)>}\n",
      "---------------\n",
      "tf.Tensor(\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]], shape=(45, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_dataset.take(1):\n",
    "    print(x)\n",
    "    print('-'*15)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ce2a3",
   "metadata": {},
   "source": [
    "<a name = 'models'></a>\n",
    "\n",
    "# Creation of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b8a00",
   "metadata": {},
   "source": [
    "The `create_model_inputs` function helps to create the Input layers to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10aa3b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:34.298748Z",
     "start_time": "2021-07-09T12:47:34.256705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'sex': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'sex')>,\n",
       " 'cp': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'cp')>,\n",
       " 'trtbps': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'trtbps')>,\n",
       " 'chol': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'chol')>,\n",
       " 'fbs': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'fbs')>,\n",
       " 'restecg': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'restecg')>,\n",
       " 'thalachh': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'thalachh')>,\n",
       " 'exng': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'exng')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'oldpeak')>,\n",
       " 'slp': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'slp')>,\n",
       " 'caa': <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'caa')>,\n",
       " 'thall': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'thall')>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model_inputs(feature_names = feature_names): \n",
    "    inputs = {}\n",
    "    for feature_name in feature_names:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(feature_shape_dtype[feature_name]['shape'],),\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n",
    "\n",
    "create_model_inputs(feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a230b97",
   "metadata": {},
   "source": [
    "## Definition of the BNN model\n",
    "\n",
    "The BNN model is defined here.\n",
    "\n",
    "* The loss is defined to be the negative log-likelihood ([Reference](http://legacydirs.umiacs.umd.edu/~xyang35/files/understanding-variational-lower.pdf)).\n",
    "* The BNN is made up of 3 layers, each with currently unspecified number of neurons.\n",
    "* The number of neurons will be found through iteration using Keras Tuner.\n",
    "\n",
    "The architecture of the BNN is shown below with `hidden_units = [32, 32, 32]` where each element in the list is the number of neurons in the i-th layer where i is the index of the element.\n",
    "\n",
    "![BNN Model Architecture](.\\assets\\bnn_model_image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e84db4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:34.328849Z",
     "start_time": "2021-07-09T12:47:34.302590Z"
    }
   },
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "def create_bnn_model(train_size):\n",
    "    \n",
    "    divergence_fn = lambda q, p, _:tfd.kl_divergence(q, p) / train_size\n",
    "    \n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseReparameterization layer.\n",
    "    for units in hidden_units: # hidden_unit: List[Int, Int, Int]\n",
    "        features_ = tfpl.DenseReparameterization(\n",
    "            units = units, activation = 'relu',\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "    \n",
    "    distribution_params = tfpl.DenseReparameterization(\n",
    "            units = tfp.layers.OneHotCategorical.params_size(2), activation=None,\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "\n",
    "    outputs = tfp.layers.OneHotCategorical(2,\n",
    "                                          convert_to_tensor_fn=tfd.Distribution.mode)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3bc7b5",
   "metadata": {},
   "source": [
    "The architecture of the DNN is shown below with `hidden_units = [32, 32, 32]`.\n",
    "\n",
    "![DNN Model Architecture](.\\assets\\dnn_model_image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bee8bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:34.359441Z",
     "start_time": "2021-07-09T12:47:34.333506Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_nn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "    \n",
    "    for units in hidden_units:\n",
    "        features_ = tf.keras.layers.Dense(\n",
    "            units=units,\n",
    "            activation = 'relu')(features_)\n",
    "        \n",
    "    outputs = tf.keras.layers.Dense(2,\n",
    "                                    activation = 'softmax')(features_)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc049f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:38.964178Z",
     "start_time": "2021-07-09T12:47:38.951166Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(model, loss, train_dataset,val_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics = ['accuracy'],\n",
    "        #experimental_run_tf_function=False\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=val_dataset\n",
    "             )\n",
    "    \n",
    "    print(\"Model training finished.\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(train_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Train loss: {round(loss, 3)}, train accuracy: {round(accuracy, 3)}.\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(test_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Test loss: {round(loss, 3)}, test accuracy: {round(accuracy, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0afa936",
   "metadata": {},
   "source": [
    "<a name='tuner'></a>\n",
    "\n",
    "# Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d180a6",
   "metadata": {},
   "source": [
    "Here, we use [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner) to do a hyperparameter search for the number of neurons in each of the 3 layers and the learning rate for the RMSProp optimizer.\n",
    "\n",
    "* `hp.Choice(f'units_{_}',values: List[Int, Int, Int])` is used to specify the possible number of neurons in each layer. I.e., in each layer, the number of neurons can be 8, 16 or 32 and these are explored by Keras Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "250729d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:41.421431Z",
     "start_time": "2021-07-09T12:47:41.394969Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_bnn_model(hp):\n",
    "\n",
    "    divergence_fn = lambda q, p, _:tfd.kl_divergence(q, p) / train_size\n",
    "    \n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "    \n",
    "    # Create hidden layers with weight uncertainty using the DenseReparameterization layer.\n",
    "    for _ in range(3): # 3 layers\n",
    "        features_ = tfpl.DenseReparameterization(\n",
    "            units = hp.Choice(f'units_{_}',values=[8, 16, 32]), activation='relu',\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "    \n",
    "    distribution_params = tfpl.DenseReparameterization(\n",
    "            units = tfp.layers.OneHotCategorical.params_size(2), activation=None,\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "\n",
    "    outputs = tfp.layers.OneHotCategorical(2,\n",
    "                                          convert_to_tensor_fn=tfd.Distribution.mode)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=hp.Choice(\"learning_rate\",\n",
    "                                                                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss=lambda y_true, y_pred: -y_pred.log_prob(y_true),\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e36edc",
   "metadata": {},
   "source": [
    "* A [`RandomSearch`](https://keras.io/api/keras_tuner/tuners/random/#randomsearch-class) strategy is chosen to conduct the hyperparameter search.\n",
    "* The results are stored in `.\\models\\bnn_model_hp_search`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f951e97e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:36:39.521122Z",
     "start_time": "2021-07-09T13:36:37.664748Z"
    }
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_bnn_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    directory=os.path.join('.','models','bnn_model_hp_search'),\n",
    "    project_name=\"bnn_model_hp_search\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c569422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:36:40.260279Z",
     "start_time": "2021-07-09T13:36:40.245658Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893383a",
   "metadata": {},
   "source": [
    "* Each trial will run maximally 500 epochs of the model training with a specified set of hyperparameters.\n",
    "* [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) is used to shorten the search time in each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fc786fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:53:24.561943Z",
     "start_time": "2021-07-09T13:36:40.768884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 33s]\n",
      "val_accuracy: 0.6162790656089783\n",
      "\n",
      "Best val_accuracy So Far: 0.9534883499145508\n",
      "Total elapsed time: 00h 16m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_dataset,\n",
    "             epochs=500,\n",
    "             validation_data=val_dataset,\n",
    "            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e0b263",
   "metadata": {},
   "source": [
    "* We can then print a summary of the trials and their results using `results_summary()`.\n",
    "* We can get a list of the best models using `get_best_models(num_models: Int)` and in this case, we specify `num_models` to be 1.\n",
    "* We then use this model to evaluate the `test_dataset` and we find that the accuracy is 0.953."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae8e3974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:54:19.935082Z",
     "start_time": "2021-07-09T13:54:19.915625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\models\\bnn_model_hp_search\\bnn_model_hp_search\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "units_1: 32\n",
      "units_2: 32\n",
      "learning_rate: 0.001\n",
      "Score: 0.9534883499145508\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "units_1: 16\n",
      "units_2: 8\n",
      "learning_rate: 0.001\n",
      "Score: 0.934108555316925\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 16\n",
      "units_1: 32\n",
      "units_2: 8\n",
      "learning_rate: 0.001\n",
      "Score: 0.930232584476471\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 8\n",
      "units_1: 16\n",
      "units_2: 16\n",
      "learning_rate: 0.001\n",
      "Score: 0.9108527302742004\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 8\n",
      "units_1: 32\n",
      "units_2: 16\n",
      "learning_rate: 0.01\n",
      "Score: 0.8759689927101135\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 16\n",
      "units_1: 32\n",
      "units_2: 16\n",
      "learning_rate: 0.01\n",
      "Score: 0.8100775480270386\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 16\n",
      "units_1: 16\n",
      "units_2: 32\n",
      "learning_rate: 0.0001\n",
      "Score: 0.6395348906517029\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "units_1: 8\n",
      "units_2: 32\n",
      "learning_rate: 0.0001\n",
      "Score: 0.6162790656089783\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "units_1: 8\n",
      "units_2: 16\n",
      "learning_rate: 0.0001\n",
      "Score: 0.6085271239280701\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "units_1: 16\n",
      "units_2: 16\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5813953280448914\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cf965f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:54:37.463331Z",
     "start_time": "2021-07-09T13:54:35.708970Z"
    }
   },
   "outputs": [],
   "source": [
    "[bnn_model_full] = tuner.get_best_models(num_models=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ba79fab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:55:18.682644Z",
     "start_time": "2021-07-09T13:55:15.437858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 32.9332 - accuracy: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[32.933223724365234, 0.9528301954269409]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnn_model_full.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e279764",
   "metadata": {},
   "source": [
    "<a name = 'training'></a>\n",
    "\n",
    "# Training and Evaluation of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee0bff",
   "metadata": {},
   "source": [
    "* We specify the best hyperparameters and train both the DNN and BNN models for 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c15940bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:56:40.860870Z",
     "start_time": "2021-07-09T13:56:40.851893Z"
    }
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "\n",
    "hidden_units = [32, 32, 32]\n",
    "\n",
    "feature_names = ['age', 'sex', 'cp',\n",
    "                 'trtbps', 'chol', 'fbs',\n",
    "                 'restecg', 'thalachh', 'exng',\n",
    "                 'oldpeak', 'slp', 'caa', 'thall']\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a40bd",
   "metadata": {},
   "source": [
    "* Here, we note that both the train and test accuracy are 1.0, which is a clear result of overfitting, even on the test data due to the small size of the dataset.\n",
    "* BNN can be used as a solution to prevent this overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40f6c2b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:56:41.825830Z",
     "start_time": "2021-07-09T13:56:41.662266Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_model_full = create_nn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1abc0979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:04:15.482267Z",
     "start_time": "2021-07-09T13:56:42.850435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7603 - accuracy: 0.4670 - val_loss: 2.5422 - val_accuracy: 0.5388\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.6784 - accuracy: 0.5991 - val_loss: 2.2931 - val_accuracy: 0.5271\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.6519 - accuracy: 0.6462 - val_loss: 2.1227 - val_accuracy: 0.5310\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.6167 - accuracy: 0.6887 - val_loss: 1.5834 - val_accuracy: 0.5271\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.6029 - accuracy: 0.7028 - val_loss: 1.5533 - val_accuracy: 0.5465\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.5611 - accuracy: 0.7783 - val_loss: 1.6544 - val_accuracy: 0.5426\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.5593 - accuracy: 0.7736 - val_loss: 1.3397 - val_accuracy: 0.5426\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.5273 - accuracy: 0.8113 - val_loss: 1.3813 - val_accuracy: 0.5504\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.5188 - accuracy: 0.7925 - val_loss: 1.2828 - val_accuracy: 0.5698\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.5045 - accuracy: 0.8255 - val_loss: 1.2080 - val_accuracy: 0.5736\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.4826 - accuracy: 0.8066 - val_loss: 1.2838 - val_accuracy: 0.5620\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.4724 - accuracy: 0.8066 - val_loss: 1.3192 - val_accuracy: 0.5504\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.4587 - accuracy: 0.8396 - val_loss: 1.1578 - val_accuracy: 0.5581\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.4532 - accuracy: 0.8491 - val_loss: 1.0541 - val_accuracy: 0.5620\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.4135 - accuracy: 0.8632 - val_loss: 1.1575 - val_accuracy: 0.5581\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.4319 - accuracy: 0.8396 - val_loss: 1.1360 - val_accuracy: 0.5543\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.4017 - accuracy: 0.8585 - val_loss: 1.0773 - val_accuracy: 0.5698\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4026 - accuracy: 0.8585 - val_loss: 1.0883 - val_accuracy: 0.5620\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.3913 - accuracy: 0.8774 - val_loss: 1.0057 - val_accuracy: 0.5853\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.3832 - accuracy: 0.8821 - val_loss: 0.9678 - val_accuracy: 0.5814\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.3866 - accuracy: 0.8585 - val_loss: 0.9595 - val_accuracy: 0.5891\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.3734 - accuracy: 0.8538 - val_loss: 0.8441 - val_accuracy: 0.6124\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.3759 - accuracy: 0.8726 - val_loss: 0.8598 - val_accuracy: 0.6124\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.3394 - accuracy: 0.8821 - val_loss: 0.8784 - val_accuracy: 0.6124\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.3297 - accuracy: 0.8774 - val_loss: 0.9219 - val_accuracy: 0.5969\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.3456 - accuracy: 0.8774 - val_loss: 0.8084 - val_accuracy: 0.6279\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.3354 - accuracy: 0.8726 - val_loss: 0.9421 - val_accuracy: 0.5853\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.3422 - accuracy: 0.8726 - val_loss: 0.9288 - val_accuracy: 0.6085\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.3384 - accuracy: 0.8726 - val_loss: 0.8371 - val_accuracy: 0.6047\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.3047 - accuracy: 0.9104 - val_loss: 0.8377 - val_accuracy: 0.6047\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.3179 - accuracy: 0.8821 - val_loss: 0.7503 - val_accuracy: 0.6589\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.3395 - accuracy: 0.8679 - val_loss: 0.7750 - val_accuracy: 0.6434\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.3270 - accuracy: 0.8821 - val_loss: 0.6591 - val_accuracy: 0.6783\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.3127 - accuracy: 0.8774 - val_loss: 0.6407 - val_accuracy: 0.7016\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.3325 - accuracy: 0.8726 - val_loss: 0.6590 - val_accuracy: 0.6860\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.3003 - accuracy: 0.9057 - val_loss: 0.6456 - val_accuracy: 0.6899\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.2827 - accuracy: 0.9057 - val_loss: 0.6150 - val_accuracy: 0.7093\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.2654 - accuracy: 0.9104 - val_loss: 0.6481 - val_accuracy: 0.7054\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.2807 - accuracy: 0.9151 - val_loss: 0.5887 - val_accuracy: 0.7209\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.2596 - accuracy: 0.9151 - val_loss: 0.6129 - val_accuracy: 0.7287\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.2678 - accuracy: 0.9104 - val_loss: 0.6247 - val_accuracy: 0.7093\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.2616 - accuracy: 0.9198 - val_loss: 0.6254 - val_accuracy: 0.7093\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.2721 - accuracy: 0.9104 - val_loss: 0.6366 - val_accuracy: 0.7093\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.2725 - accuracy: 0.8915 - val_loss: 0.6234 - val_accuracy: 0.7132\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.2620 - accuracy: 0.9009 - val_loss: 0.5582 - val_accuracy: 0.7403\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.2563 - accuracy: 0.9104 - val_loss: 0.5654 - val_accuracy: 0.7481\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.2627 - accuracy: 0.9198 - val_loss: 0.5168 - val_accuracy: 0.7868\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.2627 - accuracy: 0.9151 - val_loss: 0.5679 - val_accuracy: 0.7519\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.2311 - accuracy: 0.9151 - val_loss: 0.5998 - val_accuracy: 0.7248\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.2224 - accuracy: 0.9340 - val_loss: 0.5002 - val_accuracy: 0.7829\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.2252 - accuracy: 0.9340 - val_loss: 0.5179 - val_accuracy: 0.7791\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.2560 - accuracy: 0.9198 - val_loss: 0.4887 - val_accuracy: 0.7713\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.2163 - accuracy: 0.9481 - val_loss: 0.5552 - val_accuracy: 0.7636\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.2290 - accuracy: 0.9434 - val_loss: 0.5521 - val_accuracy: 0.7558\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2410 - accuracy: 0.9104 - val_loss: 0.5443 - val_accuracy: 0.7674\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.2386 - accuracy: 0.9198 - val_loss: 0.5585 - val_accuracy: 0.7636\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.2312 - accuracy: 0.9151 - val_loss: 0.5452 - val_accuracy: 0.7829\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.2321 - accuracy: 0.9245 - val_loss: 0.5404 - val_accuracy: 0.7791\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.2231 - accuracy: 0.9292 - val_loss: 0.5483 - val_accuracy: 0.7713\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.2221 - accuracy: 0.9340 - val_loss: 0.5009 - val_accuracy: 0.7946\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.2036 - accuracy: 0.9434 - val_loss: 0.5666 - val_accuracy: 0.7713\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.2201 - accuracy: 0.9292 - val_loss: 0.5154 - val_accuracy: 0.7829\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.2036 - accuracy: 0.9434 - val_loss: 0.5304 - val_accuracy: 0.7868\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1968 - accuracy: 0.9387 - val_loss: 0.5396 - val_accuracy: 0.7868\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1999 - accuracy: 0.9434 - val_loss: 0.4650 - val_accuracy: 0.8101\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1813 - accuracy: 0.9387 - val_loss: 0.4719 - val_accuracy: 0.8023\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.2052 - accuracy: 0.9340 - val_loss: 0.5181 - val_accuracy: 0.7907\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2049 - accuracy: 0.9434 - val_loss: 0.4663 - val_accuracy: 0.8062\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.1956 - accuracy: 0.9481 - val_loss: 0.4268 - val_accuracy: 0.8217\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.1890 - accuracy: 0.9387 - val_loss: 0.4393 - val_accuracy: 0.8062\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1755 - accuracy: 0.9575 - val_loss: 0.4718 - val_accuracy: 0.7946\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.1942 - accuracy: 0.9387 - val_loss: 0.4471 - val_accuracy: 0.8101\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1907 - accuracy: 0.9387 - val_loss: 0.4700 - val_accuracy: 0.8140\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1531 - accuracy: 0.9575 - val_loss: 0.4553 - val_accuracy: 0.8178\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1686 - accuracy: 0.9528 - val_loss: 0.4913 - val_accuracy: 0.7868\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1727 - accuracy: 0.9481 - val_loss: 0.4437 - val_accuracy: 0.8062\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1898 - accuracy: 0.9387 - val_loss: 0.4245 - val_accuracy: 0.8140\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1752 - accuracy: 0.9481 - val_loss: 0.4078 - val_accuracy: 0.8140\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1749 - accuracy: 0.9528 - val_loss: 0.4234 - val_accuracy: 0.8023\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.1574 - accuracy: 0.9528 - val_loss: 0.4258 - val_accuracy: 0.8295\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1655 - accuracy: 0.9528 - val_loss: 0.4117 - val_accuracy: 0.8256\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1658 - accuracy: 0.9528 - val_loss: 0.4346 - val_accuracy: 0.8062\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1475 - accuracy: 0.9575 - val_loss: 0.4094 - val_accuracy: 0.8062\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1666 - accuracy: 0.9481 - val_loss: 0.4308 - val_accuracy: 0.8140\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.1548 - accuracy: 0.9434 - val_loss: 0.4451 - val_accuracy: 0.7984\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1513 - accuracy: 0.9575 - val_loss: 0.4069 - val_accuracy: 0.8256\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1290 - accuracy: 0.9575 - val_loss: 0.4476 - val_accuracy: 0.8140\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1388 - accuracy: 0.9575 - val_loss: 0.4011 - val_accuracy: 0.8140\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.1204 - accuracy: 0.9623 - val_loss: 0.4355 - val_accuracy: 0.8140\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1549 - accuracy: 0.9528 - val_loss: 0.3660 - val_accuracy: 0.8295\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.1675 - accuracy: 0.9481 - val_loss: 0.4586 - val_accuracy: 0.8101\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1623 - accuracy: 0.9481 - val_loss: 0.4092 - val_accuracy: 0.7907\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1551 - accuracy: 0.9481 - val_loss: 0.4031 - val_accuracy: 0.8178\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.1396 - accuracy: 0.9670 - val_loss: 0.3973 - val_accuracy: 0.8256\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.1397 - accuracy: 0.9575 - val_loss: 0.3883 - val_accuracy: 0.8023\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1231 - accuracy: 0.9764 - val_loss: 0.3953 - val_accuracy: 0.8101\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1175 - accuracy: 0.9623 - val_loss: 0.4106 - val_accuracy: 0.8178\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.1472 - accuracy: 0.9434 - val_loss: 0.3868 - val_accuracy: 0.8178\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.1226 - accuracy: 0.9717 - val_loss: 0.4030 - val_accuracy: 0.8062\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1065 - accuracy: 0.9811 - val_loss: 0.3989 - val_accuracy: 0.8101\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.1374 - accuracy: 0.9575 - val_loss: 0.3648 - val_accuracy: 0.8140\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1244 - accuracy: 0.9623 - val_loss: 0.3753 - val_accuracy: 0.8178\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.1324 - accuracy: 0.9575 - val_loss: 0.3817 - val_accuracy: 0.8062\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.1002 - accuracy: 0.9717 - val_loss: 0.3866 - val_accuracy: 0.8140\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0977 - accuracy: 0.9906 - val_loss: 0.3541 - val_accuracy: 0.8295\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.1218 - accuracy: 0.9670 - val_loss: 0.3637 - val_accuracy: 0.8256\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1177 - accuracy: 0.9528 - val_loss: 0.4108 - val_accuracy: 0.8140\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.1185 - accuracy: 0.9717 - val_loss: 0.3524 - val_accuracy: 0.8333\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1073 - accuracy: 0.9670 - val_loss: 0.3729 - val_accuracy: 0.8217\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1037 - accuracy: 0.9717 - val_loss: 0.3858 - val_accuracy: 0.8217\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1129 - accuracy: 0.9764 - val_loss: 0.3792 - val_accuracy: 0.8256\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1049 - accuracy: 0.9717 - val_loss: 0.3611 - val_accuracy: 0.8295\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1008 - accuracy: 0.9670 - val_loss: 0.3686 - val_accuracy: 0.8372\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.1037 - accuracy: 0.9623 - val_loss: 0.3863 - val_accuracy: 0.8023\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1097 - accuracy: 0.9623 - val_loss: 0.3551 - val_accuracy: 0.8295\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1071 - accuracy: 0.9670 - val_loss: 0.3385 - val_accuracy: 0.8372\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1025 - accuracy: 0.9670 - val_loss: 0.3463 - val_accuracy: 0.8488\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.1096 - accuracy: 0.9623 - val_loss: 0.3567 - val_accuracy: 0.8256\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0910 - accuracy: 0.9764 - val_loss: 0.3504 - val_accuracy: 0.8450\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.0920 - accuracy: 0.9811 - val_loss: 0.3584 - val_accuracy: 0.8295\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0845 - accuracy: 0.9764 - val_loss: 0.3759 - val_accuracy: 0.8295\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.0778 - accuracy: 0.9858 - val_loss: 0.3527 - val_accuracy: 0.8372\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0855 - accuracy: 0.9811 - val_loss: 0.3669 - val_accuracy: 0.8295\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0762 - accuracy: 0.9811 - val_loss: 0.3304 - val_accuracy: 0.8527\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.0929 - accuracy: 0.9670 - val_loss: 0.3094 - val_accuracy: 0.8566\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0838 - accuracy: 0.9764 - val_loss: 0.3487 - val_accuracy: 0.8450\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0764 - accuracy: 0.9717 - val_loss: 0.3388 - val_accuracy: 0.8566\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0759 - accuracy: 0.9764 - val_loss: 0.3504 - val_accuracy: 0.8450\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0870 - accuracy: 0.9764 - val_loss: 0.3021 - val_accuracy: 0.8682\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0866 - accuracy: 0.9811 - val_loss: 0.3520 - val_accuracy: 0.8411\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0854 - accuracy: 0.9717 - val_loss: 0.3250 - val_accuracy: 0.8682\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.0748 - accuracy: 0.9811 - val_loss: 0.3377 - val_accuracy: 0.8488\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.0611 - accuracy: 0.9906 - val_loss: 0.3218 - val_accuracy: 0.8721\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0684 - accuracy: 0.9858 - val_loss: 0.3350 - val_accuracy: 0.8450\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0660 - accuracy: 0.9858 - val_loss: 0.2901 - val_accuracy: 0.8721\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0697 - accuracy: 0.9764 - val_loss: 0.3189 - val_accuracy: 0.8566\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0521 - accuracy: 0.9953 - val_loss: 0.3376 - val_accuracy: 0.8566\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0668 - accuracy: 0.9858 - val_loss: 0.2942 - val_accuracy: 0.8798\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0830 - accuracy: 0.9764 - val_loss: 0.3192 - val_accuracy: 0.8605\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0795 - accuracy: 0.9764 - val_loss: 0.3213 - val_accuracy: 0.8721\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0653 - accuracy: 0.9764 - val_loss: 0.3168 - val_accuracy: 0.8760\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0711 - accuracy: 0.9858 - val_loss: 0.2734 - val_accuracy: 0.8837\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0564 - accuracy: 0.9906 - val_loss: 0.3159 - val_accuracy: 0.8760\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0610 - accuracy: 0.9858 - val_loss: 0.3368 - val_accuracy: 0.8566\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.0651 - accuracy: 0.9858 - val_loss: 0.3060 - val_accuracy: 0.8682\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0526 - accuracy: 0.9906 - val_loss: 0.3051 - val_accuracy: 0.8760\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0676 - accuracy: 0.9764 - val_loss: 0.3302 - val_accuracy: 0.8682\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0556 - accuracy: 0.9858 - val_loss: 0.2916 - val_accuracy: 0.8837\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.0614 - accuracy: 0.9906 - val_loss: 0.2897 - val_accuracy: 0.8760\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0531 - accuracy: 0.9858 - val_loss: 0.2832 - val_accuracy: 0.8876\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0473 - accuracy: 0.9811 - val_loss: 0.3269 - val_accuracy: 0.8682\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.3142 - val_accuracy: 0.8682\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0505 - accuracy: 0.9953 - val_loss: 0.3097 - val_accuracy: 0.8837\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0705 - accuracy: 0.9906 - val_loss: 0.3049 - val_accuracy: 0.8760\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0632 - accuracy: 0.9764 - val_loss: 0.2739 - val_accuracy: 0.8876\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0458 - accuracy: 0.9953 - val_loss: 0.2993 - val_accuracy: 0.8760\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0492 - accuracy: 0.9953 - val_loss: 0.2885 - val_accuracy: 0.8721\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0497 - accuracy: 0.9906 - val_loss: 0.2838 - val_accuracy: 0.8798\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0521 - accuracy: 0.9953 - val_loss: 0.2990 - val_accuracy: 0.8798\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0527 - accuracy: 0.9953 - val_loss: 0.2899 - val_accuracy: 0.8915\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0526 - accuracy: 0.9906 - val_loss: 0.2679 - val_accuracy: 0.8953\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0547 - accuracy: 0.9906 - val_loss: 0.3069 - val_accuracy: 0.8682\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0457 - accuracy: 0.9953 - val_loss: 0.2873 - val_accuracy: 0.8798\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0410 - accuracy: 0.9953 - val_loss: 0.2481 - val_accuracy: 0.8953\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0418 - accuracy: 0.9906 - val_loss: 0.2605 - val_accuracy: 0.8953\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0396 - accuracy: 0.9953 - val_loss: 0.2626 - val_accuracy: 0.8876\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0437 - accuracy: 0.9906 - val_loss: 0.2519 - val_accuracy: 0.8992\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.2623 - val_accuracy: 0.8953\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.8992\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0435 - accuracy: 0.9953 - val_loss: 0.2406 - val_accuracy: 0.8953\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0465 - accuracy: 0.9953 - val_loss: 0.2549 - val_accuracy: 0.8915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.0480 - accuracy: 0.9906 - val_loss: 0.2494 - val_accuracy: 0.8915\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.0425 - accuracy: 0.9953 - val_loss: 0.2410 - val_accuracy: 0.8915\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0463 - accuracy: 0.9953 - val_loss: 0.2565 - val_accuracy: 0.8915\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.8992\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0397 - accuracy: 0.9906 - val_loss: 0.2190 - val_accuracy: 0.9031\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0367 - accuracy: 0.9953 - val_loss: 0.2421 - val_accuracy: 0.8992\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0342 - accuracy: 0.9953 - val_loss: 0.2337 - val_accuracy: 0.8953\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.0379 - accuracy: 0.9906 - val_loss: 0.2384 - val_accuracy: 0.8992\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0393 - accuracy: 0.9906 - val_loss: 0.2440 - val_accuracy: 0.8953\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.8992\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0360 - accuracy: 0.9953 - val_loss: 0.2206 - val_accuracy: 0.8953\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0339 - accuracy: 0.9953 - val_loss: 0.2284 - val_accuracy: 0.9109\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0328 - accuracy: 0.9953 - val_loss: 0.2070 - val_accuracy: 0.9147\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0349 - accuracy: 0.9953 - val_loss: 0.2316 - val_accuracy: 0.8876\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.8953\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.8915\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0354 - accuracy: 0.9953 - val_loss: 0.2305 - val_accuracy: 0.8953\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0309 - accuracy: 0.9953 - val_loss: 0.1932 - val_accuracy: 0.9147\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0297 - accuracy: 0.9953 - val_loss: 0.2023 - val_accuracy: 0.9109\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0303 - accuracy: 0.9953 - val_loss: 0.2249 - val_accuracy: 0.9147\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9109\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0288 - accuracy: 0.9953 - val_loss: 0.1901 - val_accuracy: 0.9225\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9225\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0297 - accuracy: 0.9953 - val_loss: 0.1878 - val_accuracy: 0.9186\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0287 - accuracy: 0.9953 - val_loss: 0.2028 - val_accuracy: 0.9109\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0258 - accuracy: 0.9953 - val_loss: 0.1997 - val_accuracy: 0.9031\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0268 - accuracy: 0.9953 - val_loss: 0.1865 - val_accuracy: 0.9186\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.0261 - accuracy: 0.9953 - val_loss: 0.1803 - val_accuracy: 0.9225\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9302\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0238 - accuracy: 0.9953 - val_loss: 0.1703 - val_accuracy: 0.9264\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0249 - accuracy: 0.9953 - val_loss: 0.1841 - val_accuracy: 0.9109\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0264 - accuracy: 0.9953 - val_loss: 0.1911 - val_accuracy: 0.9225\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0258 - accuracy: 0.9953 - val_loss: 0.1513 - val_accuracy: 0.9302\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.1715 - val_accuracy: 0.9264\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.0212 - accuracy: 0.9953 - val_loss: 0.1467 - val_accuracy: 0.9380\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9264\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 0.1676 - val_accuracy: 0.9302\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9302\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9302\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9302\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.1340 - val_accuracy: 0.9457\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.1811 - val_accuracy: 0.9225\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0228 - accuracy: 0.9953 - val_loss: 0.1398 - val_accuracy: 0.9302\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0256 - accuracy: 0.9953 - val_loss: 0.1381 - val_accuracy: 0.9380\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.1454 - val_accuracy: 0.9380\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.1537 - val_accuracy: 0.9264\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9419\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.1183 - val_accuracy: 0.9419\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9457\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.1249 - val_accuracy: 0.9419\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9535\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9496\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0162 - accuracy: 0.9906 - val_loss: 0.1444 - val_accuracy: 0.9341\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9457\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.1104 - val_accuracy: 0.9535\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9380\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.1401 - val_accuracy: 0.9380\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9457\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9419\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.1122 - val_accuracy: 0.9496\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9496\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9496\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9574\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9535\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9419\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9612\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9574\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9496\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9535\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9496\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9457\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9651\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9651\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9690\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9690\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9651\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9651\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9690\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9612\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9535\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9612\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9690\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9651\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9651\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9690\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9690\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9729\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9690\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9729\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9535\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9767\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9729\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9729\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9690\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9884\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9767\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9767\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9806\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9922\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9806\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9884\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9884\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9767\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9845\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9884\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9922\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9884\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9961\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9961\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9961\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9961\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9961\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9961\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9961\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9884\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9961\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9961\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9961\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9961\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9961\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 8.7508e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 9.9569e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 9.6369e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 9.4236e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 9.7825e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 4.4320e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 8.7765e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 6.9623e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 7.0306e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 7.7767e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 8.2330e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 8.6225e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 9.2478e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 6.8026e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 7.3446e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 7.9733e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 5.5780e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 6.6718e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 5.6211e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 3.4217e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 5.0901e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 9.7372e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 5.5708e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 4.6533e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 4.8163e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 4.4181e-04 - accuracy: 1.0000 - val_loss: 8.8865e-04 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 7.4143e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 5.7214e-04 - accuracy: 1.0000 - val_loss: 8.3422e-04 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 4.0115e-04 - accuracy: 1.0000 - val_loss: 8.3635e-04 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 4.6551e-04 - accuracy: 1.0000 - val_loss: 8.9216e-04 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 9.5096e-04 - accuracy: 1.0000 - val_loss: 9.1244e-04 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 4.7494e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 4.5183e-04 - accuracy: 1.0000 - val_loss: 7.2741e-04 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 4.0393e-04 - accuracy: 1.0000 - val_loss: 7.3315e-04 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 3.7504e-04 - accuracy: 1.0000 - val_loss: 5.1284e-04 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 5.0393e-04 - accuracy: 1.0000 - val_loss: 6.4008e-04 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 3.1123e-04 - accuracy: 1.0000 - val_loss: 7.1737e-04 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 3.2458e-04 - accuracy: 1.0000 - val_loss: 6.3689e-04 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.8418e-04 - accuracy: 1.0000 - val_loss: 8.0515e-04 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 3.3779e-04 - accuracy: 1.0000 - val_loss: 5.7763e-04 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4.1174e-04 - accuracy: 1.0000 - val_loss: 5.4800e-04 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 2.7030e-04 - accuracy: 1.0000 - val_loss: 6.2106e-04 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 3.7630e-04 - accuracy: 1.0000 - val_loss: 5.7397e-04 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 3.1678e-04 - accuracy: 1.0000 - val_loss: 6.3702e-04 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 3.4502e-04 - accuracy: 1.0000 - val_loss: 5.7098e-04 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 2.2280e-04 - accuracy: 1.0000 - val_loss: 5.1369e-04 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 4.1345e-04 - accuracy: 1.0000 - val_loss: 5.6005e-04 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 3.6481e-04 - accuracy: 1.0000 - val_loss: 4.8933e-04 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.1401e-04 - accuracy: 1.0000 - val_loss: 4.0110e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2.8802e-04 - accuracy: 1.0000 - val_loss: 4.3764e-04 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 2.7252e-04 - accuracy: 1.0000 - val_loss: 4.5175e-04 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 2.5270e-04 - accuracy: 1.0000 - val_loss: 3.0660e-04 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 2.2407e-04 - accuracy: 1.0000 - val_loss: 3.9363e-04 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 2.6401e-04 - accuracy: 1.0000 - val_loss: 3.9247e-04 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 3.4558e-04 - accuracy: 1.0000 - val_loss: 2.2940e-04 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 2.3229e-04 - accuracy: 1.0000 - val_loss: 3.7204e-04 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 3.2714e-04 - accuracy: 1.0000 - val_loss: 3.5762e-04 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 2.9227e-04 - accuracy: 1.0000 - val_loss: 3.5392e-04 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 1.5801e-04 - accuracy: 1.0000 - val_loss: 2.9793e-04 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 1.2991e-04 - accuracy: 1.0000 - val_loss: 3.3217e-04 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 2.5360e-04 - accuracy: 1.0000 - val_loss: 2.6874e-04 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 2.5833e-04 - accuracy: 1.0000 - val_loss: 3.5397e-04 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 2.5943e-04 - accuracy: 1.0000 - val_loss: 3.0398e-04 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 2.5270e-04 - accuracy: 1.0000 - val_loss: 2.6494e-04 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.2743e-04 - accuracy: 1.0000 - val_loss: 3.2818e-04 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 2.0595e-04 - accuracy: 1.0000 - val_loss: 1.9967e-04 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 2.7513e-04 - accuracy: 1.0000 - val_loss: 1.7200e-04 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.2795e-04 - accuracy: 1.0000 - val_loss: 4.1616e-04 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 3.4564e-04 - accuracy: 1.0000 - val_loss: 4.9302e-04 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 2.0791e-04 - accuracy: 1.0000 - val_loss: 2.4882e-04 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.3732e-04 - accuracy: 1.0000 - val_loss: 2.1149e-04 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 9.1132e-05 - accuracy: 1.0000 - val_loss: 2.0044e-04 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1177e-04 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 2.0739e-04 - accuracy: 1.0000 - val_loss: 1.9153e-04 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.8507e-04 - accuracy: 1.0000 - val_loss: 1.8063e-04 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 1.4556e-04 - accuracy: 1.0000 - val_loss: 1.6318e-04 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.7832e-04 - accuracy: 1.0000 - val_loss: 1.7435e-04 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.9721e-04 - accuracy: 1.0000 - val_loss: 1.7246e-04 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 2.0774e-04 - accuracy: 1.0000 - val_loss: 1.3459e-04 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.5878e-04 - accuracy: 1.0000 - val_loss: 1.6244e-04 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.4606e-04 - accuracy: 1.0000 - val_loss: 1.6423e-04 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.1486e-04 - accuracy: 1.0000 - val_loss: 1.1090e-04 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 2.1972e-04 - accuracy: 1.0000 - val_loss: 1.3559e-04 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.7487e-04 - accuracy: 1.0000 - val_loss: 1.5480e-04 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.6426e-04 - accuracy: 1.0000 - val_loss: 1.5487e-04 - val_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.1380e-04 - accuracy: 1.0000 - val_loss: 1.4440e-04 - val_accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.3583e-04 - accuracy: 1.0000 - val_loss: 1.3743e-04 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.4172e-04 - accuracy: 1.0000 - val_loss: 1.0172e-04 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 9.2499e-05 - accuracy: 1.0000 - val_loss: 1.2210e-04 - val_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 1.4847e-04 - accuracy: 1.0000 - val_loss: 1.3250e-04 - val_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 9.0720e-05 - accuracy: 1.0000 - val_loss: 1.1891e-04 - val_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 7.9889e-05 - accuracy: 1.0000 - val_loss: 1.2620e-04 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.4013e-04 - accuracy: 1.0000 - val_loss: 1.2651e-04 - val_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 3.5444e-04 - accuracy: 1.0000 - val_loss: 1.4871e-04 - val_accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.8588e-04 - accuracy: 1.0000 - val_loss: 1.0314e-04 - val_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.2086e-04 - accuracy: 1.0000 - val_loss: 1.1882e-04 - val_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.3096e-04 - accuracy: 1.0000 - val_loss: 1.1360e-04 - val_accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.2150e-04 - accuracy: 1.0000 - val_loss: 8.1504e-05 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.0689e-04 - accuracy: 1.0000 - val_loss: 1.0257e-04 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.1346e-04 - accuracy: 1.0000 - val_loss: 8.0770e-05 - val_accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 9.6470e-05 - accuracy: 1.0000 - val_loss: 1.0542e-04 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.1213e-04 - accuracy: 1.0000 - val_loss: 9.7411e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 1.1997e-04 - accuracy: 1.0000 - val_loss: 1.0757e-04 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 8.4103e-05 - accuracy: 1.0000 - val_loss: 1.1065e-04 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.3785e-04 - accuracy: 1.0000 - val_loss: 8.7187e-05 - val_accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 8.7367e-05 - accuracy: 1.0000 - val_loss: 9.2266e-05 - val_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.7994e-04 - accuracy: 1.0000 - val_loss: 2.1030e-04 - val_accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 1.2523e-04 - accuracy: 1.0000 - val_loss: 7.8242e-05 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 7.0542e-05 - accuracy: 1.0000 - val_loss: 6.4746e-05 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 6.8303e-05 - accuracy: 1.0000 - val_loss: 6.1987e-05 - val_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 7.0793e-05 - accuracy: 1.0000 - val_loss: 7.7632e-05 - val_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 6.7313e-05 - accuracy: 1.0000 - val_loss: 7.0817e-05 - val_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 7.3560e-05 - accuracy: 1.0000 - val_loss: 8.3917e-05 - val_accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 5.9078e-05 - accuracy: 1.0000 - val_loss: 7.5917e-05 - val_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.5289e-04 - accuracy: 1.0000 - val_loss: 1.1816e-04 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 1.5469e-04 - accuracy: 1.0000 - val_loss: 7.9854e-05 - val_accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.3787e-04 - accuracy: 1.0000 - val_loss: 9.9237e-05 - val_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.3739e-04 - accuracy: 1.0000 - val_loss: 6.5756e-05 - val_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 9.2693e-05 - accuracy: 1.0000 - val_loss: 6.2325e-05 - val_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 8.3319e-05 - accuracy: 1.0000 - val_loss: 4.7089e-05 - val_accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 7.1024e-05 - accuracy: 1.0000 - val_loss: 4.9215e-05 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 4.1187e-05 - accuracy: 1.0000 - val_loss: 4.7398e-05 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 4.9814e-05 - accuracy: 1.0000 - val_loss: 4.3480e-05 - val_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 5.1744e-05 - accuracy: 1.0000 - val_loss: 5.2382e-05 - val_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 7.0159e-05 - accuracy: 1.0000 - val_loss: 4.1333e-05 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 3.6868e-05 - accuracy: 1.0000 - val_loss: 4.8329e-05 - val_accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 9.7477e-05 - accuracy: 1.0000 - val_loss: 1.0770e-04 - val_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.2293e-04 - accuracy: 1.0000 - val_loss: 4.3357e-05 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 6.5171e-05 - accuracy: 1.0000 - val_loss: 4.0422e-05 - val_accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 4.7484e-05 - accuracy: 1.0000 - val_loss: 3.4846e-05 - val_accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 9.5085e-05 - accuracy: 1.0000 - val_loss: 5.9629e-05 - val_accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 7.5293e-05 - accuracy: 1.0000 - val_loss: 8.7561e-05 - val_accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 5.7330e-05 - accuracy: 1.0000 - val_loss: 4.9781e-05 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 3.6246e-05 - accuracy: 1.0000 - val_loss: 4.1012e-05 - val_accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 4.5493e-05 - accuracy: 1.0000 - val_loss: 3.9135e-05 - val_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 7.3852e-05 - accuracy: 1.0000 - val_loss: 2.8290e-05 - val_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 4.6793e-05 - accuracy: 1.0000 - val_loss: 3.6249e-05 - val_accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 3.6746e-05 - accuracy: 1.0000 - val_loss: 3.3752e-05 - val_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 3.2349e-05 - accuracy: 1.0000 - val_loss: 3.1628e-05 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 2.1744e-05 - accuracy: 1.0000 - val_loss: 3.3663e-05 - val_accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.2433e-04 - accuracy: 1.0000 - val_loss: 1.3968e-04 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 7.4370e-04 - accuracy: 1.0000 - val_loss: 1.7428e-04 - val_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.8670e-04 - accuracy: 1.0000 - val_loss: 5.1320e-05 - val_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 2.6619e-04 - accuracy: 1.0000 - val_loss: 2.7147e-05 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 4.6451e-05 - accuracy: 1.0000 - val_loss: 2.7213e-05 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 2.4879e-05 - accuracy: 1.0000 - val_loss: 2.2054e-05 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 3.0710e-05 - accuracy: 1.0000 - val_loss: 2.7705e-05 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 3.4257e-05 - accuracy: 1.0000 - val_loss: 1.8505e-05 - val_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 4.2105e-05 - accuracy: 1.0000 - val_loss: 2.5717e-05 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.1785e-04 - accuracy: 1.0000 - val_loss: 3.7119e-05 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 4.1812e-05 - accuracy: 1.0000 - val_loss: 4.0944e-05 - val_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 4.9225e-05 - accuracy: 1.0000 - val_loss: 3.0040e-05 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 2.6229e-05 - accuracy: 1.0000 - val_loss: 3.2976e-05 - val_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 3.3445e-05 - accuracy: 1.0000 - val_loss: 2.8998e-05 - val_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.5239e-05 - accuracy: 1.0000 - val_loss: 2.8355e-05 - val_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 2.1367e-05 - accuracy: 1.0000 - val_loss: 2.7267e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 3.0868e-05 - accuracy: 1.0000 - val_loss: 2.8733e-05 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.7486e-05 - accuracy: 1.0000 - val_loss: 2.7099e-05 - val_accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 2.0645e-05 - accuracy: 1.0000 - val_loss: 2.6055e-05 - val_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 2.4725e-05 - accuracy: 1.0000 - val_loss: 2.3528e-05 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 3.9991e-05 - accuracy: 1.0000 - val_loss: 1.6360e-05 - val_accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.5772e-05 - accuracy: 1.0000 - val_loss: 2.5416e-05 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 3.2491e-05 - accuracy: 1.0000 - val_loss: 2.6473e-05 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 3.4278e-05 - accuracy: 1.0000 - val_loss: 2.2891e-05 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 6.3031e-05 - accuracy: 1.0000 - val_loss: 2.7914e-05 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 8.7467e-05 - accuracy: 1.0000 - val_loss: 3.0432e-05 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 8.7974e-05 - accuracy: 1.0000 - val_loss: 2.3614e-05 - val_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 2.0087e-05 - accuracy: 1.0000 - val_loss: 2.4029e-05 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 2.6129e-05 - accuracy: 1.0000 - val_loss: 1.8813e-05 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 6.4980e-05 - accuracy: 1.0000 - val_loss: 2.4399e-05 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 4.8187e-05 - accuracy: 1.0000 - val_loss: 1.7600e-05 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 2.7676e-05 - accuracy: 1.0000 - val_loss: 1.4961e-05 - val_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 3.0103e-05 - accuracy: 1.0000 - val_loss: 1.4207e-05 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.8334e-05 - accuracy: 1.0000 - val_loss: 1.8756e-05 - val_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 3.7917e-05 - accuracy: 1.0000 - val_loss: 1.6909e-05 - val_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.4955e-05 - accuracy: 1.0000 - val_loss: 1.6810e-05 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 2.1201e-05 - accuracy: 1.0000 - val_loss: 1.6280e-05 - val_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.9281e-05 - accuracy: 1.0000 - val_loss: 1.6311e-05 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 2.7070e-05 - accuracy: 1.0000 - val_loss: 9.6024e-06 - val_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 3.3634e-05 - accuracy: 1.0000 - val_loss: 1.1833e-05 - val_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 2.3081e-05 - accuracy: 1.0000 - val_loss: 1.4647e-05 - val_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.3448e-05 - accuracy: 1.0000 - val_loss: 1.3301e-05 - val_accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.2720e-05 - accuracy: 1.0000 - val_loss: 1.4364e-05 - val_accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 2.0636e-05 - accuracy: 1.0000 - val_loss: 1.3975e-05 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 2.2834e-05 - accuracy: 1.0000 - val_loss: 1.5766e-05 - val_accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 1.7797e-05 - accuracy: 1.0000 - val_loss: 1.2075e-05 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 2.1263e-05 - accuracy: 1.0000 - val_loss: 1.2704e-05 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 2.6079e-05 - accuracy: 1.0000 - val_loss: 1.9407e-05 - val_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.5777e-05 - accuracy: 1.0000 - val_loss: 1.5529e-05 - val_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.3023e-05 - accuracy: 1.0000 - val_loss: 1.1234e-05 - val_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 3.5053e-05 - accuracy: 1.0000 - val_loss: 1.5775e-05 - val_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 1.6635e-05 - accuracy: 1.0000 - val_loss: 1.1847e-05 - val_accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.4531e-05 - accuracy: 1.0000 - val_loss: 9.1822e-06 - val_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.7017e-05 - accuracy: 1.0000 - val_loss: 1.0954e-05 - val_accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.6062e-05 - accuracy: 1.0000 - val_loss: 7.5144e-06 - val_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.6484e-05 - accuracy: 1.0000 - val_loss: 1.1033e-05 - val_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 9.7536e-06 - accuracy: 1.0000 - val_loss: 1.1739e-05 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.7491e-05 - accuracy: 1.0000 - val_loss: 1.0059e-05 - val_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.9834e-05 - accuracy: 1.0000 - val_loss: 9.1023e-06 - val_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1.2562e-05 - accuracy: 1.0000 - val_loss: 9.7306e-06 - val_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.1997e-05 - accuracy: 1.0000 - val_loss: 8.6569e-06 - val_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.5588e-05 - accuracy: 1.0000 - val_loss: 9.2220e-06 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 9.5180e-06 - accuracy: 1.0000 - val_loss: 7.4959e-06 - val_accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1.3312e-05 - accuracy: 1.0000 - val_loss: 1.1862e-05 - val_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 9.1805e-06 - accuracy: 1.0000 - val_loss: 9.3577e-06 - val_accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 9.9994e-06 - accuracy: 1.0000 - val_loss: 4.1778e-06 - val_accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 9.7395e-06 - accuracy: 1.0000 - val_loss: 7.3840e-06 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 1.4232e-05 - accuracy: 1.0000 - val_loss: 4.6527e-06 - val_accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 4.0639e-05 - accuracy: 1.0000 - val_loss: 1.7870e-05 - val_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.4420e-05 - accuracy: 1.0000 - val_loss: 1.3849e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 2.0990e-05 - accuracy: 1.0000 - val_loss: 5.8221e-06 - val_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 5.6711e-06 - accuracy: 1.0000 - val_loss: 4.7470e-06 - val_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 8.4074e-06 - accuracy: 1.0000 - val_loss: 5.8960e-06 - val_accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.1503e-05 - accuracy: 1.0000 - val_loss: 9.1789e-06 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 7.5440e-06 - accuracy: 1.0000 - val_loss: 8.4120e-06 - val_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 6.2503e-06 - accuracy: 1.0000 - val_loss: 6.5714e-06 - val_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.4279e-05 - accuracy: 1.0000 - val_loss: 6.7455e-06 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.1572e-05 - accuracy: 1.0000 - val_loss: 4.8088e-06 - val_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 7.7280e-06 - accuracy: 1.0000 - val_loss: 6.8562e-06 - val_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 6.6890e-06 - accuracy: 1.0000 - val_loss: 5.8963e-06 - val_accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 4.8329e-06 - accuracy: 1.0000 - val_loss: 6.1693e-06 - val_accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 6.9698e-06 - accuracy: 1.0000 - val_loss: 4.4041e-06 - val_accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.3152e-05 - accuracy: 1.0000 - val_loss: 4.8800e-06 - val_accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.1387e-05 - accuracy: 1.0000 - val_loss: 3.7984e-06 - val_accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 9.3369e-06 - accuracy: 1.0000 - val_loss: 4.2628e-06 - val_accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 3.1370e-05 - accuracy: 1.0000 - val_loss: 3.8890e-05 - val_accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.2423e-04 - accuracy: 1.0000 - val_loss: 8.3903e-05 - val_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 5.0324e-04 - accuracy: 1.0000 - val_loss: 1.0728e-05 - val_accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 9.6104e-05 - accuracy: 1.0000 - val_loss: 1.0556e-05 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.7869e-05 - accuracy: 1.0000 - val_loss: 4.7806e-06 - val_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 9.6316e-06 - accuracy: 1.0000 - val_loss: 3.2343e-06 - val_accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 4.9812e-06 - accuracy: 1.0000 - val_loss: 3.7956e-06 - val_accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 7.7015e-06 - accuracy: 1.0000 - val_loss: 4.0155e-06 - val_accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 6.0766e-06 - accuracy: 1.0000 - val_loss: 3.0416e-06 - val_accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 7.2230e-06 - accuracy: 1.0000 - val_loss: 3.4713e-06 - val_accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 6.8211e-06 - accuracy: 1.0000 - val_loss: 3.5697e-06 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 6.1615e-06 - accuracy: 1.0000 - val_loss: 3.7258e-06 - val_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 6.9467e-06 - accuracy: 1.0000 - val_loss: 2.5796e-06 - val_accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.1169e-05 - accuracy: 1.0000 - val_loss: 3.4260e-06 - val_accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 1.1287e-05 - accuracy: 1.0000 - val_loss: 4.1851e-06 - val_accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 5.2775e-06 - accuracy: 1.0000 - val_loss: 4.5021e-06 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 3.0216e-04 - accuracy: 1.0000 - val_loss: 1.4418e-05 - val_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.9470e-05 - accuracy: 1.0000 - val_loss: 1.1661e-05 - val_accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 3.0775e-05 - accuracy: 1.0000 - val_loss: 6.0020e-06 - val_accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 6.2464e-06 - accuracy: 1.0000 - val_loss: 5.4005e-06 - val_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 7.3623e-06 - accuracy: 1.0000 - val_loss: 5.1349e-06 - val_accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.6283e-05 - accuracy: 1.0000 - val_loss: 3.8169e-06 - val_accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 5.6897e-06 - accuracy: 1.0000 - val_loss: 4.7672e-06 - val_accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 9.5834e-06 - accuracy: 1.0000 - val_loss: 4.2567e-06 - val_accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 4.5910e-06 - accuracy: 1.0000 - val_loss: 4.9201e-06 - val_accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 7.7046e-06 - accuracy: 1.0000 - val_loss: 4.4678e-06 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 5.5380e-06 - accuracy: 1.0000 - val_loss: 4.3588e-06 - val_accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 6.5468e-06 - accuracy: 1.0000 - val_loss: 4.3777e-06 - val_accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 5.0885e-06 - accuracy: 1.0000 - val_loss: 4.2549e-06 - val_accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 8.4469e-06 - accuracy: 1.0000 - val_loss: 1.9327e-06 - val_accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 3.3428e-06 - accuracy: 1.0000 - val_loss: 3.2989e-06 - val_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 5.9248e-06 - accuracy: 1.0000 - val_loss: 3.1497e-06 - val_accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 5.2122e-06 - accuracy: 1.0000 - val_loss: 3.8118e-06 - val_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 5.1922e-06 - accuracy: 1.0000 - val_loss: 2.9529e-06 - val_accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 4.2576e-06 - accuracy: 1.0000 - val_loss: 3.9601e-06 - val_accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.9007e-05 - accuracy: 1.0000 - val_loss: 5.2795e-06 - val_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.2669e-05 - accuracy: 1.0000 - val_loss: 3.4167e-06 - val_accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 7.5733e-06 - accuracy: 1.0000 - val_loss: 3.2209e-06 - val_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 2.9768e-06 - accuracy: 1.0000 - val_loss: 3.3808e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 5.3977e-06 - accuracy: 1.0000 - val_loss: 3.0994e-06 - val_accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 5.3029e-06 - accuracy: 1.0000 - val_loss: 2.5667e-06 - val_accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 9.3675e-06 - accuracy: 1.0000 - val_loss: 2.8554e-06 - val_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 3.6493e-06 - accuracy: 1.0000 - val_loss: 3.1456e-06 - val_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 6.5292e-06 - accuracy: 1.0000 - val_loss: 2.9945e-06 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 8.7628e-06 - accuracy: 1.0000 - val_loss: 2.7583e-06 - val_accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.0039e-05 - accuracy: 1.0000 - val_loss: 2.8462e-06 - val_accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.1241e-05 - accuracy: 1.0000 - val_loss: 2.4437e-06 - val_accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 2.9442e-06 - accuracy: 1.0000 - val_loss: 2.6762e-06 - val_accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 8.3360e-06 - accuracy: 1.0000 - val_loss: 2.7468e-06 - val_accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 2.8503e-06 - accuracy: 1.0000 - val_loss: 2.6383e-06 - val_accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 5.6026e-06 - accuracy: 1.0000 - val_loss: 1.6500e-06 - val_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 2.9549e-06 - accuracy: 1.0000 - val_loss: 2.0889e-06 - val_accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 3.2512e-06 - accuracy: 1.0000 - val_loss: 2.2580e-06 - val_accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 3.5889e-06 - accuracy: 1.0000 - val_loss: 1.9873e-06 - val_accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 3.9006e-06 - accuracy: 1.0000 - val_loss: 2.4595e-06 - val_accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 3.7836e-06 - accuracy: 1.0000 - val_loss: 1.9059e-06 - val_accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 6.8411e-06 - accuracy: 1.0000 - val_loss: 2.3172e-06 - val_accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.7676e-06 - accuracy: 1.0000 - val_loss: 2.3389e-06 - val_accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 6.5604e-06 - accuracy: 1.0000 - val_loss: 2.6460e-06 - val_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.2638e-06 - accuracy: 1.0000 - val_loss: 2.8520e-06 - val_accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 2.0265e-06 - accuracy: 1.0000 - val_loss: 2.6649e-06 - val_accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 1.0793e-05 - accuracy: 1.0000 - val_loss: 4.0750e-06 - val_accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.9504e-06 - accuracy: 1.0000 - val_loss: 3.0254e-06 - val_accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 7.1147e-06 - accuracy: 1.0000 - val_loss: 1.9207e-06 - val_accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 2.6895e-06 - accuracy: 1.0000 - val_loss: 1.7691e-06 - val_accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 3.3389e-06 - accuracy: 1.0000 - val_loss: 1.9202e-06 - val_accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 3.9808e-06 - accuracy: 1.0000 - val_loss: 1.9956e-06 - val_accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 2.4454e-06 - accuracy: 1.0000 - val_loss: 1.7779e-06 - val_accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 2.0580e-06 - accuracy: 1.0000 - val_loss: 1.4347e-06 - val_accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 5.0519e-06 - accuracy: 1.0000 - val_loss: 1.6167e-06 - val_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 2.6197e-06 - accuracy: 1.0000 - val_loss: 1.5871e-06 - val_accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.9782e-06 - accuracy: 1.0000 - val_loss: 1.3233e-06 - val_accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.7381e-06 - accuracy: 1.0000 - val_loss: 1.5848e-06 - val_accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 2.7856e-06 - accuracy: 1.0000 - val_loss: 1.4393e-06 - val_accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.4991e-06 - accuracy: 1.0000 - val_loss: 1.5922e-06 - val_accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 2.9172e-06 - accuracy: 1.0000 - val_loss: 1.4998e-06 - val_accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.0012e-06 - accuracy: 1.0000 - val_loss: 1.3838e-06 - val_accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 2.6822e-06 - accuracy: 1.0000 - val_loss: 1.4933e-06 - val_accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 2.8884e-06 - accuracy: 1.0000 - val_loss: 1.2882e-06 - val_accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 2.1412e-06 - accuracy: 1.0000 - val_loss: 1.3053e-06 - val_accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 2.3425e-06 - accuracy: 1.0000 - val_loss: 1.2983e-06 - val_accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 3.6587e-06 - accuracy: 1.0000 - val_loss: 1.5446e-06 - val_accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 3.7600e-06 - accuracy: 1.0000 - val_loss: 1.4245e-06 - val_accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 7.2414e-06 - accuracy: 1.0000 - val_loss: 2.6646e-06 - val_accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 2.9503e-06 - accuracy: 1.0000 - val_loss: 1.8011e-06 - val_accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 4.4414e-06 - accuracy: 1.0000 - val_loss: 2.3935e-06 - val_accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 5.4070e-06 - accuracy: 1.0000 - val_loss: 2.4419e-06 - val_accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.4244e-05 - accuracy: 1.0000 - val_loss: 1.4617e-05 - val_accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 9.1715e-05 - accuracy: 1.0000 - val_loss: 7.6370e-06 - val_accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 5.9758e-06 - accuracy: 1.0000 - val_loss: 5.3228e-06 - val_accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 2.8413e-06 - accuracy: 1.0000 - val_loss: 3.7919e-06 - val_accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 7.0550e-06 - accuracy: 1.0000 - val_loss: 2.6936e-06 - val_accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 2.5494e-06 - accuracy: 1.0000 - val_loss: 1.4924e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 6.8436e-06 - accuracy: 1.0000 - val_loss: 1.8177e-06 - val_accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.5385e-05 - accuracy: 1.0000 - val_loss: 2.0551e-06 - val_accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 2.3369e-06 - accuracy: 1.0000 - val_loss: 1.2448e-06 - val_accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 2.7620e-06 - accuracy: 1.0000 - val_loss: 1.3884e-06 - val_accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.8348e-06 - accuracy: 1.0000 - val_loss: 1.4346e-06 - val_accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.3863e-06 - accuracy: 1.0000 - val_loss: 1.3242e-06 - val_accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.2837e-06 - accuracy: 1.0000 - val_loss: 1.0248e-06 - val_accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.3785e-06 - accuracy: 1.0000 - val_loss: 1.1528e-06 - val_accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 1.4704e-06 - accuracy: 1.0000 - val_loss: 8.6680e-07 - val_accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.2247e-06 - accuracy: 1.0000 - val_loss: 9.5274e-07 - val_accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 1.8719e-06 - accuracy: 1.0000 - val_loss: 1.1135e-06 - val_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 2.9638e-06 - accuracy: 1.0000 - val_loss: 8.2291e-07 - val_accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.8618e-06 - accuracy: 1.0000 - val_loss: 8.8713e-07 - val_accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.5446e-06 - accuracy: 1.0000 - val_loss: 7.6562e-07 - val_accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.0768e-06 - accuracy: 1.0000 - val_loss: 7.0740e-07 - val_accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 2.2233e-06 - accuracy: 1.0000 - val_loss: 8.3169e-07 - val_accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.7915e-06 - accuracy: 1.0000 - val_loss: 7.4297e-07 - val_accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 2.1637e-06 - accuracy: 1.0000 - val_loss: 9.4905e-07 - val_accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 9.0419e-07 - accuracy: 1.0000 - val_loss: 7.2865e-07 - val_accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.7909e-06 - accuracy: 1.0000 - val_loss: 7.1156e-07 - val_accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.0622e-06 - accuracy: 1.0000 - val_loss: 6.9169e-07 - val_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 2.0822e-06 - accuracy: 1.0000 - val_loss: 6.6073e-07 - val_accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.1668e-06 - accuracy: 1.0000 - val_loss: 6.1730e-07 - val_accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 8.3390e-07 - accuracy: 1.0000 - val_loss: 7.1294e-07 - val_accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 7.7654e-07 - accuracy: 1.0000 - val_loss: 5.6601e-07 - val_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 2.0951e-06 - accuracy: 1.0000 - val_loss: 8.6588e-07 - val_accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 1.8342e-06 - accuracy: 1.0000 - val_loss: 6.8476e-07 - val_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 1.5401e-06 - accuracy: 1.0000 - val_loss: 4.9948e-07 - val_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.3484e-06 - accuracy: 1.0000 - val_loss: 6.0991e-07 - val_accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 8.6313e-07 - accuracy: 1.0000 - val_loss: 6.2284e-07 - val_accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.1128e-06 - accuracy: 1.0000 - val_loss: 6.1591e-07 - val_accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.6414e-06 - accuracy: 1.0000 - val_loss: 5.6370e-07 - val_accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 3.6934e-06 - accuracy: 1.0000 - val_loss: 2.2001e-06 - val_accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 2.8365e-05 - accuracy: 1.0000 - val_loss: 1.4809e-05 - val_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 4.1183e-06 - accuracy: 1.0000 - val_loss: 7.1712e-06 - val_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 9.4728e-06 - accuracy: 1.0000 - val_loss: 5.4937e-07 - val_accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 9.7222e-07 - accuracy: 1.0000 - val_loss: 2.0669e-06 - val_accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.5991e-06 - accuracy: 1.0000 - val_loss: 1.8646e-06 - val_accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.1561e-06 - accuracy: 1.0000 - val_loss: 1.6891e-06 - val_accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 7.3943e-07 - accuracy: 1.0000 - val_loss: 1.6540e-06 - val_accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 7.7360e-06 - accuracy: 1.0000 - val_loss: 6.2053e-07 - val_accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 2.0023e-06 - accuracy: 1.0000 - val_loss: 5.2258e-07 - val_accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 6.6858e-07 - accuracy: 1.0000 - val_loss: 5.1149e-07 - val_accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 8.0635e-07 - accuracy: 1.0000 - val_loss: 3.3822e-07 - val_accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 8.0634e-07 - accuracy: 1.0000 - val_loss: 4.9670e-07 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 6.4440e-07 - accuracy: 1.0000 - val_loss: 4.2693e-07 - val_accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 6.9895e-07 - accuracy: 1.0000 - val_loss: 4.4264e-07 - val_accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 5.9323e-07 - accuracy: 1.0000 - val_loss: 4.4634e-07 - val_accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 5.2070e-07 - accuracy: 1.0000 - val_loss: 3.9690e-07 - val_accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 5.9211e-07 - accuracy: 1.0000 - val_loss: 4.1631e-07 - val_accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.9526e-06 - accuracy: 1.0000 - val_loss: 3.0819e-07 - val_accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 2.6938e-06 - accuracy: 1.0000 - val_loss: 4.3017e-07 - val_accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 7.5573e-07 - accuracy: 1.0000 - val_loss: 3.9089e-07 - val_accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 1.7364e-06 - accuracy: 1.0000 - val_loss: 4.6575e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 3.8314e-06 - accuracy: 1.0000 - val_loss: 4.6806e-07 - val_accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 5.1451e-07 - accuracy: 1.0000 - val_loss: 3.5994e-07 - val_accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 9.3566e-07 - accuracy: 1.0000 - val_loss: 4.1862e-07 - val_accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 5.2294e-07 - accuracy: 1.0000 - val_loss: 4.1169e-07 - val_accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 5.9154e-07 - accuracy: 1.0000 - val_loss: 3.5439e-07 - val_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 6.8770e-07 - accuracy: 1.0000 - val_loss: 3.5994e-07 - val_accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 6.5789e-07 - accuracy: 1.0000 - val_loss: 3.3868e-07 - val_accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 8.0634e-07 - accuracy: 1.0000 - val_loss: 3.4377e-07 - val_accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.4583e-06 - accuracy: 1.0000 - val_loss: 7.1201e-07 - val_accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.4659e-06 - accuracy: 1.0000 - val_loss: 4.6112e-07 - val_accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.1600e-06 - accuracy: 1.0000 - val_loss: 3.7842e-07 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 1.1369e-06 - accuracy: 1.0000 - val_loss: 2.9386e-07 - val_accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 6.1291e-07 - accuracy: 1.0000 - val_loss: 3.0865e-07 - val_accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 9.5198e-07 - accuracy: 1.0000 - val_loss: 3.0311e-07 - val_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 4.8696e-07 - accuracy: 1.0000 - val_loss: 2.8093e-07 - val_accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 6.6239e-07 - accuracy: 1.0000 - val_loss: 1.6310e-07 - val_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 6.7026e-07 - accuracy: 1.0000 - val_loss: 3.4654e-07 - val_accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 7.9734e-07 - accuracy: 1.0000 - val_loss: 2.7400e-07 - val_accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 3.2445e-07 - accuracy: 1.0000 - val_loss: 3.0726e-07 - val_accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 3.9249e-07 - accuracy: 1.0000 - val_loss: 3.3129e-07 - val_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 9.3622e-07 - accuracy: 1.0000 - val_loss: 3.0172e-07 - val_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 4.3466e-07 - accuracy: 1.0000 - val_loss: 2.4258e-07 - val_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 2.8284e-07 - accuracy: 1.0000 - val_loss: 2.7723e-07 - val_accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 3.4469e-07 - accuracy: 1.0000 - val_loss: 2.2825e-07 - val_accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.1808e-06 - accuracy: 1.0000 - val_loss: 5.5168e-07 - val_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 2.2911e-06 - accuracy: 1.0000 - val_loss: 7.9425e-07 - val_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 6.6408e-07 - accuracy: 1.0000 - val_loss: 4.4172e-07 - val_accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 8.5638e-07 - accuracy: 1.0000 - val_loss: 2.8416e-07 - val_accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 3.9924e-07 - accuracy: 1.0000 - val_loss: 2.7122e-07 - val_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 4.0823e-07 - accuracy: 1.0000 - val_loss: 2.5598e-07 - val_accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 4.2173e-07 - accuracy: 1.0000 - val_loss: 2.1716e-07 - val_accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 4.9033e-07 - accuracy: 1.0000 - val_loss: 1.7558e-07 - val_accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 4.8583e-07 - accuracy: 1.0000 - val_loss: 3.0541e-07 - val_accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 6.1403e-07 - accuracy: 1.0000 - val_loss: 2.9987e-07 - val_accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 3.6100e-07 - accuracy: 1.0000 - val_loss: 2.5829e-07 - val_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.7441e-07 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 3.4132e-07 - accuracy: 1.0000 - val_loss: 2.3195e-07 - val_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 4.4422e-07 - accuracy: 1.0000 - val_loss: 2.0330e-07 - val_accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 5.3025e-07 - accuracy: 1.0000 - val_loss: 1.9314e-07 - val_accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 3.0252e-07 - accuracy: 1.0000 - val_loss: 2.1578e-07 - val_accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 2.4629e-07 - accuracy: 1.0000 - val_loss: 1.8390e-07 - val_accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.4620e-07 - accuracy: 1.0000 - val_loss: 1.7835e-07 - val_accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 5.1507e-07 - accuracy: 1.0000 - val_loss: 1.6079e-07 - val_accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 3.0027e-07 - accuracy: 1.0000 - val_loss: 1.7003e-07 - val_accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 2.3111e-07 - accuracy: 1.0000 - val_loss: 1.3030e-07 - val_accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 4.5996e-07 - accuracy: 1.0000 - val_loss: 1.6079e-07 - val_accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 3.0646e-07 - accuracy: 1.0000 - val_loss: 1.5664e-07 - val_accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 2.2661e-07 - accuracy: 1.0000 - val_loss: 1.2383e-07 - val_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 2.3448e-07 - accuracy: 1.0000 - val_loss: 1.5664e-07 - val_accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 3.6269e-07 - accuracy: 1.0000 - val_loss: 1.6819e-07 - val_accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 3.0421e-07 - accuracy: 1.0000 - val_loss: 1.6218e-07 - val_accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 6.1741e-07 - accuracy: 1.0000 - val_loss: 2.9756e-07 - val_accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 2.8565e-07 - accuracy: 1.0000 - val_loss: 1.5340e-07 - val_accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 6.0222e-07 - accuracy: 1.0000 - val_loss: 4.5604e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 2.1011e-06 - accuracy: 1.0000 - val_loss: 3.2623e-06 - val_accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 3.6656e-06 - accuracy: 1.0000 - val_loss: 1.4555e-07 - val_accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.7450e-07 - accuracy: 1.0000 - val_loss: 2.0145e-07 - val_accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.3898e-07 - accuracy: 1.0000 - val_loss: 1.9545e-07 - val_accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 3.3120e-07 - accuracy: 1.0000 - val_loss: 1.5432e-07 - val_accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 3.4244e-07 - accuracy: 1.0000 - val_loss: 1.0258e-07 - val_accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 1.5576e-07 - accuracy: 1.0000 - val_loss: 1.2429e-07 - val_accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 3.8068e-07 - accuracy: 1.0000 - val_loss: 9.2410e-08 - val_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 2.0862e-07 - accuracy: 1.0000 - val_loss: 9.1486e-08 - val_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.7216e-07 - accuracy: 1.0000 - val_loss: 1.0904e-07 - val_accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 8.6651e-07 - accuracy: 1.0000 - val_loss: 4.4217e-07 - val_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 6.8544e-07 - accuracy: 1.0000 - val_loss: 8.7790e-08 - val_accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 2.3617e-07 - accuracy: 1.0000 - val_loss: 9.0562e-08 - val_accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 1.3945e-07 - accuracy: 1.0000 - val_loss: 8.9638e-08 - val_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.5913e-07 - accuracy: 1.0000 - val_loss: 8.7328e-08 - val_accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.9849e-07 - accuracy: 1.0000 - val_loss: 8.0397e-08 - val_accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 6.0447e-07 - accuracy: 1.0000 - val_loss: 1.3815e-07 - val_accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 3.8574e-07 - accuracy: 1.0000 - val_loss: 2.4258e-07 - val_accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 2.7890e-07 - accuracy: 1.0000 - val_loss: 1.0581e-07 - val_accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 1.5857e-07 - accuracy: 1.0000 - val_loss: 8.5017e-08 - val_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 1.2033e-07 - accuracy: 1.0000 - val_loss: 1.0211e-07 - val_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 6.7589e-07 - accuracy: 1.0000 - val_loss: 1.8205e-07 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 2.1030e-07 - accuracy: 1.0000 - val_loss: 1.0766e-07 - val_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 7.4616e-07 - accuracy: 1.0000 - val_loss: 3.4007e-07 - val_accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 7.6360e-07 - accuracy: 1.0000 - val_loss: 7.6700e-08 - val_accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.3158e-07 - accuracy: 1.0000 - val_loss: 7.6238e-08 - val_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 6.2978e-08 - accuracy: 1.0000 - val_loss: 7.6700e-08 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.0403e-07 - accuracy: 1.0000 - val_loss: 7.3928e-08 - val_accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 6.2416e-08 - accuracy: 1.0000 - val_loss: 6.1915e-08 - val_accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.5745e-07 - accuracy: 1.0000 - val_loss: 6.4225e-08 - val_accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 9.3905e-08 - accuracy: 1.0000 - val_loss: 5.8680e-08 - val_accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 1.3889e-07 - accuracy: 1.0000 - val_loss: 5.8680e-08 - val_accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 1.0403e-07 - accuracy: 1.0000 - val_loss: 6.0991e-08 - val_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 1.1246e-07 - accuracy: 1.0000 - val_loss: 4.3433e-08 - val_accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 7.0288e-08 - accuracy: 1.0000 - val_loss: 6.0991e-08 - val_accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 1.5463e-07 - accuracy: 1.0000 - val_loss: 4.9902e-08 - val_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 1.3270e-07 - accuracy: 1.0000 - val_loss: 5.8681e-08 - val_accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 8.1535e-08 - accuracy: 1.0000 - val_loss: 4.9902e-08 - val_accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.4620e-07 - accuracy: 1.0000 - val_loss: 5.2212e-08 - val_accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 8.7158e-08 - accuracy: 1.0000 - val_loss: 5.9143e-08 - val_accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1.0009e-07 - accuracy: 1.0000 - val_loss: 5.4522e-08 - val_accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 9.9528e-08 - accuracy: 1.0000 - val_loss: 4.9902e-08 - val_accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1.4395e-07 - accuracy: 1.0000 - val_loss: 4.8977e-08 - val_accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 6.0729e-08 - accuracy: 1.0000 - val_loss: 5.2212e-08 - val_accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.6363e-07 - accuracy: 1.0000 - val_loss: 8.1783e-08 - val_accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.0346e-07 - accuracy: 1.0000 - val_loss: 6.0067e-08 - val_accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 3.3738e-07 - accuracy: 1.0000 - val_loss: 2.0099e-07 - val_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 2.0918e-07 - accuracy: 1.0000 - val_loss: 1.0812e-07 - val_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.3814e-06 - accuracy: 1.0000 - val_loss: 2.0517e-06 - val_accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 5.7242e-07 - accuracy: 1.0000 - val_loss: 3.2527e-07 - val_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 2.7721e-07 - accuracy: 1.0000 - val_loss: 1.5848e-07 - val_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 8.2097e-08 - accuracy: 1.0000 - val_loss: 1.3677e-07 - val_accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.0244e-06 - accuracy: 1.0000 - val_loss: 1.3492e-07 - val_accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 1.5857e-07 - accuracy: 1.0000 - val_loss: 7.5314e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 2.6372e-07 - accuracy: 1.0000 - val_loss: 1.8898e-07 - val_accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 3.5706e-07 - accuracy: 1.0000 - val_loss: 4.8977e-08 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 5.4544e-08 - accuracy: 1.0000 - val_loss: 4.0198e-08 - val_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 5.4037e-07 - accuracy: 1.0000 - val_loss: 4.9439e-08 - val_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 7.8161e-08 - accuracy: 1.0000 - val_loss: 2.4951e-08 - val_accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.4845e-07 - accuracy: 1.0000 - val_loss: 4.1123e-08 - val_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 1.9906e-07 - accuracy: 1.0000 - val_loss: 3.7426e-08 - val_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.0290e-07 - accuracy: 1.0000 - val_loss: 3.1419e-08 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 8.1535e-08 - accuracy: 1.0000 - val_loss: 2.9571e-08 - val_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.2427e-07 - accuracy: 1.0000 - val_loss: 2.4027e-08 - val_accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1.3495e-07 - accuracy: 1.0000 - val_loss: 2.9109e-08 - val_accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 1.2596e-07 - accuracy: 1.0000 - val_loss: 3.0495e-08 - val_accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 6.4103e-08 - accuracy: 1.0000 - val_loss: 3.1419e-08 - val_accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 6.9164e-08 - accuracy: 1.0000 - val_loss: 2.9571e-08 - val_accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 4.6109e-08 - accuracy: 1.0000 - val_loss: 2.8647e-08 - val_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 5.7918e-08 - accuracy: 1.0000 - val_loss: 2.4951e-08 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 3.4301e-08 - accuracy: 1.0000 - val_loss: 2.1254e-08 - val_accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 5.1170e-08 - accuracy: 1.0000 - val_loss: 2.3103e-08 - val_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 7.4224e-08 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 5.6793e-08 - accuracy: 1.0000 - val_loss: 2.7261e-08 - val_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 5.5668e-08 - accuracy: 1.0000 - val_loss: 2.6337e-08 - val_accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 5.5668e-08 - accuracy: 1.0000 - val_loss: 1.8944e-08 - val_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 6.8039e-08 - accuracy: 1.0000 - val_loss: 1.8020e-08 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 3.2501e-07 - accuracy: 1.0000 - val_loss: 8.1783e-08 - val_accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.2179e-06 - accuracy: 1.0000 - val_loss: 4.8977e-08 - val_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 1.7094e-07 - accuracy: 1.0000 - val_loss: 6.5611e-08 - val_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.7656e-07 - accuracy: 1.0000 - val_loss: 3.9736e-08 - val_accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.2033e-07 - accuracy: 1.0000 - val_loss: 3.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 8.0972e-08 - accuracy: 1.0000 - val_loss: 3.7426e-08 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 6.1292e-08 - accuracy: 1.0000 - val_loss: 3.6040e-08 - val_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 1.9287e-07 - accuracy: 1.0000 - val_loss: 5.3136e-08 - val_accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 3.7955e-07 - accuracy: 1.0000 - val_loss: 4.9439e-08 - val_accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 3.2164e-07 - accuracy: 1.0000 - val_loss: 2.8185e-08 - val_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 1.3833e-07 - accuracy: 1.0000 - val_loss: 2.5413e-08 - val_accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.5182e-07 - accuracy: 1.0000 - val_loss: 3.7888e-08 - val_accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 5.1732e-08 - accuracy: 1.0000 - val_loss: 3.3730e-08 - val_accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 3.5312e-07 - accuracy: 1.0000 - val_loss: 8.2245e-08 - val_accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 5.6231e-08 - accuracy: 1.0000 - val_loss: 4.6667e-08 - val_accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 1.6588e-07 - accuracy: 1.0000 - val_loss: 1.8020e-08 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 8.2097e-08 - accuracy: 1.0000 - val_loss: 1.9868e-08 - val_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 5.3419e-08 - accuracy: 1.0000 - val_loss: 2.2641e-08 - val_accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 3.0533e-07 - accuracy: 1.0000 - val_loss: 5.7756e-08 - val_accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 7.2538e-08 - accuracy: 1.0000 - val_loss: 3.8350e-08 - val_accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 1.6925e-07 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 2.0792e-08 - val_accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 2.6991e-08 - accuracy: 1.0000 - val_loss: 2.0330e-08 - val_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 2.9577e-07 - accuracy: 1.0000 - val_loss: 7.4390e-08 - val_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 6.1292e-08 - accuracy: 1.0000 - val_loss: 1.1182e-07 - val_accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.1190e-07 - accuracy: 1.0000 - val_loss: 3.5578e-08 - val_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 7.4787e-08 - accuracy: 1.0000 - val_loss: 2.1254e-08 - val_accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 3.9924e-08 - accuracy: 1.0000 - val_loss: 3.5116e-08 - val_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 9.6717e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 2.8115e-08 - accuracy: 1.0000 - val_loss: 1.6172e-08 - val_accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.0853e-07 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 9.2781e-08 - accuracy: 1.0000 - val_loss: 2.3103e-08 - val_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 6.4665e-08 - accuracy: 1.0000 - val_loss: 2.4489e-08 - val_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 2.9802e-08 - accuracy: 1.0000 - val_loss: 1.9868e-08 - val_accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 4.1329e-07 - accuracy: 1.0000 - val_loss: 2.3565e-08 - val_accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.8950e-07 - accuracy: 1.0000 - val_loss: 5.4060e-08 - val_accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.3833e-07 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.5238e-07 - accuracy: 1.0000 - val_loss: 1.6172e-08 - val_accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 2.7553e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.3495e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 2.4179e-08 - accuracy: 1.0000 - val_loss: 1.6634e-08 - val_accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 5.3982e-08 - accuracy: 1.0000 - val_loss: 1.6172e-08 - val_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 8.3784e-08 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.0909e-07 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2.3617e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 1.6307e-08 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 1.9559e-06 - accuracy: 1.0000 - val_loss: 2.5505e-07 - val_accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 3.0083e-07 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 6.3541e-08 - accuracy: 1.0000 - val_loss: 2.7723e-08 - val_accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 9.7841e-08 - accuracy: 1.0000 - val_loss: 1.4786e-08 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 3.4301e-08 - accuracy: 1.0000 - val_loss: 1.7096e-08 - val_accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 6.9164e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 2.5304e-08 - accuracy: 1.0000 - val_loss: 2.0792e-08 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 2.9802e-08 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 2.1368e-08 - accuracy: 1.0000 - val_loss: 1.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 6.4103e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 6.2978e-08 - accuracy: 1.0000 - val_loss: 1.4786e-08 - val_accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 8.6033e-08 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 6.5790e-08 - accuracy: 1.0000 - val_loss: 1.4324e-08 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 2.3055e-08 - accuracy: 1.0000 - val_loss: 1.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 6.9726e-08 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 3.3738e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 6.7477e-08 - accuracy: 1.0000 - val_loss: 1.2475e-08 - val_accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 3.1489e-08 - accuracy: 1.0000 - val_loss: 1.2475e-08 - val_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 2.6428e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 3.3738e-08 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 1.3399e-08 - val_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 1.9118e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 2.3617e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 5.4879e-07 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 2.3617e-08 - accuracy: 1.0000 - val_loss: 1.5248e-08 - val_accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.6991e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 2.5866e-08 - accuracy: 1.0000 - val_loss: 1.5248e-08 - val_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 2.5304e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 7.7598e-08 - accuracy: 1.0000 - val_loss: 1.6172e-08 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 6.8602e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 1.7994e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 3.2052e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 3.2614e-08 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 3.1489e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.7432e-08 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 4.4985e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 2.0805e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 2.5866e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 5.2295e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.7553e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.2933e-07 - accuracy: 1.0000 - val_loss: 2.1716e-08 - val_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 3.6550e-08 - accuracy: 1.0000 - val_loss: 1.3862e-08 - val_accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 6.0729e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 6.1854e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 5.8480e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 2.1930e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 2.6991e-08 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 2.8115e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 1.2933e-07 - accuracy: 1.0000 - val_loss: 2.7723e-08 - val_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 2.0243e-08 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 6.7080e-07 - accuracy: 1.0000 - val_loss: 3.7888e-08 - val_accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 1.5745e-07 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 2.0243e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 5.1170e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 4.6726e-07 - accuracy: 1.0000 - val_loss: 4.3433e-08 - val_accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 4.0198e-08 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 3.7393e-07 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 2.7553e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 7.3100e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 3.3738e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 2.0805e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 1.7432e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 8.7158e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 2.7103e-07 - accuracy: 1.0000 - val_loss: 2.8185e-08 - val_accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 9.7841e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 2.6428e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 2.1368e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 4.4422e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 9.6154e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 5.7918e-08 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 3.1489e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 3.6550e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.4742e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 2.3055e-08 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 2.3617e-08 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 7.8723e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.7994e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Model training finished.\n",
      "Train loss: 0.0, train accuracy: 1.0.\n",
      "Evaluating model performance...\n",
      "Test loss: 0.0, test accuracy: 1.0.\n"
     ]
    }
   ],
   "source": [
    "run_experiment(nn_model_full,\n",
    "               tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               train_dataset,\n",
    "               val_dataset,\n",
    "               test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ecd1d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:04:16.428091Z",
     "start_time": "2021-07-09T14:04:15.485284Z"
    }
   },
   "outputs": [],
   "source": [
    "bnn_model_full = create_bnn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eccd126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:11:59.916583Z",
     "start_time": "2021-07-09T14:04:16.433077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 38.5549 - accuracy: 0.4764 - val_loss: 38.5063 - val_accuracy: 0.5310\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 38.5030 - accuracy: 0.4245 - val_loss: 38.4818 - val_accuracy: 0.5543\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 38.4675 - accuracy: 0.4340 - val_loss: 38.4572 - val_accuracy: 0.4884\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 38.4193 - accuracy: 0.5613 - val_loss: 38.4129 - val_accuracy: 0.5426\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 38.4109 - accuracy: 0.4858 - val_loss: 38.3591 - val_accuracy: 0.5698\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 38.3707 - accuracy: 0.4811 - val_loss: 38.3841 - val_accuracy: 0.4961\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 38.3531 - accuracy: 0.5519 - val_loss: 38.3342 - val_accuracy: 0.5388\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 38.3371 - accuracy: 0.4670 - val_loss: 38.3166 - val_accuracy: 0.5465\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 38.3252 - accuracy: 0.4481 - val_loss: 38.3024 - val_accuracy: 0.5271\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 38.2925 - accuracy: 0.5991 - val_loss: 38.2768 - val_accuracy: 0.5504\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 38.2782 - accuracy: 0.5236 - val_loss: 38.2618 - val_accuracy: 0.5155\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 38.2415 - accuracy: 0.7406 - val_loss: 38.2309 - val_accuracy: 0.5814\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 38.2267 - accuracy: 0.6745 - val_loss: 38.2316 - val_accuracy: 0.5271\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 38.2279 - accuracy: 0.4292 - val_loss: 38.2245 - val_accuracy: 0.4767\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 38.1951 - accuracy: 0.6132 - val_loss: 38.1955 - val_accuracy: 0.5155\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 38.1862 - accuracy: 0.4623 - val_loss: 38.1578 - val_accuracy: 0.6512\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 38.1315 - accuracy: 0.8208 - val_loss: 38.1480 - val_accuracy: 0.6163\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 38.1226 - accuracy: 0.7830 - val_loss: 38.1250 - val_accuracy: 0.6202\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 38.1122 - accuracy: 0.7358 - val_loss: 38.1017 - val_accuracy: 0.6163\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 38.0696 - accuracy: 0.8208 - val_loss: 38.0901 - val_accuracy: 0.5969\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 38.0594 - accuracy: 0.7925 - val_loss: 38.0662 - val_accuracy: 0.6279\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 38.0249 - accuracy: 0.8113 - val_loss: 38.0515 - val_accuracy: 0.6240\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 38.0125 - accuracy: 0.7736 - val_loss: 38.0281 - val_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 37.9932 - accuracy: 0.7547 - val_loss: 38.0280 - val_accuracy: 0.6512\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 37.9606 - accuracy: 0.8160 - val_loss: 38.0045 - val_accuracy: 0.6047\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 37.9541 - accuracy: 0.7547 - val_loss: 37.9817 - val_accuracy: 0.6124\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 37.9022 - accuracy: 0.8208 - val_loss: 37.9614 - val_accuracy: 0.6202\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 37.8825 - accuracy: 0.8160 - val_loss: 37.9447 - val_accuracy: 0.6512\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 37.8769 - accuracy: 0.8160 - val_loss: 37.9330 - val_accuracy: 0.6860\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 37.8693 - accuracy: 0.8255 - val_loss: 37.9035 - val_accuracy: 0.7016\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 37.8533 - accuracy: 0.7783 - val_loss: 37.8910 - val_accuracy: 0.6628\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 37.7949 - accuracy: 0.8066 - val_loss: 37.8704 - val_accuracy: 0.7403\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 37.7835 - accuracy: 0.7877 - val_loss: 37.8338 - val_accuracy: 0.7403\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 37.7506 - accuracy: 0.8160 - val_loss: 37.8187 - val_accuracy: 0.6977\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 37.7011 - accuracy: 0.8302 - val_loss: 37.7640 - val_accuracy: 0.7674\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 37.7083 - accuracy: 0.8255 - val_loss: 37.7544 - val_accuracy: 0.7519\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 37.7030 - accuracy: 0.8349 - val_loss: 37.7729 - val_accuracy: 0.6822\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 37.6927 - accuracy: 0.8349 - val_loss: 37.7258 - val_accuracy: 0.7442\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 37.6524 - accuracy: 0.8302 - val_loss: 37.7000 - val_accuracy: 0.7868\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 37.6237 - accuracy: 0.8349 - val_loss: 37.7009 - val_accuracy: 0.6977\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 37.5928 - accuracy: 0.8349 - val_loss: 37.6782 - val_accuracy: 0.7093\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 37.6209 - accuracy: 0.8208 - val_loss: 37.6700 - val_accuracy: 0.7713\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 37.5530 - accuracy: 0.8208 - val_loss: 37.6234 - val_accuracy: 0.7403\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 37.5015 - accuracy: 0.8538 - val_loss: 37.6287 - val_accuracy: 0.7248\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 37.5081 - accuracy: 0.8349 - val_loss: 37.5661 - val_accuracy: 0.8101\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 37.4712 - accuracy: 0.8632 - val_loss: 37.5673 - val_accuracy: 0.7752\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 37.4535 - accuracy: 0.8396 - val_loss: 37.6270 - val_accuracy: 0.6860\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 37.4281 - accuracy: 0.8255 - val_loss: 37.5235 - val_accuracy: 0.7674\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 37.4455 - accuracy: 0.8585 - val_loss: 37.5250 - val_accuracy: 0.7636\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 37.3924 - accuracy: 0.8349 - val_loss: 37.4982 - val_accuracy: 0.7519\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 37.3481 - accuracy: 0.8632 - val_loss: 37.4317 - val_accuracy: 0.8062\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 37.3785 - accuracy: 0.8538 - val_loss: 37.4453 - val_accuracy: 0.7597\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 37.3488 - accuracy: 0.8585 - val_loss: 37.4654 - val_accuracy: 0.7636\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 37.2991 - accuracy: 0.8491 - val_loss: 37.3870 - val_accuracy: 0.8295\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 37.3226 - accuracy: 0.8255 - val_loss: 37.3753 - val_accuracy: 0.8023\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 37.2539 - accuracy: 0.8774 - val_loss: 37.3719 - val_accuracy: 0.8023\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 37.2711 - accuracy: 0.8396 - val_loss: 37.3392 - val_accuracy: 0.7907\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 37.1975 - accuracy: 0.8726 - val_loss: 37.3061 - val_accuracy: 0.7984\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 37.2176 - accuracy: 0.8726 - val_loss: 37.2658 - val_accuracy: 0.8256\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 37.1929 - accuracy: 0.8302 - val_loss: 37.2929 - val_accuracy: 0.7907\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 37.2064 - accuracy: 0.8349 - val_loss: 37.2375 - val_accuracy: 0.8372\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 37.1727 - accuracy: 0.8491 - val_loss: 37.2916 - val_accuracy: 0.7481\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 37.1738 - accuracy: 0.8396 - val_loss: 37.2251 - val_accuracy: 0.8178\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 37.1384 - accuracy: 0.8491 - val_loss: 37.1927 - val_accuracy: 0.8333\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 37.1627 - accuracy: 0.8208 - val_loss: 37.1999 - val_accuracy: 0.8062\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 37.0867 - accuracy: 0.8679 - val_loss: 37.2321 - val_accuracy: 0.7326\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 37.0728 - accuracy: 0.8726 - val_loss: 37.1286 - val_accuracy: 0.8295\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 37.0867 - accuracy: 0.8491 - val_loss: 37.1380 - val_accuracy: 0.8178\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 37.0575 - accuracy: 0.8585 - val_loss: 37.0962 - val_accuracy: 0.8682\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 37.0138 - accuracy: 0.8915 - val_loss: 37.1188 - val_accuracy: 0.7907\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 37.0467 - accuracy: 0.8302 - val_loss: 37.1042 - val_accuracy: 0.7984\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 36.9970 - accuracy: 0.8679 - val_loss: 37.0803 - val_accuracy: 0.8295\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 36.9944 - accuracy: 0.8679 - val_loss: 37.0888 - val_accuracy: 0.7907\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 36.9892 - accuracy: 0.8538 - val_loss: 37.0510 - val_accuracy: 0.8333\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 36.9552 - accuracy: 0.8679 - val_loss: 37.0270 - val_accuracy: 0.8217\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 36.9350 - accuracy: 0.8632 - val_loss: 36.9870 - val_accuracy: 0.8488\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 36.8973 - accuracy: 0.8726 - val_loss: 37.0343 - val_accuracy: 0.7946\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 36.8959 - accuracy: 0.8868 - val_loss: 36.9540 - val_accuracy: 0.8643\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 36.9050 - accuracy: 0.8679 - val_loss: 36.9770 - val_accuracy: 0.8178\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 36.8836 - accuracy: 0.8679 - val_loss: 36.9315 - val_accuracy: 0.8488\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 36.8831 - accuracy: 0.8632 - val_loss: 36.9357 - val_accuracy: 0.8178\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 36.8561 - accuracy: 0.8726 - val_loss: 36.9334 - val_accuracy: 0.8217\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 36.8306 - accuracy: 0.8585 - val_loss: 36.9053 - val_accuracy: 0.8295\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 36.7906 - accuracy: 0.8726 - val_loss: 36.8858 - val_accuracy: 0.7907\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 36.7923 - accuracy: 0.8726 - val_loss: 36.8982 - val_accuracy: 0.7984\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 36.8122 - accuracy: 0.8491 - val_loss: 36.8815 - val_accuracy: 0.8062\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 36.7785 - accuracy: 0.8585 - val_loss: 36.8208 - val_accuracy: 0.8372\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 36.7366 - accuracy: 0.8774 - val_loss: 36.8206 - val_accuracy: 0.8333\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 36.7282 - accuracy: 0.8632 - val_loss: 36.8094 - val_accuracy: 0.8217\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 36.7571 - accuracy: 0.8491 - val_loss: 36.7653 - val_accuracy: 0.8488\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 36.7294 - accuracy: 0.8679 - val_loss: 36.7974 - val_accuracy: 0.8295\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 36.7137 - accuracy: 0.8632 - val_loss: 36.7542 - val_accuracy: 0.8217\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 36.6817 - accuracy: 0.8774 - val_loss: 36.7288 - val_accuracy: 0.8450\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 36.6697 - accuracy: 0.8726 - val_loss: 36.7301 - val_accuracy: 0.8217\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 36.5899 - accuracy: 0.8915 - val_loss: 36.6925 - val_accuracy: 0.8372\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 36.6065 - accuracy: 0.8868 - val_loss: 36.6998 - val_accuracy: 0.8178\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 36.6430 - accuracy: 0.8538 - val_loss: 36.6574 - val_accuracy: 0.8566\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 36.5801 - accuracy: 0.8821 - val_loss: 36.6606 - val_accuracy: 0.8450\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 36.6266 - accuracy: 0.8726 - val_loss: 36.6292 - val_accuracy: 0.8372\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 36.5736 - accuracy: 0.8821 - val_loss: 36.6290 - val_accuracy: 0.8372\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 36.5523 - accuracy: 0.8868 - val_loss: 36.6041 - val_accuracy: 0.8450\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 36.5486 - accuracy: 0.8585 - val_loss: 36.6036 - val_accuracy: 0.8295\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 36.5338 - accuracy: 0.8632 - val_loss: 36.5859 - val_accuracy: 0.8372\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 36.4935 - accuracy: 0.8821 - val_loss: 36.5654 - val_accuracy: 0.8295\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 36.4754 - accuracy: 0.8962 - val_loss: 36.5577 - val_accuracy: 0.8488\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 36.4872 - accuracy: 0.8774 - val_loss: 36.5508 - val_accuracy: 0.8566\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 36.4742 - accuracy: 0.8726 - val_loss: 36.5156 - val_accuracy: 0.8605\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 36.4354 - accuracy: 0.8726 - val_loss: 36.5384 - val_accuracy: 0.8062\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 36.4232 - accuracy: 0.8774 - val_loss: 36.5135 - val_accuracy: 0.8140\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 36.4364 - accuracy: 0.8538 - val_loss: 36.4904 - val_accuracy: 0.8217\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 36.3910 - accuracy: 0.8915 - val_loss: 36.4318 - val_accuracy: 0.8721\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 36.3655 - accuracy: 0.8774 - val_loss: 36.4014 - val_accuracy: 0.8992\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 433ms/step - loss: 36.3866 - accuracy: 0.8821 - val_loss: 36.4026 - val_accuracy: 0.8721\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 36.3091 - accuracy: 0.9057 - val_loss: 36.4332 - val_accuracy: 0.8140\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 36.2790 - accuracy: 0.8915 - val_loss: 36.3827 - val_accuracy: 0.8643\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 36.3026 - accuracy: 0.9104 - val_loss: 36.4085 - val_accuracy: 0.8217\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 36.2493 - accuracy: 0.9292 - val_loss: 36.3437 - val_accuracy: 0.8643\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 36.2988 - accuracy: 0.8774 - val_loss: 36.3611 - val_accuracy: 0.8411\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 36.2891 - accuracy: 0.8774 - val_loss: 36.3476 - val_accuracy: 0.7984\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 36.2054 - accuracy: 0.9009 - val_loss: 36.3151 - val_accuracy: 0.8643\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 36.2299 - accuracy: 0.8868 - val_loss: 36.2726 - val_accuracy: 0.8837\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 36.2406 - accuracy: 0.8679 - val_loss: 36.2759 - val_accuracy: 0.8566\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 36.2238 - accuracy: 0.8821 - val_loss: 36.2657 - val_accuracy: 0.8721\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 36.1919 - accuracy: 0.8868 - val_loss: 36.2403 - val_accuracy: 0.8643\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 36.1527 - accuracy: 0.8868 - val_loss: 36.2269 - val_accuracy: 0.8721\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 36.1201 - accuracy: 0.9198 - val_loss: 36.1870 - val_accuracy: 0.8643\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 36.1273 - accuracy: 0.9009 - val_loss: 36.1924 - val_accuracy: 0.8605\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 36.1610 - accuracy: 0.8491 - val_loss: 36.1328 - val_accuracy: 0.8992\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 36.1357 - accuracy: 0.8962 - val_loss: 36.1464 - val_accuracy: 0.8643\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 36.1128 - accuracy: 0.8774 - val_loss: 36.1400 - val_accuracy: 0.8566\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 36.0955 - accuracy: 0.8868 - val_loss: 36.1415 - val_accuracy: 0.8721\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 36.1055 - accuracy: 0.8821 - val_loss: 36.1389 - val_accuracy: 0.8450\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 36.0473 - accuracy: 0.9104 - val_loss: 36.0698 - val_accuracy: 0.8876\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 36.0308 - accuracy: 0.9057 - val_loss: 36.0730 - val_accuracy: 0.8837\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 36.0107 - accuracy: 0.9151 - val_loss: 36.0624 - val_accuracy: 0.8643\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 36.0280 - accuracy: 0.8868 - val_loss: 36.0223 - val_accuracy: 0.8915\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 36.0000 - accuracy: 0.9057 - val_loss: 35.9967 - val_accuracy: 0.9031\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 35.9844 - accuracy: 0.9009 - val_loss: 36.0299 - val_accuracy: 0.8605\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 35.9713 - accuracy: 0.8915 - val_loss: 36.0171 - val_accuracy: 0.8488\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 35.9669 - accuracy: 0.9057 - val_loss: 35.9652 - val_accuracy: 0.8760\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 35.9281 - accuracy: 0.9104 - val_loss: 35.9914 - val_accuracy: 0.8566\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 35.9300 - accuracy: 0.8821 - val_loss: 35.9439 - val_accuracy: 0.8760\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 35.9109 - accuracy: 0.8868 - val_loss: 35.9303 - val_accuracy: 0.8798\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 35.8880 - accuracy: 0.8962 - val_loss: 35.9161 - val_accuracy: 0.8992\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 35.8812 - accuracy: 0.8726 - val_loss: 35.9451 - val_accuracy: 0.8566\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 35.8715 - accuracy: 0.8868 - val_loss: 35.9066 - val_accuracy: 0.8760\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 35.8462 - accuracy: 0.8962 - val_loss: 35.8598 - val_accuracy: 0.8992\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 35.8351 - accuracy: 0.9245 - val_loss: 35.8886 - val_accuracy: 0.8488\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 35.8244 - accuracy: 0.8726 - val_loss: 35.8622 - val_accuracy: 0.8682\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 35.8028 - accuracy: 0.9151 - val_loss: 35.8129 - val_accuracy: 0.8992\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 35.7984 - accuracy: 0.9057 - val_loss: 35.8102 - val_accuracy: 0.8953\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 35.7831 - accuracy: 0.9151 - val_loss: 35.7718 - val_accuracy: 0.9031\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 35.7366 - accuracy: 0.8962 - val_loss: 35.7867 - val_accuracy: 0.9031\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 35.7491 - accuracy: 0.9009 - val_loss: 35.7594 - val_accuracy: 0.8953\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 35.7465 - accuracy: 0.8774 - val_loss: 35.7132 - val_accuracy: 0.8992\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 35.7386 - accuracy: 0.8915 - val_loss: 35.7673 - val_accuracy: 0.8643\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 35.7085 - accuracy: 0.8726 - val_loss: 35.7053 - val_accuracy: 0.8798\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 35.7413 - accuracy: 0.8585 - val_loss: 35.7142 - val_accuracy: 0.8837\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 35.6584 - accuracy: 0.9104 - val_loss: 35.7026 - val_accuracy: 0.8721\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 35.6554 - accuracy: 0.9245 - val_loss: 35.6537 - val_accuracy: 0.9070\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 35.6312 - accuracy: 0.8868 - val_loss: 35.6577 - val_accuracy: 0.8876\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 35.6446 - accuracy: 0.8868 - val_loss: 35.6528 - val_accuracy: 0.8837\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 35.5850 - accuracy: 0.9198 - val_loss: 35.6024 - val_accuracy: 0.8953\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 35.6134 - accuracy: 0.8726 - val_loss: 35.6358 - val_accuracy: 0.8721\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 35.5697 - accuracy: 0.9104 - val_loss: 35.6264 - val_accuracy: 0.8837\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 35.5768 - accuracy: 0.8962 - val_loss: 35.6006 - val_accuracy: 0.8760\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 35.5710 - accuracy: 0.8868 - val_loss: 35.5525 - val_accuracy: 0.9109\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 35.5215 - accuracy: 0.8962 - val_loss: 35.5437 - val_accuracy: 0.8953\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 35.5416 - accuracy: 0.8962 - val_loss: 35.5363 - val_accuracy: 0.8760\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 35.4556 - accuracy: 0.9340 - val_loss: 35.5186 - val_accuracy: 0.8953\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 35.4967 - accuracy: 0.9198 - val_loss: 35.5285 - val_accuracy: 0.8682\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 35.4924 - accuracy: 0.9151 - val_loss: 35.4961 - val_accuracy: 0.8876\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 35.4502 - accuracy: 0.9104 - val_loss: 35.4750 - val_accuracy: 0.9070\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 35.4429 - accuracy: 0.8962 - val_loss: 35.4370 - val_accuracy: 0.9031\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 35.4046 - accuracy: 0.9198 - val_loss: 35.4567 - val_accuracy: 0.8915\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 35.4318 - accuracy: 0.8915 - val_loss: 35.4181 - val_accuracy: 0.8953\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 35.4030 - accuracy: 0.8962 - val_loss: 35.4134 - val_accuracy: 0.8915\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 35.3839 - accuracy: 0.9057 - val_loss: 35.4087 - val_accuracy: 0.8915\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 35.3896 - accuracy: 0.8962 - val_loss: 35.3815 - val_accuracy: 0.8953\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 35.3686 - accuracy: 0.9009 - val_loss: 35.3550 - val_accuracy: 0.8837\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 35.3745 - accuracy: 0.8868 - val_loss: 35.3265 - val_accuracy: 0.9302\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 35.3397 - accuracy: 0.9198 - val_loss: 35.3275 - val_accuracy: 0.8915\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 35.3141 - accuracy: 0.9151 - val_loss: 35.3437 - val_accuracy: 0.8760\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 35.3080 - accuracy: 0.8868 - val_loss: 35.2933 - val_accuracy: 0.9109\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 35.2737 - accuracy: 0.9198 - val_loss: 35.2896 - val_accuracy: 0.8915\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 35.2778 - accuracy: 0.9057 - val_loss: 35.2994 - val_accuracy: 0.8837\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 35.2553 - accuracy: 0.8962 - val_loss: 35.2885 - val_accuracy: 0.8876\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 35.2462 - accuracy: 0.9198 - val_loss: 35.2374 - val_accuracy: 0.9070\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 35.2343 - accuracy: 0.9009 - val_loss: 35.2241 - val_accuracy: 0.8992\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 35.2023 - accuracy: 0.8962 - val_loss: 35.2068 - val_accuracy: 0.9031\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 35.1857 - accuracy: 0.9104 - val_loss: 35.1720 - val_accuracy: 0.8992\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 35.1815 - accuracy: 0.9292 - val_loss: 35.1883 - val_accuracy: 0.9147\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 35.1650 - accuracy: 0.9245 - val_loss: 35.1662 - val_accuracy: 0.8915\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 35.1598 - accuracy: 0.8962 - val_loss: 35.1470 - val_accuracy: 0.9147\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 35.1534 - accuracy: 0.9009 - val_loss: 35.1272 - val_accuracy: 0.9147\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 35.1240 - accuracy: 0.9151 - val_loss: 35.1035 - val_accuracy: 0.9070\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 35.0870 - accuracy: 0.9151 - val_loss: 35.0843 - val_accuracy: 0.9070\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 35.0631 - accuracy: 0.9009 - val_loss: 35.0936 - val_accuracy: 0.8992\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 35.0997 - accuracy: 0.8915 - val_loss: 35.0882 - val_accuracy: 0.9031\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 35.0343 - accuracy: 0.9198 - val_loss: 35.0406 - val_accuracy: 0.9186\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 35.0535 - accuracy: 0.9104 - val_loss: 35.0456 - val_accuracy: 0.9031\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 35.0498 - accuracy: 0.9104 - val_loss: 35.0411 - val_accuracy: 0.9070\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 35.0281 - accuracy: 0.9057 - val_loss: 35.0007 - val_accuracy: 0.9147\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 34.9711 - accuracy: 0.9245 - val_loss: 35.0018 - val_accuracy: 0.9264\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 34.9785 - accuracy: 0.9198 - val_loss: 34.9758 - val_accuracy: 0.9109\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 34.9669 - accuracy: 0.9292 - val_loss: 34.9777 - val_accuracy: 0.9031\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 34.9520 - accuracy: 0.9151 - val_loss: 34.9718 - val_accuracy: 0.9109\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 34.9124 - accuracy: 0.9387 - val_loss: 34.9357 - val_accuracy: 0.9031\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 34.9259 - accuracy: 0.9057 - val_loss: 34.9119 - val_accuracy: 0.9147\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 34.8872 - accuracy: 0.9387 - val_loss: 34.9141 - val_accuracy: 0.9031\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 34.9157 - accuracy: 0.8962 - val_loss: 34.8939 - val_accuracy: 0.9070\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 34.8640 - accuracy: 0.9151 - val_loss: 34.8747 - val_accuracy: 0.9147\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 34.8652 - accuracy: 0.9292 - val_loss: 34.8668 - val_accuracy: 0.9225\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 34.8291 - accuracy: 0.9198 - val_loss: 34.8350 - val_accuracy: 0.9302\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 34.8021 - accuracy: 0.9387 - val_loss: 34.8448 - val_accuracy: 0.9031\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 34.8056 - accuracy: 0.9245 - val_loss: 34.8030 - val_accuracy: 0.9225\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 34.7739 - accuracy: 0.9434 - val_loss: 34.8127 - val_accuracy: 0.8953\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 34.7780 - accuracy: 0.9198 - val_loss: 34.7911 - val_accuracy: 0.8992\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 34.7465 - accuracy: 0.9245 - val_loss: 34.7462 - val_accuracy: 0.9341\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 34.8004 - accuracy: 0.9009 - val_loss: 34.7410 - val_accuracy: 0.9302\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 34.7675 - accuracy: 0.8962 - val_loss: 34.7395 - val_accuracy: 0.9109\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 34.7111 - accuracy: 0.9245 - val_loss: 34.7405 - val_accuracy: 0.9031\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 34.7129 - accuracy: 0.9198 - val_loss: 34.7158 - val_accuracy: 0.9109\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 34.7201 - accuracy: 0.9198 - val_loss: 34.7054 - val_accuracy: 0.9186\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 378ms/step - loss: 34.7187 - accuracy: 0.9104 - val_loss: 34.6830 - val_accuracy: 0.9147\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 34.6888 - accuracy: 0.9057 - val_loss: 34.7036 - val_accuracy: 0.8876\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 34.6677 - accuracy: 0.9057 - val_loss: 34.6482 - val_accuracy: 0.9070\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 34.6190 - accuracy: 0.9340 - val_loss: 34.6432 - val_accuracy: 0.9070\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 34.5988 - accuracy: 0.9340 - val_loss: 34.6342 - val_accuracy: 0.9070\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 34.6310 - accuracy: 0.9057 - val_loss: 34.6340 - val_accuracy: 0.8992\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 34.5952 - accuracy: 0.9151 - val_loss: 34.5950 - val_accuracy: 0.9225\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 34.5887 - accuracy: 0.9198 - val_loss: 34.5721 - val_accuracy: 0.9070\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 34.5581 - accuracy: 0.9104 - val_loss: 34.5723 - val_accuracy: 0.9186\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 34.5599 - accuracy: 0.9292 - val_loss: 34.5759 - val_accuracy: 0.8915\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 34.6187 - accuracy: 0.8632 - val_loss: 34.5419 - val_accuracy: 0.8992\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 34.5058 - accuracy: 0.9340 - val_loss: 34.5149 - val_accuracy: 0.9109\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 34.5260 - accuracy: 0.9151 - val_loss: 34.4993 - val_accuracy: 0.9147\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 34.5029 - accuracy: 0.9340 - val_loss: 34.4720 - val_accuracy: 0.9225\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 34.4724 - accuracy: 0.9434 - val_loss: 34.4701 - val_accuracy: 0.9380\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 34.4514 - accuracy: 0.9292 - val_loss: 34.4556 - val_accuracy: 0.9109\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 34.4268 - accuracy: 0.9340 - val_loss: 34.4715 - val_accuracy: 0.9031\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 34.4570 - accuracy: 0.8868 - val_loss: 34.4371 - val_accuracy: 0.9225\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 34.4618 - accuracy: 0.9057 - val_loss: 34.3868 - val_accuracy: 0.9302\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 34.4219 - accuracy: 0.8962 - val_loss: 34.4102 - val_accuracy: 0.9070\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 34.3519 - accuracy: 0.9151 - val_loss: 34.3842 - val_accuracy: 0.9302\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 34.3572 - accuracy: 0.9340 - val_loss: 34.3864 - val_accuracy: 0.9070\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 34.3390 - accuracy: 0.9245 - val_loss: 34.3569 - val_accuracy: 0.9225\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 34.3999 - accuracy: 0.8868 - val_loss: 34.3497 - val_accuracy: 0.9109\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 34.3395 - accuracy: 0.9104 - val_loss: 34.3198 - val_accuracy: 0.9302\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 34.2978 - accuracy: 0.9292 - val_loss: 34.3075 - val_accuracy: 0.9225\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 34.2955 - accuracy: 0.9340 - val_loss: 34.3020 - val_accuracy: 0.9186\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 34.2526 - accuracy: 0.9434 - val_loss: 34.2854 - val_accuracy: 0.8992\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 34.2774 - accuracy: 0.9009 - val_loss: 34.2658 - val_accuracy: 0.9109\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 34.2736 - accuracy: 0.9245 - val_loss: 34.2984 - val_accuracy: 0.9070\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 34.2109 - accuracy: 0.9340 - val_loss: 34.2554 - val_accuracy: 0.9109\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 34.2004 - accuracy: 0.9245 - val_loss: 34.2612 - val_accuracy: 0.8915\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 34.2320 - accuracy: 0.9198 - val_loss: 34.2141 - val_accuracy: 0.9225\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 34.2348 - accuracy: 0.9009 - val_loss: 34.1912 - val_accuracy: 0.9186\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 34.1724 - accuracy: 0.9245 - val_loss: 34.2056 - val_accuracy: 0.9109\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 34.1647 - accuracy: 0.9292 - val_loss: 34.1357 - val_accuracy: 0.9225\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 34.1600 - accuracy: 0.9151 - val_loss: 34.1371 - val_accuracy: 0.9302\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 34.1543 - accuracy: 0.9151 - val_loss: 34.1513 - val_accuracy: 0.9070\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 34.1732 - accuracy: 0.9009 - val_loss: 34.1150 - val_accuracy: 0.9225\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 34.0817 - accuracy: 0.9387 - val_loss: 34.0844 - val_accuracy: 0.9341\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 34.1831 - accuracy: 0.8774 - val_loss: 34.0931 - val_accuracy: 0.9264\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 34.0996 - accuracy: 0.9198 - val_loss: 34.0781 - val_accuracy: 0.9109\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 34.0653 - accuracy: 0.9198 - val_loss: 34.0682 - val_accuracy: 0.9070\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 34.0560 - accuracy: 0.9245 - val_loss: 34.0283 - val_accuracy: 0.9302\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 34.0064 - accuracy: 0.9292 - val_loss: 34.0439 - val_accuracy: 0.9264\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 34.0558 - accuracy: 0.9104 - val_loss: 34.0039 - val_accuracy: 0.9457\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 34.0010 - accuracy: 0.9340 - val_loss: 34.0232 - val_accuracy: 0.9186\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 34.0139 - accuracy: 0.8962 - val_loss: 34.0101 - val_accuracy: 0.9070\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 33.9843 - accuracy: 0.9292 - val_loss: 33.9852 - val_accuracy: 0.9031\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 34.0127 - accuracy: 0.9009 - val_loss: 33.9404 - val_accuracy: 0.9225\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 33.9395 - accuracy: 0.9151 - val_loss: 33.9613 - val_accuracy: 0.8992\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 33.9397 - accuracy: 0.9104 - val_loss: 33.9208 - val_accuracy: 0.9264\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 33.9192 - accuracy: 0.9292 - val_loss: 33.9196 - val_accuracy: 0.9264\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 33.9139 - accuracy: 0.9104 - val_loss: 33.8803 - val_accuracy: 0.9302\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 33.8978 - accuracy: 0.9387 - val_loss: 33.8862 - val_accuracy: 0.9225\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 33.8895 - accuracy: 0.9057 - val_loss: 33.8599 - val_accuracy: 0.9380\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 33.8462 - accuracy: 0.9009 - val_loss: 33.8803 - val_accuracy: 0.8992\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 33.8553 - accuracy: 0.9151 - val_loss: 33.8346 - val_accuracy: 0.9264\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 33.8504 - accuracy: 0.9245 - val_loss: 33.8128 - val_accuracy: 0.9419\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 33.8146 - accuracy: 0.9245 - val_loss: 33.8318 - val_accuracy: 0.9225\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 33.8048 - accuracy: 0.9104 - val_loss: 33.7867 - val_accuracy: 0.9225\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 33.8358 - accuracy: 0.9009 - val_loss: 33.7940 - val_accuracy: 0.9186\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 33.7520 - accuracy: 0.9292 - val_loss: 33.7540 - val_accuracy: 0.9419\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 33.7751 - accuracy: 0.9151 - val_loss: 33.7405 - val_accuracy: 0.9457\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 33.7374 - accuracy: 0.9528 - val_loss: 33.7289 - val_accuracy: 0.9225\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 33.7363 - accuracy: 0.9009 - val_loss: 33.7241 - val_accuracy: 0.9341\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 33.7535 - accuracy: 0.9009 - val_loss: 33.7080 - val_accuracy: 0.9341\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 33.7019 - accuracy: 0.9151 - val_loss: 33.7089 - val_accuracy: 0.9147\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 33.7355 - accuracy: 0.9198 - val_loss: 33.7050 - val_accuracy: 0.9225\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 33.6762 - accuracy: 0.9245 - val_loss: 33.6559 - val_accuracy: 0.9341\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 33.6585 - accuracy: 0.9198 - val_loss: 33.6450 - val_accuracy: 0.9341\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 33.6375 - accuracy: 0.9340 - val_loss: 33.6513 - val_accuracy: 0.9264\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 33.6228 - accuracy: 0.9198 - val_loss: 33.6337 - val_accuracy: 0.9070\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 33.6361 - accuracy: 0.9057 - val_loss: 33.6477 - val_accuracy: 0.8992\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 33.5658 - accuracy: 0.9340 - val_loss: 33.5778 - val_accuracy: 0.9186\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 33.6203 - accuracy: 0.8774 - val_loss: 33.5641 - val_accuracy: 0.9147\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 33.6182 - accuracy: 0.9104 - val_loss: 33.5883 - val_accuracy: 0.9109\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 33.5683 - accuracy: 0.9245 - val_loss: 33.5696 - val_accuracy: 0.8992\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 33.5427 - accuracy: 0.9387 - val_loss: 33.5504 - val_accuracy: 0.9264\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 33.4727 - accuracy: 0.9481 - val_loss: 33.5372 - val_accuracy: 0.9264\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 33.4976 - accuracy: 0.9434 - val_loss: 33.4876 - val_accuracy: 0.9302\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 33.4988 - accuracy: 0.9245 - val_loss: 33.5090 - val_accuracy: 0.9147\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 33.4944 - accuracy: 0.9009 - val_loss: 33.4894 - val_accuracy: 0.9070\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 33.4528 - accuracy: 0.9292 - val_loss: 33.4606 - val_accuracy: 0.9225\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 33.4389 - accuracy: 0.9292 - val_loss: 33.4612 - val_accuracy: 0.9070\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 33.4403 - accuracy: 0.9151 - val_loss: 33.4321 - val_accuracy: 0.9147\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 33.3828 - accuracy: 0.9481 - val_loss: 33.4198 - val_accuracy: 0.9225\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 33.3610 - accuracy: 0.9434 - val_loss: 33.4123 - val_accuracy: 0.9147\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 33.4047 - accuracy: 0.9245 - val_loss: 33.3805 - val_accuracy: 0.9419\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 33.3917 - accuracy: 0.9245 - val_loss: 33.3881 - val_accuracy: 0.9186\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 33.4402 - accuracy: 0.8962 - val_loss: 33.3661 - val_accuracy: 0.9264\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 33.3547 - accuracy: 0.9245 - val_loss: 33.3578 - val_accuracy: 0.9186\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 33.3629 - accuracy: 0.9104 - val_loss: 33.3368 - val_accuracy: 0.9186\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 33.3154 - accuracy: 0.9387 - val_loss: 33.3150 - val_accuracy: 0.9225\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 33.2802 - accuracy: 0.9434 - val_loss: 33.3181 - val_accuracy: 0.9302\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 33.3197 - accuracy: 0.9198 - val_loss: 33.2870 - val_accuracy: 0.9341\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 33.2874 - accuracy: 0.9340 - val_loss: 33.2682 - val_accuracy: 0.9264\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 33.2541 - accuracy: 0.9198 - val_loss: 33.2505 - val_accuracy: 0.9341\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 33.2593 - accuracy: 0.9292 - val_loss: 33.2224 - val_accuracy: 0.9457\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 33.2693 - accuracy: 0.8962 - val_loss: 33.2055 - val_accuracy: 0.9380\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 33.2251 - accuracy: 0.9340 - val_loss: 33.2224 - val_accuracy: 0.9186\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 33.2271 - accuracy: 0.9292 - val_loss: 33.2151 - val_accuracy: 0.9109\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 33.2480 - accuracy: 0.8821 - val_loss: 33.1861 - val_accuracy: 0.9264\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 33.1800 - accuracy: 0.9387 - val_loss: 33.1979 - val_accuracy: 0.9109\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 33.1258 - accuracy: 0.9481 - val_loss: 33.1434 - val_accuracy: 0.9341\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 33.1622 - accuracy: 0.9245 - val_loss: 33.1273 - val_accuracy: 0.9496\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 33.1699 - accuracy: 0.9151 - val_loss: 33.1046 - val_accuracy: 0.9341\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 33.1132 - accuracy: 0.9245 - val_loss: 33.1099 - val_accuracy: 0.9186\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 33.1590 - accuracy: 0.9198 - val_loss: 33.0701 - val_accuracy: 0.9341\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 33.0669 - accuracy: 0.9340 - val_loss: 33.1069 - val_accuracy: 0.9186\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 33.0957 - accuracy: 0.9198 - val_loss: 33.0543 - val_accuracy: 0.9225\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 33.0375 - accuracy: 0.9481 - val_loss: 33.0674 - val_accuracy: 0.9225\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 287ms/step - loss: 33.0454 - accuracy: 0.9245 - val_loss: 33.0534 - val_accuracy: 0.9147\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 33.0198 - accuracy: 0.9340 - val_loss: 33.0433 - val_accuracy: 0.9264\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 33.0317 - accuracy: 0.9245 - val_loss: 33.0020 - val_accuracy: 0.9457\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 33.0153 - accuracy: 0.9198 - val_loss: 33.0075 - val_accuracy: 0.9225\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 32.9757 - accuracy: 0.9387 - val_loss: 32.9675 - val_accuracy: 0.9302\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 32.9874 - accuracy: 0.9292 - val_loss: 32.9639 - val_accuracy: 0.9225\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 32.9537 - accuracy: 0.9340 - val_loss: 32.9715 - val_accuracy: 0.9302\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 32.9668 - accuracy: 0.9151 - val_loss: 32.9465 - val_accuracy: 0.9225\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 32.8995 - accuracy: 0.9387 - val_loss: 32.9008 - val_accuracy: 0.9457\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 32.9392 - accuracy: 0.9198 - val_loss: 32.8723 - val_accuracy: 0.9419\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 32.8627 - accuracy: 0.9481 - val_loss: 32.8728 - val_accuracy: 0.9302\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 32.8958 - accuracy: 0.9387 - val_loss: 32.9055 - val_accuracy: 0.9186\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 32.9067 - accuracy: 0.9104 - val_loss: 32.8579 - val_accuracy: 0.9264\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 32.8518 - accuracy: 0.9292 - val_loss: 32.8356 - val_accuracy: 0.9419\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 32.8374 - accuracy: 0.9434 - val_loss: 32.8441 - val_accuracy: 0.9341\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 32.8359 - accuracy: 0.9292 - val_loss: 32.8350 - val_accuracy: 0.9341\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 32.8003 - accuracy: 0.9340 - val_loss: 32.8121 - val_accuracy: 0.9302\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 32.7648 - accuracy: 0.9528 - val_loss: 32.7710 - val_accuracy: 0.9419\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 32.7849 - accuracy: 0.9340 - val_loss: 32.7637 - val_accuracy: 0.9419\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 32.7693 - accuracy: 0.9292 - val_loss: 32.7737 - val_accuracy: 0.9070\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 32.7574 - accuracy: 0.9387 - val_loss: 32.7471 - val_accuracy: 0.9341\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 32.7247 - accuracy: 0.9340 - val_loss: 32.7514 - val_accuracy: 0.9186\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 32.7286 - accuracy: 0.9340 - val_loss: 32.7210 - val_accuracy: 0.9380\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 32.7278 - accuracy: 0.9245 - val_loss: 32.7236 - val_accuracy: 0.9225\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 32.6994 - accuracy: 0.9481 - val_loss: 32.6841 - val_accuracy: 0.9264\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 32.6885 - accuracy: 0.9340 - val_loss: 32.6717 - val_accuracy: 0.9302\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 32.6839 - accuracy: 0.9151 - val_loss: 32.6834 - val_accuracy: 0.9147\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 32.6496 - accuracy: 0.9528 - val_loss: 32.6633 - val_accuracy: 0.9264\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 32.6156 - accuracy: 0.9387 - val_loss: 32.6559 - val_accuracy: 0.9302\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 32.6465 - accuracy: 0.9292 - val_loss: 32.6270 - val_accuracy: 0.9302\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 32.5784 - accuracy: 0.9528 - val_loss: 32.6189 - val_accuracy: 0.9264\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 32.6329 - accuracy: 0.9057 - val_loss: 32.5822 - val_accuracy: 0.9264\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 32.5762 - accuracy: 0.9292 - val_loss: 32.5742 - val_accuracy: 0.9419\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 32.5699 - accuracy: 0.9340 - val_loss: 32.5418 - val_accuracy: 0.9380\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 32.5466 - accuracy: 0.9387 - val_loss: 32.5148 - val_accuracy: 0.9341\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 32.5358 - accuracy: 0.9292 - val_loss: 32.5361 - val_accuracy: 0.9147\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 32.5599 - accuracy: 0.9245 - val_loss: 32.5068 - val_accuracy: 0.9419\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 32.5065 - accuracy: 0.9387 - val_loss: 32.4795 - val_accuracy: 0.9380\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 32.4923 - accuracy: 0.9198 - val_loss: 32.4907 - val_accuracy: 0.9264\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 32.4625 - accuracy: 0.9387 - val_loss: 32.4378 - val_accuracy: 0.9496\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 32.4517 - accuracy: 0.9387 - val_loss: 32.4673 - val_accuracy: 0.9186\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 32.4435 - accuracy: 0.9481 - val_loss: 32.4719 - val_accuracy: 0.9186\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 32.4038 - accuracy: 0.9528 - val_loss: 32.4451 - val_accuracy: 0.9147\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 32.4652 - accuracy: 0.9245 - val_loss: 32.4039 - val_accuracy: 0.9380\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 32.4051 - accuracy: 0.9387 - val_loss: 32.4086 - val_accuracy: 0.9225\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 32.3919 - accuracy: 0.9340 - val_loss: 32.3971 - val_accuracy: 0.9186\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 32.3964 - accuracy: 0.9104 - val_loss: 32.3973 - val_accuracy: 0.9225\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 32.3720 - accuracy: 0.9434 - val_loss: 32.3443 - val_accuracy: 0.9380\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 32.3312 - accuracy: 0.9481 - val_loss: 32.3658 - val_accuracy: 0.9070\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 32.3288 - accuracy: 0.9292 - val_loss: 32.3175 - val_accuracy: 0.9341\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 32.3205 - accuracy: 0.9340 - val_loss: 32.3129 - val_accuracy: 0.9419\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 32.2868 - accuracy: 0.9528 - val_loss: 32.2988 - val_accuracy: 0.9380\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 32.2846 - accuracy: 0.9387 - val_loss: 32.2994 - val_accuracy: 0.9302\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 32.3005 - accuracy: 0.9292 - val_loss: 32.2335 - val_accuracy: 0.9457\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 32.2580 - accuracy: 0.9387 - val_loss: 32.2429 - val_accuracy: 0.9302\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 32.3049 - accuracy: 0.9151 - val_loss: 32.2502 - val_accuracy: 0.9302\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 32.2316 - accuracy: 0.9387 - val_loss: 32.2373 - val_accuracy: 0.9380\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 32.2545 - accuracy: 0.9104 - val_loss: 32.2073 - val_accuracy: 0.9380\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 32.2554 - accuracy: 0.9245 - val_loss: 32.2216 - val_accuracy: 0.9070\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 32.1817 - accuracy: 0.9387 - val_loss: 32.1834 - val_accuracy: 0.9341\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 32.1935 - accuracy: 0.9528 - val_loss: 32.1162 - val_accuracy: 0.9457\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 32.1510 - accuracy: 0.9340 - val_loss: 32.1831 - val_accuracy: 0.9109\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 32.1715 - accuracy: 0.9151 - val_loss: 32.1254 - val_accuracy: 0.9302\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 32.1334 - accuracy: 0.9434 - val_loss: 32.1105 - val_accuracy: 0.9419\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 32.2051 - accuracy: 0.8915 - val_loss: 32.0861 - val_accuracy: 0.9496\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 32.1137 - accuracy: 0.9340 - val_loss: 32.1187 - val_accuracy: 0.9264\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 32.1227 - accuracy: 0.9245 - val_loss: 32.0932 - val_accuracy: 0.9186\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 32.1000 - accuracy: 0.9104 - val_loss: 32.0507 - val_accuracy: 0.9419\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 32.0635 - accuracy: 0.9245 - val_loss: 32.0452 - val_accuracy: 0.9419\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 32.0443 - accuracy: 0.9198 - val_loss: 32.0537 - val_accuracy: 0.9341\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 32.0421 - accuracy: 0.9340 - val_loss: 32.0263 - val_accuracy: 0.9419\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 32.0362 - accuracy: 0.9528 - val_loss: 32.0091 - val_accuracy: 0.9341\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 32.0077 - accuracy: 0.9340 - val_loss: 32.0227 - val_accuracy: 0.9109\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 31.9496 - accuracy: 0.9481 - val_loss: 31.9500 - val_accuracy: 0.9457\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 32.0238 - accuracy: 0.9104 - val_loss: 31.9736 - val_accuracy: 0.9302\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 31.9913 - accuracy: 0.9198 - val_loss: 31.9363 - val_accuracy: 0.9457\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 31.9760 - accuracy: 0.9292 - val_loss: 31.9481 - val_accuracy: 0.9109\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 32.0150 - accuracy: 0.9151 - val_loss: 31.9099 - val_accuracy: 0.9302\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 31.9193 - accuracy: 0.9434 - val_loss: 31.9211 - val_accuracy: 0.9186\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 31.9070 - accuracy: 0.9434 - val_loss: 31.8699 - val_accuracy: 0.9457\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 31.8820 - accuracy: 0.9245 - val_loss: 31.8950 - val_accuracy: 0.9225\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 31.8849 - accuracy: 0.9292 - val_loss: 31.9187 - val_accuracy: 0.9186\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 31.9403 - accuracy: 0.9104 - val_loss: 31.8219 - val_accuracy: 0.9496\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 31.8724 - accuracy: 0.9245 - val_loss: 31.8165 - val_accuracy: 0.9341\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 31.8243 - accuracy: 0.9340 - val_loss: 31.8180 - val_accuracy: 0.9457\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 31.8641 - accuracy: 0.9104 - val_loss: 31.7920 - val_accuracy: 0.9457\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 31.7857 - accuracy: 0.9528 - val_loss: 31.8153 - val_accuracy: 0.9302\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 31.7963 - accuracy: 0.9434 - val_loss: 31.7506 - val_accuracy: 0.9535\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 31.8528 - accuracy: 0.9009 - val_loss: 31.7703 - val_accuracy: 0.9302\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 31.7208 - accuracy: 0.9340 - val_loss: 31.7920 - val_accuracy: 0.9225\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 31.7638 - accuracy: 0.9340 - val_loss: 31.7287 - val_accuracy: 0.9419\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 31.7407 - accuracy: 0.9340 - val_loss: 31.7250 - val_accuracy: 0.9419\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 31.7465 - accuracy: 0.9198 - val_loss: 31.7258 - val_accuracy: 0.9419\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 31.7986 - accuracy: 0.9057 - val_loss: 31.7032 - val_accuracy: 0.9341\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 31.7107 - accuracy: 0.9340 - val_loss: 31.6994 - val_accuracy: 0.9302\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 31.7060 - accuracy: 0.9151 - val_loss: 31.6924 - val_accuracy: 0.9264\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 31.6527 - accuracy: 0.9387 - val_loss: 31.6808 - val_accuracy: 0.9225\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 31.6780 - accuracy: 0.9340 - val_loss: 31.6557 - val_accuracy: 0.9225\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 31.6349 - accuracy: 0.9340 - val_loss: 31.6647 - val_accuracy: 0.9147\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 31.6258 - accuracy: 0.9292 - val_loss: 31.6014 - val_accuracy: 0.9457\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 31.6255 - accuracy: 0.9340 - val_loss: 31.6049 - val_accuracy: 0.9302\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 31.6013 - accuracy: 0.9340 - val_loss: 31.5814 - val_accuracy: 0.9302\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 31.5801 - accuracy: 0.9434 - val_loss: 31.5524 - val_accuracy: 0.9341\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 31.5710 - accuracy: 0.9198 - val_loss: 31.5795 - val_accuracy: 0.9147\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 31.5378 - accuracy: 0.9575 - val_loss: 31.5845 - val_accuracy: 0.9070\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 31.6350 - accuracy: 0.9009 - val_loss: 31.4991 - val_accuracy: 0.9457\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 31.5252 - accuracy: 0.9387 - val_loss: 31.5197 - val_accuracy: 0.9457\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 31.5028 - accuracy: 0.9387 - val_loss: 31.5034 - val_accuracy: 0.9302\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 31.4732 - accuracy: 0.9434 - val_loss: 31.4946 - val_accuracy: 0.9225\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 31.4530 - accuracy: 0.9340 - val_loss: 31.4829 - val_accuracy: 0.9225\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 31.4727 - accuracy: 0.9340 - val_loss: 31.4507 - val_accuracy: 0.9380\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 31.4016 - accuracy: 0.9575 - val_loss: 31.4807 - val_accuracy: 0.8992\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 391ms/step - loss: 31.4707 - accuracy: 0.9340 - val_loss: 31.4239 - val_accuracy: 0.9302\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 31.4111 - accuracy: 0.9292 - val_loss: 31.4034 - val_accuracy: 0.9496\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 31.4013 - accuracy: 0.9481 - val_loss: 31.3995 - val_accuracy: 0.9380\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 31.4153 - accuracy: 0.9198 - val_loss: 31.3770 - val_accuracy: 0.9457\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 31.3576 - accuracy: 0.9481 - val_loss: 31.3863 - val_accuracy: 0.9302\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 31.3731 - accuracy: 0.9340 - val_loss: 31.3388 - val_accuracy: 0.9419\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 31.3707 - accuracy: 0.9198 - val_loss: 31.3696 - val_accuracy: 0.9225\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 31.3525 - accuracy: 0.9151 - val_loss: 31.3179 - val_accuracy: 0.9341\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 31.3379 - accuracy: 0.9104 - val_loss: 31.3096 - val_accuracy: 0.9419\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 31.3133 - accuracy: 0.9434 - val_loss: 31.2609 - val_accuracy: 0.9535\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 31.2968 - accuracy: 0.9340 - val_loss: 31.3196 - val_accuracy: 0.9147\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 31.2870 - accuracy: 0.9198 - val_loss: 31.2947 - val_accuracy: 0.9186\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 31.3302 - accuracy: 0.8962 - val_loss: 31.2316 - val_accuracy: 0.9419\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 31.2293 - accuracy: 0.9481 - val_loss: 31.2478 - val_accuracy: 0.9419\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 31.2423 - accuracy: 0.9245 - val_loss: 31.2168 - val_accuracy: 0.9341\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 31.2195 - accuracy: 0.9340 - val_loss: 31.2220 - val_accuracy: 0.9186\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 31.2260 - accuracy: 0.9340 - val_loss: 31.2292 - val_accuracy: 0.9225\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 31.2080 - accuracy: 0.9198 - val_loss: 31.1468 - val_accuracy: 0.9535\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 31.1841 - accuracy: 0.9340 - val_loss: 31.1399 - val_accuracy: 0.9419\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 31.1408 - accuracy: 0.9434 - val_loss: 31.1792 - val_accuracy: 0.9302\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 31.1463 - accuracy: 0.9387 - val_loss: 31.1634 - val_accuracy: 0.9186\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 31.1686 - accuracy: 0.9245 - val_loss: 31.1691 - val_accuracy: 0.9070\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 31.1351 - accuracy: 0.9292 - val_loss: 31.1094 - val_accuracy: 0.9225\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 31.0785 - accuracy: 0.9481 - val_loss: 31.0741 - val_accuracy: 0.9457\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 31.0933 - accuracy: 0.9340 - val_loss: 31.0884 - val_accuracy: 0.9457\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 31.0354 - accuracy: 0.9575 - val_loss: 31.1054 - val_accuracy: 0.9186\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 31.1077 - accuracy: 0.9151 - val_loss: 31.0462 - val_accuracy: 0.9341\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 31.0731 - accuracy: 0.9198 - val_loss: 31.0400 - val_accuracy: 0.9341\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 31.0571 - accuracy: 0.9292 - val_loss: 31.0266 - val_accuracy: 0.9264\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 31.0351 - accuracy: 0.9387 - val_loss: 30.9948 - val_accuracy: 0.9380\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 30.9673 - accuracy: 0.9481 - val_loss: 30.9988 - val_accuracy: 0.9341\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 31.0054 - accuracy: 0.9387 - val_loss: 31.0288 - val_accuracy: 0.9186\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 30.9639 - accuracy: 0.9340 - val_loss: 30.9888 - val_accuracy: 0.9147\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 30.9808 - accuracy: 0.9292 - val_loss: 30.9555 - val_accuracy: 0.9341\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 30.9261 - accuracy: 0.9434 - val_loss: 30.9180 - val_accuracy: 0.9457\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 30.9409 - accuracy: 0.9387 - val_loss: 30.9293 - val_accuracy: 0.9380\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 30.9719 - accuracy: 0.9151 - val_loss: 30.9104 - val_accuracy: 0.9380\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 30.9307 - accuracy: 0.9292 - val_loss: 30.9054 - val_accuracy: 0.9419\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 30.8932 - accuracy: 0.9104 - val_loss: 30.9268 - val_accuracy: 0.9070\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 30.9095 - accuracy: 0.9198 - val_loss: 30.8865 - val_accuracy: 0.9341\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 30.8425 - accuracy: 0.9387 - val_loss: 30.8332 - val_accuracy: 0.9380\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 30.8910 - accuracy: 0.9198 - val_loss: 30.8858 - val_accuracy: 0.9186\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 30.8379 - accuracy: 0.9434 - val_loss: 30.8070 - val_accuracy: 0.9535\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 30.8237 - accuracy: 0.9434 - val_loss: 30.8034 - val_accuracy: 0.9380\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 30.7984 - accuracy: 0.9340 - val_loss: 30.7711 - val_accuracy: 0.9419\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 30.8056 - accuracy: 0.9340 - val_loss: 30.7858 - val_accuracy: 0.9341\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 30.7672 - accuracy: 0.9434 - val_loss: 30.7922 - val_accuracy: 0.9264\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 30.7224 - accuracy: 0.9575 - val_loss: 30.7721 - val_accuracy: 0.9341\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 30.7478 - accuracy: 0.9387 - val_loss: 30.7628 - val_accuracy: 0.9341\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 30.7351 - accuracy: 0.9387 - val_loss: 30.7629 - val_accuracy: 0.9264\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 30.7869 - accuracy: 0.9057 - val_loss: 30.6997 - val_accuracy: 0.9651\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 30.7229 - accuracy: 0.9387 - val_loss: 30.7244 - val_accuracy: 0.9341\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 30.6970 - accuracy: 0.9575 - val_loss: 30.6854 - val_accuracy: 0.9380\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 30.6422 - accuracy: 0.9481 - val_loss: 30.6551 - val_accuracy: 0.9419\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 30.7225 - accuracy: 0.8962 - val_loss: 30.6159 - val_accuracy: 0.9651\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 30.6143 - accuracy: 0.9575 - val_loss: 30.6395 - val_accuracy: 0.9496\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 30.6448 - accuracy: 0.9387 - val_loss: 30.6337 - val_accuracy: 0.9341\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 30.6565 - accuracy: 0.9151 - val_loss: 30.6319 - val_accuracy: 0.9225\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 30.6055 - accuracy: 0.9245 - val_loss: 30.6176 - val_accuracy: 0.9147\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 30.6365 - accuracy: 0.9198 - val_loss: 30.6150 - val_accuracy: 0.9186\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 30.6123 - accuracy: 0.9387 - val_loss: 30.5744 - val_accuracy: 0.9341\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 30.6428 - accuracy: 0.9245 - val_loss: 30.5406 - val_accuracy: 0.9341\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 30.5563 - accuracy: 0.9387 - val_loss: 30.5563 - val_accuracy: 0.9341\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 30.5101 - accuracy: 0.9528 - val_loss: 30.5026 - val_accuracy: 0.9457\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 30.5500 - accuracy: 0.9151 - val_loss: 30.4991 - val_accuracy: 0.9302\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 30.5320 - accuracy: 0.9481 - val_loss: 30.5024 - val_accuracy: 0.9264\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 30.4909 - accuracy: 0.9481 - val_loss: 30.4711 - val_accuracy: 0.9419\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 30.5068 - accuracy: 0.9340 - val_loss: 30.4967 - val_accuracy: 0.9147\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 30.4808 - accuracy: 0.9292 - val_loss: 30.4743 - val_accuracy: 0.9264\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 30.5051 - accuracy: 0.8962 - val_loss: 30.4335 - val_accuracy: 0.9380\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 30.4744 - accuracy: 0.9245 - val_loss: 30.4386 - val_accuracy: 0.9225\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 30.4255 - accuracy: 0.9481 - val_loss: 30.4305 - val_accuracy: 0.9380\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 30.4573 - accuracy: 0.9245 - val_loss: 30.4394 - val_accuracy: 0.9186\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 30.3894 - accuracy: 0.9528 - val_loss: 30.3730 - val_accuracy: 0.9302\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 30.4016 - accuracy: 0.9387 - val_loss: 30.3445 - val_accuracy: 0.9341\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 30.3652 - accuracy: 0.9387 - val_loss: 30.3610 - val_accuracy: 0.9264\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 30.3611 - accuracy: 0.9245 - val_loss: 30.3347 - val_accuracy: 0.9419\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 30.3201 - accuracy: 0.9434 - val_loss: 30.3529 - val_accuracy: 0.9070\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 30.2818 - accuracy: 0.9670 - val_loss: 30.3129 - val_accuracy: 0.9341\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 30.2764 - accuracy: 0.9528 - val_loss: 30.3006 - val_accuracy: 0.9264\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 30.3308 - accuracy: 0.9292 - val_loss: 30.3103 - val_accuracy: 0.9225\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 30.2917 - accuracy: 0.9340 - val_loss: 30.2873 - val_accuracy: 0.9225\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 30.2813 - accuracy: 0.9434 - val_loss: 30.2867 - val_accuracy: 0.9225\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 30.3183 - accuracy: 0.9009 - val_loss: 30.2292 - val_accuracy: 0.9419\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 30.2346 - accuracy: 0.9481 - val_loss: 30.2187 - val_accuracy: 0.9496\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 30.1973 - accuracy: 0.9387 - val_loss: 30.2094 - val_accuracy: 0.9380\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 30.2081 - accuracy: 0.9340 - val_loss: 30.1743 - val_accuracy: 0.9380\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 30.1687 - accuracy: 0.9575 - val_loss: 30.2143 - val_accuracy: 0.9186\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 30.2276 - accuracy: 0.9340 - val_loss: 30.1767 - val_accuracy: 0.9225\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 30.2163 - accuracy: 0.9245 - val_loss: 30.1435 - val_accuracy: 0.9535\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 30.2865 - accuracy: 0.8962 - val_loss: 30.1321 - val_accuracy: 0.9341\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 30.1708 - accuracy: 0.9292 - val_loss: 30.1633 - val_accuracy: 0.9380\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 30.1322 - accuracy: 0.9245 - val_loss: 30.0881 - val_accuracy: 0.9419\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 30.1312 - accuracy: 0.9387 - val_loss: 30.1338 - val_accuracy: 0.9070\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 30.1334 - accuracy: 0.9198 - val_loss: 30.0828 - val_accuracy: 0.9496\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 30.0922 - accuracy: 0.9340 - val_loss: 30.1260 - val_accuracy: 0.9109\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 30.0947 - accuracy: 0.9292 - val_loss: 30.0833 - val_accuracy: 0.9341\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 30.0794 - accuracy: 0.9387 - val_loss: 30.0622 - val_accuracy: 0.9070\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 30.0465 - accuracy: 0.9528 - val_loss: 30.0367 - val_accuracy: 0.9419\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 30.1237 - accuracy: 0.8726 - val_loss: 29.9861 - val_accuracy: 0.9341\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 30.0051 - accuracy: 0.9387 - val_loss: 29.9826 - val_accuracy: 0.9535\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 30.0408 - accuracy: 0.9340 - val_loss: 29.9888 - val_accuracy: 0.9380\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 29.9705 - accuracy: 0.9528 - val_loss: 29.9815 - val_accuracy: 0.9341\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 29.9846 - accuracy: 0.9340 - val_loss: 29.9821 - val_accuracy: 0.9419\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 29.9688 - accuracy: 0.9434 - val_loss: 29.9544 - val_accuracy: 0.9380\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 29.9220 - accuracy: 0.9481 - val_loss: 29.9660 - val_accuracy: 0.9147\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 29.9520 - accuracy: 0.9434 - val_loss: 29.9672 - val_accuracy: 0.9109\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 29.9688 - accuracy: 0.9198 - val_loss: 29.8946 - val_accuracy: 0.9457\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 29.8900 - accuracy: 0.9292 - val_loss: 29.8945 - val_accuracy: 0.9457\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 29.8816 - accuracy: 0.9387 - val_loss: 29.8719 - val_accuracy: 0.9341\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 29.8902 - accuracy: 0.9245 - val_loss: 29.8974 - val_accuracy: 0.9147\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 29.8572 - accuracy: 0.9528 - val_loss: 29.8309 - val_accuracy: 0.9496\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 400ms/step - loss: 29.8768 - accuracy: 0.9104 - val_loss: 29.8396 - val_accuracy: 0.9380\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 29.8425 - accuracy: 0.9387 - val_loss: 29.8466 - val_accuracy: 0.9341\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 29.8229 - accuracy: 0.9292 - val_loss: 29.8644 - val_accuracy: 0.9225\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 29.8439 - accuracy: 0.9292 - val_loss: 29.7894 - val_accuracy: 0.9341\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 29.7929 - accuracy: 0.9481 - val_loss: 29.7858 - val_accuracy: 0.9341\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 29.8246 - accuracy: 0.9245 - val_loss: 29.7535 - val_accuracy: 0.9380\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 29.7670 - accuracy: 0.9245 - val_loss: 29.7683 - val_accuracy: 0.9341\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 29.8194 - accuracy: 0.9292 - val_loss: 29.7646 - val_accuracy: 0.9380\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 29.7205 - accuracy: 0.9528 - val_loss: 29.7493 - val_accuracy: 0.9380\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 29.7339 - accuracy: 0.9245 - val_loss: 29.7411 - val_accuracy: 0.9341\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 29.6438 - accuracy: 0.9623 - val_loss: 29.7193 - val_accuracy: 0.9302\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 29.7145 - accuracy: 0.9340 - val_loss: 29.6753 - val_accuracy: 0.9380\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 29.6974 - accuracy: 0.9151 - val_loss: 29.6719 - val_accuracy: 0.9457\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 29.6875 - accuracy: 0.9245 - val_loss: 29.6563 - val_accuracy: 0.9419\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 29.6539 - accuracy: 0.9434 - val_loss: 29.6387 - val_accuracy: 0.9496\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 29.6345 - accuracy: 0.9340 - val_loss: 29.6436 - val_accuracy: 0.9225\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 29.6347 - accuracy: 0.9481 - val_loss: 29.6113 - val_accuracy: 0.9341\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 29.5920 - accuracy: 0.9481 - val_loss: 29.5744 - val_accuracy: 0.9496\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 29.6188 - accuracy: 0.9292 - val_loss: 29.5684 - val_accuracy: 0.9380\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 29.5916 - accuracy: 0.9245 - val_loss: 29.5783 - val_accuracy: 0.9264\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 29.6208 - accuracy: 0.8915 - val_loss: 29.5595 - val_accuracy: 0.9341\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 29.5570 - accuracy: 0.9292 - val_loss: 29.5352 - val_accuracy: 0.9457\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 29.5510 - accuracy: 0.9434 - val_loss: 29.5348 - val_accuracy: 0.9341\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 29.5201 - accuracy: 0.9292 - val_loss: 29.5605 - val_accuracy: 0.9302\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 29.5057 - accuracy: 0.9292 - val_loss: 29.5115 - val_accuracy: 0.9302\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 29.5037 - accuracy: 0.9434 - val_loss: 29.5114 - val_accuracy: 0.9147\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 29.5230 - accuracy: 0.9151 - val_loss: 29.4815 - val_accuracy: 0.9186\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 29.4673 - accuracy: 0.9340 - val_loss: 29.4699 - val_accuracy: 0.9186\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 29.4783 - accuracy: 0.9434 - val_loss: 29.4485 - val_accuracy: 0.9457\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 29.4670 - accuracy: 0.9387 - val_loss: 29.4198 - val_accuracy: 0.9341\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 29.4423 - accuracy: 0.9245 - val_loss: 29.4194 - val_accuracy: 0.9419\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 29.4360 - accuracy: 0.9292 - val_loss: 29.4036 - val_accuracy: 0.9341\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 29.4094 - accuracy: 0.9198 - val_loss: 29.3924 - val_accuracy: 0.9341\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 29.3911 - accuracy: 0.9434 - val_loss: 29.4339 - val_accuracy: 0.9031\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 29.3346 - accuracy: 0.9481 - val_loss: 29.3783 - val_accuracy: 0.9109\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 29.4576 - accuracy: 0.8962 - val_loss: 29.3666 - val_accuracy: 0.9225\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 29.3483 - accuracy: 0.9151 - val_loss: 29.3026 - val_accuracy: 0.9457\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 29.3431 - accuracy: 0.9387 - val_loss: 29.3638 - val_accuracy: 0.9147\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 29.3045 - accuracy: 0.9245 - val_loss: 29.3205 - val_accuracy: 0.9109\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 29.3561 - accuracy: 0.9292 - val_loss: 29.3446 - val_accuracy: 0.9186\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 29.2815 - accuracy: 0.9387 - val_loss: 29.3217 - val_accuracy: 0.9147\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 29.3082 - accuracy: 0.9198 - val_loss: 29.2486 - val_accuracy: 0.9419\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 29.2829 - accuracy: 0.9198 - val_loss: 29.3090 - val_accuracy: 0.9031\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 29.2562 - accuracy: 0.9151 - val_loss: 29.2837 - val_accuracy: 0.9070\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 29.2220 - accuracy: 0.9481 - val_loss: 29.2229 - val_accuracy: 0.9341\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 29.2320 - accuracy: 0.9245 - val_loss: 29.2309 - val_accuracy: 0.9264\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 29.2373 - accuracy: 0.9104 - val_loss: 29.2173 - val_accuracy: 0.9225\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 29.2067 - accuracy: 0.9104 - val_loss: 29.1736 - val_accuracy: 0.9457\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 29.1676 - accuracy: 0.9481 - val_loss: 29.1967 - val_accuracy: 0.8953\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 29.1516 - accuracy: 0.9481 - val_loss: 29.1496 - val_accuracy: 0.9147\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 29.1611 - accuracy: 0.9292 - val_loss: 29.1545 - val_accuracy: 0.9147\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 29.1245 - accuracy: 0.9575 - val_loss: 29.1267 - val_accuracy: 0.9380\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 29.1220 - accuracy: 0.9340 - val_loss: 29.1280 - val_accuracy: 0.9186\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 29.1601 - accuracy: 0.9009 - val_loss: 29.0965 - val_accuracy: 0.9109\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 29.1390 - accuracy: 0.9151 - val_loss: 29.1162 - val_accuracy: 0.9341\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 29.0874 - accuracy: 0.9387 - val_loss: 29.0524 - val_accuracy: 0.9380\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 29.0490 - accuracy: 0.9340 - val_loss: 29.0554 - val_accuracy: 0.9186\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 29.0123 - accuracy: 0.9434 - val_loss: 29.0434 - val_accuracy: 0.9380\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 29.0512 - accuracy: 0.9198 - val_loss: 29.0433 - val_accuracy: 0.9225\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 29.0737 - accuracy: 0.9057 - val_loss: 29.0033 - val_accuracy: 0.9419\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 29.0318 - accuracy: 0.9104 - val_loss: 29.0045 - val_accuracy: 0.9186\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 28.9622 - accuracy: 0.9481 - val_loss: 28.9899 - val_accuracy: 0.9302\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 28.9432 - accuracy: 0.9670 - val_loss: 28.9964 - val_accuracy: 0.9070\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 28.9698 - accuracy: 0.9292 - val_loss: 28.9730 - val_accuracy: 0.9341\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 28.9423 - accuracy: 0.9481 - val_loss: 28.9504 - val_accuracy: 0.9341\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 28.9667 - accuracy: 0.9198 - val_loss: 28.9366 - val_accuracy: 0.9264\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 28.9263 - accuracy: 0.9245 - val_loss: 28.9176 - val_accuracy: 0.9380\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 28.8978 - accuracy: 0.9340 - val_loss: 28.8898 - val_accuracy: 0.9496\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 28.8932 - accuracy: 0.9481 - val_loss: 28.9781 - val_accuracy: 0.9070\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 28.8778 - accuracy: 0.9481 - val_loss: 28.8684 - val_accuracy: 0.9419\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 28.9902 - accuracy: 0.9245 - val_loss: 28.8713 - val_accuracy: 0.9109\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 28.8841 - accuracy: 0.9245 - val_loss: 28.8913 - val_accuracy: 0.9109\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 28.8349 - accuracy: 0.9528 - val_loss: 28.8248 - val_accuracy: 0.9419\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 28.8569 - accuracy: 0.9387 - val_loss: 28.8024 - val_accuracy: 0.9264\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 28.8333 - accuracy: 0.9387 - val_loss: 28.8038 - val_accuracy: 0.9457\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 28.8707 - accuracy: 0.9104 - val_loss: 28.7806 - val_accuracy: 0.9302\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 28.7827 - accuracy: 0.9340 - val_loss: 28.7663 - val_accuracy: 0.9380\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 28.7412 - accuracy: 0.9340 - val_loss: 28.7800 - val_accuracy: 0.9225\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 28.7196 - accuracy: 0.9434 - val_loss: 28.7696 - val_accuracy: 0.9302\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 28.7525 - accuracy: 0.9528 - val_loss: 28.7318 - val_accuracy: 0.9419\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 28.7842 - accuracy: 0.9104 - val_loss: 28.7379 - val_accuracy: 0.9302\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 28.7055 - accuracy: 0.9292 - val_loss: 28.7408 - val_accuracy: 0.9147\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 28.6908 - accuracy: 0.9245 - val_loss: 28.6940 - val_accuracy: 0.9225\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 28.7668 - accuracy: 0.8915 - val_loss: 28.6414 - val_accuracy: 0.9574\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 28.6751 - accuracy: 0.9387 - val_loss: 28.6701 - val_accuracy: 0.9302\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 28.6442 - accuracy: 0.9434 - val_loss: 28.6275 - val_accuracy: 0.9380\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 28.6571 - accuracy: 0.9292 - val_loss: 28.6508 - val_accuracy: 0.9225\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 28.6105 - accuracy: 0.9434 - val_loss: 28.6924 - val_accuracy: 0.9031\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 28.6353 - accuracy: 0.9104 - val_loss: 28.6153 - val_accuracy: 0.9264\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 28.6322 - accuracy: 0.9198 - val_loss: 28.6432 - val_accuracy: 0.9147\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 28.5786 - accuracy: 0.9481 - val_loss: 28.5824 - val_accuracy: 0.9341\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 28.6604 - accuracy: 0.8915 - val_loss: 28.5636 - val_accuracy: 0.9457\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 28.5872 - accuracy: 0.9198 - val_loss: 28.5683 - val_accuracy: 0.9186\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 28.6070 - accuracy: 0.9198 - val_loss: 28.5279 - val_accuracy: 0.9264\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 28.5385 - accuracy: 0.9198 - val_loss: 28.5514 - val_accuracy: 0.9341\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 28.5848 - accuracy: 0.9057 - val_loss: 28.5578 - val_accuracy: 0.9225\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 28.5224 - accuracy: 0.9387 - val_loss: 28.4925 - val_accuracy: 0.9341\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 28.4637 - accuracy: 0.9434 - val_loss: 28.4579 - val_accuracy: 0.9496\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 28.5446 - accuracy: 0.9057 - val_loss: 28.4509 - val_accuracy: 0.9535\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 28.5621 - accuracy: 0.8915 - val_loss: 28.4669 - val_accuracy: 0.9264\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 28.4496 - accuracy: 0.9198 - val_loss: 28.4534 - val_accuracy: 0.9109\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 28.4434 - accuracy: 0.9340 - val_loss: 28.4825 - val_accuracy: 0.9225\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 28.4456 - accuracy: 0.9340 - val_loss: 28.4186 - val_accuracy: 0.9264\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 28.4220 - accuracy: 0.9434 - val_loss: 28.4333 - val_accuracy: 0.9109\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 28.4548 - accuracy: 0.8962 - val_loss: 28.4020 - val_accuracy: 0.9147\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 28.4329 - accuracy: 0.9151 - val_loss: 28.4236 - val_accuracy: 0.9264\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 28.4303 - accuracy: 0.8915 - val_loss: 28.4081 - val_accuracy: 0.8953\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 28.3121 - accuracy: 0.9575 - val_loss: 28.3968 - val_accuracy: 0.8953\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 28.3242 - accuracy: 0.9481 - val_loss: 28.3466 - val_accuracy: 0.9264\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 28.3383 - accuracy: 0.9340 - val_loss: 28.3702 - val_accuracy: 0.9070\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 28.3172 - accuracy: 0.9292 - val_loss: 28.3240 - val_accuracy: 0.9225\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 28.3191 - accuracy: 0.9340 - val_loss: 28.3084 - val_accuracy: 0.9186\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 465ms/step - loss: 28.2625 - accuracy: 0.9434 - val_loss: 28.2603 - val_accuracy: 0.9419\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 28.2884 - accuracy: 0.9340 - val_loss: 28.2713 - val_accuracy: 0.9380\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 28.2398 - accuracy: 0.9481 - val_loss: 28.2617 - val_accuracy: 0.9186\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 28.2238 - accuracy: 0.9245 - val_loss: 28.2367 - val_accuracy: 0.9264\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 28.2017 - accuracy: 0.9528 - val_loss: 28.2286 - val_accuracy: 0.9302\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 28.1899 - accuracy: 0.9481 - val_loss: 28.1990 - val_accuracy: 0.9419\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 28.2276 - accuracy: 0.9151 - val_loss: 28.1915 - val_accuracy: 0.9419\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 28.1796 - accuracy: 0.9434 - val_loss: 28.1666 - val_accuracy: 0.9341\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 28.1787 - accuracy: 0.9340 - val_loss: 28.1925 - val_accuracy: 0.9264\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 28.1487 - accuracy: 0.9340 - val_loss: 28.1722 - val_accuracy: 0.9264\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 28.2546 - accuracy: 0.8868 - val_loss: 28.1699 - val_accuracy: 0.9186\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 28.1526 - accuracy: 0.9198 - val_loss: 28.1097 - val_accuracy: 0.9457\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 28.1166 - accuracy: 0.9340 - val_loss: 28.1456 - val_accuracy: 0.9070\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 28.1349 - accuracy: 0.9104 - val_loss: 28.1243 - val_accuracy: 0.9341\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 28.1178 - accuracy: 0.9245 - val_loss: 28.1177 - val_accuracy: 0.9186\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 28.1402 - accuracy: 0.9009 - val_loss: 28.0752 - val_accuracy: 0.9341\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 28.0296 - accuracy: 0.9528 - val_loss: 28.0584 - val_accuracy: 0.9341\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 28.0424 - accuracy: 0.9387 - val_loss: 28.0182 - val_accuracy: 0.9419\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 28.0544 - accuracy: 0.9292 - val_loss: 28.0253 - val_accuracy: 0.9380\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 28.0476 - accuracy: 0.9151 - val_loss: 28.0398 - val_accuracy: 0.9264\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 28.0392 - accuracy: 0.9104 - val_loss: 28.0147 - val_accuracy: 0.9264\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 27.9905 - accuracy: 0.9387 - val_loss: 28.0131 - val_accuracy: 0.9070\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 27.9751 - accuracy: 0.9387 - val_loss: 27.9901 - val_accuracy: 0.9186\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 28.0001 - accuracy: 0.9245 - val_loss: 27.9306 - val_accuracy: 0.9419\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 27.9589 - accuracy: 0.9104 - val_loss: 27.9318 - val_accuracy: 0.9341\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 27.9537 - accuracy: 0.9151 - val_loss: 27.9456 - val_accuracy: 0.9225\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 27.9399 - accuracy: 0.9151 - val_loss: 27.8875 - val_accuracy: 0.9457\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 27.9004 - accuracy: 0.9340 - val_loss: 27.8852 - val_accuracy: 0.9380\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 27.9207 - accuracy: 0.9245 - val_loss: 27.9196 - val_accuracy: 0.9070\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 27.8803 - accuracy: 0.9245 - val_loss: 27.9089 - val_accuracy: 0.9225\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 27.8887 - accuracy: 0.9151 - val_loss: 27.8989 - val_accuracy: 0.9070\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 27.8577 - accuracy: 0.9434 - val_loss: 27.8837 - val_accuracy: 0.9147\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 27.8808 - accuracy: 0.9104 - val_loss: 27.8166 - val_accuracy: 0.9341\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 27.8893 - accuracy: 0.8962 - val_loss: 27.8253 - val_accuracy: 0.9264\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 27.8433 - accuracy: 0.9198 - val_loss: 27.8127 - val_accuracy: 0.9457\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 27.7793 - accuracy: 0.9387 - val_loss: 27.7759 - val_accuracy: 0.9496\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 27.7774 - accuracy: 0.9245 - val_loss: 27.7846 - val_accuracy: 0.9302\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 27.7894 - accuracy: 0.9387 - val_loss: 27.7721 - val_accuracy: 0.9225\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 27.7397 - accuracy: 0.9481 - val_loss: 27.7575 - val_accuracy: 0.9186\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 27.7719 - accuracy: 0.9245 - val_loss: 27.7852 - val_accuracy: 0.8837\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 27.7367 - accuracy: 0.9387 - val_loss: 27.7281 - val_accuracy: 0.9457\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 27.7703 - accuracy: 0.9009 - val_loss: 27.7188 - val_accuracy: 0.9341\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 27.7160 - accuracy: 0.9387 - val_loss: 27.6794 - val_accuracy: 0.9186\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 27.7041 - accuracy: 0.9387 - val_loss: 27.6701 - val_accuracy: 0.9419\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 27.7134 - accuracy: 0.9009 - val_loss: 27.6602 - val_accuracy: 0.9302\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 27.6472 - accuracy: 0.9340 - val_loss: 27.7152 - val_accuracy: 0.9147\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 27.6687 - accuracy: 0.9245 - val_loss: 27.6054 - val_accuracy: 0.9651\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 27.6447 - accuracy: 0.9387 - val_loss: 27.6366 - val_accuracy: 0.9225\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 27.6389 - accuracy: 0.9151 - val_loss: 27.6145 - val_accuracy: 0.9186\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 27.6523 - accuracy: 0.9387 - val_loss: 27.5960 - val_accuracy: 0.9264\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 27.5594 - accuracy: 0.9387 - val_loss: 27.6209 - val_accuracy: 0.9264\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 27.6166 - accuracy: 0.9151 - val_loss: 27.5865 - val_accuracy: 0.9302\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 27.5894 - accuracy: 0.9104 - val_loss: 27.5743 - val_accuracy: 0.9419\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 27.5440 - accuracy: 0.9340 - val_loss: 27.5739 - val_accuracy: 0.9070\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 27.5741 - accuracy: 0.9198 - val_loss: 27.5643 - val_accuracy: 0.9147\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 27.5142 - accuracy: 0.9387 - val_loss: 27.4994 - val_accuracy: 0.9380\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 27.5066 - accuracy: 0.9198 - val_loss: 27.5141 - val_accuracy: 0.9264\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 27.5048 - accuracy: 0.9292 - val_loss: 27.5039 - val_accuracy: 0.9109\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 27.4819 - accuracy: 0.9292 - val_loss: 27.4647 - val_accuracy: 0.9380\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 27.4924 - accuracy: 0.9340 - val_loss: 27.4403 - val_accuracy: 0.9419\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 27.4448 - accuracy: 0.9292 - val_loss: 27.4476 - val_accuracy: 0.9380\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 27.4619 - accuracy: 0.9245 - val_loss: 27.4238 - val_accuracy: 0.9302\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 27.5371 - accuracy: 0.8726 - val_loss: 27.4363 - val_accuracy: 0.9225\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 27.4264 - accuracy: 0.9340 - val_loss: 27.4405 - val_accuracy: 0.8992\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 27.4244 - accuracy: 0.9151 - val_loss: 27.3945 - val_accuracy: 0.9225\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 27.3871 - accuracy: 0.9292 - val_loss: 27.3579 - val_accuracy: 0.9380\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 27.4191 - accuracy: 0.9057 - val_loss: 27.3536 - val_accuracy: 0.9380\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 27.3591 - accuracy: 0.9340 - val_loss: 27.3540 - val_accuracy: 0.9419\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 27.3796 - accuracy: 0.9009 - val_loss: 27.3296 - val_accuracy: 0.9380\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 27.3001 - accuracy: 0.9481 - val_loss: 27.3120 - val_accuracy: 0.9419\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 27.3328 - accuracy: 0.9387 - val_loss: 27.2794 - val_accuracy: 0.9457\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 27.3113 - accuracy: 0.9340 - val_loss: 27.3590 - val_accuracy: 0.8992\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 27.3242 - accuracy: 0.9104 - val_loss: 27.2911 - val_accuracy: 0.9341\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 27.3287 - accuracy: 0.9151 - val_loss: 27.2347 - val_accuracy: 0.9419\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 27.2613 - accuracy: 0.9292 - val_loss: 27.2864 - val_accuracy: 0.9147\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 27.2545 - accuracy: 0.9292 - val_loss: 27.2177 - val_accuracy: 0.9341\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 27.3047 - accuracy: 0.8915 - val_loss: 27.1800 - val_accuracy: 0.9535\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 27.3015 - accuracy: 0.9151 - val_loss: 27.2340 - val_accuracy: 0.9264\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 27.3068 - accuracy: 0.9104 - val_loss: 27.2229 - val_accuracy: 0.9186\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 27.2462 - accuracy: 0.9057 - val_loss: 27.2048 - val_accuracy: 0.9225\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 27.1898 - accuracy: 0.9245 - val_loss: 27.1824 - val_accuracy: 0.9109\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 27.1340 - accuracy: 0.9528 - val_loss: 27.1773 - val_accuracy: 0.9225\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 27.2132 - accuracy: 0.8868 - val_loss: 27.2077 - val_accuracy: 0.8798\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 27.1241 - accuracy: 0.9387 - val_loss: 27.1448 - val_accuracy: 0.9147\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 27.1207 - accuracy: 0.9575 - val_loss: 27.1081 - val_accuracy: 0.9186\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 27.1598 - accuracy: 0.9104 - val_loss: 27.1045 - val_accuracy: 0.9225\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 27.1032 - accuracy: 0.9340 - val_loss: 27.1111 - val_accuracy: 0.9186\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 27.0740 - accuracy: 0.9387 - val_loss: 27.0447 - val_accuracy: 0.9302\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 27.0981 - accuracy: 0.9245 - val_loss: 27.1226 - val_accuracy: 0.9070\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 27.0677 - accuracy: 0.9340 - val_loss: 27.0551 - val_accuracy: 0.9341\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 27.0564 - accuracy: 0.9245 - val_loss: 27.0529 - val_accuracy: 0.9264\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 27.0318 - accuracy: 0.9245 - val_loss: 27.0249 - val_accuracy: 0.9457\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 27.0798 - accuracy: 0.9009 - val_loss: 27.0385 - val_accuracy: 0.9225\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 27.0069 - accuracy: 0.9245 - val_loss: 27.0115 - val_accuracy: 0.9031\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 26.9700 - accuracy: 0.9292 - val_loss: 27.0386 - val_accuracy: 0.9147\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 26.9841 - accuracy: 0.9245 - val_loss: 26.9549 - val_accuracy: 0.9496\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 26.9858 - accuracy: 0.9292 - val_loss: 26.9523 - val_accuracy: 0.9147\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 26.9761 - accuracy: 0.9151 - val_loss: 26.9324 - val_accuracy: 0.9302\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 26.9684 - accuracy: 0.9151 - val_loss: 26.9193 - val_accuracy: 0.9302\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 26.9747 - accuracy: 0.9057 - val_loss: 26.9420 - val_accuracy: 0.9225\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 26.9207 - accuracy: 0.9292 - val_loss: 26.9043 - val_accuracy: 0.9341\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 26.9031 - accuracy: 0.9292 - val_loss: 26.8679 - val_accuracy: 0.9225\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 26.9180 - accuracy: 0.9245 - val_loss: 26.8675 - val_accuracy: 0.9186\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 26.8813 - accuracy: 0.9198 - val_loss: 26.9227 - val_accuracy: 0.8992\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 26.8456 - accuracy: 0.9151 - val_loss: 26.8995 - val_accuracy: 0.9147\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 26.8654 - accuracy: 0.9057 - val_loss: 26.8077 - val_accuracy: 0.9341\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 26.8350 - accuracy: 0.9245 - val_loss: 26.8071 - val_accuracy: 0.9302\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 26.8482 - accuracy: 0.9292 - val_loss: 26.7713 - val_accuracy: 0.9574\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 26.7709 - accuracy: 0.9434 - val_loss: 26.7806 - val_accuracy: 0.9186\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 26.7725 - accuracy: 0.9198 - val_loss: 26.7758 - val_accuracy: 0.9302\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 26.7977 - accuracy: 0.9198 - val_loss: 26.7956 - val_accuracy: 0.9031\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 26.7550 - accuracy: 0.9434 - val_loss: 26.7457 - val_accuracy: 0.9264\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 386ms/step - loss: 26.7772 - accuracy: 0.9340 - val_loss: 26.7472 - val_accuracy: 0.9147\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 26.7695 - accuracy: 0.9245 - val_loss: 26.7443 - val_accuracy: 0.9264\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 26.6938 - accuracy: 0.9434 - val_loss: 26.6786 - val_accuracy: 0.9380\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 26.7085 - accuracy: 0.9387 - val_loss: 26.6940 - val_accuracy: 0.9186\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 26.7117 - accuracy: 0.9340 - val_loss: 26.6964 - val_accuracy: 0.9225\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 26.6735 - accuracy: 0.9245 - val_loss: 26.6357 - val_accuracy: 0.9496\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 26.6685 - accuracy: 0.9198 - val_loss: 26.6088 - val_accuracy: 0.9380\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 26.6779 - accuracy: 0.9245 - val_loss: 26.7097 - val_accuracy: 0.8953\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 26.5904 - accuracy: 0.9528 - val_loss: 26.6145 - val_accuracy: 0.9302\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 26.6396 - accuracy: 0.9198 - val_loss: 26.6093 - val_accuracy: 0.9186\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 26.7028 - accuracy: 0.8821 - val_loss: 26.6083 - val_accuracy: 0.9302\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 26.5935 - accuracy: 0.9292 - val_loss: 26.5746 - val_accuracy: 0.9457\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 26.5917 - accuracy: 0.9245 - val_loss: 26.6147 - val_accuracy: 0.8992\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 26.5822 - accuracy: 0.9198 - val_loss: 26.5712 - val_accuracy: 0.9109\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 26.5838 - accuracy: 0.9292 - val_loss: 26.5622 - val_accuracy: 0.9147\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 26.5310 - accuracy: 0.9387 - val_loss: 26.4985 - val_accuracy: 0.9341\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 26.4939 - accuracy: 0.9434 - val_loss: 26.4963 - val_accuracy: 0.9457\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 26.5038 - accuracy: 0.9340 - val_loss: 26.5257 - val_accuracy: 0.9147\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 26.5773 - accuracy: 0.8774 - val_loss: 26.5070 - val_accuracy: 0.9225\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 26.5420 - accuracy: 0.9104 - val_loss: 26.4368 - val_accuracy: 0.9380\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 26.4800 - accuracy: 0.9387 - val_loss: 26.4800 - val_accuracy: 0.8992\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 26.4553 - accuracy: 0.9245 - val_loss: 26.4253 - val_accuracy: 0.9380\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 26.4619 - accuracy: 0.9151 - val_loss: 26.4273 - val_accuracy: 0.9264\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 26.4162 - accuracy: 0.9387 - val_loss: 26.4442 - val_accuracy: 0.9031\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 26.4010 - accuracy: 0.9434 - val_loss: 26.3635 - val_accuracy: 0.9419\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 26.3709 - accuracy: 0.9434 - val_loss: 26.4205 - val_accuracy: 0.9031\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 26.4072 - accuracy: 0.9292 - val_loss: 26.3910 - val_accuracy: 0.9302\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 26.3867 - accuracy: 0.9292 - val_loss: 26.3473 - val_accuracy: 0.9457\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 26.3993 - accuracy: 0.9245 - val_loss: 26.3759 - val_accuracy: 0.9186\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 26.3559 - accuracy: 0.9104 - val_loss: 26.3314 - val_accuracy: 0.9186\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 26.3336 - accuracy: 0.9292 - val_loss: 26.3156 - val_accuracy: 0.9341\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 26.3240 - accuracy: 0.9245 - val_loss: 26.3158 - val_accuracy: 0.9186\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 26.3039 - accuracy: 0.9292 - val_loss: 26.2805 - val_accuracy: 0.9264\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 26.3094 - accuracy: 0.9387 - val_loss: 26.2989 - val_accuracy: 0.9225\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 26.2544 - accuracy: 0.9481 - val_loss: 26.2472 - val_accuracy: 0.9457\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 26.2772 - accuracy: 0.9198 - val_loss: 26.2698 - val_accuracy: 0.9225\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 26.2967 - accuracy: 0.9104 - val_loss: 26.2177 - val_accuracy: 0.9419\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 26.2484 - accuracy: 0.9292 - val_loss: 26.2728 - val_accuracy: 0.9147\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 26.2832 - accuracy: 0.9057 - val_loss: 26.2557 - val_accuracy: 0.8953\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 26.2000 - accuracy: 0.9292 - val_loss: 26.2198 - val_accuracy: 0.9186\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 26.1837 - accuracy: 0.9434 - val_loss: 26.1874 - val_accuracy: 0.9264\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 26.2379 - accuracy: 0.9151 - val_loss: 26.1952 - val_accuracy: 0.9225\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 26.2765 - accuracy: 0.8915 - val_loss: 26.1376 - val_accuracy: 0.9264\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 26.1508 - accuracy: 0.9340 - val_loss: 26.1402 - val_accuracy: 0.9419\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 26.1564 - accuracy: 0.9245 - val_loss: 26.1431 - val_accuracy: 0.9302\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 26.1401 - accuracy: 0.9245 - val_loss: 26.1507 - val_accuracy: 0.9264\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 26.1297 - accuracy: 0.9245 - val_loss: 26.1192 - val_accuracy: 0.9225\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 26.0487 - accuracy: 0.9434 - val_loss: 26.0937 - val_accuracy: 0.9419\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 26.0931 - accuracy: 0.9198 - val_loss: 26.0732 - val_accuracy: 0.9264\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 26.0670 - accuracy: 0.9292 - val_loss: 26.0386 - val_accuracy: 0.9419\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 26.1156 - accuracy: 0.8962 - val_loss: 26.1099 - val_accuracy: 0.8992\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 26.0504 - accuracy: 0.9292 - val_loss: 26.0142 - val_accuracy: 0.9302\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 26.0568 - accuracy: 0.9245 - val_loss: 26.0532 - val_accuracy: 0.9186\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 25.9847 - accuracy: 0.9481 - val_loss: 26.0247 - val_accuracy: 0.9147\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 26.0508 - accuracy: 0.9198 - val_loss: 25.9840 - val_accuracy: 0.9380\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 26.0601 - accuracy: 0.8821 - val_loss: 25.9853 - val_accuracy: 0.9147\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 25.9838 - accuracy: 0.9340 - val_loss: 25.9654 - val_accuracy: 0.9264\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 25.9635 - accuracy: 0.9245 - val_loss: 25.9743 - val_accuracy: 0.9302\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 25.9577 - accuracy: 0.9340 - val_loss: 25.9292 - val_accuracy: 0.9419\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 25.9874 - accuracy: 0.9104 - val_loss: 25.9130 - val_accuracy: 0.9341\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 25.9012 - accuracy: 0.9292 - val_loss: 25.9408 - val_accuracy: 0.9109\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 25.8816 - accuracy: 0.9575 - val_loss: 25.9100 - val_accuracy: 0.9341\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 26.0280 - accuracy: 0.8868 - val_loss: 25.8860 - val_accuracy: 0.9186\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 25.8735 - accuracy: 0.9198 - val_loss: 25.8933 - val_accuracy: 0.9031\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 25.7965 - accuracy: 0.9670 - val_loss: 25.8432 - val_accuracy: 0.9302\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 25.8292 - accuracy: 0.9340 - val_loss: 25.8565 - val_accuracy: 0.9186\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 25.8699 - accuracy: 0.9387 - val_loss: 25.9057 - val_accuracy: 0.8798\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 25.8089 - accuracy: 0.9198 - val_loss: 25.8222 - val_accuracy: 0.9264\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 25.8557 - accuracy: 0.8821 - val_loss: 25.8292 - val_accuracy: 0.9031\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 25.7494 - accuracy: 0.9434 - val_loss: 25.8122 - val_accuracy: 0.9109\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 25.8092 - accuracy: 0.9245 - val_loss: 25.8056 - val_accuracy: 0.8953\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 25.7505 - accuracy: 0.9387 - val_loss: 25.7417 - val_accuracy: 0.9225\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 25.7291 - accuracy: 0.9481 - val_loss: 25.7328 - val_accuracy: 0.9264\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 25.7601 - accuracy: 0.9198 - val_loss: 25.7261 - val_accuracy: 0.9264\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 25.7535 - accuracy: 0.9151 - val_loss: 25.7290 - val_accuracy: 0.9341\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 25.6888 - accuracy: 0.9387 - val_loss: 25.6715 - val_accuracy: 0.9574\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 25.7690 - accuracy: 0.8962 - val_loss: 25.6725 - val_accuracy: 0.9264\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 25.7085 - accuracy: 0.9104 - val_loss: 25.6729 - val_accuracy: 0.9186\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 25.7013 - accuracy: 0.9057 - val_loss: 25.6872 - val_accuracy: 0.9109\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 25.6609 - accuracy: 0.9292 - val_loss: 25.6576 - val_accuracy: 0.9147\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 25.8596 - accuracy: 0.8066 - val_loss: 25.6241 - val_accuracy: 0.9341\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 25.6113 - accuracy: 0.9575 - val_loss: 25.6057 - val_accuracy: 0.9302\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 25.5885 - accuracy: 0.9481 - val_loss: 25.5997 - val_accuracy: 0.9109\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 25.6069 - accuracy: 0.9387 - val_loss: 25.6433 - val_accuracy: 0.9147\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 25.5926 - accuracy: 0.9198 - val_loss: 25.5981 - val_accuracy: 0.9186\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 25.5873 - accuracy: 0.9340 - val_loss: 25.5747 - val_accuracy: 0.9147\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 25.5793 - accuracy: 0.9292 - val_loss: 25.5240 - val_accuracy: 0.9535\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 25.5364 - accuracy: 0.9387 - val_loss: 25.5304 - val_accuracy: 0.9264\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 25.5671 - accuracy: 0.9104 - val_loss: 25.4979 - val_accuracy: 0.9302\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 25.6146 - accuracy: 0.8868 - val_loss: 25.5184 - val_accuracy: 0.9341\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 25.5293 - accuracy: 0.9340 - val_loss: 25.5063 - val_accuracy: 0.9186\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 25.4664 - accuracy: 0.9481 - val_loss: 25.5081 - val_accuracy: 0.9186\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 25.5262 - accuracy: 0.9245 - val_loss: 25.5612 - val_accuracy: 0.8876\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 25.4765 - accuracy: 0.9151 - val_loss: 25.4492 - val_accuracy: 0.9341\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 25.4693 - accuracy: 0.9340 - val_loss: 25.4441 - val_accuracy: 0.9341\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 25.5007 - accuracy: 0.8868 - val_loss: 25.3992 - val_accuracy: 0.9535\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 25.4395 - accuracy: 0.9245 - val_loss: 25.4429 - val_accuracy: 0.9264\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 25.4901 - accuracy: 0.9198 - val_loss: 25.4541 - val_accuracy: 0.9302\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 25.5757 - accuracy: 0.8632 - val_loss: 25.3690 - val_accuracy: 0.9302\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 25.4123 - accuracy: 0.9151 - val_loss: 25.4567 - val_accuracy: 0.9031\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 25.3660 - accuracy: 0.9245 - val_loss: 25.3656 - val_accuracy: 0.9264\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 25.3674 - accuracy: 0.9198 - val_loss: 25.4078 - val_accuracy: 0.9070\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 25.3617 - accuracy: 0.9340 - val_loss: 25.3884 - val_accuracy: 0.9031\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 25.3592 - accuracy: 0.9104 - val_loss: 25.3491 - val_accuracy: 0.9264\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 25.3510 - accuracy: 0.9340 - val_loss: 25.3256 - val_accuracy: 0.9147\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 25.3219 - accuracy: 0.9104 - val_loss: 25.3464 - val_accuracy: 0.9070\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 25.2813 - accuracy: 0.9292 - val_loss: 25.2693 - val_accuracy: 0.9419\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 25.2997 - accuracy: 0.9198 - val_loss: 25.2934 - val_accuracy: 0.9031\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 25.2211 - accuracy: 0.9481 - val_loss: 25.3392 - val_accuracy: 0.9186\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 25.2787 - accuracy: 0.9198 - val_loss: 25.2503 - val_accuracy: 0.9070\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 25.3203 - accuracy: 0.9151 - val_loss: 25.2230 - val_accuracy: 0.9264\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 25.2140 - accuracy: 0.9292 - val_loss: 25.2578 - val_accuracy: 0.9070\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 399ms/step - loss: 25.2934 - accuracy: 0.8774 - val_loss: 25.2139 - val_accuracy: 0.9070\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 25.2169 - accuracy: 0.9151 - val_loss: 25.2431 - val_accuracy: 0.9070\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 25.1651 - accuracy: 0.9434 - val_loss: 25.2053 - val_accuracy: 0.9070\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 25.1722 - accuracy: 0.9245 - val_loss: 25.1972 - val_accuracy: 0.8992\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 25.1404 - accuracy: 0.9434 - val_loss: 25.1967 - val_accuracy: 0.9031\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 25.1923 - accuracy: 0.9104 - val_loss: 25.1420 - val_accuracy: 0.9341\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 25.1056 - accuracy: 0.9481 - val_loss: 25.1240 - val_accuracy: 0.9147\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 25.1914 - accuracy: 0.8774 - val_loss: 25.1001 - val_accuracy: 0.9186\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 25.0944 - accuracy: 0.9340 - val_loss: 25.1298 - val_accuracy: 0.8992\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 25.0979 - accuracy: 0.9292 - val_loss: 25.0980 - val_accuracy: 0.9186\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 25.1411 - accuracy: 0.9009 - val_loss: 25.0695 - val_accuracy: 0.9186\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 25.0617 - accuracy: 0.9245 - val_loss: 25.0508 - val_accuracy: 0.9031\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 25.0349 - accuracy: 0.9481 - val_loss: 25.0146 - val_accuracy: 0.9419\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 25.0624 - accuracy: 0.9245 - val_loss: 25.0451 - val_accuracy: 0.9302\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 24.9849 - accuracy: 0.9340 - val_loss: 25.0193 - val_accuracy: 0.9264\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 25.2339 - accuracy: 0.8491 - val_loss: 24.9877 - val_accuracy: 0.9496\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 24.9582 - accuracy: 0.9481 - val_loss: 25.0477 - val_accuracy: 0.9186\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 24.9904 - accuracy: 0.9292 - val_loss: 24.9703 - val_accuracy: 0.9341\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 24.9987 - accuracy: 0.9057 - val_loss: 25.0049 - val_accuracy: 0.8992\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 24.9651 - accuracy: 0.9198 - val_loss: 25.0449 - val_accuracy: 0.9031\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 24.9623 - accuracy: 0.9245 - val_loss: 24.9339 - val_accuracy: 0.9341\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 24.9467 - accuracy: 0.9151 - val_loss: 24.9595 - val_accuracy: 0.9031\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 24.8728 - accuracy: 0.9481 - val_loss: 24.9771 - val_accuracy: 0.8837\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 24.9121 - accuracy: 0.9151 - val_loss: 24.9403 - val_accuracy: 0.9031\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 24.8652 - accuracy: 0.9292 - val_loss: 24.9254 - val_accuracy: 0.9186\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 24.9095 - accuracy: 0.9198 - val_loss: 24.8857 - val_accuracy: 0.9186\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 24.8316 - accuracy: 0.9340 - val_loss: 24.8948 - val_accuracy: 0.9147\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 24.9175 - accuracy: 0.8821 - val_loss: 24.8826 - val_accuracy: 0.9109\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 25.0068 - accuracy: 0.8915 - val_loss: 24.8302 - val_accuracy: 0.9147\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 24.8675 - accuracy: 0.8962 - val_loss: 24.8270 - val_accuracy: 0.9419\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 24.8834 - accuracy: 0.8962 - val_loss: 24.7792 - val_accuracy: 0.9380\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 24.8435 - accuracy: 0.9104 - val_loss: 24.7799 - val_accuracy: 0.9302\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 24.8390 - accuracy: 0.8868 - val_loss: 24.8122 - val_accuracy: 0.9302\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 24.7776 - accuracy: 0.9292 - val_loss: 24.7803 - val_accuracy: 0.8992\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 24.7520 - accuracy: 0.9434 - val_loss: 24.7260 - val_accuracy: 0.9380\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 24.7857 - accuracy: 0.9104 - val_loss: 24.7373 - val_accuracy: 0.9186\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 24.6757 - accuracy: 0.9764 - val_loss: 24.7719 - val_accuracy: 0.8953\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 24.7265 - accuracy: 0.9340 - val_loss: 24.7062 - val_accuracy: 0.9264\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 24.7148 - accuracy: 0.9198 - val_loss: 24.6734 - val_accuracy: 0.9341\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 24.7237 - accuracy: 0.9151 - val_loss: 24.6675 - val_accuracy: 0.9302\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 24.7050 - accuracy: 0.9104 - val_loss: 24.7025 - val_accuracy: 0.8992\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 24.7484 - accuracy: 0.8774 - val_loss: 24.6841 - val_accuracy: 0.9186\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 24.6973 - accuracy: 0.9151 - val_loss: 24.6645 - val_accuracy: 0.9109\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 24.6657 - accuracy: 0.9151 - val_loss: 24.6266 - val_accuracy: 0.9302\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 24.6349 - accuracy: 0.9434 - val_loss: 24.6165 - val_accuracy: 0.9186\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 24.6202 - accuracy: 0.9245 - val_loss: 24.5742 - val_accuracy: 0.9341\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 24.6587 - accuracy: 0.8915 - val_loss: 24.5576 - val_accuracy: 0.9496\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 24.5732 - accuracy: 0.9245 - val_loss: 24.6105 - val_accuracy: 0.9109\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 24.5940 - accuracy: 0.9340 - val_loss: 24.5747 - val_accuracy: 0.9109\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 24.5620 - accuracy: 0.9057 - val_loss: 24.5804 - val_accuracy: 0.9302\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 24.6744 - accuracy: 0.8679 - val_loss: 24.5065 - val_accuracy: 0.9419\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 24.5465 - accuracy: 0.9057 - val_loss: 24.5740 - val_accuracy: 0.8876\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 24.5960 - accuracy: 0.8774 - val_loss: 24.4927 - val_accuracy: 0.9341\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 24.5404 - accuracy: 0.9104 - val_loss: 24.5374 - val_accuracy: 0.9031\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 24.4966 - accuracy: 0.9245 - val_loss: 24.4756 - val_accuracy: 0.9341\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 24.5119 - accuracy: 0.9104 - val_loss: 24.4659 - val_accuracy: 0.9302\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 24.4955 - accuracy: 0.9151 - val_loss: 24.4991 - val_accuracy: 0.9031\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 24.4659 - accuracy: 0.9245 - val_loss: 24.4374 - val_accuracy: 0.9186\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 24.4430 - accuracy: 0.9245 - val_loss: 24.4216 - val_accuracy: 0.9225\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 24.3806 - accuracy: 0.9481 - val_loss: 24.4657 - val_accuracy: 0.8876\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 24.4299 - accuracy: 0.9292 - val_loss: 24.4092 - val_accuracy: 0.9186\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 24.3298 - accuracy: 0.9575 - val_loss: 24.3869 - val_accuracy: 0.9147\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 24.4542 - accuracy: 0.9009 - val_loss: 24.3595 - val_accuracy: 0.9419\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 24.4085 - accuracy: 0.9104 - val_loss: 24.3398 - val_accuracy: 0.9419\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 24.3120 - accuracy: 0.9387 - val_loss: 24.4203 - val_accuracy: 0.8837\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 24.3279 - accuracy: 0.9292 - val_loss: 24.3924 - val_accuracy: 0.8876\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 24.3382 - accuracy: 0.9245 - val_loss: 24.3391 - val_accuracy: 0.9186\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 24.3773 - accuracy: 0.8868 - val_loss: 24.3003 - val_accuracy: 0.9341\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 24.2916 - accuracy: 0.9292 - val_loss: 24.3151 - val_accuracy: 0.9109\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 24.3882 - accuracy: 0.9057 - val_loss: 24.2909 - val_accuracy: 0.9264\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 24.2404 - accuracy: 0.9434 - val_loss: 24.2669 - val_accuracy: 0.9341\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 24.2891 - accuracy: 0.9104 - val_loss: 24.3252 - val_accuracy: 0.8992\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 24.2786 - accuracy: 0.9057 - val_loss: 24.2057 - val_accuracy: 0.9341\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 24.2710 - accuracy: 0.9104 - val_loss: 24.2427 - val_accuracy: 0.8953\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 24.2557 - accuracy: 0.9057 - val_loss: 24.1933 - val_accuracy: 0.9302\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 24.2140 - accuracy: 0.9104 - val_loss: 24.2164 - val_accuracy: 0.9070\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 24.1859 - accuracy: 0.9292 - val_loss: 24.2063 - val_accuracy: 0.9031\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 24.2134 - accuracy: 0.9057 - val_loss: 24.1443 - val_accuracy: 0.9341\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 24.2101 - accuracy: 0.9057 - val_loss: 24.1452 - val_accuracy: 0.9186\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 24.1354 - accuracy: 0.9387 - val_loss: 24.2085 - val_accuracy: 0.8953\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 24.1418 - accuracy: 0.9292 - val_loss: 24.1619 - val_accuracy: 0.9031\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 24.1200 - accuracy: 0.9340 - val_loss: 24.1111 - val_accuracy: 0.9147\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 24.1926 - accuracy: 0.9009 - val_loss: 24.0900 - val_accuracy: 0.9302\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 24.1512 - accuracy: 0.8774 - val_loss: 24.0767 - val_accuracy: 0.9341\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 24.1048 - accuracy: 0.9151 - val_loss: 24.0940 - val_accuracy: 0.9186\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 24.0932 - accuracy: 0.9198 - val_loss: 24.1037 - val_accuracy: 0.8992\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 24.0684 - accuracy: 0.9009 - val_loss: 24.0591 - val_accuracy: 0.9341\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 24.1131 - accuracy: 0.9151 - val_loss: 24.0646 - val_accuracy: 0.9225\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 24.1049 - accuracy: 0.9009 - val_loss: 24.0280 - val_accuracy: 0.9264\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 24.0597 - accuracy: 0.8915 - val_loss: 24.0186 - val_accuracy: 0.9186\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 24.0371 - accuracy: 0.8821 - val_loss: 23.9715 - val_accuracy: 0.9380\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 23.9755 - accuracy: 0.9245 - val_loss: 23.9781 - val_accuracy: 0.9419\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 24.0172 - accuracy: 0.9104 - val_loss: 24.0330 - val_accuracy: 0.9031\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 23.9742 - accuracy: 0.9198 - val_loss: 23.9454 - val_accuracy: 0.9419\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 23.9995 - accuracy: 0.9104 - val_loss: 23.9482 - val_accuracy: 0.8992\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 23.9877 - accuracy: 0.8821 - val_loss: 23.9058 - val_accuracy: 0.9225\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 23.9287 - accuracy: 0.9151 - val_loss: 23.9035 - val_accuracy: 0.9302\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 23.9068 - accuracy: 0.9387 - val_loss: 23.8686 - val_accuracy: 0.9302\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 23.8875 - accuracy: 0.9340 - val_loss: 23.9391 - val_accuracy: 0.9264\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 23.8822 - accuracy: 0.9340 - val_loss: 23.8749 - val_accuracy: 0.9380\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 23.8995 - accuracy: 0.9057 - val_loss: 23.8771 - val_accuracy: 0.9341\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 23.8926 - accuracy: 0.9151 - val_loss: 23.8375 - val_accuracy: 0.9341\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 23.8370 - accuracy: 0.9292 - val_loss: 23.8706 - val_accuracy: 0.9225\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 23.9127 - accuracy: 0.8821 - val_loss: 23.8376 - val_accuracy: 0.9186\n",
      "Model training finished.\n",
      "Train loss: 23.81, train accuracy: 0.92.\n",
      "Evaluating model performance...\n",
      "Test loss: 23.797, test accuracy: 0.933.\n"
     ]
    }
   ],
   "source": [
    "run_experiment(bnn_model_full,\n",
    "               nll,\n",
    "               train_dataset,\n",
    "               val_dataset,\n",
    "               test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467947b",
   "metadata": {},
   "source": [
    "* Here, we see that the test accuracy is a high 93.3%.\n",
    "* What's more important is that for each of the prediction, there is an associated probability and entropy that quantify the confidence and uncertainty associated to the prediction by the model.\n",
    "* As mentioned in the [Background](#background), this is exceptionally important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81924e8f",
   "metadata": {},
   "source": [
    "<a name = 'saving'></a>\n",
    "\n",
    "# Saving of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1faf1e",
   "metadata": {},
   "source": [
    "Next, we save the tuned and trained models to the respective directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23753737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:12:07.245561Z",
     "start_time": "2021-07-09T14:11:59.921769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\models\\tuned_nn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "nn_model_savepath = os.path.join('.','models','tuned_nn_model')\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    nn_model_full,\n",
    "    nn_model_savepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91e29538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:12:26.108661Z",
     "start_time": "2021-07-09T14:12:07.249748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\models\\tuned_bnn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "bnn_model_savepath = os.path.join('.','models','tuned_bnn_model')\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    bnn_model_full,\n",
    "    bnn_model_savepath\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b1636",
   "metadata": {},
   "source": [
    "Here, we show how we can load the model and use it for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf65b093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:12:40.326983Z",
     "start_time": "2021-07-09T14:12:26.111614Z"
    }
   },
   "outputs": [],
   "source": [
    "bnn_model_loaded = tf.keras.models.load_model(bnn_model_savepath,\n",
    "                                              compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56a19916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:12:40.918858Z",
     "start_time": "2021-07-09T14:12:40.331415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnn_model_loaded.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3485181",
   "metadata": {},
   "source": [
    "<a name = 'entropies'></a>\n",
    "\n",
    "# Entropies of Predictions on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a40d2c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:12:42.594036Z",
     "start_time": "2021-07-09T14:12:40.925836Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions_bnn = bnn_model_full.predict(test_dataset)\n",
    "test_predictions_nn = nn_model_full.predict(test_dataset)\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eec06ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:12:42.624668Z",
     "start_time": "2021-07-09T14:12:42.598766Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_predictions_probabilities(model, test_dataset = test_dataset):\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    entropies = []\n",
    "    i = 1\n",
    "\n",
    "    for x, y in test_dataset.unbatch().batch(1).take(-1):\n",
    "        \n",
    "        output_dist = model(x)\n",
    "        \n",
    "        # prediction\n",
    "        [prediction] = highest_prob = output_dist.mode()\n",
    "        prediction = np.argmax(prediction)\n",
    "        \n",
    "        # probability of this prediction\n",
    "        probability = output_dist.prob(highest_prob).numpy().squeeze()\n",
    "        \n",
    "        # true label of test example\n",
    "        true_label = np.argmax(y.numpy().squeeze())\n",
    "        \n",
    "        # entropy\n",
    "        [entropy] = output_dist.entropy().numpy()\n",
    "        \n",
    "        print(f\"Test Example: {i}\")\n",
    "        print(f\"Test Prediction: {prediction}, probability of this prediction: {probability} and entropy: {entropy}\")\n",
    "        print(f\"True Label: {true_label}\")\n",
    "        print(\"=\"*15)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "        true_labels.append(true_label)\n",
    "        probabilities.append(probability)\n",
    "        entropies.append(entropy)\n",
    "        \n",
    "    return predictions, true_labels, probabilities, entropies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fdcf66",
   "metadata": {},
   "source": [
    "Here, we use the function `output_predictions_probabilities` to output the prediction, actual label, probability of the prediction and its entropy for each test data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "586fabd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:17:45.832018Z",
     "start_time": "2021-07-09T14:17:42.322999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Example: 1\n",
      "Test Prediction: 0, probability of this prediction: 0.9855256676673889 and entropy: 0.07567346096038818\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 2\n",
      "Test Prediction: 1, probability of this prediction: 0.9917690753936768 and entropy: 0.047704219818115234\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 3\n",
      "Test Prediction: 1, probability of this prediction: 0.998964786529541 and entropy: 0.008149862289428711\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 4\n",
      "Test Prediction: 0, probability of this prediction: 0.8517488837242126 and entropy: 0.4196634888648987\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 5\n",
      "Test Prediction: 0, probability of this prediction: 0.9997528195381165 and entropy: 0.002299785614013672\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 6\n",
      "Test Prediction: 1, probability of this prediction: 0.960555374622345 and entropy: 0.1661750078201294\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 7\n",
      "Test Prediction: 0, probability of this prediction: 0.9994810223579407 and entropy: 0.0044443607330322266\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 8\n",
      "Test Prediction: 1, probability of this prediction: 0.9995156526565552 and entropy: 0.004181385040283203\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 9\n",
      "Test Prediction: 1, probability of this prediction: 0.9766831994056702 and entropy: 0.11068093776702881\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 10\n",
      "Test Prediction: 1, probability of this prediction: 0.8944891691207886 and entropy: 0.3370254635810852\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 11\n",
      "Test Prediction: 1, probability of this prediction: 0.9818519353866577 and entropy: 0.09074163436889648\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 12\n",
      "Test Prediction: 0, probability of this prediction: 0.7143991589546204 and entropy: 0.5981656312942505\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 13\n",
      "Test Prediction: 1, probability of this prediction: 0.724947988986969 and entropy: 0.588219165802002\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 14\n",
      "Test Prediction: 0, probability of this prediction: 0.6865739822387695 and entropy: 0.621814489364624\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 15\n",
      "Test Prediction: 0, probability of this prediction: 0.791860818862915 and entropy: 0.5114806890487671\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 16\n",
      "Test Prediction: 0, probability of this prediction: 0.798276424407959 and entropy: 0.5027825832366943\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 17\n",
      "Test Prediction: 0, probability of this prediction: 0.9425399899482727 and entropy: 0.21992063522338867\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 18\n",
      "Test Prediction: 0, probability of this prediction: 0.9999356269836426 and entropy: 0.0006856918334960938\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 19\n",
      "Test Prediction: 0, probability of this prediction: 0.873395562171936 and entropy: 0.37988054752349854\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 20\n",
      "Test Prediction: 0, probability of this prediction: 0.9277279376983643 and entropy: 0.25947678089141846\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 21\n",
      "Test Prediction: 1, probability of this prediction: 0.9999817609786987 and entropy: 0.00021696090698242188\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 22\n",
      "Test Prediction: 0, probability of this prediction: 0.9782067537307739 and entropy: 0.10493838787078857\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 23\n",
      "Test Prediction: 0, probability of this prediction: 0.9998530149459839 and entropy: 0.0014438629150390625\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 24\n",
      "Test Prediction: 1, probability of this prediction: 0.9949550032615662 and entropy: 0.03171706199645996\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 25\n",
      "Test Prediction: 0, probability of this prediction: 0.5703880786895752 and entropy: 0.6832051873207092\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 26\n",
      "Test Prediction: 1, probability of this prediction: 0.9932559728622437 and entropy: 0.0404353141784668\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 27\n",
      "Test Prediction: 1, probability of this prediction: 0.9093425869941711 and entropy: 0.30405622720718384\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 28\n",
      "Test Prediction: 1, probability of this prediction: 0.9960393905639648 and entropy: 0.025860309600830078\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 29\n",
      "Test Prediction: 0, probability of this prediction: 0.9859547019004822 and entropy: 0.07385587692260742\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 30\n",
      "Test Prediction: 0, probability of this prediction: 0.999950647354126 and entropy: 0.0005388259887695312\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 31\n",
      "Test Prediction: 0, probability of this prediction: 0.9939516186714172 and entropy: 0.03692507743835449\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 32\n",
      "Test Prediction: 1, probability of this prediction: 0.9548097252845764 and entropy: 0.18410193920135498\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 33\n",
      "Test Prediction: 1, probability of this prediction: 0.7959456443786621 and entropy: 0.5059719085693359\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 34\n",
      "Test Prediction: 0, probability of this prediction: 0.9996039271354675 and entropy: 0.0034987926483154297\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 35\n",
      "Test Prediction: 1, probability of this prediction: 0.619293749332428 and entropy: 0.6644088625907898\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 36\n",
      "Test Prediction: 0, probability of this prediction: 0.9472479224205017 and entropy: 0.20654022693634033\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 37\n",
      "Test Prediction: 0, probability of this prediction: 0.9994938373565674 and entropy: 0.004347085952758789\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 38\n",
      "Test Prediction: 1, probability of this prediction: 0.8256168961524963 and entropy: 0.4627685546875\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 39\n",
      "Test Prediction: 0, probability of this prediction: 0.9928015470504761 and entropy: 0.042688846588134766\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 40\n",
      "Test Prediction: 1, probability of this prediction: 0.9042140245437622 and entropy: 0.31572389602661133\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 41\n",
      "Test Prediction: 0, probability of this prediction: 0.9985871315002441 and entropy: 0.010683298110961914\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 42\n",
      "Test Prediction: 1, probability of this prediction: 0.7437649965286255 and entropy: 0.5690819025039673\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 43\n",
      "Test Prediction: 1, probability of this prediction: 0.9927204847335815 and entropy: 0.04308772087097168\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 44\n",
      "Test Prediction: 0, probability of this prediction: 0.9999998807907104 and entropy: 1.430511474609375e-06\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 45\n",
      "Test Prediction: 0, probability of this prediction: 0.9995903372764587 and entropy: 0.003605365753173828\n",
      "True Label: 0\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels, probabilities, entropies = output_predictions_probabilities(bnn_model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0753c641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:17:45.863215Z",
     "start_time": "2021-07-09T14:17:45.836131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>entropies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98552567</td>\n",
       "      <td>0.075673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9917691</td>\n",
       "      <td>0.047704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9989648</td>\n",
       "      <td>0.008150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8517489</td>\n",
       "      <td>0.419663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9997528</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9605554</td>\n",
       "      <td>0.166175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99951565</td>\n",
       "      <td>0.004181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9766832</td>\n",
       "      <td>0.110681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89448917</td>\n",
       "      <td>0.337025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98185194</td>\n",
       "      <td>0.090742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71439916</td>\n",
       "      <td>0.598166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724948</td>\n",
       "      <td>0.588219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686574</td>\n",
       "      <td>0.621814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7918608</td>\n",
       "      <td>0.511481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7982764</td>\n",
       "      <td>0.502783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94254</td>\n",
       "      <td>0.219921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999356</td>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87339556</td>\n",
       "      <td>0.379881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92772794</td>\n",
       "      <td>0.259477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99998176</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97820675</td>\n",
       "      <td>0.104938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.001444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.031717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5703881</td>\n",
       "      <td>0.683205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993256</td>\n",
       "      <td>0.040435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9093426</td>\n",
       "      <td>0.304056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9960394</td>\n",
       "      <td>0.025860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9859547</td>\n",
       "      <td>0.073856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99995065</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9939516</td>\n",
       "      <td>0.036925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9548097</td>\n",
       "      <td>0.184102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79594564</td>\n",
       "      <td>0.505972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9996039</td>\n",
       "      <td>0.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.61929375</td>\n",
       "      <td>0.664409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9472479</td>\n",
       "      <td>0.206540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99949384</td>\n",
       "      <td>0.004347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8256169</td>\n",
       "      <td>0.462769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99280155</td>\n",
       "      <td>0.042689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904214</td>\n",
       "      <td>0.315724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99858713</td>\n",
       "      <td>0.010683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743765</td>\n",
       "      <td>0.569082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9927205</td>\n",
       "      <td>0.043088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999999</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99959034</td>\n",
       "      <td>0.003605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions  true_labels probabilities  entropies\n",
       "0             0            0    0.98552567   0.075673\n",
       "1             1            1     0.9917691   0.047704\n",
       "2             1            1     0.9989648   0.008150\n",
       "3             0            0     0.8517489   0.419663\n",
       "4             0            0     0.9997528   0.002300\n",
       "5             1            1     0.9605554   0.166175\n",
       "6             0            0      0.999481   0.004444\n",
       "7             1            1    0.99951565   0.004181\n",
       "8             1            1     0.9766832   0.110681\n",
       "9             1            1    0.89448917   0.337025\n",
       "10            1            1    0.98185194   0.090742\n",
       "11            0            1    0.71439916   0.598166\n",
       "12            1            1      0.724948   0.588219\n",
       "13            0            0      0.686574   0.621814\n",
       "14            0            0     0.7918608   0.511481\n",
       "15            0            1     0.7982764   0.502783\n",
       "16            0            0       0.94254   0.219921\n",
       "17            0            0     0.9999356   0.000686\n",
       "18            0            0    0.87339556   0.379881\n",
       "19            0            0    0.92772794   0.259477\n",
       "20            1            1    0.99998176   0.000217\n",
       "21            0            0    0.97820675   0.104938\n",
       "22            0            0      0.999853   0.001444\n",
       "23            1            1      0.994955   0.031717\n",
       "24            0            1     0.5703881   0.683205\n",
       "25            1            1      0.993256   0.040435\n",
       "26            1            1     0.9093426   0.304056\n",
       "27            1            1     0.9960394   0.025860\n",
       "28            0            0     0.9859547   0.073856\n",
       "29            0            0    0.99995065   0.000539\n",
       "30            0            0     0.9939516   0.036925\n",
       "31            1            1     0.9548097   0.184102\n",
       "32            1            1    0.79594564   0.505972\n",
       "33            0            0     0.9996039   0.003499\n",
       "34            1            0    0.61929375   0.664409\n",
       "35            0            0     0.9472479   0.206540\n",
       "36            0            0    0.99949384   0.004347\n",
       "37            1            1     0.8256169   0.462769\n",
       "38            0            0    0.99280155   0.042689\n",
       "39            1            1      0.904214   0.315724\n",
       "40            0            0    0.99858713   0.010683\n",
       "41            1            1      0.743765   0.569082\n",
       "42            1            1     0.9927205   0.043088\n",
       "43            0            0     0.9999999   0.000001\n",
       "44            0            0    0.99959034   0.003605"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_result_dict = {k: v for k, v in zip(['predictions', 'true_labels', 'probabilities', 'entropies'],\n",
    "                                                [predictions, true_labels, probabilities, entropies])}\n",
    "\n",
    "test_dataset_result_df = pd.DataFrame(test_dataset_result_dict)\n",
    "test_dataset_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0be6e17f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:17:46.205796Z",
     "start_time": "2021-07-09T14:17:45.868200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correctly Predicted')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_entropies = test_dataset_result_df[test_dataset_result_df.predictions == test_dataset_result_df.true_labels]['entropies']\n",
    "correct_density = gaussian_kde(correct_entropies.to_numpy())\n",
    "plt.plot(np.linspace(0,1,100), correct_density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Correctly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8545605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:17:46.500408Z",
     "start_time": "2021-07-09T14:17:46.210692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Wrongly Predicted')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_entropies = test_dataset_result_df[test_dataset_result_df.predictions != test_dataset_result_df.true_labels]['entropies']\n",
    "wrong_density = gaussian_kde(wrong_entropies)\n",
    "plt.plot(np.linspace(0,1,100), wrong_density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Wrongly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "680652a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T14:17:47.181252Z",
     "start_time": "2021-07-09T14:17:46.505395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Wrongly Predicted')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (10, 6))\n",
    "ax = axes.flat\n",
    "\n",
    "ax[0].plot(np.linspace(0,1,100), correct_density(np.linspace(0,1,100)))\n",
    "ax[0].set_ylabel('Frequency', fontsize=10)\n",
    "ax[0].set_xlabel('Entropy', fontsize=10)\n",
    "ax[0].set_title('Correctly Predicted', fontsize=10)\n",
    "\n",
    "ax[1].plot(np.linspace(0,1,100), wrong_density(np.linspace(0,1,100)))\n",
    "ax[1].set_ylabel('Frequency', fontsize=10)\n",
    "ax[1].set_xlabel('Entropy', fontsize=10)\n",
    "ax[1].set_title('Wrongly Predicted', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a2f78",
   "metadata": {},
   "source": [
    "Finally, we can see that correct predictions have a lower entropy compared to incorrect predictions. This highlights two points:\n",
    "\n",
    "   1) BNN model is capable of associating uncertainty to its predictions, be it correct or wrong. Any user may use this information to determine if they should trust their model for a particular prediction.\n",
    "\n",
    "   2) Given the universal approximation property, a BNN is capable of giving a higher uncertainty associated to wrong predictions and be more certain of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3f3b0",
   "metadata": {},
   "source": [
    "<a name='references'></a>\n",
    "\n",
    "# References\n",
    "\n",
    "1. [Probabilistic Deep Learning with Tensorflow 2](https://www.coursera.org/learn/probabilistic-deep-learning-with-tensorflow2?specialization=tensorflow2-deeplearning)\n",
    "2. [Hands-on Bayesian Neural Networks - a Tutorial for Deep\n",
    "Learning Users](https://arxiv.org/pdf/2007.06823.pdf)\n",
    "3. [Keras Tuner Get Started Guide](https://keras.io/guides/keras_tuner/getting_started/)\n",
    "4. [Explanation on Variation Inference, ELBO and KL Divergence](https://mpatacchiola.github.io/blog/2021/01/25/intro-variational-inference.html)\n",
    "5. [StackOverflow answer to why BNN can be better](https://stats.stackexchange.com/questions/141879/what-are-the-advantages-of-using-a-bayesian-neural-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76784023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
