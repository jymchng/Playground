{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/uriel-sc-11KDtiUWRq4-unsplash.jpg\" width=400 height=400 />\n",
    "\n",
    "<center> <a href=\"https://unsplash.com/photos/11KDtiUWRq4\">Source</a> </center>\n",
    "\n",
    "# Bayesian Neural Network on the 'Heart Disease' Dataset\n",
    "\n",
    "Author: CHNG Soon Siang ([LinkedIn](https://www.linkedin.com/in/soon-siang-chng/))<br>\n",
    "Dataset: [Heart Disease Dataset](https://www.kaggle.com/ronitf/heart-disease-uci)\n",
    "\n",
    "Date last updated: 5 July 2021\n",
    "\n",
    "_**Summary**_    \n",
    "In applications where the size of the data collected is small and the outcome to be predicted is of great importance, one would require a probabilistic model to quantify the uncertainty of its predictions. This is often encountered in healthcare, engineering, academia, and other industries. In this exercise, a deterministic neural network (DNN) (acting as a baseline model) and a Bayesian neural network (BNN) were trained separately on the preprocessed heart attack dataset. The objective is to predict if heart disease is present in a patient. The accuracies attained by both models are tabulated below. Both models attained similar accuracy on the test dataset, however, in this context, the BNN model is advantageous as it quantifies the uncertainty, using entropy, associated with its prediction.\n",
    "\n",
    "<center>Table of Accuracies for the 2 Networks</center>\n",
    "\n",
    "|                   | Deterministic NN | Bayesian NN |\n",
    "|-------------------|------------------|-------------|\n",
    "| Training Accuracy |1.000             |0.925        |\n",
    "| Test Accuracy     |1.000             |0.956        |\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "<center>(Left) Entropies associated with correct predictions. (Right) Entropies associated with wrong predictions.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'background'></a>\n",
    "\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:42.372649Z",
     "start_time": "2021-07-09T12:46:07.964312Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cloudpickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:42.404159Z",
     "start_time": "2021-07-09T12:46:42.377232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:42.483284Z",
     "start_time": "2021-07-09T12:46:42.407186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data size:  303\n",
      "Sizes for different datasets are: Train 212, Test 45 and Validation 45.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = os.path.join('.', 'data', 'heart.csv')\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "feature_names = df.columns.to_list()[:-1]\n",
    "\n",
    "print(\"Whole data size: \", len(df))\n",
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "val_size = int(0.15 * len(df))\n",
    "test_size = int(0.15 * len(df))\n",
    "\n",
    "print(f\"Sizes for different datasets are: Train {train_size}, Test {test_size} and Validation {val_size}.\")\n",
    "\n",
    "train_dataframe = df[:train_size]\n",
    "test_dataframe = df[train_size:]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'preprocessing'></a>\n",
    "\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The features of the dataset and its respective description\n",
    "\n",
    "| Feature  | Description                                                    |\n",
    "|----------|----------------------------------------------------------------|\n",
    "| age      | age in years                                                   |\n",
    "| sex      | (1 = male; 0 = female)                                         |\n",
    "| cp       | chest pain type                                                |\n",
    "| trtbps   | resting blood pressure (in mm Hg on admission to the hospital) |\n",
    "| chol     | serum cholestoral in mg/dl                                     |\n",
    "| fbs      | (fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)     |\n",
    "| restecg  | resting electrocardiographic results                           |\n",
    "| thalachh | maximum heart rate achieved                                    |\n",
    "| exng     | exercise induced angina (1 = yes; 0 = no)                      |\n",
    "| oldpeak  | ST depression induced by exercise relative to rest             |\n",
    "| slp      | the slope of the peak exercise ST segment                      |\n",
    "| caa      | number of major vessels (0-3) colored by flourosopy            |\n",
    "| thall    | 3 = normal; 6 = fixed defect; 7 = reversable defect            |\n",
    "| output   | 1 (heart disease) or 0                                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:43.371540Z",
     "start_time": "2021-07-09T12:46:42.485941Z"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = tf.data.Dataset.from_tensor_slices(dict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:43.432194Z",
     "start_time": "2021-07-09T12:46:43.375347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex :  [1 0]\n",
      "cp :  [3 2 1 0]\n",
      "fbs :  [1 0]\n",
      "restecg :  [0 1 2]\n",
      "exng :  [0 1]\n",
      "slp :  [0 2 1]\n",
      "caa :  [0 2 1 3 4]\n",
      "thall :  [1 2 3 0]\n",
      "output :  [1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sex': 2,\n",
       " 'cp': 4,\n",
       " 'fbs': 2,\n",
       " 'restecg': 3,\n",
       " 'exng': 2,\n",
       " 'slp': 3,\n",
       " 'caa': 5,\n",
       " 'thall': 4,\n",
       " 'output': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall', 'output']\n",
    "cat_feat_depth = {k:v for k, v in zip(categorical_features, map(lambda x: len(df[x].unique()), categorical_features))}\n",
    "\n",
    "for cat_feat in categorical_features:\n",
    "    print(cat_feat,': ', df[cat_feat].unique())\n",
    "    \n",
    "cat_feat_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:43.463110Z",
     "start_time": "2021-07-09T12:46:43.437180Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_x(x):\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        \n",
    "        if feature in categorical_features:\n",
    "            \n",
    "            x[feature] = tf.one_hot(x[feature], depth = cat_feat_depth[feature], dtype = tf.float32)\n",
    "            x[feature] = tf.cast(x[feature], dtype = tf.float32)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x[feature] = tf.cast(x[feature], dtype = tf.float32)\n",
    "    \n",
    "    x['output'] = tf.one_hot(x['output'], depth = cat_feat_depth['output'], dtype = tf.int32)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:43.973706Z",
     "start_time": "2021-07-09T12:46:43.468265Z"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.map(transform_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:43.989667Z",
     "start_time": "2021-07-09T12:46:43.976698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       " 'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'output': TensorSpec(shape=(2,), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:44.020877Z",
     "start_time": "2021-07-09T12:46:43.994653Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_feature_label(x):\n",
    "    features = {feature:x[feature] for feature in df.columns.to_list()[:-1]}\n",
    "    return (features, x['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:44.237772Z",
     "start_time": "2021-07-09T12:46:44.023870Z"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.map(map_feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:44.473456Z",
     "start_time": "2021-07-09T12:46:44.241766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': {}, 'sex': {}, 'cp': {}, 'trtbps': {}, 'chol': {}, 'fbs': {}, 'restecg': {}, 'thalachh': {}, 'exng': {}, 'oldpeak': {}, 'slp': {}, 'caa': {}, 'thall': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': {'shape': 1, 'dtype': tf.float32},\n",
       " 'sex': {'shape': 2, 'dtype': tf.float32},\n",
       " 'cp': {'shape': 4, 'dtype': tf.float32},\n",
       " 'trtbps': {'shape': 1, 'dtype': tf.float32},\n",
       " 'chol': {'shape': 1, 'dtype': tf.float32},\n",
       " 'fbs': {'shape': 2, 'dtype': tf.float32},\n",
       " 'restecg': {'shape': 3, 'dtype': tf.float32},\n",
       " 'thalachh': {'shape': 1, 'dtype': tf.float32},\n",
       " 'exng': {'shape': 2, 'dtype': tf.float32},\n",
       " 'oldpeak': {'shape': 1, 'dtype': tf.float32},\n",
       " 'slp': {'shape': 3, 'dtype': tf.float32},\n",
       " 'caa': {'shape': 5, 'dtype': tf.float32},\n",
       " 'thall': {'shape': 4, 'dtype': tf.float32}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_shape_dtype = {feature: dict() for feature in feature_names}\n",
    "print(feature_shape_dtype)\n",
    "\n",
    "for x in full_dataset.take(1):\n",
    "    q = x[0]\n",
    "    for feature in feature_names:\n",
    "        feature_shape_dtype[feature]['shape'] = int(cat_feat_depth[feature]) if feature in cat_feat_depth.keys() else 1\n",
    "        feature_shape_dtype[feature]['dtype'] = q[feature].dtype\n",
    "        \n",
    "feature_shape_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:44.504377Z",
     "start_time": "2021-07-09T12:46:44.478443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.233059Z",
     "start_time": "2021-07-09T12:46:44.509361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22169811320754718, 0.7783018867924528)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neg_proportion = len(train_dataframe[train_dataframe.output ==0])/len(train_dataframe)\n",
    "num_pos_proportion = len(train_dataframe[train_dataframe.output ==1])/len(train_dataframe)\n",
    "\n",
    "num_neg_proportion, num_pos_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.263830Z",
     "start_time": "2021-07-09T12:46:45.239833Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_to_train_val_test(dataset, train_size, val_size, test_size):\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size = len(df))\n",
    "    train_dataset = dataset.take(train_size).batch(train_size)\n",
    "    test_dataset = dataset.skip(train_size)\n",
    "    val_dataset = dataset.skip(val_size).batch(val_size)\n",
    "    test_dataset = dataset.take(test_size).batch(test_size)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.295100Z",
     "start_time": "2021-07-09T12:46:45.266759Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset_to_train_val_test(full_dataset,\n",
    "                                                                     train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.310049Z",
     "start_time": "2021-07-09T12:46:45.297675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(None, 2), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.497603Z",
     "start_time": "2021-07-09T12:46:45.313042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([76., 41., 48., 62., 50., 54., 64., 58., 46., 45., 60., 61., 63.,\n",
      "       47., 64., 51., 63., 52., 43., 34., 53., 63., 59., 60., 77., 66.,\n",
      "       61., 38., 71., 55., 61., 67., 44., 54., 70., 53., 46., 44., 34.,\n",
      "       47., 39., 62., 62., 48., 59.], dtype=float32)>, 'sex': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.]], dtype=float32)>, 'cp': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.]], dtype=float32)>, 'trtbps': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([140., 112., 130., 160., 129., 124., 130., 114., 120., 138., 117.,\n",
      "       140., 130., 108., 128., 100., 140., 152., 132., 118., 142., 150.,\n",
      "       160., 120., 125., 160., 120., 138., 112., 132., 148., 152., 120.,\n",
      "       135., 160., 140., 105., 120., 118., 110., 118., 130., 140., 124.,\n",
      "       164.], dtype=float32)>, 'chol': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([197., 250., 245., 164., 196., 266., 303., 318., 249., 236., 230.,\n",
      "       207., 330., 243., 263., 222., 187., 298., 341., 182., 226., 407.,\n",
      "       273., 178., 304., 228., 260., 175., 149., 353., 203., 277., 220.,\n",
      "       304., 269., 203., 204., 226., 210., 275., 219., 263., 268., 255.,\n",
      "       176.], dtype=float32)>, 'fbs': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.]], dtype=float32)>, 'restecg': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.]], dtype=float32)>, 'thalachh': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([116., 179., 180., 145., 163., 109., 122., 140., 144., 152., 160.,\n",
      "       138., 132., 152., 105., 143., 144., 178., 136., 174., 111., 154.,\n",
      "       125.,  96., 162., 138., 140., 173., 125., 132., 161., 172., 170.,\n",
      "       170., 112., 155., 172., 169., 192., 118., 140.,  97., 160., 175.,\n",
      "        90.], dtype=float32)>, 'exng': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32)>, 'oldpeak': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([1.1, 0. , 0.2, 6.2, 0. , 2.2, 2. , 4.4, 0.8, 0.2, 1.4, 1.9, 1.8,\n",
      "       0. , 0.2, 1.2, 4. , 1.2, 3. , 0. , 0. , 4. , 0. , 0. , 0. , 2.3,\n",
      "       3.6, 0. , 1.6, 1.2, 0. , 0. , 0. , 0. , 2.9, 3.1, 0. , 0. , 0.7,\n",
      "       1. , 1.2, 1.2, 3.6, 0. , 1. ], dtype=float32)>, 'slp': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.]], dtype=float32)>, 'caa': <tf.Tensor: shape=(45, 5), dtype=float32, numpy=\n",
      "array([[1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.]], dtype=float32)>, 'thall': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.]], dtype=float32)>}\n",
      "---------------\n",
      "tf.Tensor(\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]], shape=(45, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_dataset.take(1):\n",
    "    print(x)\n",
    "    print('-'*15)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'models'></a>\n",
    "\n",
    "# Creation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.512859Z",
     "start_time": "2021-07-09T12:46:45.500540Z"
    }
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "\n",
    "hidden_units = [32, 32, 32]\n",
    "\n",
    "feature_names = ['age', 'sex', 'cp',\n",
    "                 'trtbps', 'chol', 'fbs',\n",
    "                 'restecg', 'thalachh', 'exng',\n",
    "                 'oldpeak', 'slp', 'caa', 'thall']\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.544775Z",
     "start_time": "2021-07-09T12:46:45.515446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'sex': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'sex')>,\n",
       " 'cp': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'cp')>,\n",
       " 'trtbps': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'trtbps')>,\n",
       " 'chol': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'chol')>,\n",
       " 'fbs': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'fbs')>,\n",
       " 'restecg': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'restecg')>,\n",
       " 'thalachh': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'thalachh')>,\n",
       " 'exng': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'exng')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'oldpeak')>,\n",
       " 'slp': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'slp')>,\n",
       " 'caa': <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'caa')>,\n",
       " 'thall': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'thall')>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model_inputs(feature_names = feature_names): \n",
    "    inputs = {}\n",
    "    for feature_name in feature_names:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(feature_shape_dtype[feature_name]['shape'],),\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n",
    "\n",
    "create_model_inputs(feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.574811Z",
     "start_time": "2021-07-09T12:46:45.546770Z"
    }
   },
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "def create_bnn_model(train_size):\n",
    "    \n",
    "    divergence_fn = lambda q, p, _:tfd.kl_divergence(q, p) / train_size\n",
    "    \n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features_ = tfpl.DenseReparameterization(\n",
    "            units = units, activation = 'relu',\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "    \n",
    "    distribution_params = tfpl.DenseReparameterization(\n",
    "            units = tfp.layers.OneHotCategorical.params_size(2), activation = None,\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "\n",
    "    outputs = tfp.layers.OneHotCategorical(2,\n",
    "                                          convert_to_tensor_fn=tfd.Distribution.mode)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.590713Z",
     "start_time": "2021-07-09T12:46:45.576689Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_nn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "    \n",
    "    for units in hidden_units:\n",
    "        features_ = tf.keras.layers.Dense(\n",
    "            units=units,\n",
    "            activation = 'relu')(features_)\n",
    "        \n",
    "    outputs = tf.keras.layers.Dense(2,\n",
    "                                    activation = 'softmax')(features_)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.622086Z",
     "start_time": "2021-07-09T12:46:45.595638Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(model, loss, train_dataset,val_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics = ['accuracy'],\n",
    "        #experimental_run_tf_function=False\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=val_dataset\n",
    "             )\n",
    "    \n",
    "    print(\"Model training finished.\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(train_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Train loss: {round(loss, 3)}, train accuracy: {round(accuracy, 3)}.\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(test_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Test loss: {round(loss, 3)}, test accuracy: {round(accuracy, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'training'></a>\n",
    "\n",
    "# Training and Evaluation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:45.840035Z",
     "start_time": "2021-07-09T12:46:45.628174Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_model_full = create_nn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:54:45.137527Z",
     "start_time": "2021-07-09T12:46:45.842826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6728 - accuracy: 0.5849 - val_loss: 1.2172 - val_accuracy: 0.3953\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.6218 - accuracy: 0.7075 - val_loss: 1.1139 - val_accuracy: 0.3876\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.5910 - accuracy: 0.7358 - val_loss: 1.0985 - val_accuracy: 0.3837\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.5675 - accuracy: 0.7783 - val_loss: 1.0401 - val_accuracy: 0.4070\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.5606 - accuracy: 0.7500 - val_loss: 1.0878 - val_accuracy: 0.3798\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.5093 - accuracy: 0.8208 - val_loss: 1.0430 - val_accuracy: 0.4070\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.4949 - accuracy: 0.8349 - val_loss: 1.0077 - val_accuracy: 0.4109\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.4743 - accuracy: 0.8113 - val_loss: 0.9095 - val_accuracy: 0.4651\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.4823 - accuracy: 0.8160 - val_loss: 0.9772 - val_accuracy: 0.4264\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.4508 - accuracy: 0.8302 - val_loss: 0.9434 - val_accuracy: 0.4225\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.4270 - accuracy: 0.8443 - val_loss: 0.9876 - val_accuracy: 0.4302\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.4220 - accuracy: 0.8349 - val_loss: 0.9950 - val_accuracy: 0.4225\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.4460 - accuracy: 0.8113 - val_loss: 0.9998 - val_accuracy: 0.4380\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.3915 - accuracy: 0.8538 - val_loss: 0.9831 - val_accuracy: 0.4225\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.3816 - accuracy: 0.8632 - val_loss: 0.9811 - val_accuracy: 0.4457\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.3921 - accuracy: 0.8443 - val_loss: 1.0392 - val_accuracy: 0.4574\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.4031 - accuracy: 0.8396 - val_loss: 1.1269 - val_accuracy: 0.4264\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.3586 - accuracy: 0.8679 - val_loss: 1.0325 - val_accuracy: 0.4535\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.3381 - accuracy: 0.8774 - val_loss: 1.0060 - val_accuracy: 0.4690\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.3690 - accuracy: 0.8491 - val_loss: 1.0987 - val_accuracy: 0.4535\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.3632 - accuracy: 0.8443 - val_loss: 0.9970 - val_accuracy: 0.4574\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.3445 - accuracy: 0.8585 - val_loss: 0.9537 - val_accuracy: 0.4845\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.3323 - accuracy: 0.8538 - val_loss: 0.9067 - val_accuracy: 0.4961\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.3339 - accuracy: 0.8632 - val_loss: 0.9396 - val_accuracy: 0.4806\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.3543 - accuracy: 0.8443 - val_loss: 1.1579 - val_accuracy: 0.4419\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.3720 - accuracy: 0.8160 - val_loss: 1.1008 - val_accuracy: 0.4380\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.3006 - accuracy: 0.8868 - val_loss: 1.0286 - val_accuracy: 0.4574\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.3119 - accuracy: 0.8679 - val_loss: 0.9923 - val_accuracy: 0.4767\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.3407 - accuracy: 0.8491 - val_loss: 1.0877 - val_accuracy: 0.4496\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.3120 - accuracy: 0.8538 - val_loss: 1.0162 - val_accuracy: 0.4419\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.3187 - accuracy: 0.8491 - val_loss: 0.9765 - val_accuracy: 0.4457\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2961 - accuracy: 0.8632 - val_loss: 0.8348 - val_accuracy: 0.4922\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.2860 - accuracy: 0.8632 - val_loss: 0.7987 - val_accuracy: 0.5116\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.3037 - accuracy: 0.8585 - val_loss: 0.7815 - val_accuracy: 0.5155\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.2974 - accuracy: 0.8632 - val_loss: 0.8181 - val_accuracy: 0.5000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.2727 - accuracy: 0.8679 - val_loss: 0.8205 - val_accuracy: 0.5155\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.2822 - accuracy: 0.8726 - val_loss: 0.7459 - val_accuracy: 0.5388\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.2890 - accuracy: 0.8632 - val_loss: 0.8224 - val_accuracy: 0.5271\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.2841 - accuracy: 0.8679 - val_loss: 0.8454 - val_accuracy: 0.5000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.2962 - accuracy: 0.8774 - val_loss: 0.8564 - val_accuracy: 0.5039\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.3039 - accuracy: 0.8538 - val_loss: 0.8598 - val_accuracy: 0.5078\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2798 - accuracy: 0.8868 - val_loss: 0.8439 - val_accuracy: 0.5078\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.2617 - accuracy: 0.8962 - val_loss: 0.8547 - val_accuracy: 0.5116\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.2630 - accuracy: 0.8962 - val_loss: 0.8459 - val_accuracy: 0.5271\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.2615 - accuracy: 0.9009 - val_loss: 0.7949 - val_accuracy: 0.5426\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.2504 - accuracy: 0.8915 - val_loss: 0.8396 - val_accuracy: 0.5155\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.2292 - accuracy: 0.9057 - val_loss: 0.8344 - val_accuracy: 0.5233\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.2574 - accuracy: 0.8962 - val_loss: 0.8251 - val_accuracy: 0.5310\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.2208 - accuracy: 0.9245 - val_loss: 0.6905 - val_accuracy: 0.6240\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.2747 - accuracy: 0.8774 - val_loss: 0.7970 - val_accuracy: 0.5388\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.2501 - accuracy: 0.9057 - val_loss: 0.7568 - val_accuracy: 0.5504\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.2485 - accuracy: 0.8868 - val_loss: 0.8003 - val_accuracy: 0.5116\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.2433 - accuracy: 0.9009 - val_loss: 0.7382 - val_accuracy: 0.5736\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.2361 - accuracy: 0.9198 - val_loss: 0.7600 - val_accuracy: 0.5698\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.2199 - accuracy: 0.9245 - val_loss: 0.7031 - val_accuracy: 0.6202\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.2354 - accuracy: 0.9009 - val_loss: 0.7910 - val_accuracy: 0.5620\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.2481 - accuracy: 0.9057 - val_loss: 0.7431 - val_accuracy: 0.5775\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.2222 - accuracy: 0.9245 - val_loss: 0.7173 - val_accuracy: 0.6124\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.2394 - accuracy: 0.9009 - val_loss: 0.7615 - val_accuracy: 0.5853\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.1957 - accuracy: 0.9292 - val_loss: 0.6181 - val_accuracy: 0.6860\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.2261 - accuracy: 0.9151 - val_loss: 0.7165 - val_accuracy: 0.6202\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.2135 - accuracy: 0.9104 - val_loss: 0.6305 - val_accuracy: 0.6667\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.2259 - accuracy: 0.9198 - val_loss: 0.6059 - val_accuracy: 0.6744\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.2276 - accuracy: 0.9104 - val_loss: 0.6797 - val_accuracy: 0.6279\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.1971 - accuracy: 0.9198 - val_loss: 0.6520 - val_accuracy: 0.6395\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.2198 - accuracy: 0.9151 - val_loss: 0.6875 - val_accuracy: 0.6357\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.2126 - accuracy: 0.9245 - val_loss: 0.5642 - val_accuracy: 0.6977\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1921 - accuracy: 0.9292 - val_loss: 0.6613 - val_accuracy: 0.6473\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.2016 - accuracy: 0.9292 - val_loss: 0.5929 - val_accuracy: 0.6860\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1842 - accuracy: 0.9387 - val_loss: 0.5813 - val_accuracy: 0.6860\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1925 - accuracy: 0.9340 - val_loss: 0.5403 - val_accuracy: 0.7171\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.2071 - accuracy: 0.9245 - val_loss: 0.6018 - val_accuracy: 0.6899\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1931 - accuracy: 0.9292 - val_loss: 0.5891 - val_accuracy: 0.6899\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1926 - accuracy: 0.9340 - val_loss: 0.7215 - val_accuracy: 0.6318\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1856 - accuracy: 0.9481 - val_loss: 0.5910 - val_accuracy: 0.7016\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1954 - accuracy: 0.9292 - val_loss: 0.5661 - val_accuracy: 0.7054\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1700 - accuracy: 0.9434 - val_loss: 0.6040 - val_accuracy: 0.6822\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.1721 - accuracy: 0.9434 - val_loss: 0.5228 - val_accuracy: 0.7171\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1562 - accuracy: 0.9434 - val_loss: 0.5817 - val_accuracy: 0.7093\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1729 - accuracy: 0.9387 - val_loss: 0.5913 - val_accuracy: 0.7016\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.1703 - accuracy: 0.9481 - val_loss: 0.6209 - val_accuracy: 0.6899\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.1449 - accuracy: 0.9528 - val_loss: 0.5765 - val_accuracy: 0.7209\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1915 - accuracy: 0.9292 - val_loss: 0.5228 - val_accuracy: 0.7248\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1438 - accuracy: 0.9623 - val_loss: 0.5469 - val_accuracy: 0.7248\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1731 - accuracy: 0.9528 - val_loss: 0.5235 - val_accuracy: 0.7403\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1758 - accuracy: 0.9434 - val_loss: 0.5197 - val_accuracy: 0.7558\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.1495 - accuracy: 0.9670 - val_loss: 0.4599 - val_accuracy: 0.7674\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1792 - accuracy: 0.9387 - val_loss: 0.4793 - val_accuracy: 0.7674\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.1685 - accuracy: 0.9481 - val_loss: 0.5563 - val_accuracy: 0.7209\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1311 - accuracy: 0.9717 - val_loss: 0.4764 - val_accuracy: 0.7713\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1348 - accuracy: 0.9670 - val_loss: 0.5169 - val_accuracy: 0.7442\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1372 - accuracy: 0.9528 - val_loss: 0.4678 - val_accuracy: 0.7636\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1543 - accuracy: 0.9481 - val_loss: 0.4936 - val_accuracy: 0.7713\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1336 - accuracy: 0.9575 - val_loss: 0.4498 - val_accuracy: 0.7752\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1293 - accuracy: 0.9670 - val_loss: 0.5005 - val_accuracy: 0.7519\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.1223 - accuracy: 0.9623 - val_loss: 0.4641 - val_accuracy: 0.7791\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.1250 - accuracy: 0.9717 - val_loss: 0.4677 - val_accuracy: 0.7752\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.1185 - accuracy: 0.9717 - val_loss: 0.4191 - val_accuracy: 0.7984\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1191 - accuracy: 0.9717 - val_loss: 0.4690 - val_accuracy: 0.7829\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.1534 - accuracy: 0.9528 - val_loss: 0.4513 - val_accuracy: 0.7752\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1438 - accuracy: 0.9481 - val_loss: 0.4960 - val_accuracy: 0.7558\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.1358 - accuracy: 0.9575 - val_loss: 0.4598 - val_accuracy: 0.7713\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1394 - accuracy: 0.9623 - val_loss: 0.3981 - val_accuracy: 0.8217\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1404 - accuracy: 0.9623 - val_loss: 0.4384 - val_accuracy: 0.7791\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.1293 - accuracy: 0.9670 - val_loss: 0.4252 - val_accuracy: 0.7907\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1253 - accuracy: 0.9717 - val_loss: 0.4347 - val_accuracy: 0.7946\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.1057 - accuracy: 0.9811 - val_loss: 0.3930 - val_accuracy: 0.8101\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1065 - accuracy: 0.9811 - val_loss: 0.3552 - val_accuracy: 0.8178\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.1173 - accuracy: 0.9717 - val_loss: 0.3724 - val_accuracy: 0.8295\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1130 - accuracy: 0.9811 - val_loss: 0.4088 - val_accuracy: 0.8178\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1085 - accuracy: 0.9717 - val_loss: 0.4256 - val_accuracy: 0.7907\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1060 - accuracy: 0.9717 - val_loss: 0.4058 - val_accuracy: 0.8140\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.1101 - accuracy: 0.9717 - val_loss: 0.3388 - val_accuracy: 0.8372\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1103 - accuracy: 0.9623 - val_loss: 0.4217 - val_accuracy: 0.8101\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step - loss: 0.1164 - accuracy: 0.9717 - val_loss: 0.3956 - val_accuracy: 0.8140\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1130 - accuracy: 0.9717 - val_loss: 0.4012 - val_accuracy: 0.8062\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0917 - accuracy: 0.9811 - val_loss: 0.3762 - val_accuracy: 0.8217\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0846 - accuracy: 0.9906 - val_loss: 0.3543 - val_accuracy: 0.8372\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0906 - accuracy: 0.9858 - val_loss: 0.3946 - val_accuracy: 0.8101\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.0976 - accuracy: 0.9764 - val_loss: 0.3879 - val_accuracy: 0.8062\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1049 - accuracy: 0.9764 - val_loss: 0.3925 - val_accuracy: 0.8140\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1024 - accuracy: 0.9764 - val_loss: 0.3855 - val_accuracy: 0.8062\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.1107 - accuracy: 0.9670 - val_loss: 0.4183 - val_accuracy: 0.7984\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.1134 - accuracy: 0.9717 - val_loss: 0.3194 - val_accuracy: 0.8488\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0965 - accuracy: 0.9717 - val_loss: 0.3004 - val_accuracy: 0.8566\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1095 - accuracy: 0.9623 - val_loss: 0.3426 - val_accuracy: 0.8372\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0957 - accuracy: 0.9764 - val_loss: 0.3388 - val_accuracy: 0.8333\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0849 - accuracy: 0.9764 - val_loss: 0.3763 - val_accuracy: 0.8062\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.1004 - accuracy: 0.9670 - val_loss: 0.3341 - val_accuracy: 0.8333\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0952 - accuracy: 0.9764 - val_loss: 0.3400 - val_accuracy: 0.8450\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0956 - accuracy: 0.9764 - val_loss: 0.3349 - val_accuracy: 0.8450\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0986 - accuracy: 0.9764 - val_loss: 0.2999 - val_accuracy: 0.8527\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0795 - accuracy: 0.9811 - val_loss: 0.3036 - val_accuracy: 0.8488\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0853 - accuracy: 0.9811 - val_loss: 0.3209 - val_accuracy: 0.8333\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0851 - accuracy: 0.9764 - val_loss: 0.3082 - val_accuracy: 0.8488\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0807 - accuracy: 0.9811 - val_loss: 0.2907 - val_accuracy: 0.8643\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0859 - accuracy: 0.9717 - val_loss: 0.2866 - val_accuracy: 0.8488\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0742 - accuracy: 0.9811 - val_loss: 0.2969 - val_accuracy: 0.8450\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.0755 - accuracy: 0.9764 - val_loss: 0.2852 - val_accuracy: 0.8721\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0825 - accuracy: 0.9764 - val_loss: 0.3254 - val_accuracy: 0.8372\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0781 - accuracy: 0.9717 - val_loss: 0.3306 - val_accuracy: 0.8372\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0667 - accuracy: 0.9858 - val_loss: 0.2851 - val_accuracy: 0.8682\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0796 - accuracy: 0.9717 - val_loss: 0.2821 - val_accuracy: 0.8605\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0606 - accuracy: 0.9953 - val_loss: 0.2648 - val_accuracy: 0.8721\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0666 - accuracy: 0.9764 - val_loss: 0.2424 - val_accuracy: 0.8760\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 0.2687 - val_accuracy: 0.8760\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0620 - accuracy: 0.9906 - val_loss: 0.2643 - val_accuracy: 0.8682\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0751 - accuracy: 0.9811 - val_loss: 0.2211 - val_accuracy: 0.8798\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0513 - accuracy: 0.9906 - val_loss: 0.2383 - val_accuracy: 0.8760\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 0.2319 - val_accuracy: 0.8915\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.0698 - accuracy: 0.9858 - val_loss: 0.2406 - val_accuracy: 0.8760\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0531 - accuracy: 0.9906 - val_loss: 0.2190 - val_accuracy: 0.8876\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0643 - accuracy: 0.9811 - val_loss: 0.2147 - val_accuracy: 0.8876\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0621 - accuracy: 0.9764 - val_loss: 0.2291 - val_accuracy: 0.8837\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0626 - accuracy: 0.9811 - val_loss: 0.2446 - val_accuracy: 0.8682\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0555 - accuracy: 0.9858 - val_loss: 0.2148 - val_accuracy: 0.8915\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.0501 - accuracy: 0.9906 - val_loss: 0.2251 - val_accuracy: 0.8953\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0559 - accuracy: 0.9858 - val_loss: 0.2286 - val_accuracy: 0.8837\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0427 - accuracy: 0.9906 - val_loss: 0.2105 - val_accuracy: 0.8953\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.2196 - val_accuracy: 0.8992\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.2090 - val_accuracy: 0.8992\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0530 - accuracy: 0.9858 - val_loss: 0.1924 - val_accuracy: 0.9147\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.0605 - accuracy: 0.9858 - val_loss: 0.2190 - val_accuracy: 0.8837\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 0.1946 - val_accuracy: 0.9109\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0470 - accuracy: 0.9906 - val_loss: 0.2014 - val_accuracy: 0.8915\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.0470 - accuracy: 0.9906 - val_loss: 0.1869 - val_accuracy: 0.9225\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0388 - accuracy: 0.9953 - val_loss: 0.2119 - val_accuracy: 0.8953\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0433 - accuracy: 0.9906 - val_loss: 0.1810 - val_accuracy: 0.9186\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0393 - accuracy: 0.9906 - val_loss: 0.1943 - val_accuracy: 0.9031\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0391 - accuracy: 0.9906 - val_loss: 0.2022 - val_accuracy: 0.9031\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.0420 - accuracy: 0.9906 - val_loss: 0.1830 - val_accuracy: 0.9109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0336 - accuracy: 0.9953 - val_loss: 0.1712 - val_accuracy: 0.9186\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0398 - accuracy: 0.9953 - val_loss: 0.1756 - val_accuracy: 0.9147\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0323 - accuracy: 0.9953 - val_loss: 0.1784 - val_accuracy: 0.9109\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0333 - accuracy: 0.9953 - val_loss: 0.1905 - val_accuracy: 0.9070\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.1812 - val_accuracy: 0.9147\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0371 - accuracy: 0.9953 - val_loss: 0.1750 - val_accuracy: 0.9225\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9186\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0375 - accuracy: 0.9953 - val_loss: 0.1517 - val_accuracy: 0.9341\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0280 - accuracy: 0.9953 - val_loss: 0.1516 - val_accuracy: 0.9419\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0285 - accuracy: 0.9953 - val_loss: 0.1534 - val_accuracy: 0.9380\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.1669 - val_accuracy: 0.9186\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.0299 - accuracy: 0.9953 - val_loss: 0.1607 - val_accuracy: 0.9264\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9341\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0353 - accuracy: 0.9953 - val_loss: 0.1340 - val_accuracy: 0.9535\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0339 - accuracy: 0.9953 - val_loss: 0.1516 - val_accuracy: 0.9380\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0327 - accuracy: 0.9953 - val_loss: 0.1354 - val_accuracy: 0.9457\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9380\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9264\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9457\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9264\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9264\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0282 - accuracy: 0.9953 - val_loss: 0.1303 - val_accuracy: 0.9457\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9380\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0277 - accuracy: 0.9953 - val_loss: 0.1339 - val_accuracy: 0.9457\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9535\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.0250 - accuracy: 0.9953 - val_loss: 0.1106 - val_accuracy: 0.9612\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0251 - accuracy: 0.9953 - val_loss: 0.1134 - val_accuracy: 0.9574\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9380\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9535\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9535\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9535\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9612\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.0207 - accuracy: 0.9953 - val_loss: 0.1062 - val_accuracy: 0.9612\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9496\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9574\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9574\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9574\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9574\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9612\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9651\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9651\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9690\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0203 - accuracy: 0.9953 - val_loss: 0.1171 - val_accuracy: 0.9496\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9806\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9690\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9729\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9690\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9651\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9767\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9690\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9845\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9884\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9690\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9767\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9690\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9729\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9767\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9767\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9767\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9845\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9767\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9806\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9922\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9806\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9845\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9922\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9884\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9845\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9845\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9806\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9845\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9922\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9884\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9922\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9922\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9845\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9961\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9961\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9922\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 0.9961\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9922\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9961\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9961\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9961\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9922\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9884\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9961\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9961\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9961\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9961\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9961\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9961\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9961\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9961\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9961\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9961\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9961\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9961\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9961\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9961\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9922\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9922\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9961\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9961\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9961\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9961\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9961\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9961\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9961\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9961\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9961\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9961\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9961\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9961\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9961\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9961\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9961\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9961\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9961\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9961\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9961\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9961\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9961\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9961\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9961\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9961\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9961\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9961\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9961\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9961\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9961\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9961\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9961\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9961\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 7.2425e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9961\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 8.6518e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9961\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9961\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 8.1198e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 8.8053e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 8.5374e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 6.5032e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 8.4494e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 8.1788e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 9.2960e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 6.2097e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 7.2685e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 6.1642e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 7.9449e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 7.2512e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 6.1355e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 4.8378e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 6.9973e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 8.1496e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 5.9103e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 5.1375e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 5.0074e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 8.0880e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 7.1165e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 7.3218e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 7.1001e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 3.6301e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 5.8471e-04 - accuracy: 1.0000 - val_loss: 8.3465e-04 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 4.7200e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 5.7608e-04 - accuracy: 1.0000 - val_loss: 7.0435e-04 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 3.7741e-04 - accuracy: 1.0000 - val_loss: 9.7419e-04 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 5.7055e-04 - accuracy: 1.0000 - val_loss: 8.9975e-04 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 3.9140e-04 - accuracy: 1.0000 - val_loss: 7.5028e-04 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 2.9986e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 3.2934e-04 - accuracy: 1.0000 - val_loss: 6.3882e-04 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 5.6281e-04 - accuracy: 1.0000 - val_loss: 8.0308e-04 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 4.3108e-04 - accuracy: 1.0000 - val_loss: 6.9813e-04 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 3.2155e-04 - accuracy: 1.0000 - val_loss: 7.4540e-04 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 5.1269e-04 - accuracy: 1.0000 - val_loss: 9.2358e-04 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 5.6942e-04 - accuracy: 1.0000 - val_loss: 6.1122e-04 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 1.9831e-04 - accuracy: 1.0000 - val_loss: 5.5351e-04 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.6752e-04 - accuracy: 1.0000 - val_loss: 5.9365e-04 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 3.6115e-04 - accuracy: 1.0000 - val_loss: 5.8033e-04 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 4.0673e-04 - accuracy: 1.0000 - val_loss: 3.7159e-04 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 2.0386e-04 - accuracy: 1.0000 - val_loss: 5.1689e-04 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 2.7598e-04 - accuracy: 1.0000 - val_loss: 4.3696e-04 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 2.7947e-04 - accuracy: 1.0000 - val_loss: 4.9599e-04 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 2.0376e-04 - accuracy: 1.0000 - val_loss: 3.7626e-04 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 2.5617e-04 - accuracy: 1.0000 - val_loss: 4.3276e-04 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 2.2427e-04 - accuracy: 1.0000 - val_loss: 3.3575e-04 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 3.8257e-04 - accuracy: 1.0000 - val_loss: 8.0558e-04 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 4.8866e-04 - accuracy: 1.0000 - val_loss: 5.3787e-04 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.8906e-04 - accuracy: 1.0000 - val_loss: 4.8983e-04 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 4.5361e-04 - accuracy: 1.0000 - val_loss: 4.8209e-04 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 2.1378e-04 - accuracy: 1.0000 - val_loss: 3.8031e-04 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.3769e-04 - accuracy: 1.0000 - val_loss: 4.0177e-04 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 5.0638e-04 - accuracy: 1.0000 - val_loss: 4.9466e-04 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 5.0686e-04 - accuracy: 1.0000 - val_loss: 5.9515e-04 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.9515e-04 - accuracy: 1.0000 - val_loss: 3.7132e-04 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 3.1426e-04 - accuracy: 1.0000 - val_loss: 3.7418e-04 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 3.4828e-04 - accuracy: 1.0000 - val_loss: 3.0151e-04 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.9222e-04 - accuracy: 1.0000 - val_loss: 2.9566e-04 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 1.7170e-04 - accuracy: 1.0000 - val_loss: 2.6329e-04 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.4973e-04 - accuracy: 1.0000 - val_loss: 2.7614e-04 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 1.7363e-04 - accuracy: 1.0000 - val_loss: 2.5067e-04 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 444ms/step - loss: 1.9631e-04 - accuracy: 1.0000 - val_loss: 2.6133e-04 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 2.0175e-04 - accuracy: 1.0000 - val_loss: 2.0915e-04 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.6537e-04 - accuracy: 1.0000 - val_loss: 1.9626e-04 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.5080e-04 - accuracy: 1.0000 - val_loss: 2.0961e-04 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.2092e-04 - accuracy: 1.0000 - val_loss: 1.7576e-04 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 1.9071e-04 - accuracy: 1.0000 - val_loss: 1.8513e-04 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.0507e-04 - accuracy: 1.0000 - val_loss: 1.5625e-04 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 1.3680e-04 - accuracy: 1.0000 - val_loss: 1.8999e-04 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.9191e-04 - accuracy: 1.0000 - val_loss: 3.4911e-04 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 4.6833e-04 - accuracy: 1.0000 - val_loss: 2.8040e-04 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 4.1104e-04 - accuracy: 1.0000 - val_loss: 4.2104e-04 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 3.2874e-04 - accuracy: 1.0000 - val_loss: 2.3440e-04 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 1.3339e-04 - accuracy: 1.0000 - val_loss: 1.8427e-04 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 1.1086e-04 - accuracy: 1.0000 - val_loss: 1.4717e-04 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 1.1467e-04 - accuracy: 1.0000 - val_loss: 1.4172e-04 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 8.0743e-05 - accuracy: 1.0000 - val_loss: 1.4313e-04 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.5753e-04 - accuracy: 1.0000 - val_loss: 1.1702e-04 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.0685e-04 - accuracy: 1.0000 - val_loss: 1.2814e-04 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 7.6444e-05 - accuracy: 1.0000 - val_loss: 1.2909e-04 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 9.4369e-05 - accuracy: 1.0000 - val_loss: 1.4253e-04 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 7.2198e-05 - accuracy: 1.0000 - val_loss: 1.2732e-04 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 6.2690e-05 - accuracy: 1.0000 - val_loss: 1.1623e-04 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.1334e-04 - accuracy: 1.0000 - val_loss: 1.2221e-04 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 1.0466e-04 - accuracy: 1.0000 - val_loss: 1.1212e-04 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 7.4313e-05 - accuracy: 1.0000 - val_loss: 1.1357e-04 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.5247e-04 - accuracy: 1.0000 - val_loss: 1.0636e-04 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.5682e-04 - accuracy: 1.0000 - val_loss: 8.6762e-05 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.2796e-04 - accuracy: 1.0000 - val_loss: 1.8821e-04 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.1690e-04 - accuracy: 1.0000 - val_loss: 1.4673e-04 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 4.1050e-04 - accuracy: 1.0000 - val_loss: 4.6861e-04 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.7500e-04 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 2.2312e-04 - accuracy: 1.0000 - val_loss: 1.7127e-04 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 3.2877e-04 - accuracy: 1.0000 - val_loss: 1.0422e-04 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 7.9228e-05 - accuracy: 1.0000 - val_loss: 7.6709e-05 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 7.0101e-05 - accuracy: 1.0000 - val_loss: 9.5328e-05 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 6.5021e-05 - accuracy: 1.0000 - val_loss: 8.1270e-05 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 7.6147e-05 - accuracy: 1.0000 - val_loss: 6.9320e-05 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 7.4672e-05 - accuracy: 1.0000 - val_loss: 8.4439e-05 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 7.1243e-05 - accuracy: 1.0000 - val_loss: 7.8338e-05 - val_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 8.2443e-05 - accuracy: 1.0000 - val_loss: 7.1205e-05 - val_accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 6.9611e-05 - accuracy: 1.0000 - val_loss: 6.7893e-05 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 5.6524e-05 - accuracy: 1.0000 - val_loss: 6.8116e-05 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 7.9663e-05 - accuracy: 1.0000 - val_loss: 6.3955e-05 - val_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 5.0998e-05 - accuracy: 1.0000 - val_loss: 5.6057e-05 - val_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 5.1906e-05 - accuracy: 1.0000 - val_loss: 6.8219e-05 - val_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 7.1781e-05 - accuracy: 1.0000 - val_loss: 6.3221e-05 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 6.2823e-05 - accuracy: 1.0000 - val_loss: 6.1198e-05 - val_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 1.0083e-04 - accuracy: 1.0000 - val_loss: 6.1578e-05 - val_accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 7.9512e-05 - accuracy: 1.0000 - val_loss: 5.4511e-05 - val_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 6.6085e-05 - accuracy: 1.0000 - val_loss: 5.5721e-05 - val_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.0035e-04 - accuracy: 1.0000 - val_loss: 5.3963e-05 - val_accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 4.9801e-05 - accuracy: 1.0000 - val_loss: 4.9939e-05 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 6.0869e-05 - accuracy: 1.0000 - val_loss: 4.3231e-05 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 6.7739e-05 - accuracy: 1.0000 - val_loss: 6.1304e-05 - val_accuracy: 1.0000\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 419ms/step - loss: 1.0596e-04 - accuracy: 1.0000 - val_loss: 5.2129e-05 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 9.7513e-05 - accuracy: 1.0000 - val_loss: 7.5573e-05 - val_accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 5.4632e-05 - accuracy: 1.0000 - val_loss: 6.4147e-05 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 6.6523e-05 - accuracy: 1.0000 - val_loss: 6.9943e-05 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 5.6221e-05 - accuracy: 1.0000 - val_loss: 5.5499e-05 - val_accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 7.2626e-05 - accuracy: 1.0000 - val_loss: 4.9957e-05 - val_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 7.5706e-05 - accuracy: 1.0000 - val_loss: 4.7395e-05 - val_accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 4.3034e-05 - accuracy: 1.0000 - val_loss: 4.5985e-05 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 7.7950e-05 - accuracy: 1.0000 - val_loss: 5.0356e-05 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 5.1738e-05 - accuracy: 1.0000 - val_loss: 3.9211e-05 - val_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 4.3639e-05 - accuracy: 1.0000 - val_loss: 3.8693e-05 - val_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 4.9252e-05 - accuracy: 1.0000 - val_loss: 4.6317e-05 - val_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 4.0485e-05 - accuracy: 1.0000 - val_loss: 4.1451e-05 - val_accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 4.6191e-05 - accuracy: 1.0000 - val_loss: 3.4096e-05 - val_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.8181e-04 - accuracy: 1.0000 - val_loss: 1.0737e-04 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 1.0822e-04 - accuracy: 1.0000 - val_loss: 6.0110e-05 - val_accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 5.0841e-05 - accuracy: 1.0000 - val_loss: 4.1558e-05 - val_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 5.1300e-05 - accuracy: 1.0000 - val_loss: 4.3396e-05 - val_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 9.1125e-05 - accuracy: 1.0000 - val_loss: 5.9391e-05 - val_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 7.3813e-05 - accuracy: 1.0000 - val_loss: 4.8838e-05 - val_accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 3.4960e-05 - accuracy: 1.0000 - val_loss: 4.6345e-05 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.0991e-04 - accuracy: 1.0000 - val_loss: 3.7474e-05 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 3.0318e-05 - accuracy: 1.0000 - val_loss: 3.8205e-05 - val_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 3.3923e-05 - accuracy: 1.0000 - val_loss: 3.0937e-05 - val_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 4.1041e-05 - accuracy: 1.0000 - val_loss: 2.7562e-05 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 3.7504e-05 - accuracy: 1.0000 - val_loss: 2.6247e-05 - val_accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 2.4179e-05 - accuracy: 1.0000 - val_loss: 2.8199e-05 - val_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 2.7824e-05 - accuracy: 1.0000 - val_loss: 2.7396e-05 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 2.0448e-05 - accuracy: 1.0000 - val_loss: 2.5663e-05 - val_accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 3.0960e-05 - accuracy: 1.0000 - val_loss: 2.7081e-05 - val_accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 3.7902e-05 - accuracy: 1.0000 - val_loss: 3.0856e-05 - val_accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 3.7559e-05 - accuracy: 1.0000 - val_loss: 2.6797e-05 - val_accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 3.0647e-05 - accuracy: 1.0000 - val_loss: 2.2306e-05 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 6.4468e-05 - accuracy: 1.0000 - val_loss: 4.6080e-05 - val_accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 3.9569e-05 - accuracy: 1.0000 - val_loss: 3.6325e-05 - val_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 3.5197e-05 - accuracy: 1.0000 - val_loss: 2.2878e-05 - val_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 2.0787e-05 - accuracy: 1.0000 - val_loss: 2.3194e-05 - val_accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.3962e-05 - accuracy: 1.0000 - val_loss: 1.7156e-05 - val_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 8.4648e-05 - accuracy: 1.0000 - val_loss: 3.9546e-05 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.0757e-04 - accuracy: 1.0000 - val_loss: 1.8654e-05 - val_accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.5729e-05 - accuracy: 1.0000 - val_loss: 2.6054e-05 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 3.5772e-05 - accuracy: 1.0000 - val_loss: 1.8091e-05 - val_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 2.0669e-05 - accuracy: 1.0000 - val_loss: 2.1035e-05 - val_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 3.2490e-05 - accuracy: 1.0000 - val_loss: 2.3695e-05 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 9.7783e-05 - accuracy: 1.0000 - val_loss: 4.4806e-05 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 5.7276e-05 - accuracy: 1.0000 - val_loss: 1.6340e-05 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 2.5310e-05 - accuracy: 1.0000 - val_loss: 1.9196e-05 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 3.9641e-05 - accuracy: 1.0000 - val_loss: 1.8925e-05 - val_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 3.1431e-05 - accuracy: 1.0000 - val_loss: 1.3591e-05 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 2.3955e-05 - accuracy: 1.0000 - val_loss: 1.5605e-05 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.6770e-05 - accuracy: 1.0000 - val_loss: 1.5613e-05 - val_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 1.2565e-05 - accuracy: 1.0000 - val_loss: 1.6118e-05 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 1.7892e-05 - accuracy: 1.0000 - val_loss: 1.3364e-05 - val_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 2.2086e-05 - accuracy: 1.0000 - val_loss: 1.2582e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 1.4811e-05 - accuracy: 1.0000 - val_loss: 1.4832e-05 - val_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 2.3491e-05 - accuracy: 1.0000 - val_loss: 1.1711e-05 - val_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 1.6376e-05 - accuracy: 1.0000 - val_loss: 1.3484e-05 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 1.5314e-05 - accuracy: 1.0000 - val_loss: 1.1812e-05 - val_accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.2483e-05 - accuracy: 1.0000 - val_loss: 1.0746e-05 - val_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.6000e-05 - accuracy: 1.0000 - val_loss: 1.2138e-05 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 1.9187e-05 - accuracy: 1.0000 - val_loss: 1.0339e-05 - val_accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 3.3430e-05 - accuracy: 1.0000 - val_loss: 1.3686e-05 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.3671e-05 - accuracy: 1.0000 - val_loss: 1.4133e-05 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 9.4790e-06 - accuracy: 1.0000 - val_loss: 1.3827e-05 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.1234e-05 - accuracy: 1.0000 - val_loss: 1.2799e-05 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.1891e-05 - accuracy: 1.0000 - val_loss: 1.0866e-05 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 5.3964e-05 - accuracy: 1.0000 - val_loss: 6.3082e-05 - val_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.8776e-04 - accuracy: 1.0000 - val_loss: 1.6182e-05 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.6762e-05 - accuracy: 1.0000 - val_loss: 9.7591e-06 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.4932e-05 - accuracy: 1.0000 - val_loss: 1.2514e-05 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 6.8037e-05 - accuracy: 1.0000 - val_loss: 2.7932e-05 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.5110e-05 - accuracy: 1.0000 - val_loss: 1.1673e-05 - val_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 1.7735e-05 - accuracy: 1.0000 - val_loss: 8.5751e-06 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 3.6881e-05 - accuracy: 1.0000 - val_loss: 1.2779e-05 - val_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.1220e-05 - accuracy: 1.0000 - val_loss: 9.3659e-06 - val_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.7655e-05 - accuracy: 1.0000 - val_loss: 7.8062e-06 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 1.6826e-05 - accuracy: 1.0000 - val_loss: 9.1239e-06 - val_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.3696e-05 - accuracy: 1.0000 - val_loss: 8.5465e-06 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 9.1325e-06 - accuracy: 1.0000 - val_loss: 8.0637e-06 - val_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.2807e-05 - accuracy: 1.0000 - val_loss: 8.2669e-06 - val_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.9461e-05 - accuracy: 1.0000 - val_loss: 8.1973e-06 - val_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.1121e-05 - accuracy: 1.0000 - val_loss: 6.9345e-06 - val_accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1.0358e-05 - accuracy: 1.0000 - val_loss: 6.8380e-06 - val_accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 8.4075e-06 - accuracy: 1.0000 - val_loss: 5.6960e-06 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 8.2258e-06 - accuracy: 1.0000 - val_loss: 8.2426e-06 - val_accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 2.1566e-05 - accuracy: 1.0000 - val_loss: 1.1213e-05 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.0505e-05 - accuracy: 1.0000 - val_loss: 7.5108e-06 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 1.4302e-05 - accuracy: 1.0000 - val_loss: 5.9639e-06 - val_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 7.1240e-06 - accuracy: 1.0000 - val_loss: 6.4273e-06 - val_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 9.6749e-06 - accuracy: 1.0000 - val_loss: 6.2744e-06 - val_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 8.4470e-06 - accuracy: 1.0000 - val_loss: 6.4856e-06 - val_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 9.1721e-06 - accuracy: 1.0000 - val_loss: 5.7643e-06 - val_accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 6.9755e-06 - accuracy: 1.0000 - val_loss: 6.2393e-06 - val_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 7.2494e-06 - accuracy: 1.0000 - val_loss: 5.3421e-06 - val_accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 7.6199e-06 - accuracy: 1.0000 - val_loss: 4.8357e-06 - val_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 7.3898e-06 - accuracy: 1.0000 - val_loss: 5.8133e-06 - val_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 7.0183e-06 - accuracy: 1.0000 - val_loss: 5.5864e-06 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.1755e-05 - accuracy: 1.0000 - val_loss: 5.8812e-06 - val_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 2.0692e-05 - accuracy: 1.0000 - val_loss: 6.8130e-06 - val_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 7.6698e-06 - accuracy: 1.0000 - val_loss: 5.3328e-06 - val_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 1.1959e-05 - accuracy: 1.0000 - val_loss: 8.9847e-06 - val_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.3887e-05 - accuracy: 1.0000 - val_loss: 6.3802e-06 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.5069e-05 - accuracy: 1.0000 - val_loss: 5.0699e-06 - val_accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 5.4777e-06 - accuracy: 1.0000 - val_loss: 4.8574e-06 - val_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 5.4912e-06 - accuracy: 1.0000 - val_loss: 3.9296e-06 - val_accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 7.8824e-06 - accuracy: 1.0000 - val_loss: 4.6249e-06 - val_accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 6.4735e-06 - accuracy: 1.0000 - val_loss: 4.0488e-06 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 5.0503e-06 - accuracy: 1.0000 - val_loss: 4.3990e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 7.4862e-06 - accuracy: 1.0000 - val_loss: 4.7049e-06 - val_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 5.0257e-06 - accuracy: 1.0000 - val_loss: 3.5627e-06 - val_accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 5.6947e-06 - accuracy: 1.0000 - val_loss: 3.2038e-06 - val_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 3.6414e-06 - accuracy: 1.0000 - val_loss: 4.0359e-06 - val_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 5.6137e-06 - accuracy: 1.0000 - val_loss: 3.6266e-06 - val_accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 8.5922e-06 - accuracy: 1.0000 - val_loss: 6.8067e-06 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 1.2096e-05 - accuracy: 1.0000 - val_loss: 6.0381e-06 - val_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 8.3969e-06 - accuracy: 1.0000 - val_loss: 3.4186e-06 - val_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 5.9841e-06 - accuracy: 1.0000 - val_loss: 3.1045e-06 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 6.6398e-06 - accuracy: 1.0000 - val_loss: 4.5855e-06 - val_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 2.8941e-06 - accuracy: 1.0000 - val_loss: 3.1276e-06 - val_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.3210e-05 - accuracy: 1.0000 - val_loss: 6.0157e-06 - val_accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.3005e-05 - accuracy: 1.0000 - val_loss: 3.4373e-06 - val_accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 3.6430e-06 - accuracy: 1.0000 - val_loss: 2.2885e-06 - val_accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 5.5271e-06 - accuracy: 1.0000 - val_loss: 2.7990e-06 - val_accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 6.6486e-06 - accuracy: 1.0000 - val_loss: 3.9971e-06 - val_accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 5.2236e-06 - accuracy: 1.0000 - val_loss: 2.0866e-06 - val_accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 7.5012e-06 - accuracy: 1.0000 - val_loss: 3.1501e-06 - val_accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 3.5085e-06 - accuracy: 1.0000 - val_loss: 2.3948e-06 - val_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 2.8188e-06 - accuracy: 1.0000 - val_loss: 2.0025e-06 - val_accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 4.8703e-06 - accuracy: 1.0000 - val_loss: 2.4474e-06 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 3.3794e-06 - accuracy: 1.0000 - val_loss: 1.8509e-06 - val_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 6.4985e-06 - accuracy: 1.0000 - val_loss: 2.7397e-06 - val_accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 1.9248e-06 - accuracy: 1.0000 - val_loss: 2.9246e-06 - val_accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 3.3775e-06 - accuracy: 1.0000 - val_loss: 1.8449e-06 - val_accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 5.1447e-06 - accuracy: 1.0000 - val_loss: 3.9407e-06 - val_accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 5.4153e-06 - accuracy: 1.0000 - val_loss: 1.8283e-06 - val_accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 3.8493e-06 - accuracy: 1.0000 - val_loss: 2.6161e-06 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.6033e-05 - accuracy: 1.0000 - val_loss: 2.3382e-04 - val_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 4.9020e-05 - accuracy: 1.0000 - val_loss: 2.5158e-06 - val_accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 7.7238e-06 - accuracy: 1.0000 - val_loss: 1.6343e-06 - val_accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 2.1193e-06 - accuracy: 1.0000 - val_loss: 1.6172e-06 - val_accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 2.7935e-06 - accuracy: 1.0000 - val_loss: 1.5414e-06 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 1.8837e-06 - accuracy: 1.0000 - val_loss: 1.6393e-06 - val_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 1.6127e-06 - accuracy: 1.0000 - val_loss: 1.3635e-06 - val_accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 2.1620e-06 - accuracy: 1.0000 - val_loss: 1.6056e-06 - val_accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 2.7232e-06 - accuracy: 1.0000 - val_loss: 1.5418e-06 - val_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 4.9183e-06 - accuracy: 1.0000 - val_loss: 2.2039e-06 - val_accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 2.3004e-06 - accuracy: 1.0000 - val_loss: 1.9364e-06 - val_accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 2.4094e-06 - accuracy: 1.0000 - val_loss: 1.5021e-06 - val_accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 3.1584e-06 - accuracy: 1.0000 - val_loss: 1.6842e-06 - val_accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.4528e-06 - accuracy: 1.0000 - val_loss: 1.2332e-06 - val_accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 2.7968e-06 - accuracy: 1.0000 - val_loss: 1.5363e-06 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.4013e-06 - accuracy: 1.0000 - val_loss: 1.0063e-06 - val_accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 3.7500e-06 - accuracy: 1.0000 - val_loss: 1.2480e-06 - val_accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 1.9793e-06 - accuracy: 1.0000 - val_loss: 1.3801e-06 - val_accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 2.0361e-06 - accuracy: 1.0000 - val_loss: 1.3312e-06 - val_accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 3.1060e-06 - accuracy: 1.0000 - val_loss: 1.0853e-06 - val_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 1.4878e-06 - accuracy: 1.0000 - val_loss: 1.1745e-06 - val_accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 1.7594e-06 - accuracy: 1.0000 - val_loss: 1.1075e-06 - val_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.6189e-06 - accuracy: 1.0000 - val_loss: 1.0022e-06 - val_accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 7.9948e-06 - accuracy: 1.0000 - val_loss: 3.7018e-06 - val_accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 4.3804e-06 - accuracy: 1.0000 - val_loss: 2.1346e-06 - val_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 2.6523e-06 - accuracy: 1.0000 - val_loss: 1.5968e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 2.0524e-06 - accuracy: 1.0000 - val_loss: 1.3811e-06 - val_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.7043e-06 - accuracy: 1.0000 - val_loss: 1.0914e-06 - val_accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 1.7302e-06 - accuracy: 1.0000 - val_loss: 1.0766e-06 - val_accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 4.4239e-06 - accuracy: 1.0000 - val_loss: 8.8298e-07 - val_accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.5688e-06 - accuracy: 1.0000 - val_loss: 1.0854e-06 - val_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.8083e-06 - accuracy: 1.0000 - val_loss: 9.9386e-07 - val_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.6487e-06 - accuracy: 1.0000 - val_loss: 7.8271e-07 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.7482e-06 - accuracy: 1.0000 - val_loss: 7.2264e-07 - val_accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.1409e-06 - accuracy: 1.0000 - val_loss: 8.0997e-07 - val_accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 1.0830e-06 - accuracy: 1.0000 - val_loss: 7.9750e-07 - val_accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.1432e-06 - accuracy: 1.0000 - val_loss: 7.0878e-07 - val_accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 9.6267e-07 - accuracy: 1.0000 - val_loss: 7.4020e-07 - val_accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.0099e-06 - accuracy: 1.0000 - val_loss: 6.8060e-07 - val_accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 9.7222e-07 - accuracy: 1.0000 - val_loss: 7.7624e-07 - val_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 2.3453e-06 - accuracy: 1.0000 - val_loss: 2.3364e-06 - val_accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.1974e-06 - accuracy: 1.0000 - val_loss: 1.3048e-06 - val_accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 3.7751e-06 - accuracy: 1.0000 - val_loss: 3.5223e-06 - val_accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.4828e-06 - accuracy: 1.0000 - val_loss: 1.8153e-06 - val_accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 3.6182e-06 - accuracy: 1.0000 - val_loss: 9.2410e-07 - val_accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 9.7447e-07 - accuracy: 1.0000 - val_loss: 6.4086e-07 - val_accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 2.3380e-06 - accuracy: 1.0000 - val_loss: 1.1565e-06 - val_accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.7527e-06 - accuracy: 1.0000 - val_loss: 6.9677e-07 - val_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.7645e-06 - accuracy: 1.0000 - val_loss: 7.1618e-07 - val_accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 7.2650e-07 - accuracy: 1.0000 - val_loss: 5.6647e-07 - val_accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 6.9613e-07 - accuracy: 1.0000 - val_loss: 5.6740e-07 - val_accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 8.9237e-07 - accuracy: 1.0000 - val_loss: 7.0462e-07 - val_accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 2.4949e-06 - accuracy: 1.0000 - val_loss: 6.1129e-07 - val_accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 2.7412e-06 - accuracy: 1.0000 - val_loss: 6.5288e-07 - val_accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1.0121e-06 - accuracy: 1.0000 - val_loss: 4.1122e-07 - val_accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 7.7485e-07 - accuracy: 1.0000 - val_loss: 5.3551e-07 - val_accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 7.1300e-07 - accuracy: 1.0000 - val_loss: 3.3591e-07 - val_accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.4890e-06 - accuracy: 1.0000 - val_loss: 6.5934e-07 - val_accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 9.6097e-07 - accuracy: 1.0000 - val_loss: 4.4680e-07 - val_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 8.0746e-07 - accuracy: 1.0000 - val_loss: 4.1723e-07 - val_accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 6.6296e-07 - accuracy: 1.0000 - val_loss: 4.4588e-07 - val_accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 6.4215e-07 - accuracy: 1.0000 - val_loss: 4.2416e-07 - val_accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 7.8666e-07 - accuracy: 1.0000 - val_loss: 3.4931e-07 - val_accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 4.9595e-07 - accuracy: 1.0000 - val_loss: 3.6225e-07 - val_accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 5.5106e-07 - accuracy: 1.0000 - val_loss: 3.1928e-07 - val_accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 7.7822e-07 - accuracy: 1.0000 - val_loss: 3.2390e-07 - val_accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 3.0758e-07 - accuracy: 1.0000 - val_loss: 2.9571e-07 - val_accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 4.2510e-07 - accuracy: 1.0000 - val_loss: 3.8073e-07 - val_accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 7.6079e-07 - accuracy: 1.0000 - val_loss: 4.2601e-07 - val_accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 6.2978e-07 - accuracy: 1.0000 - val_loss: 3.5716e-07 - val_accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.2044e-06 - accuracy: 1.0000 - val_loss: 9.0883e-07 - val_accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.2084e-06 - accuracy: 1.0000 - val_loss: 4.2832e-07 - val_accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 9.1205e-07 - accuracy: 1.0000 - val_loss: 2.3426e-07 - val_accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 5.6118e-07 - accuracy: 1.0000 - val_loss: 3.8443e-07 - val_accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.0779e-06 - accuracy: 1.0000 - val_loss: 8.2752e-07 - val_accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.8469e-06 - accuracy: 1.0000 - val_loss: 4.7252e-06 - val_accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.3715e-05 - accuracy: 1.0000 - val_loss: 3.8756e-06 - val_accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 3.7540e-06 - accuracy: 1.0000 - val_loss: 1.3015e-06 - val_accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 4.0711e-07 - accuracy: 1.0000 - val_loss: 1.0779e-06 - val_accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 6.7138e-07 - accuracy: 1.0000 - val_loss: 9.4856e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.3692e-06 - accuracy: 1.0000 - val_loss: 4.8283e-07 - val_accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.4668e-05 - accuracy: 1.0000 - val_loss: 5.3923e-06 - val_accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 5.6927e-06 - accuracy: 1.0000 - val_loss: 3.3314e-07 - val_accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2.2773e-07 - accuracy: 1.0000 - val_loss: 3.0172e-07 - val_accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.4946e-06 - accuracy: 1.0000 - val_loss: 2.8370e-07 - val_accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 3.8968e-07 - accuracy: 1.0000 - val_loss: 2.8693e-07 - val_accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 4.9089e-07 - accuracy: 1.0000 - val_loss: 3.8304e-07 - val_accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.3197e-06 - accuracy: 1.0000 - val_loss: 2.2687e-07 - val_accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 2.9465e-07 - accuracy: 1.0000 - val_loss: 2.3287e-07 - val_accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 8.6257e-07 - accuracy: 1.0000 - val_loss: 2.1301e-07 - val_accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 4.8358e-07 - accuracy: 1.0000 - val_loss: 2.5320e-07 - val_accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 2.1593e-07 - accuracy: 1.0000 - val_loss: 2.5875e-07 - val_accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.7497e-07 - accuracy: 1.0000 - val_loss: 2.1023e-07 - val_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 5.5949e-07 - accuracy: 1.0000 - val_loss: 1.9499e-07 - val_accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 3.4244e-07 - accuracy: 1.0000 - val_loss: 1.8297e-07 - val_accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 2.7159e-07 - accuracy: 1.0000 - val_loss: 2.0654e-07 - val_accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.2492e-07 - accuracy: 1.0000 - val_loss: 1.9730e-07 - val_accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 4.4366e-07 - accuracy: 1.0000 - val_loss: 1.9360e-07 - val_accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 2.4460e-07 - accuracy: 1.0000 - val_loss: 1.7743e-07 - val_accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.5783e-06 - accuracy: 1.0000 - val_loss: 3.2390e-07 - val_accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 7.6080e-07 - accuracy: 1.0000 - val_loss: 1.8621e-07 - val_accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 5.6343e-07 - accuracy: 1.0000 - val_loss: 2.1023e-07 - val_accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 7.1750e-07 - accuracy: 1.0000 - val_loss: 3.2713e-07 - val_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 2.1536e-07 - accuracy: 1.0000 - val_loss: 2.8231e-07 - val_accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 3.3570e-07 - accuracy: 1.0000 - val_loss: 2.1809e-07 - val_accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 3.2895e-07 - accuracy: 1.0000 - val_loss: 1.6218e-07 - val_accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 3.2051e-07 - accuracy: 1.0000 - val_loss: 1.9822e-07 - val_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 2.5585e-07 - accuracy: 1.0000 - val_loss: 1.7512e-07 - val_accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 2.5697e-07 - accuracy: 1.0000 - val_loss: 1.7003e-07 - val_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 1.4597e-06 - accuracy: 1.0000 - val_loss: 1.9763e-06 - val_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 1.5647e-06 - accuracy: 1.0000 - val_loss: 1.4878e-07 - val_accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.3158e-07 - accuracy: 1.0000 - val_loss: 1.4093e-07 - val_accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.4460e-07 - accuracy: 1.0000 - val_loss: 1.2106e-07 - val_accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 2.3786e-07 - accuracy: 1.0000 - val_loss: 1.2429e-07 - val_accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.8790e-07 - accuracy: 1.0000 - val_loss: 1.5248e-07 - val_accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 1.7544e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 3.0983e-07 - accuracy: 1.0000 - val_loss: 1.2429e-07 - val_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.5520e-07 - accuracy: 1.0000 - val_loss: 1.2614e-07 - val_accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 3.1995e-07 - accuracy: 1.0000 - val_loss: 1.3908e-07 - val_accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.8331e-07 - accuracy: 1.0000 - val_loss: 1.2383e-07 - val_accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 9.1092e-07 - accuracy: 1.0000 - val_loss: 3.5624e-07 - val_accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 2.3729e-07 - accuracy: 1.0000 - val_loss: 2.2040e-07 - val_accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 2.7328e-07 - accuracy: 1.0000 - val_loss: 2.4442e-07 - val_accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 2.1649e-07 - accuracy: 1.0000 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 5.2856e-07 - accuracy: 1.0000 - val_loss: 1.6449e-07 - val_accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 1.3327e-07 - accuracy: 1.0000 - val_loss: 1.4739e-07 - val_accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 2.7384e-07 - accuracy: 1.0000 - val_loss: 1.4601e-07 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.4517e-07 - accuracy: 1.0000 - val_loss: 1.4555e-07 - val_accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 1.9512e-07 - accuracy: 1.0000 - val_loss: 1.2383e-07 - val_accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 3.0758e-07 - accuracy: 1.0000 - val_loss: 1.2429e-07 - val_accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 2.5978e-07 - accuracy: 1.0000 - val_loss: 1.3862e-07 - val_accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.3833e-07 - accuracy: 1.0000 - val_loss: 1.4046e-07 - val_accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 2.8059e-07 - accuracy: 1.0000 - val_loss: 1.0258e-07 - val_accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 1.7038e-07 - accuracy: 1.0000 - val_loss: 8.7328e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.0187e-07 - accuracy: 1.0000 - val_loss: 8.8714e-08 - val_accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 1.9400e-07 - accuracy: 1.0000 - val_loss: 1.0165e-07 - val_accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 3.2051e-07 - accuracy: 1.0000 - val_loss: 1.3538e-07 - val_accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 2.9296e-07 - accuracy: 1.0000 - val_loss: 8.2707e-08 - val_accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 9.3451e-07 - accuracy: 1.0000 - val_loss: 3.8627e-06 - val_accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 4.0768e-06 - accuracy: 1.0000 - val_loss: 2.0376e-07 - val_accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 4.7108e-06 - accuracy: 1.0000 - val_loss: 2.3749e-07 - val_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 4.1217e-07 - accuracy: 1.0000 - val_loss: 1.9683e-07 - val_accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 1.8275e-07 - accuracy: 1.0000 - val_loss: 1.1228e-07 - val_accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 2.0074e-07 - accuracy: 1.0000 - val_loss: 1.5432e-07 - val_accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.5632e-07 - accuracy: 1.0000 - val_loss: 1.2522e-07 - val_accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 1.1696e-07 - accuracy: 1.0000 - val_loss: 1.1644e-07 - val_accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 1.7319e-07 - accuracy: 1.0000 - val_loss: 1.2799e-07 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 4.6502e-07 - accuracy: 1.0000 - val_loss: 1.3261e-07 - val_accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.5126e-07 - accuracy: 1.0000 - val_loss: 1.1459e-07 - val_accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.9737e-07 - accuracy: 1.0000 - val_loss: 1.3815e-07 - val_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 4.3916e-07 - accuracy: 1.0000 - val_loss: 1.0304e-07 - val_accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 4.0092e-07 - accuracy: 1.0000 - val_loss: 1.0997e-07 - val_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 3.6156e-07 - accuracy: 1.0000 - val_loss: 1.1413e-07 - val_accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.6035e-07 - accuracy: 1.0000 - val_loss: 7.9011e-08 - val_accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 2.8621e-07 - accuracy: 1.0000 - val_loss: 8.4093e-08 - val_accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 1.2483e-07 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 1.7600e-07 - accuracy: 1.0000 - val_loss: 6.4225e-08 - val_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 1.2877e-07 - accuracy: 1.0000 - val_loss: 6.6997e-08 - val_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 2.5360e-07 - accuracy: 1.0000 - val_loss: 8.5479e-08 - val_accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 4.5322e-07 - accuracy: 1.0000 - val_loss: 5.8218e-08 - val_accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 1.8612e-07 - accuracy: 1.0000 - val_loss: 4.3895e-08 - val_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 7.1975e-08 - accuracy: 1.0000 - val_loss: 5.7294e-08 - val_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.5295e-07 - accuracy: 1.0000 - val_loss: 6.4687e-08 - val_accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 8.5471e-08 - accuracy: 1.0000 - val_loss: 5.9143e-08 - val_accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 7.4787e-08 - accuracy: 1.0000 - val_loss: 5.2212e-08 - val_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 9.6717e-08 - accuracy: 1.0000 - val_loss: 4.6667e-08 - val_accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.4629e-07 - accuracy: 1.0000 - val_loss: 6.9770e-08 - val_accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 2.6878e-07 - accuracy: 1.0000 - val_loss: 6.4687e-08 - val_accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 8.7720e-08 - accuracy: 1.0000 - val_loss: 8.3169e-08 - val_accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 9.6717e-08 - accuracy: 1.0000 - val_loss: 6.6535e-08 - val_accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 9.5030e-08 - accuracy: 1.0000 - val_loss: 6.8846e-08 - val_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 2.4910e-07 - accuracy: 1.0000 - val_loss: 6.9770e-08 - val_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.5857e-07 - accuracy: 1.0000 - val_loss: 5.8218e-08 - val_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.0628e-07 - accuracy: 1.0000 - val_loss: 5.2212e-08 - val_accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 4.4028e-07 - accuracy: 1.0000 - val_loss: 2.4442e-07 - val_accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 5.2125e-07 - accuracy: 1.0000 - val_loss: 7.9935e-08 - val_accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.2371e-07 - accuracy: 1.0000 - val_loss: 6.9770e-08 - val_accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 9.9528e-08 - accuracy: 1.0000 - val_loss: 7.4852e-08 - val_accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.4058e-07 - accuracy: 1.0000 - val_loss: 4.2971e-08 - val_accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 9.6717e-08 - accuracy: 1.0000 - val_loss: 3.4654e-08 - val_accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 6.5228e-08 - accuracy: 1.0000 - val_loss: 4.9439e-08 - val_accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 5.2674e-08 - val_accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 6.0167e-08 - accuracy: 1.0000 - val_loss: 6.0529e-08 - val_accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 2.2267e-07 - accuracy: 1.0000 - val_loss: 4.2971e-08 - val_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 5.1732e-08 - accuracy: 1.0000 - val_loss: 4.3895e-08 - val_accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.3102e-07 - accuracy: 1.0000 - val_loss: 2.7261e-08 - val_accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 1.6757e-07 - accuracy: 1.0000 - val_loss: 5.0364e-08 - val_accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 7.7765e-07 - accuracy: 1.0000 - val_loss: 1.7373e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 3.3625e-07 - accuracy: 1.0000 - val_loss: 1.0396e-07 - val_accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 1.0740e-07 - accuracy: 1.0000 - val_loss: 4.2047e-08 - val_accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 2.2155e-07 - accuracy: 1.0000 - val_loss: 1.2152e-07 - val_accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 5.5667e-07 - accuracy: 1.0000 - val_loss: 3.9274e-08 - val_accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 4.8921e-08 - accuracy: 1.0000 - val_loss: 4.7591e-08 - val_accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 6.6352e-08 - accuracy: 1.0000 - val_loss: 4.8515e-08 - val_accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 8.3784e-08 - accuracy: 1.0000 - val_loss: 4.0661e-08 - val_accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 5.5555e-07 - accuracy: 1.0000 - val_loss: 2.7676e-07 - val_accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.9737e-07 - accuracy: 1.0000 - val_loss: 3.3268e-08 - val_accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 4.4422e-08 - accuracy: 1.0000 - val_loss: 4.1585e-08 - val_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 9.2781e-08 - accuracy: 1.0000 - val_loss: 3.9736e-08 - val_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 2.4179e-07 - accuracy: 1.0000 - val_loss: 3.2344e-08 - val_accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.3102e-07 - accuracy: 1.0000 - val_loss: 3.8350e-08 - val_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 5.2295e-08 - accuracy: 1.0000 - val_loss: 3.6040e-08 - val_accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 9.3343e-08 - accuracy: 1.0000 - val_loss: 3.4192e-08 - val_accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 4.0486e-08 - accuracy: 1.0000 - val_loss: 3.3268e-08 - val_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 3.7112e-08 - accuracy: 1.0000 - val_loss: 2.6799e-08 - val_accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.7263e-07 - accuracy: 1.0000 - val_loss: 4.1585e-08 - val_accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 6.8039e-08 - accuracy: 1.0000 - val_loss: 3.6502e-08 - val_accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 5.2857e-08 - accuracy: 1.0000 - val_loss: 2.1716e-08 - val_accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 1.0684e-07 - accuracy: 1.0000 - val_loss: 2.9109e-08 - val_accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 2.3617e-08 - accuracy: 1.0000 - val_loss: 2.0330e-08 - val_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 3.9924e-08 - accuracy: 1.0000 - val_loss: 2.7261e-08 - val_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 6.0729e-08 - accuracy: 1.0000 - val_loss: 2.3565e-08 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 4.3298e-08 - accuracy: 1.0000 - val_loss: 2.4027e-08 - val_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 9.2218e-08 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 9.3905e-08 - accuracy: 1.0000 - val_loss: 2.4951e-08 - val_accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.4508e-07 - accuracy: 1.0000 - val_loss: 4.4357e-08 - val_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 6.2978e-08 - accuracy: 1.0000 - val_loss: 5.5908e-08 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 3.0140e-07 - accuracy: 1.0000 - val_loss: 4.2971e-08 - val_accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 7.4225e-08 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.1640e-07 - accuracy: 1.0000 - val_loss: 1.8020e-08 - val_accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.7553e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 4.2735e-08 - accuracy: 1.0000 - val_loss: 1.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 7.5349e-08 - accuracy: 1.0000 - val_loss: 2.2178e-08 - val_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 4.2735e-08 - accuracy: 1.0000 - val_loss: 2.4489e-08 - val_accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 6.0729e-08 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 5.2857e-08 - accuracy: 1.0000 - val_loss: 2.3103e-08 - val_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 2.1649e-07 - accuracy: 1.0000 - val_loss: 8.4093e-08 - val_accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 5.3642e-07 - accuracy: 1.0000 - val_loss: 6.0529e-08 - val_accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 4.0486e-08 - accuracy: 1.0000 - val_loss: 6.2377e-08 - val_accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.8115e-08 - accuracy: 1.0000 - val_loss: 5.0364e-08 - val_accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 4.1611e-08 - accuracy: 1.0000 - val_loss: 2.5413e-08 - val_accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1.9343e-07 - accuracy: 1.0000 - val_loss: 2.8647e-08 - val_accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 3.0927e-08 - accuracy: 1.0000 - val_loss: 2.3103e-08 - val_accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 4.9483e-08 - accuracy: 1.0000 - val_loss: 1.9868e-08 - val_accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 5.4544e-08 - accuracy: 1.0000 - val_loss: 1.7096e-08 - val_accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 4.4422e-08 - accuracy: 1.0000 - val_loss: 1.6634e-08 - val_accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 2.6428e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 2.1368e-08 - accuracy: 1.0000 - val_loss: 1.7096e-08 - val_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 3.5425e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 3.7112e-08 - accuracy: 1.0000 - val_loss: 1.4324e-08 - val_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 7.9285e-08 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.1077e-07 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 1.6869e-08 - accuracy: 1.0000 - val_loss: 1.8020e-08 - val_accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 2.4179e-08 - accuracy: 1.0000 - val_loss: 1.8944e-08 - val_accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 7.4225e-08 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 2.8678e-07 - accuracy: 1.0000 - val_loss: 1.4601e-07 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 2.1030e-07 - accuracy: 1.0000 - val_loss: 2.0330e-08 - val_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 7.0288e-08 - accuracy: 1.0000 - val_loss: 1.2013e-08 - val_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 2.5304e-08 - accuracy: 1.0000 - val_loss: 1.3862e-08 - val_accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.1808e-08 - accuracy: 1.0000 - val_loss: 1.3862e-08 - val_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 3.3738e-08 - accuracy: 1.0000 - val_loss: 1.6172e-08 - val_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 3.4132e-07 - accuracy: 1.0000 - val_loss: 1.8297e-07 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 8.0972e-08 - accuracy: 1.0000 - val_loss: 6.8846e-08 - val_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 8.8844e-08 - accuracy: 1.0000 - val_loss: 3.1419e-08 - val_accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 2.3055e-08 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 2.5866e-08 - accuracy: 1.0000 - val_loss: 2.2178e-08 - val_accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.0852e-07 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 3.2614e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 1.9118e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.7432e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 7.4225e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.7994e-08 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 3.7112e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 9.1656e-08 - accuracy: 1.0000 - val_loss: 1.4324e-08 - val_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 2.1930e-08 - accuracy: 1.0000 - val_loss: 1.2013e-08 - val_accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 2.8678e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 2.0805e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 3.4301e-08 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 2.0243e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 5.3982e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 9.0531e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 2.0243e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.5182e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 6.2978e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 2.4742e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 3.1489e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 2.6991e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 2.3617e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.6307e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 2.0805e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 7.0288e-08 - accuracy: 1.0000 - val_loss: 1.3399e-08 - val_accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 1.4324e-08 - val_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 4.7796e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.0243e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 8.9969e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 8.9969e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 7.5349e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.8275e-07 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 3.7112e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.9118e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 4.8358e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 5.0608e-09 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 1.5745e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 1.6869e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.1808e-07 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.2257e-06 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 3.6550e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 2.5304e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.8678e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 6.0167e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.8725e-07 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 3.3738e-08 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.7432e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 4.3298e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 1.6307e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.0823e-06 - accuracy: 1.0000 - val_loss: 3.0079e-07 - val_accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 5.6961e-07 - accuracy: 1.0000 - val_loss: 2.9571e-08 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 5.7918e-08 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 3.7675e-08 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 9.2218e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 5.6231e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 9.3342e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.6869e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 8.1534e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 6.4665e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 2.4179e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 1.5745e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 2.0243e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 2.4179e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 8.9969e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.5182e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 5.6231e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 3.9362e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 5.6231e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.9681e-08 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 1.6869e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 1.7432e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 5.6231e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 5.6231e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 6.9164e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 6.8039e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 5.3419e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.9681e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.5182e-08 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 3.9362e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 1.3862e-09 - val_accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 3.0927e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 9.2410e-10 - val_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.9118e-08 - accuracy: 1.0000 - val_loss: 1.3862e-09 - val_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.6869e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 9.2410e-10 - val_accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Model training finished.\n",
      "Train loss: 0.0, train accuracy: 1.0.\n",
      "Evaluating model performance...\n",
      "Test loss: 0.0, test accuracy: 1.0.\n"
     ]
    }
   ],
   "source": [
    "run_experiment(nn_model_full, tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               train_dataset, val_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:54:46.280138Z",
     "start_time": "2021-07-09T12:54:45.143512Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jymch\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "bnn_model_full = create_bnn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:02:59.880950Z",
     "start_time": "2021-07-09T12:54:46.285306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 11s 11s/step - loss: 38.5774 - accuracy: 0.4858 - val_loss: 38.6233 - val_accuracy: 0.4612\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 38.5265 - accuracy: 0.4764 - val_loss: 38.5975 - val_accuracy: 0.4612\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 38.4790 - accuracy: 0.6179 - val_loss: 38.4954 - val_accuracy: 0.5000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 38.4491 - accuracy: 0.6604 - val_loss: 38.4479 - val_accuracy: 0.5310\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 38.4257 - accuracy: 0.6462 - val_loss: 38.4814 - val_accuracy: 0.4806\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 38.3898 - accuracy: 0.5802 - val_loss: 38.3981 - val_accuracy: 0.5194\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 38.3721 - accuracy: 0.6934 - val_loss: 38.3844 - val_accuracy: 0.4961\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 38.3580 - accuracy: 0.6792 - val_loss: 38.3442 - val_accuracy: 0.5078\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 38.3361 - accuracy: 0.6085 - val_loss: 38.3263 - val_accuracy: 0.4922\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 38.2873 - accuracy: 0.6132 - val_loss: 38.3240 - val_accuracy: 0.5194\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 38.2904 - accuracy: 0.6981 - val_loss: 38.2840 - val_accuracy: 0.5775\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 38.2826 - accuracy: 0.5519 - val_loss: 38.2835 - val_accuracy: 0.5271\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 38.2611 - accuracy: 0.5283 - val_loss: 38.2602 - val_accuracy: 0.5310\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 38.2249 - accuracy: 0.5896 - val_loss: 38.2614 - val_accuracy: 0.4961\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 38.1926 - accuracy: 0.7406 - val_loss: 38.2664 - val_accuracy: 0.5543\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 38.1897 - accuracy: 0.7783 - val_loss: 38.2041 - val_accuracy: 0.4922\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 38.1665 - accuracy: 0.7547 - val_loss: 38.1833 - val_accuracy: 0.5155\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 38.1635 - accuracy: 0.6132 - val_loss: 38.1988 - val_accuracy: 0.4729\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 38.1297 - accuracy: 0.5566 - val_loss: 38.1616 - val_accuracy: 0.5194\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 38.0985 - accuracy: 0.8585 - val_loss: 38.1390 - val_accuracy: 0.5465\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 38.0890 - accuracy: 0.7830 - val_loss: 38.1159 - val_accuracy: 0.5116\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 38.0853 - accuracy: 0.7264 - val_loss: 38.0836 - val_accuracy: 0.6240\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 38.0525 - accuracy: 0.5613 - val_loss: 38.0970 - val_accuracy: 0.5736\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 38.0296 - accuracy: 0.7972 - val_loss: 38.0752 - val_accuracy: 0.5194\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 37.9937 - accuracy: 0.8019 - val_loss: 38.0342 - val_accuracy: 0.6395\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 37.9890 - accuracy: 0.7877 - val_loss: 38.0363 - val_accuracy: 0.5736\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 37.9704 - accuracy: 0.7783 - val_loss: 38.0044 - val_accuracy: 0.6047\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 37.8808 - accuracy: 0.8443 - val_loss: 37.9876 - val_accuracy: 0.6395\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 37.9433 - accuracy: 0.7830 - val_loss: 37.9342 - val_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 37.8841 - accuracy: 0.8491 - val_loss: 37.9443 - val_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 37.8559 - accuracy: 0.8349 - val_loss: 37.9506 - val_accuracy: 0.5775\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 37.8389 - accuracy: 0.8491 - val_loss: 37.9027 - val_accuracy: 0.6550\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 37.8109 - accuracy: 0.8443 - val_loss: 37.8896 - val_accuracy: 0.7093\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 37.7641 - accuracy: 0.8255 - val_loss: 37.8901 - val_accuracy: 0.5659\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 37.8030 - accuracy: 0.8396 - val_loss: 37.8553 - val_accuracy: 0.6783\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 37.7519 - accuracy: 0.8019 - val_loss: 37.8420 - val_accuracy: 0.6085\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 37.7087 - accuracy: 0.8443 - val_loss: 37.7884 - val_accuracy: 0.7752\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 37.6778 - accuracy: 0.8585 - val_loss: 37.7771 - val_accuracy: 0.7016\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 37.6521 - accuracy: 0.8821 - val_loss: 37.7660 - val_accuracy: 0.6977\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 37.6135 - accuracy: 0.8726 - val_loss: 37.7418 - val_accuracy: 0.7248\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 37.6158 - accuracy: 0.8491 - val_loss: 37.7276 - val_accuracy: 0.6899\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 37.6125 - accuracy: 0.8349 - val_loss: 37.7343 - val_accuracy: 0.6860\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 37.5816 - accuracy: 0.8349 - val_loss: 37.6850 - val_accuracy: 0.7016\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 37.5415 - accuracy: 0.8632 - val_loss: 37.6370 - val_accuracy: 0.7791\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 37.5083 - accuracy: 0.8443 - val_loss: 37.6517 - val_accuracy: 0.7209\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 37.5138 - accuracy: 0.8160 - val_loss: 37.6116 - val_accuracy: 0.7481\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 37.4922 - accuracy: 0.8491 - val_loss: 37.6101 - val_accuracy: 0.7248\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 37.4862 - accuracy: 0.8443 - val_loss: 37.5956 - val_accuracy: 0.7326\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 37.4345 - accuracy: 0.8491 - val_loss: 37.6022 - val_accuracy: 0.7674\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 37.4290 - accuracy: 0.8538 - val_loss: 37.5379 - val_accuracy: 0.7791\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 37.3964 - accuracy: 0.8443 - val_loss: 37.6000 - val_accuracy: 0.6318\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 37.3812 - accuracy: 0.8255 - val_loss: 37.5897 - val_accuracy: 0.6395\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 37.3740 - accuracy: 0.8396 - val_loss: 37.4947 - val_accuracy: 0.7752\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 37.3473 - accuracy: 0.8255 - val_loss: 37.4813 - val_accuracy: 0.7674\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 37.3080 - accuracy: 0.8585 - val_loss: 37.4318 - val_accuracy: 0.7907\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 37.3195 - accuracy: 0.8255 - val_loss: 37.5077 - val_accuracy: 0.6977\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 37.2829 - accuracy: 0.8538 - val_loss: 37.3598 - val_accuracy: 0.8023\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 37.2598 - accuracy: 0.8396 - val_loss: 37.4099 - val_accuracy: 0.7287\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 37.2924 - accuracy: 0.8443 - val_loss: 37.4196 - val_accuracy: 0.7287\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 37.2373 - accuracy: 0.8443 - val_loss: 37.3718 - val_accuracy: 0.7481\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 37.2117 - accuracy: 0.8632 - val_loss: 37.2889 - val_accuracy: 0.8256\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 37.2319 - accuracy: 0.8208 - val_loss: 37.2659 - val_accuracy: 0.8178\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 37.1806 - accuracy: 0.8491 - val_loss: 37.3405 - val_accuracy: 0.7481\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 37.1440 - accuracy: 0.8491 - val_loss: 37.2888 - val_accuracy: 0.7674\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 37.0890 - accuracy: 0.8915 - val_loss: 37.1835 - val_accuracy: 0.8411\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 37.1086 - accuracy: 0.8585 - val_loss: 37.2062 - val_accuracy: 0.8101\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 37.1295 - accuracy: 0.8491 - val_loss: 37.2296 - val_accuracy: 0.7829\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 37.0897 - accuracy: 0.8585 - val_loss: 37.2109 - val_accuracy: 0.7829\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 37.0540 - accuracy: 0.8679 - val_loss: 37.2086 - val_accuracy: 0.7636\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 37.0783 - accuracy: 0.8538 - val_loss: 37.1209 - val_accuracy: 0.8295\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 37.0202 - accuracy: 0.8585 - val_loss: 37.1161 - val_accuracy: 0.8023\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 37.0361 - accuracy: 0.8538 - val_loss: 37.1683 - val_accuracy: 0.7519\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 36.9960 - accuracy: 0.8821 - val_loss: 37.1582 - val_accuracy: 0.7558\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 36.9841 - accuracy: 0.8821 - val_loss: 37.1033 - val_accuracy: 0.7946\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 36.9837 - accuracy: 0.8679 - val_loss: 37.0672 - val_accuracy: 0.8256\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 36.9332 - accuracy: 0.8868 - val_loss: 37.0401 - val_accuracy: 0.8217\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 36.9511 - accuracy: 0.8679 - val_loss: 36.9928 - val_accuracy: 0.8178\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 36.9445 - accuracy: 0.8726 - val_loss: 36.9420 - val_accuracy: 0.8605\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 36.9693 - accuracy: 0.8443 - val_loss: 36.9697 - val_accuracy: 0.8605\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 36.8762 - accuracy: 0.8821 - val_loss: 36.9547 - val_accuracy: 0.8372\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 36.8894 - accuracy: 0.8632 - val_loss: 36.9699 - val_accuracy: 0.8023\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 36.8684 - accuracy: 0.8679 - val_loss: 36.9312 - val_accuracy: 0.8256\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 36.8721 - accuracy: 0.8726 - val_loss: 36.8957 - val_accuracy: 0.8295\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 36.8023 - accuracy: 0.9151 - val_loss: 36.9287 - val_accuracy: 0.8217\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 36.8231 - accuracy: 0.8821 - val_loss: 36.8906 - val_accuracy: 0.8178\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 36.8164 - accuracy: 0.8632 - val_loss: 36.8830 - val_accuracy: 0.8178\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 36.7613 - accuracy: 0.8868 - val_loss: 36.9521 - val_accuracy: 0.7674\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 36.7935 - accuracy: 0.8679 - val_loss: 36.8704 - val_accuracy: 0.8217\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 36.8130 - accuracy: 0.8585 - val_loss: 36.8422 - val_accuracy: 0.8178\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 36.7233 - accuracy: 0.8821 - val_loss: 36.8378 - val_accuracy: 0.8217\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 36.7321 - accuracy: 0.8585 - val_loss: 36.8192 - val_accuracy: 0.8023\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 36.6856 - accuracy: 0.8915 - val_loss: 36.7743 - val_accuracy: 0.8488\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 36.6965 - accuracy: 0.8679 - val_loss: 36.7255 - val_accuracy: 0.8566\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 36.6418 - accuracy: 0.8915 - val_loss: 36.7268 - val_accuracy: 0.8488\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 36.6834 - accuracy: 0.8585 - val_loss: 36.7948 - val_accuracy: 0.7907\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 36.6437 - accuracy: 0.8915 - val_loss: 36.8044 - val_accuracy: 0.7752\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 36.6035 - accuracy: 0.9057 - val_loss: 36.7530 - val_accuracy: 0.7791\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 36.6469 - accuracy: 0.8491 - val_loss: 36.6837 - val_accuracy: 0.8333\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 36.5765 - accuracy: 0.9057 - val_loss: 36.6997 - val_accuracy: 0.8372\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 36.6263 - accuracy: 0.8443 - val_loss: 36.6475 - val_accuracy: 0.8605\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 36.5928 - accuracy: 0.8774 - val_loss: 36.6546 - val_accuracy: 0.8295\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 36.5891 - accuracy: 0.8632 - val_loss: 36.6715 - val_accuracy: 0.8140\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 36.5320 - accuracy: 0.8915 - val_loss: 36.6106 - val_accuracy: 0.8295\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 36.5134 - accuracy: 0.9009 - val_loss: 36.6787 - val_accuracy: 0.7791\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 36.5020 - accuracy: 0.8868 - val_loss: 36.6845 - val_accuracy: 0.7907\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 36.5018 - accuracy: 0.8962 - val_loss: 36.7385 - val_accuracy: 0.7209\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 36.5174 - accuracy: 0.8679 - val_loss: 36.5201 - val_accuracy: 0.8566\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 36.4438 - accuracy: 0.8962 - val_loss: 36.5855 - val_accuracy: 0.8062\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 36.4423 - accuracy: 0.8962 - val_loss: 36.5426 - val_accuracy: 0.7984\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 36.4361 - accuracy: 0.8915 - val_loss: 36.5131 - val_accuracy: 0.8372\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 36.4125 - accuracy: 0.8962 - val_loss: 36.5273 - val_accuracy: 0.8023\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 36.3735 - accuracy: 0.9151 - val_loss: 36.5010 - val_accuracy: 0.8333\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 454ms/step - loss: 36.4142 - accuracy: 0.8821 - val_loss: 36.4635 - val_accuracy: 0.8450\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 36.3437 - accuracy: 0.8962 - val_loss: 36.4217 - val_accuracy: 0.8682\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 36.3881 - accuracy: 0.8915 - val_loss: 36.4392 - val_accuracy: 0.8295\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 36.3962 - accuracy: 0.8632 - val_loss: 36.4636 - val_accuracy: 0.8178\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 36.3263 - accuracy: 0.8868 - val_loss: 36.3908 - val_accuracy: 0.8333\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 36.3370 - accuracy: 0.8632 - val_loss: 36.3756 - val_accuracy: 0.8411\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 36.3388 - accuracy: 0.8868 - val_loss: 36.4820 - val_accuracy: 0.7791\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 36.2919 - accuracy: 0.8915 - val_loss: 36.3827 - val_accuracy: 0.8372\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 36.2475 - accuracy: 0.9104 - val_loss: 36.3506 - val_accuracy: 0.8450\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 36.2060 - accuracy: 0.9009 - val_loss: 36.3432 - val_accuracy: 0.8411\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 36.2740 - accuracy: 0.8726 - val_loss: 36.3144 - val_accuracy: 0.8372\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 36.2079 - accuracy: 0.9104 - val_loss: 36.2699 - val_accuracy: 0.8450\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 36.2030 - accuracy: 0.8868 - val_loss: 36.2685 - val_accuracy: 0.8411\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 36.1730 - accuracy: 0.8915 - val_loss: 36.2537 - val_accuracy: 0.8450\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 36.1624 - accuracy: 0.9151 - val_loss: 36.3445 - val_accuracy: 0.7984\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 36.1563 - accuracy: 0.8868 - val_loss: 36.2128 - val_accuracy: 0.8527\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 36.1463 - accuracy: 0.8868 - val_loss: 36.2539 - val_accuracy: 0.8411\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 36.1321 - accuracy: 0.8915 - val_loss: 36.2076 - val_accuracy: 0.8372\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 36.0977 - accuracy: 0.9198 - val_loss: 36.1674 - val_accuracy: 0.8527\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 36.1011 - accuracy: 0.8774 - val_loss: 36.1844 - val_accuracy: 0.8411\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 36.0979 - accuracy: 0.8821 - val_loss: 36.1045 - val_accuracy: 0.8721\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 36.1000 - accuracy: 0.8774 - val_loss: 36.1032 - val_accuracy: 0.8798\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 36.0454 - accuracy: 0.8915 - val_loss: 36.0766 - val_accuracy: 0.8953\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 36.0326 - accuracy: 0.9057 - val_loss: 36.0855 - val_accuracy: 0.8605\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 35.9996 - accuracy: 0.9198 - val_loss: 36.0244 - val_accuracy: 0.8837\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 36.0178 - accuracy: 0.8868 - val_loss: 36.0194 - val_accuracy: 0.8721\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 36.0113 - accuracy: 0.8868 - val_loss: 36.0059 - val_accuracy: 0.8760\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 35.9890 - accuracy: 0.8774 - val_loss: 36.0032 - val_accuracy: 0.8876\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 35.9723 - accuracy: 0.8915 - val_loss: 35.9624 - val_accuracy: 0.9031\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 35.9494 - accuracy: 0.9009 - val_loss: 35.9600 - val_accuracy: 0.8682\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 35.8845 - accuracy: 0.9245 - val_loss: 35.9715 - val_accuracy: 0.8682\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 35.8965 - accuracy: 0.9151 - val_loss: 35.9321 - val_accuracy: 0.8798\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 35.9060 - accuracy: 0.9009 - val_loss: 35.9560 - val_accuracy: 0.8682\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 35.9105 - accuracy: 0.8821 - val_loss: 35.9821 - val_accuracy: 0.8411\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 35.8216 - accuracy: 0.9387 - val_loss: 35.9138 - val_accuracy: 0.8837\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 35.8485 - accuracy: 0.9009 - val_loss: 35.9202 - val_accuracy: 0.8411\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 35.8349 - accuracy: 0.8915 - val_loss: 35.9146 - val_accuracy: 0.8450\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 35.8077 - accuracy: 0.9057 - val_loss: 35.8523 - val_accuracy: 0.8760\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 35.8505 - accuracy: 0.8726 - val_loss: 35.9003 - val_accuracy: 0.8721\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 35.7945 - accuracy: 0.9057 - val_loss: 35.8437 - val_accuracy: 0.8605\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 35.8047 - accuracy: 0.8962 - val_loss: 35.8292 - val_accuracy: 0.8798\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 35.7582 - accuracy: 0.9057 - val_loss: 35.8178 - val_accuracy: 0.8682\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 35.7523 - accuracy: 0.9009 - val_loss: 35.8146 - val_accuracy: 0.8450\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 35.7803 - accuracy: 0.8915 - val_loss: 35.8103 - val_accuracy: 0.8372\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 35.7099 - accuracy: 0.9292 - val_loss: 35.7814 - val_accuracy: 0.8760\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 35.7333 - accuracy: 0.8962 - val_loss: 35.7902 - val_accuracy: 0.8527\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 35.7284 - accuracy: 0.8915 - val_loss: 35.7962 - val_accuracy: 0.8411\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 35.6750 - accuracy: 0.9057 - val_loss: 35.7369 - val_accuracy: 0.8837\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 35.6826 - accuracy: 0.8868 - val_loss: 35.7255 - val_accuracy: 0.8643\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 35.6517 - accuracy: 0.9151 - val_loss: 35.6870 - val_accuracy: 0.8488\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 35.6290 - accuracy: 0.9057 - val_loss: 35.6563 - val_accuracy: 0.8915\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 35.6227 - accuracy: 0.9057 - val_loss: 35.6292 - val_accuracy: 0.8876\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 35.6246 - accuracy: 0.8915 - val_loss: 35.6591 - val_accuracy: 0.8605\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 35.5434 - accuracy: 0.9340 - val_loss: 35.5716 - val_accuracy: 0.9225\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 35.5646 - accuracy: 0.8915 - val_loss: 35.5990 - val_accuracy: 0.8915\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 35.5649 - accuracy: 0.9009 - val_loss: 35.5948 - val_accuracy: 0.8605\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 35.5220 - accuracy: 0.9292 - val_loss: 35.5644 - val_accuracy: 0.8953\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 35.5174 - accuracy: 0.9198 - val_loss: 35.5289 - val_accuracy: 0.8953\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 35.5223 - accuracy: 0.9104 - val_loss: 35.5445 - val_accuracy: 0.8915\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 35.4957 - accuracy: 0.9151 - val_loss: 35.5243 - val_accuracy: 0.8682\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 35.4806 - accuracy: 0.9151 - val_loss: 35.4959 - val_accuracy: 0.8798\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 35.5067 - accuracy: 0.8821 - val_loss: 35.4979 - val_accuracy: 0.8953\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 35.4705 - accuracy: 0.8962 - val_loss: 35.4549 - val_accuracy: 0.8992\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 35.4326 - accuracy: 0.9151 - val_loss: 35.4834 - val_accuracy: 0.8837\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 35.4264 - accuracy: 0.9057 - val_loss: 35.4540 - val_accuracy: 0.8837\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 35.4097 - accuracy: 0.9198 - val_loss: 35.4580 - val_accuracy: 0.8876\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 35.3894 - accuracy: 0.9057 - val_loss: 35.3809 - val_accuracy: 0.9109\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 35.3606 - accuracy: 0.9057 - val_loss: 35.4130 - val_accuracy: 0.8837\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 35.4099 - accuracy: 0.8915 - val_loss: 35.3997 - val_accuracy: 0.8798\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 35.3763 - accuracy: 0.9009 - val_loss: 35.3734 - val_accuracy: 0.8915\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 35.3678 - accuracy: 0.8821 - val_loss: 35.3334 - val_accuracy: 0.8992\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 35.3400 - accuracy: 0.9057 - val_loss: 35.3756 - val_accuracy: 0.8566\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 35.3136 - accuracy: 0.9151 - val_loss: 35.3430 - val_accuracy: 0.8837\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 35.3261 - accuracy: 0.8868 - val_loss: 35.3103 - val_accuracy: 0.9031\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 35.2406 - accuracy: 0.9387 - val_loss: 35.3070 - val_accuracy: 0.8876\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 35.2445 - accuracy: 0.9245 - val_loss: 35.2858 - val_accuracy: 0.8760\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 35.2238 - accuracy: 0.9340 - val_loss: 35.2553 - val_accuracy: 0.9070\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 35.1948 - accuracy: 0.9387 - val_loss: 35.2564 - val_accuracy: 0.9031\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 35.2206 - accuracy: 0.9245 - val_loss: 35.2053 - val_accuracy: 0.8992\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 35.1832 - accuracy: 0.9009 - val_loss: 35.1923 - val_accuracy: 0.8915\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 35.1549 - accuracy: 0.9340 - val_loss: 35.1657 - val_accuracy: 0.9070\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 35.1988 - accuracy: 0.8915 - val_loss: 35.1834 - val_accuracy: 0.9109\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 35.1771 - accuracy: 0.9057 - val_loss: 35.1651 - val_accuracy: 0.9109\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 35.1451 - accuracy: 0.9245 - val_loss: 35.1697 - val_accuracy: 0.8837\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 35.1478 - accuracy: 0.9151 - val_loss: 35.1452 - val_accuracy: 0.9070\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 35.1171 - accuracy: 0.9009 - val_loss: 35.1365 - val_accuracy: 0.9070\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 35.0625 - accuracy: 0.9198 - val_loss: 35.1084 - val_accuracy: 0.9031\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 35.0957 - accuracy: 0.8962 - val_loss: 35.1027 - val_accuracy: 0.8837\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 35.0597 - accuracy: 0.9292 - val_loss: 35.0718 - val_accuracy: 0.9070\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 35.0470 - accuracy: 0.9151 - val_loss: 35.0675 - val_accuracy: 0.8915\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 35.0342 - accuracy: 0.9292 - val_loss: 35.0543 - val_accuracy: 0.8915\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 35.0181 - accuracy: 0.9057 - val_loss: 35.0136 - val_accuracy: 0.9186\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 35.0295 - accuracy: 0.9104 - val_loss: 35.0131 - val_accuracy: 0.8915\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 35.0210 - accuracy: 0.9057 - val_loss: 34.9933 - val_accuracy: 0.9147\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 34.9862 - accuracy: 0.9198 - val_loss: 34.9804 - val_accuracy: 0.9031\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 34.9581 - accuracy: 0.9104 - val_loss: 34.9765 - val_accuracy: 0.8992\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 34.9443 - accuracy: 0.9151 - val_loss: 34.9823 - val_accuracy: 0.9031\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 35.0006 - accuracy: 0.9009 - val_loss: 34.9490 - val_accuracy: 0.9147\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 34.9487 - accuracy: 0.8821 - val_loss: 34.9278 - val_accuracy: 0.8915\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 34.8993 - accuracy: 0.9151 - val_loss: 34.8999 - val_accuracy: 0.9186\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 34.8938 - accuracy: 0.9340 - val_loss: 34.8889 - val_accuracy: 0.9186\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 34.8136 - accuracy: 0.9528 - val_loss: 34.8666 - val_accuracy: 0.9031\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 34.8561 - accuracy: 0.8962 - val_loss: 34.8548 - val_accuracy: 0.9109\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 34.8145 - accuracy: 0.9340 - val_loss: 34.8946 - val_accuracy: 0.8682\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 34.7845 - accuracy: 0.9481 - val_loss: 34.8562 - val_accuracy: 0.8953\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 34.8258 - accuracy: 0.9198 - val_loss: 34.8137 - val_accuracy: 0.9147\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 34.7770 - accuracy: 0.9292 - val_loss: 34.8143 - val_accuracy: 0.8992\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 34.7774 - accuracy: 0.9104 - val_loss: 34.8313 - val_accuracy: 0.8992\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 34.7647 - accuracy: 0.9292 - val_loss: 34.7870 - val_accuracy: 0.9186\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 34.7484 - accuracy: 0.9245 - val_loss: 34.7398 - val_accuracy: 0.9147\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 34.7381 - accuracy: 0.9151 - val_loss: 34.7665 - val_accuracy: 0.8953\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 34.7107 - accuracy: 0.9340 - val_loss: 34.7376 - val_accuracy: 0.8953\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 408ms/step - loss: 34.7813 - accuracy: 0.8774 - val_loss: 34.6973 - val_accuracy: 0.9264\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 34.6779 - accuracy: 0.9198 - val_loss: 34.7030 - val_accuracy: 0.8876\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 34.6660 - accuracy: 0.9057 - val_loss: 34.6700 - val_accuracy: 0.9031\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 34.6425 - accuracy: 0.9292 - val_loss: 34.6412 - val_accuracy: 0.9264\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 34.6431 - accuracy: 0.9198 - val_loss: 34.6539 - val_accuracy: 0.9147\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 34.6551 - accuracy: 0.9104 - val_loss: 34.6374 - val_accuracy: 0.9070\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 34.6047 - accuracy: 0.9340 - val_loss: 34.6472 - val_accuracy: 0.9031\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 34.6007 - accuracy: 0.9151 - val_loss: 34.6160 - val_accuracy: 0.9109\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 34.5862 - accuracy: 0.9292 - val_loss: 34.5977 - val_accuracy: 0.9147\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 34.6286 - accuracy: 0.8868 - val_loss: 34.5918 - val_accuracy: 0.9070\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 34.6025 - accuracy: 0.8962 - val_loss: 34.5507 - val_accuracy: 0.9225\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 34.5362 - accuracy: 0.9245 - val_loss: 34.5696 - val_accuracy: 0.8992\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 34.5062 - accuracy: 0.9292 - val_loss: 34.5395 - val_accuracy: 0.9186\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 34.4726 - accuracy: 0.9387 - val_loss: 34.5079 - val_accuracy: 0.9302\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 34.4685 - accuracy: 0.9292 - val_loss: 34.4870 - val_accuracy: 0.9302\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 34.4889 - accuracy: 0.9292 - val_loss: 34.5183 - val_accuracy: 0.8915\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 34.4789 - accuracy: 0.9151 - val_loss: 34.4900 - val_accuracy: 0.9070\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 34.4634 - accuracy: 0.9245 - val_loss: 34.4352 - val_accuracy: 0.9264\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 34.4653 - accuracy: 0.8915 - val_loss: 34.4392 - val_accuracy: 0.9186\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 34.4821 - accuracy: 0.9009 - val_loss: 34.4268 - val_accuracy: 0.9109\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 34.4021 - accuracy: 0.9245 - val_loss: 34.4118 - val_accuracy: 0.9109\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 34.3885 - accuracy: 0.9198 - val_loss: 34.4203 - val_accuracy: 0.9031\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 34.4101 - accuracy: 0.8962 - val_loss: 34.3710 - val_accuracy: 0.9109\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 34.3783 - accuracy: 0.9151 - val_loss: 34.4066 - val_accuracy: 0.8915\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 34.4013 - accuracy: 0.9009 - val_loss: 34.3643 - val_accuracy: 0.9070\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 34.3436 - accuracy: 0.9104 - val_loss: 34.3277 - val_accuracy: 0.9070\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 34.3037 - accuracy: 0.9245 - val_loss: 34.3436 - val_accuracy: 0.9225\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 34.2899 - accuracy: 0.9387 - val_loss: 34.3152 - val_accuracy: 0.9147\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 34.2824 - accuracy: 0.9340 - val_loss: 34.3015 - val_accuracy: 0.9031\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 34.2662 - accuracy: 0.9245 - val_loss: 34.2759 - val_accuracy: 0.9225\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 34.2756 - accuracy: 0.9151 - val_loss: 34.2898 - val_accuracy: 0.9225\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 34.2553 - accuracy: 0.9198 - val_loss: 34.2573 - val_accuracy: 0.9225\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 34.2020 - accuracy: 0.9340 - val_loss: 34.2581 - val_accuracy: 0.9109\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 34.2055 - accuracy: 0.9387 - val_loss: 34.2110 - val_accuracy: 0.9264\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 34.1995 - accuracy: 0.9292 - val_loss: 34.2001 - val_accuracy: 0.9225\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 34.1986 - accuracy: 0.9245 - val_loss: 34.1894 - val_accuracy: 0.9264\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 34.2185 - accuracy: 0.9151 - val_loss: 34.2289 - val_accuracy: 0.8992\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 34.1657 - accuracy: 0.9245 - val_loss: 34.1712 - val_accuracy: 0.8992\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 34.1149 - accuracy: 0.9387 - val_loss: 34.1510 - val_accuracy: 0.9147\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 34.1237 - accuracy: 0.9245 - val_loss: 34.1313 - val_accuracy: 0.9225\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 34.1443 - accuracy: 0.9104 - val_loss: 34.1313 - val_accuracy: 0.9186\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 34.1343 - accuracy: 0.9151 - val_loss: 34.0983 - val_accuracy: 0.9225\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 34.1155 - accuracy: 0.9104 - val_loss: 34.0676 - val_accuracy: 0.9380\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 34.0938 - accuracy: 0.9292 - val_loss: 34.0499 - val_accuracy: 0.9380\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 34.0796 - accuracy: 0.9104 - val_loss: 34.0537 - val_accuracy: 0.9109\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 34.0732 - accuracy: 0.9057 - val_loss: 34.0557 - val_accuracy: 0.9186\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 34.0174 - accuracy: 0.9292 - val_loss: 34.0540 - val_accuracy: 0.9031\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 34.0177 - accuracy: 0.9198 - val_loss: 34.0284 - val_accuracy: 0.9186\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 34.0304 - accuracy: 0.9292 - val_loss: 33.9830 - val_accuracy: 0.9341\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 33.9744 - accuracy: 0.9340 - val_loss: 34.0034 - val_accuracy: 0.9186\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 33.9697 - accuracy: 0.9340 - val_loss: 33.9689 - val_accuracy: 0.9147\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 33.9970 - accuracy: 0.9104 - val_loss: 33.9412 - val_accuracy: 0.9225\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 33.9333 - accuracy: 0.9292 - val_loss: 33.9418 - val_accuracy: 0.9225\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 33.9596 - accuracy: 0.9151 - val_loss: 33.9394 - val_accuracy: 0.9225\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 33.9075 - accuracy: 0.9292 - val_loss: 33.9251 - val_accuracy: 0.9070\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 33.8514 - accuracy: 0.9575 - val_loss: 33.9035 - val_accuracy: 0.9186\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 33.8968 - accuracy: 0.9340 - val_loss: 33.8676 - val_accuracy: 0.9302\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 33.8576 - accuracy: 0.9528 - val_loss: 33.8624 - val_accuracy: 0.9225\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 33.8718 - accuracy: 0.9198 - val_loss: 33.8393 - val_accuracy: 0.9147\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 33.8593 - accuracy: 0.9198 - val_loss: 33.7952 - val_accuracy: 0.9419\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 33.8949 - accuracy: 0.8962 - val_loss: 33.8288 - val_accuracy: 0.9186\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 33.8126 - accuracy: 0.9245 - val_loss: 33.8027 - val_accuracy: 0.9186\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 33.7833 - accuracy: 0.9292 - val_loss: 33.7929 - val_accuracy: 0.8992\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 33.7677 - accuracy: 0.9340 - val_loss: 33.7930 - val_accuracy: 0.9264\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 33.8207 - accuracy: 0.9009 - val_loss: 33.7628 - val_accuracy: 0.9186\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 33.7477 - accuracy: 0.9198 - val_loss: 33.7543 - val_accuracy: 0.9264\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 33.7518 - accuracy: 0.9245 - val_loss: 33.7431 - val_accuracy: 0.9225\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 33.7551 - accuracy: 0.9057 - val_loss: 33.7154 - val_accuracy: 0.9341\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 33.6763 - accuracy: 0.9575 - val_loss: 33.6870 - val_accuracy: 0.9341\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 33.6802 - accuracy: 0.9387 - val_loss: 33.7155 - val_accuracy: 0.8992\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 33.7532 - accuracy: 0.8868 - val_loss: 33.7044 - val_accuracy: 0.9186\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 33.6697 - accuracy: 0.9340 - val_loss: 33.6564 - val_accuracy: 0.9302\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 33.6442 - accuracy: 0.9528 - val_loss: 33.6459 - val_accuracy: 0.9225\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 33.6590 - accuracy: 0.9340 - val_loss: 33.6354 - val_accuracy: 0.9264\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 33.6361 - accuracy: 0.9151 - val_loss: 33.6153 - val_accuracy: 0.9186\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 33.6013 - accuracy: 0.9481 - val_loss: 33.6037 - val_accuracy: 0.9302\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 33.6240 - accuracy: 0.9151 - val_loss: 33.5804 - val_accuracy: 0.9186\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 33.5676 - accuracy: 0.9292 - val_loss: 33.5905 - val_accuracy: 0.9225\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 33.5585 - accuracy: 0.9434 - val_loss: 33.5493 - val_accuracy: 0.9225\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 33.5843 - accuracy: 0.9057 - val_loss: 33.5308 - val_accuracy: 0.9302\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 33.5759 - accuracy: 0.9198 - val_loss: 33.5408 - val_accuracy: 0.9186\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 33.4903 - accuracy: 0.9340 - val_loss: 33.5139 - val_accuracy: 0.9225\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 33.5247 - accuracy: 0.9198 - val_loss: 33.4933 - val_accuracy: 0.9225\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 33.4978 - accuracy: 0.9292 - val_loss: 33.5203 - val_accuracy: 0.9070\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 33.4686 - accuracy: 0.9245 - val_loss: 33.4962 - val_accuracy: 0.9070\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 33.4339 - accuracy: 0.9434 - val_loss: 33.4754 - val_accuracy: 0.9109\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 33.4525 - accuracy: 0.9340 - val_loss: 33.4655 - val_accuracy: 0.9225\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 33.4217 - accuracy: 0.9340 - val_loss: 33.4310 - val_accuracy: 0.9264\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 33.4556 - accuracy: 0.9198 - val_loss: 33.4417 - val_accuracy: 0.9109\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 33.4032 - accuracy: 0.9198 - val_loss: 33.4281 - val_accuracy: 0.9147\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 33.4174 - accuracy: 0.9104 - val_loss: 33.3580 - val_accuracy: 0.9341\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 33.3616 - accuracy: 0.9434 - val_loss: 33.3603 - val_accuracy: 0.9264\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 33.3818 - accuracy: 0.9245 - val_loss: 33.4010 - val_accuracy: 0.8953\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 33.3468 - accuracy: 0.9340 - val_loss: 33.3881 - val_accuracy: 0.8953\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 33.3341 - accuracy: 0.9292 - val_loss: 33.3386 - val_accuracy: 0.9302\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 33.3336 - accuracy: 0.9198 - val_loss: 33.3016 - val_accuracy: 0.9264\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 33.2983 - accuracy: 0.9245 - val_loss: 33.3181 - val_accuracy: 0.9109\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 33.3318 - accuracy: 0.9057 - val_loss: 33.2898 - val_accuracy: 0.9225\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 33.2424 - accuracy: 0.9387 - val_loss: 33.2762 - val_accuracy: 0.9264\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 33.2724 - accuracy: 0.9198 - val_loss: 33.2693 - val_accuracy: 0.9109\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 33.2838 - accuracy: 0.9104 - val_loss: 33.2458 - val_accuracy: 0.9264\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 33.2168 - accuracy: 0.9151 - val_loss: 33.1992 - val_accuracy: 0.9302\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 33.2428 - accuracy: 0.9009 - val_loss: 33.2103 - val_accuracy: 0.9264\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 33.2255 - accuracy: 0.9104 - val_loss: 33.1825 - val_accuracy: 0.9341\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 33.1902 - accuracy: 0.9292 - val_loss: 33.1947 - val_accuracy: 0.9186\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 33.1319 - accuracy: 0.9528 - val_loss: 33.1676 - val_accuracy: 0.9225\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 33.1669 - accuracy: 0.9198 - val_loss: 33.1531 - val_accuracy: 0.9147\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 33.1221 - accuracy: 0.9292 - val_loss: 33.1065 - val_accuracy: 0.9341\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 33.1129 - accuracy: 0.9481 - val_loss: 33.1271 - val_accuracy: 0.9031\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 33.1167 - accuracy: 0.9245 - val_loss: 33.0874 - val_accuracy: 0.9341\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 33.1066 - accuracy: 0.9292 - val_loss: 33.1007 - val_accuracy: 0.9419\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 33.1109 - accuracy: 0.9104 - val_loss: 33.1203 - val_accuracy: 0.8953\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 458ms/step - loss: 33.0892 - accuracy: 0.9198 - val_loss: 33.1136 - val_accuracy: 0.8915\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 33.0739 - accuracy: 0.9198 - val_loss: 33.0513 - val_accuracy: 0.9264\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 33.0539 - accuracy: 0.9245 - val_loss: 33.0270 - val_accuracy: 0.9341\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 33.0273 - accuracy: 0.9245 - val_loss: 33.0551 - val_accuracy: 0.9109\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 33.0520 - accuracy: 0.8962 - val_loss: 33.0237 - val_accuracy: 0.9341\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 33.0786 - accuracy: 0.9057 - val_loss: 32.9967 - val_accuracy: 0.9186\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 33.0407 - accuracy: 0.9151 - val_loss: 32.9767 - val_accuracy: 0.9341\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 32.9878 - accuracy: 0.9151 - val_loss: 32.9526 - val_accuracy: 0.9264\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 32.9429 - accuracy: 0.9387 - val_loss: 32.9302 - val_accuracy: 0.9419\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 32.9425 - accuracy: 0.9292 - val_loss: 32.9535 - val_accuracy: 0.9302\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 32.9293 - accuracy: 0.9340 - val_loss: 32.9280 - val_accuracy: 0.9302\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 32.9342 - accuracy: 0.9292 - val_loss: 32.9023 - val_accuracy: 0.9225\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 32.8919 - accuracy: 0.9057 - val_loss: 32.9253 - val_accuracy: 0.9070\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 32.8796 - accuracy: 0.9481 - val_loss: 32.9007 - val_accuracy: 0.9341\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 32.9029 - accuracy: 0.9292 - val_loss: 32.8610 - val_accuracy: 0.9225\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 32.8505 - accuracy: 0.9387 - val_loss: 32.8737 - val_accuracy: 0.8992\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 32.8608 - accuracy: 0.9104 - val_loss: 32.8560 - val_accuracy: 0.8992\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 32.8529 - accuracy: 0.9104 - val_loss: 32.8428 - val_accuracy: 0.9264\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 32.8190 - accuracy: 0.9340 - val_loss: 32.8076 - val_accuracy: 0.9264\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 32.7978 - accuracy: 0.9292 - val_loss: 32.8109 - val_accuracy: 0.9264\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 32.7927 - accuracy: 0.9340 - val_loss: 32.7904 - val_accuracy: 0.9109\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 32.8176 - accuracy: 0.9104 - val_loss: 32.7647 - val_accuracy: 0.9302\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 32.7458 - accuracy: 0.9481 - val_loss: 32.7326 - val_accuracy: 0.9341\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 32.7204 - accuracy: 0.9481 - val_loss: 32.7356 - val_accuracy: 0.9147\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 32.7307 - accuracy: 0.9340 - val_loss: 32.6997 - val_accuracy: 0.9535\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 32.7433 - accuracy: 0.9245 - val_loss: 32.7269 - val_accuracy: 0.9186\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 32.7045 - accuracy: 0.9245 - val_loss: 32.7024 - val_accuracy: 0.9186\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 32.6540 - accuracy: 0.9528 - val_loss: 32.6735 - val_accuracy: 0.9186\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 32.6235 - accuracy: 0.9575 - val_loss: 32.6803 - val_accuracy: 0.9225\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 32.6360 - accuracy: 0.9434 - val_loss: 32.6427 - val_accuracy: 0.9419\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 32.6307 - accuracy: 0.9434 - val_loss: 32.6540 - val_accuracy: 0.9186\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 32.6498 - accuracy: 0.9198 - val_loss: 32.6191 - val_accuracy: 0.9186\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 32.7790 - accuracy: 0.8679 - val_loss: 32.6124 - val_accuracy: 0.9264\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 32.5763 - accuracy: 0.9292 - val_loss: 32.5683 - val_accuracy: 0.9380\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 32.5779 - accuracy: 0.9340 - val_loss: 32.6012 - val_accuracy: 0.9109\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 32.6074 - accuracy: 0.9151 - val_loss: 32.5463 - val_accuracy: 0.9419\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 32.6231 - accuracy: 0.9057 - val_loss: 32.5565 - val_accuracy: 0.9302\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 32.5646 - accuracy: 0.9245 - val_loss: 32.5404 - val_accuracy: 0.9225\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 32.5431 - accuracy: 0.9198 - val_loss: 32.5298 - val_accuracy: 0.9147\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 32.6179 - accuracy: 0.8726 - val_loss: 32.5159 - val_accuracy: 0.9031\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 32.5581 - accuracy: 0.8962 - val_loss: 32.5119 - val_accuracy: 0.9186\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 32.4812 - accuracy: 0.9434 - val_loss: 32.4596 - val_accuracy: 0.9380\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 32.4867 - accuracy: 0.9292 - val_loss: 32.4745 - val_accuracy: 0.9109\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 32.4502 - accuracy: 0.9245 - val_loss: 32.4370 - val_accuracy: 0.9302\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 32.4314 - accuracy: 0.9340 - val_loss: 32.4296 - val_accuracy: 0.9225\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 32.4163 - accuracy: 0.9198 - val_loss: 32.3990 - val_accuracy: 0.9535\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 32.4206 - accuracy: 0.9340 - val_loss: 32.3771 - val_accuracy: 0.9419\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 32.3843 - accuracy: 0.9292 - val_loss: 32.4436 - val_accuracy: 0.9109\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 32.3958 - accuracy: 0.9340 - val_loss: 32.3910 - val_accuracy: 0.9070\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 32.3516 - accuracy: 0.9481 - val_loss: 32.3732 - val_accuracy: 0.9031\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 32.3361 - accuracy: 0.9434 - val_loss: 32.3672 - val_accuracy: 0.9264\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 32.3438 - accuracy: 0.9198 - val_loss: 32.3164 - val_accuracy: 0.9496\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 32.3502 - accuracy: 0.9292 - val_loss: 32.3103 - val_accuracy: 0.9341\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 32.3024 - accuracy: 0.9340 - val_loss: 32.3181 - val_accuracy: 0.9186\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 32.3406 - accuracy: 0.9151 - val_loss: 32.2724 - val_accuracy: 0.9380\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 32.2681 - accuracy: 0.9387 - val_loss: 32.2693 - val_accuracy: 0.9380\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 32.3052 - accuracy: 0.9057 - val_loss: 32.2614 - val_accuracy: 0.9341\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 32.2934 - accuracy: 0.9151 - val_loss: 32.2313 - val_accuracy: 0.9419\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 32.2925 - accuracy: 0.9009 - val_loss: 32.2289 - val_accuracy: 0.9341\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 32.2164 - accuracy: 0.9387 - val_loss: 32.1966 - val_accuracy: 0.9341\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 32.2026 - accuracy: 0.9340 - val_loss: 32.2034 - val_accuracy: 0.9380\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 32.1987 - accuracy: 0.9387 - val_loss: 32.1633 - val_accuracy: 0.9419\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 32.1908 - accuracy: 0.9387 - val_loss: 32.1843 - val_accuracy: 0.9302\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 32.1969 - accuracy: 0.9104 - val_loss: 32.1715 - val_accuracy: 0.9225\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 32.1868 - accuracy: 0.9198 - val_loss: 32.1565 - val_accuracy: 0.9225\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 32.1226 - accuracy: 0.9481 - val_loss: 32.0941 - val_accuracy: 0.9341\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 32.1284 - accuracy: 0.9340 - val_loss: 32.1207 - val_accuracy: 0.9419\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 32.1461 - accuracy: 0.9057 - val_loss: 32.1369 - val_accuracy: 0.8992\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 32.0762 - accuracy: 0.9575 - val_loss: 32.1267 - val_accuracy: 0.9225\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 32.1074 - accuracy: 0.9292 - val_loss: 32.0687 - val_accuracy: 0.9302\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 32.0637 - accuracy: 0.9481 - val_loss: 32.0499 - val_accuracy: 0.9457\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 32.0533 - accuracy: 0.9434 - val_loss: 32.0624 - val_accuracy: 0.9147\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 32.0641 - accuracy: 0.9198 - val_loss: 32.0213 - val_accuracy: 0.9380\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 32.0448 - accuracy: 0.9292 - val_loss: 32.0283 - val_accuracy: 0.9302\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 32.0498 - accuracy: 0.9245 - val_loss: 31.9897 - val_accuracy: 0.9496\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 31.9959 - accuracy: 0.9340 - val_loss: 31.9902 - val_accuracy: 0.9186\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 31.9864 - accuracy: 0.9198 - val_loss: 31.9775 - val_accuracy: 0.9109\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 31.9569 - accuracy: 0.9292 - val_loss: 31.9325 - val_accuracy: 0.9457\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 31.9520 - accuracy: 0.9292 - val_loss: 31.9670 - val_accuracy: 0.9186\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 31.9476 - accuracy: 0.9340 - val_loss: 31.9260 - val_accuracy: 0.9225\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 31.9486 - accuracy: 0.9104 - val_loss: 31.9046 - val_accuracy: 0.9419\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 31.9442 - accuracy: 0.9198 - val_loss: 31.8574 - val_accuracy: 0.9574\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 31.9372 - accuracy: 0.9104 - val_loss: 31.8631 - val_accuracy: 0.9264\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 31.8467 - accuracy: 0.9481 - val_loss: 31.8980 - val_accuracy: 0.9186\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 31.8782 - accuracy: 0.9104 - val_loss: 31.8794 - val_accuracy: 0.9264\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 31.8591 - accuracy: 0.9292 - val_loss: 31.8612 - val_accuracy: 0.9302\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 31.8569 - accuracy: 0.9198 - val_loss: 31.7830 - val_accuracy: 0.9496\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 31.8417 - accuracy: 0.9245 - val_loss: 31.8196 - val_accuracy: 0.9496\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 31.7724 - accuracy: 0.9575 - val_loss: 31.7967 - val_accuracy: 0.9419\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 31.7884 - accuracy: 0.9340 - val_loss: 31.8051 - val_accuracy: 0.9225\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 31.8133 - accuracy: 0.9151 - val_loss: 31.7656 - val_accuracy: 0.9341\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 31.7838 - accuracy: 0.9151 - val_loss: 31.7797 - val_accuracy: 0.9341\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 31.7306 - accuracy: 0.9575 - val_loss: 31.7346 - val_accuracy: 0.9380\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 31.7153 - accuracy: 0.9528 - val_loss: 31.7416 - val_accuracy: 0.9419\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 31.7130 - accuracy: 0.9528 - val_loss: 31.7111 - val_accuracy: 0.9302\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 31.7203 - accuracy: 0.9292 - val_loss: 31.7079 - val_accuracy: 0.9302\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 31.7567 - accuracy: 0.8868 - val_loss: 31.6956 - val_accuracy: 0.9264\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 31.6718 - accuracy: 0.9481 - val_loss: 31.6487 - val_accuracy: 0.9457\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 31.6830 - accuracy: 0.9198 - val_loss: 31.6790 - val_accuracy: 0.9147\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 31.6579 - accuracy: 0.9245 - val_loss: 31.6514 - val_accuracy: 0.9341\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 31.6501 - accuracy: 0.9387 - val_loss: 31.6335 - val_accuracy: 0.9264\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 31.6141 - accuracy: 0.9340 - val_loss: 31.6452 - val_accuracy: 0.9147\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 31.6489 - accuracy: 0.9151 - val_loss: 31.6055 - val_accuracy: 0.9264\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 31.6132 - accuracy: 0.9198 - val_loss: 31.5689 - val_accuracy: 0.9380\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 31.5721 - accuracy: 0.9340 - val_loss: 31.5663 - val_accuracy: 0.9341\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 31.6091 - accuracy: 0.9292 - val_loss: 31.5513 - val_accuracy: 0.9264\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 31.5568 - accuracy: 0.9292 - val_loss: 31.5216 - val_accuracy: 0.9302\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 31.5290 - accuracy: 0.9340 - val_loss: 31.5169 - val_accuracy: 0.9419\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 31.5250 - accuracy: 0.9387 - val_loss: 31.5125 - val_accuracy: 0.9225\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 31.4986 - accuracy: 0.9387 - val_loss: 31.4782 - val_accuracy: 0.9419\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 31.5382 - accuracy: 0.9151 - val_loss: 31.4520 - val_accuracy: 0.9535\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 31.5199 - accuracy: 0.9292 - val_loss: 31.4921 - val_accuracy: 0.9225\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 431ms/step - loss: 31.4565 - accuracy: 0.9481 - val_loss: 31.4752 - val_accuracy: 0.9186\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 31.4888 - accuracy: 0.9245 - val_loss: 31.4742 - val_accuracy: 0.9264\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 31.4602 - accuracy: 0.9292 - val_loss: 31.4225 - val_accuracy: 0.9302\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 31.4409 - accuracy: 0.9198 - val_loss: 31.3616 - val_accuracy: 0.9690\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 31.4107 - accuracy: 0.9198 - val_loss: 31.4081 - val_accuracy: 0.9147\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 31.4562 - accuracy: 0.9057 - val_loss: 31.3747 - val_accuracy: 0.9264\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 31.3516 - accuracy: 0.9528 - val_loss: 31.3700 - val_accuracy: 0.9264\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 31.3823 - accuracy: 0.9292 - val_loss: 31.3629 - val_accuracy: 0.9419\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 31.3599 - accuracy: 0.9340 - val_loss: 31.3373 - val_accuracy: 0.9225\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 31.3897 - accuracy: 0.9057 - val_loss: 31.3049 - val_accuracy: 0.9341\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 31.3347 - accuracy: 0.9198 - val_loss: 31.3726 - val_accuracy: 0.9147\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 31.2831 - accuracy: 0.9528 - val_loss: 31.3443 - val_accuracy: 0.9302\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 31.2645 - accuracy: 0.9575 - val_loss: 31.3070 - val_accuracy: 0.9225\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 31.3070 - accuracy: 0.9245 - val_loss: 31.3078 - val_accuracy: 0.9109\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 31.2780 - accuracy: 0.9387 - val_loss: 31.2375 - val_accuracy: 0.9535\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 31.2306 - accuracy: 0.9528 - val_loss: 31.2558 - val_accuracy: 0.9341\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 31.2594 - accuracy: 0.9198 - val_loss: 31.2549 - val_accuracy: 0.9147\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 31.2335 - accuracy: 0.9292 - val_loss: 31.1858 - val_accuracy: 0.9457\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 31.2061 - accuracy: 0.9340 - val_loss: 31.2159 - val_accuracy: 0.9302\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 31.1682 - accuracy: 0.9434 - val_loss: 31.1523 - val_accuracy: 0.9457\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 31.1925 - accuracy: 0.9292 - val_loss: 31.1445 - val_accuracy: 0.9651\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 31.1552 - accuracy: 0.9340 - val_loss: 31.1577 - val_accuracy: 0.9457\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 31.1461 - accuracy: 0.9387 - val_loss: 31.1364 - val_accuracy: 0.9341\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 31.0856 - accuracy: 0.9575 - val_loss: 31.1520 - val_accuracy: 0.9031\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 31.1455 - accuracy: 0.9245 - val_loss: 31.1242 - val_accuracy: 0.9225\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 31.0881 - accuracy: 0.9434 - val_loss: 31.1045 - val_accuracy: 0.9186\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 31.1678 - accuracy: 0.8915 - val_loss: 31.1065 - val_accuracy: 0.9186\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 31.0791 - accuracy: 0.9292 - val_loss: 31.0560 - val_accuracy: 0.9457\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 31.0395 - accuracy: 0.9340 - val_loss: 31.0716 - val_accuracy: 0.9302\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 31.0734 - accuracy: 0.9245 - val_loss: 31.0505 - val_accuracy: 0.9302\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 31.0352 - accuracy: 0.9292 - val_loss: 31.0471 - val_accuracy: 0.9302\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 31.0280 - accuracy: 0.9387 - val_loss: 31.0164 - val_accuracy: 0.9302\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 30.9955 - accuracy: 0.9481 - val_loss: 31.0037 - val_accuracy: 0.9419\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 31.0144 - accuracy: 0.9292 - val_loss: 30.9956 - val_accuracy: 0.9225\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 31.0066 - accuracy: 0.9057 - val_loss: 30.9818 - val_accuracy: 0.9341\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 30.9821 - accuracy: 0.9292 - val_loss: 30.9518 - val_accuracy: 0.9147\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 31.0479 - accuracy: 0.9104 - val_loss: 30.9594 - val_accuracy: 0.9302\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 30.9778 - accuracy: 0.9151 - val_loss: 30.9436 - val_accuracy: 0.9302\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 30.9367 - accuracy: 0.9198 - val_loss: 30.8989 - val_accuracy: 0.9574\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 30.9506 - accuracy: 0.9198 - val_loss: 30.9469 - val_accuracy: 0.9147\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 30.8929 - accuracy: 0.9292 - val_loss: 30.8880 - val_accuracy: 0.9341\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 30.8954 - accuracy: 0.9245 - val_loss: 30.8845 - val_accuracy: 0.9186\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 30.8862 - accuracy: 0.9340 - val_loss: 30.8390 - val_accuracy: 0.9380\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 30.8698 - accuracy: 0.9198 - val_loss: 30.8306 - val_accuracy: 0.9302\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 30.8714 - accuracy: 0.9198 - val_loss: 30.8331 - val_accuracy: 0.9264\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 30.8360 - accuracy: 0.9292 - val_loss: 30.8435 - val_accuracy: 0.9186\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 30.8565 - accuracy: 0.9104 - val_loss: 30.7964 - val_accuracy: 0.9302\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 30.7941 - accuracy: 0.9340 - val_loss: 30.8257 - val_accuracy: 0.9147\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 30.7793 - accuracy: 0.9292 - val_loss: 30.7808 - val_accuracy: 0.9380\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 30.7915 - accuracy: 0.9340 - val_loss: 30.7482 - val_accuracy: 0.9264\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 30.7843 - accuracy: 0.9151 - val_loss: 30.7696 - val_accuracy: 0.9225\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 30.7491 - accuracy: 0.9434 - val_loss: 30.7453 - val_accuracy: 0.9109\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 30.6796 - accuracy: 0.9481 - val_loss: 30.6842 - val_accuracy: 0.9341\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 30.7105 - accuracy: 0.9245 - val_loss: 30.7388 - val_accuracy: 0.9186\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 30.6762 - accuracy: 0.9434 - val_loss: 30.6804 - val_accuracy: 0.9380\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 30.6595 - accuracy: 0.9292 - val_loss: 30.6624 - val_accuracy: 0.9419\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 30.6892 - accuracy: 0.9245 - val_loss: 30.6631 - val_accuracy: 0.9419\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 30.6822 - accuracy: 0.9151 - val_loss: 30.6564 - val_accuracy: 0.9070\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 30.6520 - accuracy: 0.9245 - val_loss: 30.6334 - val_accuracy: 0.9264\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 30.6080 - accuracy: 0.9481 - val_loss: 30.6244 - val_accuracy: 0.9380\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 30.6089 - accuracy: 0.9434 - val_loss: 30.6036 - val_accuracy: 0.9380\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 30.6500 - accuracy: 0.9151 - val_loss: 30.5776 - val_accuracy: 0.9302\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 30.6028 - accuracy: 0.9151 - val_loss: 30.5933 - val_accuracy: 0.9225\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 30.5304 - accuracy: 0.9434 - val_loss: 30.5556 - val_accuracy: 0.9457\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 30.5636 - accuracy: 0.9292 - val_loss: 30.5462 - val_accuracy: 0.9264\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 30.5681 - accuracy: 0.9198 - val_loss: 30.5200 - val_accuracy: 0.9341\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 30.5228 - accuracy: 0.9434 - val_loss: 30.5102 - val_accuracy: 0.9302\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 30.5382 - accuracy: 0.9104 - val_loss: 30.5384 - val_accuracy: 0.9380\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 30.4963 - accuracy: 0.9387 - val_loss: 30.4921 - val_accuracy: 0.9264\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 30.4424 - accuracy: 0.9481 - val_loss: 30.5167 - val_accuracy: 0.8992\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 30.4926 - accuracy: 0.9198 - val_loss: 30.4937 - val_accuracy: 0.9186\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 30.4678 - accuracy: 0.9245 - val_loss: 30.4623 - val_accuracy: 0.9186\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 30.4532 - accuracy: 0.9340 - val_loss: 30.4617 - val_accuracy: 0.9225\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 30.3676 - accuracy: 0.9575 - val_loss: 30.4413 - val_accuracy: 0.9341\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 30.4171 - accuracy: 0.9340 - val_loss: 30.4384 - val_accuracy: 0.9109\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 30.3868 - accuracy: 0.9387 - val_loss: 30.3746 - val_accuracy: 0.9302\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 30.4501 - accuracy: 0.8868 - val_loss: 30.3628 - val_accuracy: 0.9341\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 30.3755 - accuracy: 0.9245 - val_loss: 30.3972 - val_accuracy: 0.9225\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 30.3776 - accuracy: 0.9198 - val_loss: 30.3554 - val_accuracy: 0.9341\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 30.3590 - accuracy: 0.9292 - val_loss: 30.3477 - val_accuracy: 0.9225\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 30.3268 - accuracy: 0.9292 - val_loss: 30.3115 - val_accuracy: 0.9264\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 30.3272 - accuracy: 0.9104 - val_loss: 30.3015 - val_accuracy: 0.9341\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 30.2923 - accuracy: 0.9481 - val_loss: 30.2904 - val_accuracy: 0.9264\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 30.3079 - accuracy: 0.9292 - val_loss: 30.2877 - val_accuracy: 0.9147\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 30.3024 - accuracy: 0.9340 - val_loss: 30.3013 - val_accuracy: 0.9109\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 30.2648 - accuracy: 0.9104 - val_loss: 30.2453 - val_accuracy: 0.9380\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 30.2850 - accuracy: 0.9151 - val_loss: 30.2313 - val_accuracy: 0.9419\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 30.2604 - accuracy: 0.9198 - val_loss: 30.2271 - val_accuracy: 0.9341\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 30.1867 - accuracy: 0.9528 - val_loss: 30.2321 - val_accuracy: 0.9147\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 30.2103 - accuracy: 0.9434 - val_loss: 30.2050 - val_accuracy: 0.9264\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 30.1763 - accuracy: 0.9575 - val_loss: 30.2136 - val_accuracy: 0.9070\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 30.1660 - accuracy: 0.9245 - val_loss: 30.2023 - val_accuracy: 0.9225\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 30.1575 - accuracy: 0.9387 - val_loss: 30.1171 - val_accuracy: 0.9457\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 30.1691 - accuracy: 0.9151 - val_loss: 30.1090 - val_accuracy: 0.9341\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 30.1366 - accuracy: 0.9387 - val_loss: 30.1240 - val_accuracy: 0.9419\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 30.1158 - accuracy: 0.9340 - val_loss: 30.1211 - val_accuracy: 0.9302\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 30.1351 - accuracy: 0.9198 - val_loss: 30.1156 - val_accuracy: 0.9225\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 30.1799 - accuracy: 0.8915 - val_loss: 30.0671 - val_accuracy: 0.9419\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 30.0860 - accuracy: 0.9245 - val_loss: 30.0658 - val_accuracy: 0.9302\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 30.0678 - accuracy: 0.9387 - val_loss: 30.0444 - val_accuracy: 0.9302\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 30.0374 - accuracy: 0.9434 - val_loss: 30.0082 - val_accuracy: 0.9380\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 30.0537 - accuracy: 0.9104 - val_loss: 30.0083 - val_accuracy: 0.9496\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 30.0460 - accuracy: 0.9292 - val_loss: 30.0255 - val_accuracy: 0.9225\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 30.0369 - accuracy: 0.9198 - val_loss: 30.0033 - val_accuracy: 0.9264\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 30.0092 - accuracy: 0.9151 - val_loss: 29.9645 - val_accuracy: 0.9341\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 30.0278 - accuracy: 0.9104 - val_loss: 29.9833 - val_accuracy: 0.9186\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 29.9702 - accuracy: 0.9245 - val_loss: 29.9888 - val_accuracy: 0.9147\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 29.9434 - accuracy: 0.9434 - val_loss: 29.9059 - val_accuracy: 0.9612\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 29.9307 - accuracy: 0.9198 - val_loss: 29.9563 - val_accuracy: 0.9264\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 30.0819 - accuracy: 0.8491 - val_loss: 29.9311 - val_accuracy: 0.9186\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 29.9597 - accuracy: 0.9151 - val_loss: 29.9128 - val_accuracy: 0.9109\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 29.8861 - accuracy: 0.9481 - val_loss: 29.9063 - val_accuracy: 0.9264\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 451ms/step - loss: 29.8602 - accuracy: 0.9292 - val_loss: 29.9143 - val_accuracy: 0.9109\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 29.8277 - accuracy: 0.9623 - val_loss: 29.8634 - val_accuracy: 0.9225\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 29.8394 - accuracy: 0.9340 - val_loss: 29.8313 - val_accuracy: 0.9380\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 29.8200 - accuracy: 0.9575 - val_loss: 29.7859 - val_accuracy: 0.9574\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 29.8778 - accuracy: 0.9151 - val_loss: 29.8362 - val_accuracy: 0.9264\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 29.8099 - accuracy: 0.9292 - val_loss: 29.7797 - val_accuracy: 0.9419\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 29.8656 - accuracy: 0.9009 - val_loss: 29.8128 - val_accuracy: 0.9186\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 29.7580 - accuracy: 0.9528 - val_loss: 29.8128 - val_accuracy: 0.9225\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 29.7989 - accuracy: 0.9198 - val_loss: 29.7567 - val_accuracy: 0.9264\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 29.7758 - accuracy: 0.9340 - val_loss: 29.7285 - val_accuracy: 0.9380\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 29.7347 - accuracy: 0.9575 - val_loss: 29.7558 - val_accuracy: 0.9109\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 29.7410 - accuracy: 0.9198 - val_loss: 29.7169 - val_accuracy: 0.9186\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 29.7606 - accuracy: 0.9292 - val_loss: 29.7017 - val_accuracy: 0.9302\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 29.7373 - accuracy: 0.9104 - val_loss: 29.6688 - val_accuracy: 0.9225\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 29.7228 - accuracy: 0.9009 - val_loss: 29.7132 - val_accuracy: 0.9186\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 29.7016 - accuracy: 0.9104 - val_loss: 29.6974 - val_accuracy: 0.9109\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 29.6784 - accuracy: 0.9340 - val_loss: 29.6469 - val_accuracy: 0.9457\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 29.6206 - accuracy: 0.9434 - val_loss: 29.6466 - val_accuracy: 0.9341\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 29.6467 - accuracy: 0.9245 - val_loss: 29.6891 - val_accuracy: 0.8915\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 29.6498 - accuracy: 0.9245 - val_loss: 29.6113 - val_accuracy: 0.9264\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 29.5781 - accuracy: 0.9387 - val_loss: 29.6274 - val_accuracy: 0.9225\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 29.6022 - accuracy: 0.9198 - val_loss: 29.5848 - val_accuracy: 0.9341\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 29.5491 - accuracy: 0.9387 - val_loss: 29.5844 - val_accuracy: 0.9186\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 29.6038 - accuracy: 0.9292 - val_loss: 29.5913 - val_accuracy: 0.9225\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 29.5392 - accuracy: 0.9387 - val_loss: 29.5705 - val_accuracy: 0.9341\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 29.5923 - accuracy: 0.8962 - val_loss: 29.5211 - val_accuracy: 0.9380\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 29.5837 - accuracy: 0.8868 - val_loss: 29.5253 - val_accuracy: 0.9109\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 29.5817 - accuracy: 0.9009 - val_loss: 29.5472 - val_accuracy: 0.9147\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 29.5119 - accuracy: 0.9387 - val_loss: 29.4534 - val_accuracy: 0.9496\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 29.4686 - accuracy: 0.9434 - val_loss: 29.4484 - val_accuracy: 0.9457\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 29.4626 - accuracy: 0.9340 - val_loss: 29.4526 - val_accuracy: 0.9302\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 29.4512 - accuracy: 0.9245 - val_loss: 29.4545 - val_accuracy: 0.9225\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 29.4022 - accuracy: 0.9623 - val_loss: 29.4074 - val_accuracy: 0.9302\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 29.4690 - accuracy: 0.8915 - val_loss: 29.4060 - val_accuracy: 0.9225\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 29.3527 - accuracy: 0.9670 - val_loss: 29.4449 - val_accuracy: 0.9186\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 29.4126 - accuracy: 0.9387 - val_loss: 29.3872 - val_accuracy: 0.9264\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 29.4201 - accuracy: 0.9245 - val_loss: 29.3678 - val_accuracy: 0.9186\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 29.3448 - accuracy: 0.9387 - val_loss: 29.3703 - val_accuracy: 0.9419\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 29.3728 - accuracy: 0.9340 - val_loss: 29.3542 - val_accuracy: 0.9341\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 29.3250 - accuracy: 0.9151 - val_loss: 29.3174 - val_accuracy: 0.9302\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 29.3437 - accuracy: 0.9292 - val_loss: 29.3181 - val_accuracy: 0.9225\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 29.3083 - accuracy: 0.9481 - val_loss: 29.2850 - val_accuracy: 0.9302\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 29.2811 - accuracy: 0.9481 - val_loss: 29.3219 - val_accuracy: 0.9186\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 29.2494 - accuracy: 0.9528 - val_loss: 29.2579 - val_accuracy: 0.9419\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 29.2762 - accuracy: 0.9245 - val_loss: 29.2842 - val_accuracy: 0.9031\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 29.2396 - accuracy: 0.9340 - val_loss: 29.2489 - val_accuracy: 0.9380\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 29.2408 - accuracy: 0.9434 - val_loss: 29.2412 - val_accuracy: 0.9341\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 29.2295 - accuracy: 0.9198 - val_loss: 29.2367 - val_accuracy: 0.9147\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 29.2300 - accuracy: 0.9245 - val_loss: 29.1667 - val_accuracy: 0.9419\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 29.1983 - accuracy: 0.9245 - val_loss: 29.1359 - val_accuracy: 0.9496\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 29.1813 - accuracy: 0.9198 - val_loss: 29.1240 - val_accuracy: 0.9419\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 29.2032 - accuracy: 0.9245 - val_loss: 29.1691 - val_accuracy: 0.9186\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 29.1943 - accuracy: 0.9057 - val_loss: 29.1303 - val_accuracy: 0.9341\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 29.1578 - accuracy: 0.9198 - val_loss: 29.1115 - val_accuracy: 0.9380\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 29.1081 - accuracy: 0.9340 - val_loss: 29.1237 - val_accuracy: 0.9380\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 29.0938 - accuracy: 0.9387 - val_loss: 29.0697 - val_accuracy: 0.9341\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 29.1026 - accuracy: 0.9292 - val_loss: 29.0739 - val_accuracy: 0.9535\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 29.0986 - accuracy: 0.9340 - val_loss: 29.0547 - val_accuracy: 0.9419\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 29.0641 - accuracy: 0.9245 - val_loss: 29.0603 - val_accuracy: 0.9070\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 29.1107 - accuracy: 0.9009 - val_loss: 29.0841 - val_accuracy: 0.9186\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 29.1148 - accuracy: 0.9057 - val_loss: 29.0274 - val_accuracy: 0.9341\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 29.0705 - accuracy: 0.9198 - val_loss: 29.0234 - val_accuracy: 0.9264\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 29.0064 - accuracy: 0.9292 - val_loss: 29.0149 - val_accuracy: 0.9186\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 29.0032 - accuracy: 0.9198 - val_loss: 28.9972 - val_accuracy: 0.9147\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 29.0047 - accuracy: 0.9151 - val_loss: 28.9573 - val_accuracy: 0.9225\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 28.9387 - accuracy: 0.9340 - val_loss: 28.9474 - val_accuracy: 0.9264\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 28.9289 - accuracy: 0.9528 - val_loss: 28.9223 - val_accuracy: 0.9380\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 28.9247 - accuracy: 0.9387 - val_loss: 28.9216 - val_accuracy: 0.9264\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 28.9024 - accuracy: 0.9245 - val_loss: 28.9394 - val_accuracy: 0.9302\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 28.9252 - accuracy: 0.9292 - val_loss: 28.8981 - val_accuracy: 0.9419\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 28.8756 - accuracy: 0.9292 - val_loss: 28.8941 - val_accuracy: 0.9380\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 28.8828 - accuracy: 0.9340 - val_loss: 28.8925 - val_accuracy: 0.9147\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 28.8971 - accuracy: 0.9198 - val_loss: 28.8381 - val_accuracy: 0.9496\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 28.8959 - accuracy: 0.9292 - val_loss: 28.8824 - val_accuracy: 0.9225\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 28.8255 - accuracy: 0.9528 - val_loss: 28.8213 - val_accuracy: 0.9380\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 28.8606 - accuracy: 0.9245 - val_loss: 28.8093 - val_accuracy: 0.9419\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 28.8326 - accuracy: 0.9057 - val_loss: 28.7932 - val_accuracy: 0.9302\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 28.7851 - accuracy: 0.9481 - val_loss: 28.8154 - val_accuracy: 0.9264\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 28.8105 - accuracy: 0.9292 - val_loss: 28.7903 - val_accuracy: 0.9341\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 28.7769 - accuracy: 0.9528 - val_loss: 28.7436 - val_accuracy: 0.9380\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 28.7494 - accuracy: 0.9481 - val_loss: 28.7687 - val_accuracy: 0.9186\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 28.7792 - accuracy: 0.9009 - val_loss: 28.7429 - val_accuracy: 0.9380\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 28.7552 - accuracy: 0.9245 - val_loss: 28.7580 - val_accuracy: 0.8992\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 28.7136 - accuracy: 0.9245 - val_loss: 28.7099 - val_accuracy: 0.9302\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 28.7144 - accuracy: 0.9434 - val_loss: 28.7151 - val_accuracy: 0.9147\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 28.6717 - accuracy: 0.9481 - val_loss: 28.6852 - val_accuracy: 0.9457\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 28.6890 - accuracy: 0.9245 - val_loss: 28.7109 - val_accuracy: 0.9109\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 28.7144 - accuracy: 0.9151 - val_loss: 28.6689 - val_accuracy: 0.9225\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 28.6738 - accuracy: 0.9104 - val_loss: 28.6304 - val_accuracy: 0.9380\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 28.7146 - accuracy: 0.9151 - val_loss: 28.6282 - val_accuracy: 0.9225\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 28.6246 - accuracy: 0.9434 - val_loss: 28.6155 - val_accuracy: 0.9380\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 28.6493 - accuracy: 0.9104 - val_loss: 28.6036 - val_accuracy: 0.9380\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 28.5544 - accuracy: 0.9481 - val_loss: 28.6105 - val_accuracy: 0.9186\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 28.5364 - accuracy: 0.9481 - val_loss: 28.5610 - val_accuracy: 0.9457\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 28.5864 - accuracy: 0.9340 - val_loss: 28.5623 - val_accuracy: 0.9457\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 28.5742 - accuracy: 0.9292 - val_loss: 28.6004 - val_accuracy: 0.8915\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 28.5384 - accuracy: 0.9245 - val_loss: 28.5108 - val_accuracy: 0.9380\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 28.5333 - accuracy: 0.9340 - val_loss: 28.5240 - val_accuracy: 0.9341\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 28.5052 - accuracy: 0.9292 - val_loss: 28.5610 - val_accuracy: 0.8992\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 28.6259 - accuracy: 0.8726 - val_loss: 28.4821 - val_accuracy: 0.9380\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 28.5173 - accuracy: 0.9151 - val_loss: 28.4827 - val_accuracy: 0.9302\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 28.5060 - accuracy: 0.9057 - val_loss: 28.4620 - val_accuracy: 0.9419\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 28.4764 - accuracy: 0.9245 - val_loss: 28.4532 - val_accuracy: 0.9264\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 28.4386 - accuracy: 0.9434 - val_loss: 28.4637 - val_accuracy: 0.9109\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 28.4357 - accuracy: 0.9340 - val_loss: 28.3974 - val_accuracy: 0.9341\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 28.4009 - accuracy: 0.9387 - val_loss: 28.4037 - val_accuracy: 0.9186\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 28.3853 - accuracy: 0.9292 - val_loss: 28.3877 - val_accuracy: 0.9380\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 28.3902 - accuracy: 0.9151 - val_loss: 28.4126 - val_accuracy: 0.9070\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 28.3712 - accuracy: 0.9104 - val_loss: 28.3769 - val_accuracy: 0.9225\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 28.3271 - accuracy: 0.9434 - val_loss: 28.3731 - val_accuracy: 0.9341\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 28.3428 - accuracy: 0.9292 - val_loss: 28.3766 - val_accuracy: 0.9147\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 28.3485 - accuracy: 0.9151 - val_loss: 28.3500 - val_accuracy: 0.9264\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 416ms/step - loss: 28.3753 - accuracy: 0.9009 - val_loss: 28.3000 - val_accuracy: 0.9380\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 28.2854 - accuracy: 0.9481 - val_loss: 28.3070 - val_accuracy: 0.9264\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 28.3004 - accuracy: 0.9245 - val_loss: 28.2986 - val_accuracy: 0.9225\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 28.2476 - accuracy: 0.9387 - val_loss: 28.2440 - val_accuracy: 0.9341\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 28.2365 - accuracy: 0.9340 - val_loss: 28.2645 - val_accuracy: 0.9186\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 28.2752 - accuracy: 0.8962 - val_loss: 28.2436 - val_accuracy: 0.9380\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 28.2358 - accuracy: 0.9434 - val_loss: 28.1810 - val_accuracy: 0.9535\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 28.2022 - accuracy: 0.9387 - val_loss: 28.2252 - val_accuracy: 0.9264\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 28.2197 - accuracy: 0.9340 - val_loss: 28.2275 - val_accuracy: 0.9225\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 28.1927 - accuracy: 0.9387 - val_loss: 28.1942 - val_accuracy: 0.9070\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 28.2089 - accuracy: 0.9151 - val_loss: 28.1337 - val_accuracy: 0.9496\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 28.1211 - accuracy: 0.9481 - val_loss: 28.1830 - val_accuracy: 0.9186\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 28.1151 - accuracy: 0.9575 - val_loss: 28.1507 - val_accuracy: 0.9070\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 28.1521 - accuracy: 0.9387 - val_loss: 28.1562 - val_accuracy: 0.9186\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 28.1208 - accuracy: 0.9387 - val_loss: 28.1173 - val_accuracy: 0.9380\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 28.1379 - accuracy: 0.9198 - val_loss: 28.0632 - val_accuracy: 0.9341\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 28.0961 - accuracy: 0.9198 - val_loss: 28.1164 - val_accuracy: 0.9225\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 28.1182 - accuracy: 0.9198 - val_loss: 28.0891 - val_accuracy: 0.9264\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 28.0964 - accuracy: 0.9057 - val_loss: 28.0729 - val_accuracy: 0.9186\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 28.0228 - accuracy: 0.9528 - val_loss: 28.0492 - val_accuracy: 0.9225\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 28.0443 - accuracy: 0.9245 - val_loss: 28.0417 - val_accuracy: 0.9264\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 28.0166 - accuracy: 0.9198 - val_loss: 28.0029 - val_accuracy: 0.9341\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 27.9960 - accuracy: 0.9481 - val_loss: 28.0103 - val_accuracy: 0.9264\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 28.0372 - accuracy: 0.9151 - val_loss: 27.9859 - val_accuracy: 0.9302\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 28.0042 - accuracy: 0.9245 - val_loss: 28.0230 - val_accuracy: 0.9147\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 27.9276 - accuracy: 0.9575 - val_loss: 27.9604 - val_accuracy: 0.9341\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 27.9463 - accuracy: 0.9528 - val_loss: 28.0035 - val_accuracy: 0.9070\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 27.9519 - accuracy: 0.9387 - val_loss: 27.9489 - val_accuracy: 0.9264\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 27.9562 - accuracy: 0.9151 - val_loss: 27.9191 - val_accuracy: 0.9225\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 27.9520 - accuracy: 0.9245 - val_loss: 27.8817 - val_accuracy: 0.9380\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 27.8688 - accuracy: 0.9623 - val_loss: 27.9099 - val_accuracy: 0.9186\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 27.9101 - accuracy: 0.9245 - val_loss: 27.8831 - val_accuracy: 0.9225\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 27.8985 - accuracy: 0.9151 - val_loss: 27.8379 - val_accuracy: 0.9574\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 27.9022 - accuracy: 0.9057 - val_loss: 27.8824 - val_accuracy: 0.9225\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 27.8674 - accuracy: 0.9104 - val_loss: 27.8407 - val_accuracy: 0.9225\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 27.8708 - accuracy: 0.9340 - val_loss: 27.8597 - val_accuracy: 0.9070\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 27.8358 - accuracy: 0.9198 - val_loss: 27.8291 - val_accuracy: 0.9147\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 27.8191 - accuracy: 0.9057 - val_loss: 27.7784 - val_accuracy: 0.9419\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 27.7807 - accuracy: 0.9434 - val_loss: 27.8168 - val_accuracy: 0.9109\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 27.7471 - accuracy: 0.9528 - val_loss: 27.7408 - val_accuracy: 0.9457\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 27.8099 - accuracy: 0.8962 - val_loss: 27.7530 - val_accuracy: 0.9380\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 27.8150 - accuracy: 0.9009 - val_loss: 27.7454 - val_accuracy: 0.9264\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 27.8046 - accuracy: 0.8962 - val_loss: 27.7249 - val_accuracy: 0.9031\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 27.7264 - accuracy: 0.9198 - val_loss: 27.6737 - val_accuracy: 0.9457\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 27.6856 - accuracy: 0.9340 - val_loss: 27.6936 - val_accuracy: 0.9264\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 27.6409 - accuracy: 0.9623 - val_loss: 27.7218 - val_accuracy: 0.9070\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 27.6855 - accuracy: 0.9434 - val_loss: 27.6642 - val_accuracy: 0.9496\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 27.7043 - accuracy: 0.9057 - val_loss: 27.6184 - val_accuracy: 0.9574\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 27.6323 - accuracy: 0.9387 - val_loss: 27.6603 - val_accuracy: 0.9264\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 27.6803 - accuracy: 0.9057 - val_loss: 27.6053 - val_accuracy: 0.9380\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 27.5863 - accuracy: 0.9528 - val_loss: 27.6212 - val_accuracy: 0.9341\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 27.6376 - accuracy: 0.9245 - val_loss: 27.5863 - val_accuracy: 0.9302\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 27.6514 - accuracy: 0.9009 - val_loss: 27.5735 - val_accuracy: 0.9341\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 27.6363 - accuracy: 0.9151 - val_loss: 27.5904 - val_accuracy: 0.9225\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 27.6086 - accuracy: 0.9340 - val_loss: 27.5770 - val_accuracy: 0.9302\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 27.5647 - accuracy: 0.9292 - val_loss: 27.5558 - val_accuracy: 0.9419\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 27.5188 - accuracy: 0.9245 - val_loss: 27.5446 - val_accuracy: 0.9302\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 27.5618 - accuracy: 0.9009 - val_loss: 27.6004 - val_accuracy: 0.9031\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 27.5213 - accuracy: 0.9151 - val_loss: 27.5120 - val_accuracy: 0.9186\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 27.5003 - accuracy: 0.9292 - val_loss: 27.5621 - val_accuracy: 0.9070\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 27.4524 - accuracy: 0.9575 - val_loss: 27.4814 - val_accuracy: 0.9302\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 27.4787 - accuracy: 0.9245 - val_loss: 27.4738 - val_accuracy: 0.9186\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 27.4391 - accuracy: 0.9340 - val_loss: 27.4215 - val_accuracy: 0.9341\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 27.4814 - accuracy: 0.9009 - val_loss: 27.4472 - val_accuracy: 0.9264\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 27.3881 - accuracy: 0.9434 - val_loss: 27.4726 - val_accuracy: 0.9070\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 27.4306 - accuracy: 0.9245 - val_loss: 27.4370 - val_accuracy: 0.9109\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 27.4100 - accuracy: 0.9340 - val_loss: 27.4176 - val_accuracy: 0.9264\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 27.3825 - accuracy: 0.9340 - val_loss: 27.3787 - val_accuracy: 0.9109\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 27.3564 - accuracy: 0.9528 - val_loss: 27.3733 - val_accuracy: 0.9264\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 27.4504 - accuracy: 0.9104 - val_loss: 27.3682 - val_accuracy: 0.9031\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 27.3478 - accuracy: 0.9387 - val_loss: 27.3445 - val_accuracy: 0.9302\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 27.3220 - accuracy: 0.9245 - val_loss: 27.3289 - val_accuracy: 0.9264\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 27.2990 - accuracy: 0.9387 - val_loss: 27.3642 - val_accuracy: 0.8992\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 27.3965 - accuracy: 0.8962 - val_loss: 27.2837 - val_accuracy: 0.9341\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 27.3095 - accuracy: 0.9245 - val_loss: 27.2902 - val_accuracy: 0.9380\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 27.2682 - accuracy: 0.9292 - val_loss: 27.2893 - val_accuracy: 0.9109\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 27.2743 - accuracy: 0.9245 - val_loss: 27.2900 - val_accuracy: 0.9070\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 27.2235 - accuracy: 0.9528 - val_loss: 27.2560 - val_accuracy: 0.8992\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 27.2710 - accuracy: 0.9151 - val_loss: 27.2137 - val_accuracy: 0.9225\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 27.2036 - accuracy: 0.9481 - val_loss: 27.2085 - val_accuracy: 0.9341\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 27.2149 - accuracy: 0.9245 - val_loss: 27.2396 - val_accuracy: 0.9070\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 27.1768 - accuracy: 0.9292 - val_loss: 27.2078 - val_accuracy: 0.9109\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 27.2325 - accuracy: 0.9104 - val_loss: 27.1917 - val_accuracy: 0.9225\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 27.1652 - accuracy: 0.9198 - val_loss: 27.1351 - val_accuracy: 0.9419\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 27.1612 - accuracy: 0.9245 - val_loss: 27.1529 - val_accuracy: 0.9419\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 27.1402 - accuracy: 0.9340 - val_loss: 27.1046 - val_accuracy: 0.9341\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 27.1947 - accuracy: 0.9057 - val_loss: 27.1133 - val_accuracy: 0.9457\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 27.1383 - accuracy: 0.9104 - val_loss: 27.1116 - val_accuracy: 0.9225\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 27.0609 - accuracy: 0.9575 - val_loss: 27.0613 - val_accuracy: 0.9419\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 27.2141 - accuracy: 0.8726 - val_loss: 27.0980 - val_accuracy: 0.9457\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 27.1244 - accuracy: 0.9104 - val_loss: 27.0983 - val_accuracy: 0.9070\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 27.0802 - accuracy: 0.9151 - val_loss: 27.0773 - val_accuracy: 0.9147\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 27.0844 - accuracy: 0.9104 - val_loss: 27.0466 - val_accuracy: 0.9147\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 27.0686 - accuracy: 0.9340 - val_loss: 27.0077 - val_accuracy: 0.9341\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 27.0200 - accuracy: 0.9340 - val_loss: 26.9991 - val_accuracy: 0.9341\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 27.0733 - accuracy: 0.8821 - val_loss: 27.0430 - val_accuracy: 0.9031\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 27.0914 - accuracy: 0.9009 - val_loss: 27.0143 - val_accuracy: 0.9186\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 27.0047 - accuracy: 0.9198 - val_loss: 26.9969 - val_accuracy: 0.9147\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 26.9620 - accuracy: 0.9292 - val_loss: 26.9494 - val_accuracy: 0.9186\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 26.9523 - accuracy: 0.9292 - val_loss: 26.9595 - val_accuracy: 0.9264\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 26.9552 - accuracy: 0.8915 - val_loss: 26.9472 - val_accuracy: 0.9302\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 26.9353 - accuracy: 0.9057 - val_loss: 26.8763 - val_accuracy: 0.9457\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 26.9289 - accuracy: 0.9151 - val_loss: 26.8819 - val_accuracy: 0.9341\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 26.8926 - accuracy: 0.9245 - val_loss: 26.8596 - val_accuracy: 0.9302\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 26.8825 - accuracy: 0.9340 - val_loss: 26.8545 - val_accuracy: 0.9341\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 26.8572 - accuracy: 0.9340 - val_loss: 26.8602 - val_accuracy: 0.9264\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 26.8504 - accuracy: 0.9387 - val_loss: 26.8353 - val_accuracy: 0.9380\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 26.8298 - accuracy: 0.9387 - val_loss: 26.8770 - val_accuracy: 0.9186\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 26.8032 - accuracy: 0.9434 - val_loss: 26.8140 - val_accuracy: 0.9457\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 26.8206 - accuracy: 0.9151 - val_loss: 26.8189 - val_accuracy: 0.9225\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 26.7799 - accuracy: 0.9387 - val_loss: 26.7910 - val_accuracy: 0.9109\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 26.8100 - accuracy: 0.9151 - val_loss: 26.7552 - val_accuracy: 0.9225\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 428ms/step - loss: 26.8264 - accuracy: 0.8868 - val_loss: 26.7670 - val_accuracy: 0.9109\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 26.7766 - accuracy: 0.9340 - val_loss: 26.8131 - val_accuracy: 0.9031\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 26.8428 - accuracy: 0.9104 - val_loss: 26.7582 - val_accuracy: 0.8992\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 26.7308 - accuracy: 0.9198 - val_loss: 26.7458 - val_accuracy: 0.9264\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 26.6487 - accuracy: 0.9481 - val_loss: 26.7179 - val_accuracy: 0.9264\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 26.7560 - accuracy: 0.8774 - val_loss: 26.7369 - val_accuracy: 0.9147\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 26.6710 - accuracy: 0.9340 - val_loss: 26.6728 - val_accuracy: 0.9147\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 26.6675 - accuracy: 0.9245 - val_loss: 26.6839 - val_accuracy: 0.9186\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 26.6444 - accuracy: 0.9340 - val_loss: 26.6608 - val_accuracy: 0.9147\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 26.6665 - accuracy: 0.9198 - val_loss: 26.6335 - val_accuracy: 0.9380\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 26.6069 - accuracy: 0.9340 - val_loss: 26.6070 - val_accuracy: 0.9264\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 26.6347 - accuracy: 0.9198 - val_loss: 26.6368 - val_accuracy: 0.9225\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 26.6227 - accuracy: 0.9009 - val_loss: 26.5658 - val_accuracy: 0.9341\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 26.5944 - accuracy: 0.9340 - val_loss: 26.5887 - val_accuracy: 0.9225\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 26.5910 - accuracy: 0.9292 - val_loss: 26.5979 - val_accuracy: 0.9147\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 26.5241 - accuracy: 0.9481 - val_loss: 26.5743 - val_accuracy: 0.9225\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 26.5388 - accuracy: 0.9245 - val_loss: 26.5982 - val_accuracy: 0.9031\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 26.5624 - accuracy: 0.9104 - val_loss: 26.4984 - val_accuracy: 0.9457\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 26.5969 - accuracy: 0.8962 - val_loss: 26.5116 - val_accuracy: 0.9225\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 26.5004 - accuracy: 0.9340 - val_loss: 26.5342 - val_accuracy: 0.9109\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 26.4968 - accuracy: 0.9340 - val_loss: 26.4926 - val_accuracy: 0.9225\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 26.4743 - accuracy: 0.9245 - val_loss: 26.4875 - val_accuracy: 0.9109\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 26.4843 - accuracy: 0.9104 - val_loss: 26.4735 - val_accuracy: 0.9264\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 26.5603 - accuracy: 0.8679 - val_loss: 26.4474 - val_accuracy: 0.9302\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 26.4523 - accuracy: 0.9340 - val_loss: 26.4635 - val_accuracy: 0.9109\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 26.4160 - accuracy: 0.9434 - val_loss: 26.4231 - val_accuracy: 0.9225\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 26.3901 - accuracy: 0.9575 - val_loss: 26.4242 - val_accuracy: 0.9302\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 26.4855 - accuracy: 0.8868 - val_loss: 26.4071 - val_accuracy: 0.9380\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 26.3872 - accuracy: 0.9340 - val_loss: 26.3464 - val_accuracy: 0.9380\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 26.4030 - accuracy: 0.8962 - val_loss: 26.3634 - val_accuracy: 0.9341\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 26.3257 - accuracy: 0.9434 - val_loss: 26.3416 - val_accuracy: 0.9341\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 26.3463 - accuracy: 0.9292 - val_loss: 26.3329 - val_accuracy: 0.9419\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 26.3271 - accuracy: 0.9292 - val_loss: 26.3354 - val_accuracy: 0.9186\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 26.3388 - accuracy: 0.9292 - val_loss: 26.2829 - val_accuracy: 0.9341\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 26.3133 - accuracy: 0.9198 - val_loss: 26.3190 - val_accuracy: 0.9225\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 26.3855 - accuracy: 0.8868 - val_loss: 26.2744 - val_accuracy: 0.9380\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 26.2596 - accuracy: 0.9481 - val_loss: 26.2539 - val_accuracy: 0.9225\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 26.3905 - accuracy: 0.8585 - val_loss: 26.2441 - val_accuracy: 0.9302\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 26.2793 - accuracy: 0.9151 - val_loss: 26.2170 - val_accuracy: 0.9419\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 26.2054 - accuracy: 0.9434 - val_loss: 26.2467 - val_accuracy: 0.9147\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 26.2321 - accuracy: 0.9245 - val_loss: 26.2082 - val_accuracy: 0.9380\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 26.1767 - accuracy: 0.9387 - val_loss: 26.2109 - val_accuracy: 0.9341\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 26.1844 - accuracy: 0.9104 - val_loss: 26.1834 - val_accuracy: 0.9147\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 26.1621 - accuracy: 0.9292 - val_loss: 26.1533 - val_accuracy: 0.9341\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 26.1679 - accuracy: 0.9387 - val_loss: 26.1796 - val_accuracy: 0.9264\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 26.1492 - accuracy: 0.9387 - val_loss: 26.1224 - val_accuracy: 0.9302\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 26.1854 - accuracy: 0.8962 - val_loss: 26.1017 - val_accuracy: 0.9419\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 26.0880 - accuracy: 0.9528 - val_loss: 26.1193 - val_accuracy: 0.9341\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 26.1403 - accuracy: 0.9057 - val_loss: 26.1170 - val_accuracy: 0.9147\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 26.1106 - accuracy: 0.9387 - val_loss: 26.1229 - val_accuracy: 0.9225\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 26.1742 - accuracy: 0.8774 - val_loss: 26.0875 - val_accuracy: 0.9186\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 26.0655 - accuracy: 0.9292 - val_loss: 26.0558 - val_accuracy: 0.9302\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 26.0520 - accuracy: 0.9340 - val_loss: 26.0628 - val_accuracy: 0.9186\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 26.0645 - accuracy: 0.9151 - val_loss: 26.0742 - val_accuracy: 0.8992\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 26.0968 - accuracy: 0.9057 - val_loss: 26.0660 - val_accuracy: 0.8992\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 26.0174 - accuracy: 0.9151 - val_loss: 26.0067 - val_accuracy: 0.9225\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 26.0100 - accuracy: 0.9151 - val_loss: 26.0171 - val_accuracy: 0.9031\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 26.0084 - accuracy: 0.9245 - val_loss: 25.9463 - val_accuracy: 0.9419\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 25.9348 - accuracy: 0.9387 - val_loss: 25.9689 - val_accuracy: 0.9147\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 26.0372 - accuracy: 0.8774 - val_loss: 25.9599 - val_accuracy: 0.9380\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 25.9723 - accuracy: 0.9104 - val_loss: 25.9575 - val_accuracy: 0.9147\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 25.9348 - accuracy: 0.9198 - val_loss: 25.9508 - val_accuracy: 0.9380\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 25.9387 - accuracy: 0.9340 - val_loss: 25.9153 - val_accuracy: 0.9380\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 25.9610 - accuracy: 0.9198 - val_loss: 25.8658 - val_accuracy: 0.9264\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 25.9064 - accuracy: 0.9292 - val_loss: 25.8715 - val_accuracy: 0.9496\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 25.9162 - accuracy: 0.9009 - val_loss: 25.8820 - val_accuracy: 0.9264\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 25.8680 - accuracy: 0.9245 - val_loss: 25.9344 - val_accuracy: 0.9031\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 25.8642 - accuracy: 0.9245 - val_loss: 25.8827 - val_accuracy: 0.8992\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 25.8504 - accuracy: 0.9151 - val_loss: 25.8487 - val_accuracy: 0.9109\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 25.7959 - accuracy: 0.9434 - val_loss: 25.8112 - val_accuracy: 0.9264\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 25.8360 - accuracy: 0.9198 - val_loss: 25.8166 - val_accuracy: 0.9225\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 25.7782 - accuracy: 0.9387 - val_loss: 25.8064 - val_accuracy: 0.9186\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 25.8636 - accuracy: 0.8821 - val_loss: 25.7803 - val_accuracy: 0.9264\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 25.7742 - accuracy: 0.9151 - val_loss: 25.7952 - val_accuracy: 0.9109\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 25.8010 - accuracy: 0.8915 - val_loss: 25.7568 - val_accuracy: 0.9186\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 25.8009 - accuracy: 0.9057 - val_loss: 25.7359 - val_accuracy: 0.9419\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 25.7586 - accuracy: 0.9198 - val_loss: 25.7207 - val_accuracy: 0.9147\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 25.7135 - accuracy: 0.9387 - val_loss: 25.6715 - val_accuracy: 0.9457\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 25.7006 - accuracy: 0.9292 - val_loss: 25.6832 - val_accuracy: 0.9341\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 25.7520 - accuracy: 0.9009 - val_loss: 25.6897 - val_accuracy: 0.9186\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 25.6828 - accuracy: 0.9151 - val_loss: 25.6736 - val_accuracy: 0.8992\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 25.6680 - accuracy: 0.9292 - val_loss: 25.6839 - val_accuracy: 0.9031\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 25.6984 - accuracy: 0.9198 - val_loss: 25.6067 - val_accuracy: 0.9380\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 25.6757 - accuracy: 0.9057 - val_loss: 25.6839 - val_accuracy: 0.8992\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 25.6824 - accuracy: 0.9009 - val_loss: 25.6365 - val_accuracy: 0.9147\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 25.6100 - accuracy: 0.9387 - val_loss: 25.5884 - val_accuracy: 0.9341\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 25.5514 - accuracy: 0.9575 - val_loss: 25.6068 - val_accuracy: 0.9031\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 25.6199 - accuracy: 0.9198 - val_loss: 25.5528 - val_accuracy: 0.9341\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 25.5703 - accuracy: 0.9198 - val_loss: 25.5629 - val_accuracy: 0.9109\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 25.5632 - accuracy: 0.9292 - val_loss: 25.5615 - val_accuracy: 0.8992\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 25.5392 - accuracy: 0.9198 - val_loss: 25.5931 - val_accuracy: 0.9070\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 25.5089 - accuracy: 0.9245 - val_loss: 25.5330 - val_accuracy: 0.9225\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 25.5537 - accuracy: 0.9104 - val_loss: 25.5008 - val_accuracy: 0.9302\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 25.4634 - accuracy: 0.9528 - val_loss: 25.4678 - val_accuracy: 0.9264\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 25.7012 - accuracy: 0.8255 - val_loss: 25.4994 - val_accuracy: 0.9147\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 25.5119 - accuracy: 0.9198 - val_loss: 25.5090 - val_accuracy: 0.8915\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 25.5021 - accuracy: 0.9151 - val_loss: 25.4749 - val_accuracy: 0.9147\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 25.4665 - accuracy: 0.9292 - val_loss: 25.4434 - val_accuracy: 0.9225\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 25.5072 - accuracy: 0.8774 - val_loss: 25.4353 - val_accuracy: 0.9302\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 25.4784 - accuracy: 0.9151 - val_loss: 25.3953 - val_accuracy: 0.9341\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 25.4453 - accuracy: 0.9057 - val_loss: 25.4305 - val_accuracy: 0.9070\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 25.4048 - accuracy: 0.9104 - val_loss: 25.4020 - val_accuracy: 0.9225\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 25.3562 - accuracy: 0.9245 - val_loss: 25.3591 - val_accuracy: 0.9186\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 25.3777 - accuracy: 0.9104 - val_loss: 25.3415 - val_accuracy: 0.9225\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 25.3599 - accuracy: 0.9245 - val_loss: 25.3603 - val_accuracy: 0.9302\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 25.3925 - accuracy: 0.8868 - val_loss: 25.3459 - val_accuracy: 0.9147\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 25.3145 - accuracy: 0.9340 - val_loss: 25.3065 - val_accuracy: 0.9225\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 25.3240 - accuracy: 0.9198 - val_loss: 25.2914 - val_accuracy: 0.9264\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 25.3121 - accuracy: 0.8962 - val_loss: 25.3237 - val_accuracy: 0.9031\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 25.3288 - accuracy: 0.9104 - val_loss: 25.3174 - val_accuracy: 0.9109\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 25.2735 - accuracy: 0.9245 - val_loss: 25.2636 - val_accuracy: 0.9186\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 25.3562 - accuracy: 0.8962 - val_loss: 25.2325 - val_accuracy: 0.9225\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 409ms/step - loss: 25.1874 - accuracy: 0.9528 - val_loss: 25.2372 - val_accuracy: 0.8992\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 25.2539 - accuracy: 0.9245 - val_loss: 25.2027 - val_accuracy: 0.9341\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 25.2618 - accuracy: 0.8915 - val_loss: 25.2392 - val_accuracy: 0.8992\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 25.1759 - accuracy: 0.9528 - val_loss: 25.1923 - val_accuracy: 0.9225\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 25.1652 - accuracy: 0.9245 - val_loss: 25.2078 - val_accuracy: 0.9147\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 25.2018 - accuracy: 0.9057 - val_loss: 25.1986 - val_accuracy: 0.9109\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 25.1529 - accuracy: 0.9245 - val_loss: 25.1803 - val_accuracy: 0.9302\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 25.1682 - accuracy: 0.9104 - val_loss: 25.1485 - val_accuracy: 0.9341\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 25.1049 - accuracy: 0.9340 - val_loss: 25.1535 - val_accuracy: 0.9031\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 25.1437 - accuracy: 0.9151 - val_loss: 25.1223 - val_accuracy: 0.9264\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 25.0931 - accuracy: 0.9387 - val_loss: 25.1153 - val_accuracy: 0.9186\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 25.1034 - accuracy: 0.9151 - val_loss: 25.0568 - val_accuracy: 0.9496\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 25.0898 - accuracy: 0.9151 - val_loss: 25.1349 - val_accuracy: 0.8837\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 25.0758 - accuracy: 0.9151 - val_loss: 25.0805 - val_accuracy: 0.9070\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 25.0609 - accuracy: 0.9481 - val_loss: 25.0188 - val_accuracy: 0.9302\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 25.0513 - accuracy: 0.9387 - val_loss: 25.0360 - val_accuracy: 0.9225\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 25.1072 - accuracy: 0.8821 - val_loss: 25.1385 - val_accuracy: 0.8527\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 24.9778 - accuracy: 0.9387 - val_loss: 25.0089 - val_accuracy: 0.9225\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 25.0331 - accuracy: 0.9151 - val_loss: 25.0342 - val_accuracy: 0.9031\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 25.0539 - accuracy: 0.8821 - val_loss: 25.0192 - val_accuracy: 0.9070\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 24.9370 - accuracy: 0.9434 - val_loss: 24.9763 - val_accuracy: 0.9186\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 24.9675 - accuracy: 0.9198 - val_loss: 24.9642 - val_accuracy: 0.9225\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 24.9311 - accuracy: 0.9340 - val_loss: 24.9286 - val_accuracy: 0.9302\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 24.9523 - accuracy: 0.9198 - val_loss: 24.9232 - val_accuracy: 0.9186\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 24.9099 - accuracy: 0.9292 - val_loss: 24.8979 - val_accuracy: 0.9225\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 24.9057 - accuracy: 0.9104 - val_loss: 24.8891 - val_accuracy: 0.9264\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 25.0218 - accuracy: 0.8726 - val_loss: 24.8914 - val_accuracy: 0.9264\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 24.8852 - accuracy: 0.9434 - val_loss: 24.8558 - val_accuracy: 0.9302\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 24.8850 - accuracy: 0.9009 - val_loss: 24.8998 - val_accuracy: 0.9109\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 24.8313 - accuracy: 0.9292 - val_loss: 24.8805 - val_accuracy: 0.8953\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 24.9105 - accuracy: 0.8868 - val_loss: 24.8094 - val_accuracy: 0.9341\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 24.8138 - accuracy: 0.9245 - val_loss: 24.8220 - val_accuracy: 0.8992\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 24.8183 - accuracy: 0.9198 - val_loss: 24.8732 - val_accuracy: 0.8953\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 24.8116 - accuracy: 0.9151 - val_loss: 24.8238 - val_accuracy: 0.9186\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 24.8047 - accuracy: 0.9104 - val_loss: 24.7784 - val_accuracy: 0.9225\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 24.7577 - accuracy: 0.9245 - val_loss: 24.7497 - val_accuracy: 0.9457\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 24.7459 - accuracy: 0.9387 - val_loss: 24.7481 - val_accuracy: 0.9225\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 24.7473 - accuracy: 0.9198 - val_loss: 24.7361 - val_accuracy: 0.9031\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 24.7803 - accuracy: 0.8962 - val_loss: 24.7350 - val_accuracy: 0.9147\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 24.7917 - accuracy: 0.8962 - val_loss: 24.7118 - val_accuracy: 0.9264\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 24.7127 - accuracy: 0.9292 - val_loss: 24.7290 - val_accuracy: 0.9031\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 24.6270 - accuracy: 0.9575 - val_loss: 24.6611 - val_accuracy: 0.9496\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 24.6593 - accuracy: 0.9340 - val_loss: 24.6401 - val_accuracy: 0.9302\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 24.6341 - accuracy: 0.9245 - val_loss: 24.6459 - val_accuracy: 0.9380\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 24.6890 - accuracy: 0.9057 - val_loss: 24.7019 - val_accuracy: 0.8953\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 24.6931 - accuracy: 0.9104 - val_loss: 24.6152 - val_accuracy: 0.9186\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 24.6562 - accuracy: 0.9057 - val_loss: 24.6107 - val_accuracy: 0.9147\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 24.5966 - accuracy: 0.9104 - val_loss: 24.6069 - val_accuracy: 0.9302\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 24.5860 - accuracy: 0.9434 - val_loss: 24.6085 - val_accuracy: 0.9147\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 24.6534 - accuracy: 0.9057 - val_loss: 24.5536 - val_accuracy: 0.9380\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 24.6274 - accuracy: 0.9198 - val_loss: 24.5891 - val_accuracy: 0.9147\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 24.5578 - accuracy: 0.9340 - val_loss: 24.5581 - val_accuracy: 0.9070\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 24.5690 - accuracy: 0.9151 - val_loss: 24.5590 - val_accuracy: 0.8915\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 24.5516 - accuracy: 0.9198 - val_loss: 24.5571 - val_accuracy: 0.9109\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 24.4982 - accuracy: 0.9340 - val_loss: 24.5051 - val_accuracy: 0.9147\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 24.4969 - accuracy: 0.9245 - val_loss: 24.5300 - val_accuracy: 0.9070\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 24.4954 - accuracy: 0.9151 - val_loss: 24.4747 - val_accuracy: 0.9341\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 24.4913 - accuracy: 0.9104 - val_loss: 24.5010 - val_accuracy: 0.9186\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 24.4639 - accuracy: 0.9198 - val_loss: 24.4488 - val_accuracy: 0.9302\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 24.4417 - accuracy: 0.9245 - val_loss: 24.4689 - val_accuracy: 0.8992\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 24.4431 - accuracy: 0.9198 - val_loss: 24.4412 - val_accuracy: 0.9225\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 24.4366 - accuracy: 0.9151 - val_loss: 24.4602 - val_accuracy: 0.8837\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 24.3636 - accuracy: 0.9481 - val_loss: 24.3855 - val_accuracy: 0.9302\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 24.4266 - accuracy: 0.9104 - val_loss: 24.3643 - val_accuracy: 0.9186\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 24.4128 - accuracy: 0.9057 - val_loss: 24.4328 - val_accuracy: 0.8876\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 24.3833 - accuracy: 0.9009 - val_loss: 24.3707 - val_accuracy: 0.8992\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 24.3911 - accuracy: 0.9151 - val_loss: 24.3945 - val_accuracy: 0.9031\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 24.3534 - accuracy: 0.8962 - val_loss: 24.3554 - val_accuracy: 0.9147\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 24.3527 - accuracy: 0.9057 - val_loss: 24.3305 - val_accuracy: 0.9070\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 24.3380 - accuracy: 0.9057 - val_loss: 24.2970 - val_accuracy: 0.9341\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 24.3274 - accuracy: 0.9151 - val_loss: 24.3560 - val_accuracy: 0.9031\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 24.3004 - accuracy: 0.9198 - val_loss: 24.3039 - val_accuracy: 0.9070\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 24.3361 - accuracy: 0.8821 - val_loss: 24.2767 - val_accuracy: 0.9147\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 24.2708 - accuracy: 0.9245 - val_loss: 24.2189 - val_accuracy: 0.9341\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 24.2461 - accuracy: 0.9292 - val_loss: 24.2297 - val_accuracy: 0.9302\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 24.3576 - accuracy: 0.8538 - val_loss: 24.2288 - val_accuracy: 0.9264\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 24.2152 - accuracy: 0.9245 - val_loss: 24.2071 - val_accuracy: 0.9225\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 24.2183 - accuracy: 0.9340 - val_loss: 24.2449 - val_accuracy: 0.8953\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 24.2318 - accuracy: 0.9009 - val_loss: 24.2117 - val_accuracy: 0.9070\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 24.3169 - accuracy: 0.8632 - val_loss: 24.1509 - val_accuracy: 0.9380\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 24.1677 - accuracy: 0.9104 - val_loss: 24.1974 - val_accuracy: 0.9147\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 24.2035 - accuracy: 0.9198 - val_loss: 24.1378 - val_accuracy: 0.9186\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 24.1456 - accuracy: 0.9057 - val_loss: 24.1479 - val_accuracy: 0.9109\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 24.0703 - accuracy: 0.9481 - val_loss: 24.0802 - val_accuracy: 0.9341\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 24.0778 - accuracy: 0.9528 - val_loss: 24.1553 - val_accuracy: 0.8953\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 24.0943 - accuracy: 0.9009 - val_loss: 24.1012 - val_accuracy: 0.9264\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 24.1005 - accuracy: 0.9340 - val_loss: 24.1155 - val_accuracy: 0.9031\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 24.0299 - accuracy: 0.9198 - val_loss: 24.0545 - val_accuracy: 0.9225\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 24.0848 - accuracy: 0.9151 - val_loss: 24.0518 - val_accuracy: 0.9264\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 24.0782 - accuracy: 0.9151 - val_loss: 24.0625 - val_accuracy: 0.9264\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 24.0700 - accuracy: 0.9198 - val_loss: 24.0409 - val_accuracy: 0.9147\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 24.0042 - accuracy: 0.9387 - val_loss: 24.0512 - val_accuracy: 0.9070\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 24.1243 - accuracy: 0.8774 - val_loss: 24.0557 - val_accuracy: 0.8876\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 24.0469 - accuracy: 0.9057 - val_loss: 23.9913 - val_accuracy: 0.9186\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 23.9845 - accuracy: 0.9151 - val_loss: 23.9928 - val_accuracy: 0.9186\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 23.9495 - accuracy: 0.9292 - val_loss: 23.9548 - val_accuracy: 0.9031\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 23.9915 - accuracy: 0.8962 - val_loss: 23.9232 - val_accuracy: 0.9419\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 23.9424 - accuracy: 0.9104 - val_loss: 23.9301 - val_accuracy: 0.9070\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 23.9270 - accuracy: 0.9387 - val_loss: 23.9366 - val_accuracy: 0.9225\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 23.9234 - accuracy: 0.9387 - val_loss: 23.9250 - val_accuracy: 0.9264\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 23.9096 - accuracy: 0.9245 - val_loss: 23.8675 - val_accuracy: 0.9341\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 23.8829 - accuracy: 0.9198 - val_loss: 23.8782 - val_accuracy: 0.9147\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 23.9018 - accuracy: 0.9198 - val_loss: 23.8547 - val_accuracy: 0.9380\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 23.9548 - accuracy: 0.9009 - val_loss: 23.8575 - val_accuracy: 0.9147\n",
      "Model training finished.\n",
      "Train loss: 23.874, train accuracy: 0.929.\n",
      "Evaluating model performance...\n",
      "Test loss: 23.929, test accuracy: 0.867.\n"
     ]
    }
   ],
   "source": [
    "run_experiment(bnn_model_full,\n",
    "               nll,\n",
    "               train_dataset,\n",
    "               val_dataset,\n",
    "               test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'saving'></a>\n",
    "\n",
    "# Saving of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:30:22.709984Z",
     "start_time": "2021-07-09T13:30:05.810199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\models\\nn_model\\assets\n",
      "INFO:tensorflow:Assets written to: .\\backups\\nn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "nn_model_savepath = os.path.join('.','models','nn_model')\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    nn_model_full,\n",
    "    nn_model_savepath\n",
    ")\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    nn_model_full,\n",
    "    os.path.join('.','backups','nn_model')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:31:17.479199Z",
     "start_time": "2021-07-09T13:30:36.039050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\models\\bnn_model\\assets\n",
      "INFO:tensorflow:Assets written to: .\\backups\\bnn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "bnn_model_savepath = os.path.join('.','models','bnn_model')\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    bnn_model_full,\n",
    "    bnn_model_savepath\n",
    ")\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    bnn_model_full,\n",
    "    os.path.join('.','backups','bnn_model')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:00.681931Z",
     "start_time": "2021-07-09T13:32:42.847364Z"
    }
   },
   "outputs": [],
   "source": [
    "bnn_model_loaded = tf.keras.models.load_model(bnn_model_savepath,\n",
    "                                              compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:01.505310Z",
     "start_time": "2021-07-09T13:33:00.686918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnn_model_loaded.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'entropies'></a>\n",
    "\n",
    "# Entropies of Predictions on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:05.252885Z",
     "start_time": "2021-07-09T13:33:03.383897Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions_bnn = bnn_model_full.predict(test_dataset)\n",
    "test_predictions_nn = nn_model_full.predict(test_dataset)\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:26.825741Z",
     "start_time": "2021-07-09T13:33:05.970486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\bnn_model_full\\assets\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join('.','bnn_model_full')\n",
    "\n",
    "tf.saved_model.save(\n",
    "    bnn_model_full, export_dir = save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:26.856680Z",
     "start_time": "2021-07-09T13:33:26.829731Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_predictions_probabilities(model, test_dataset = test_dataset):\n",
    "    \n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    entropies = []\n",
    "    i = 1\n",
    "\n",
    "    for x, y in test_dataset.unbatch().batch(1).take(-1):\n",
    "        \n",
    "        output_dist = model(x)\n",
    "        \n",
    "        # prediction\n",
    "        [prediction] = highest_prob = output_dist.mode()\n",
    "        prediction = np.argmax(prediction)\n",
    "        \n",
    "        # probability of this prediction\n",
    "        probability = output_dist.prob(highest_prob).numpy().squeeze()\n",
    "        \n",
    "        # true label of test example\n",
    "        true_label = np.argmax(y.numpy().squeeze())\n",
    "        \n",
    "        # entropy\n",
    "        [entropy] = output_dist.entropy().numpy()\n",
    "        \n",
    "        print(f\"Test Example: {i}\")\n",
    "        print(f\"Test Prediction: {prediction}, probability of this prediction: {probability:.5f} and entropy: {entropy:.5f}\")\n",
    "        print(f\"True Label: {true_label}\")\n",
    "        print(\"=\"*15)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "        true_labels.append(true_label)\n",
    "        probabilities.append(probability)\n",
    "        entropies.append(entropy)\n",
    "        \n",
    "    return predictions, true_labels, probabilities, entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:30.868758Z",
     "start_time": "2021-07-09T13:33:26.860648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Example: 1\n",
      "Test Prediction: 0, probability of this prediction: 0.99903 and entropy: 0.00767\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 2\n",
      "Test Prediction: 1, probability of this prediction: 0.76821 and entropy: 0.54143\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 3\n",
      "Test Prediction: 0, probability of this prediction: 0.65212 and entropy: 0.64613\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 4\n",
      "Test Prediction: 1, probability of this prediction: 0.99779 and entropy: 0.01571\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 5\n",
      "Test Prediction: 1, probability of this prediction: 0.95206 and entropy: 0.19241\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 6\n",
      "Test Prediction: 0, probability of this prediction: 0.82646 and entropy: 0.46146\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 7\n",
      "Test Prediction: 0, probability of this prediction: 0.87701 and entropy: 0.37283\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 8\n",
      "Test Prediction: 1, probability of this prediction: 0.88423 and entropy: 0.35841\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 9\n",
      "Test Prediction: 0, probability of this prediction: 0.99990 and entropy: 0.00098\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 10\n",
      "Test Prediction: 0, probability of this prediction: 1.00000 and entropy: 0.00006\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 11\n",
      "Test Prediction: 0, probability of this prediction: 0.99997 and entropy: 0.00030\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 12\n",
      "Test Prediction: 0, probability of this prediction: 0.99981 and entropy: 0.00179\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 13\n",
      "Test Prediction: 1, probability of this prediction: 0.91721 and entropy: 0.28552\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 14\n",
      "Test Prediction: 0, probability of this prediction: 0.72279 and entropy: 0.59030\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 15\n",
      "Test Prediction: 1, probability of this prediction: 0.82621 and entropy: 0.46184\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 16\n",
      "Test Prediction: 0, probability of this prediction: 1.00000 and entropy: 0.00000\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 17\n",
      "Test Prediction: 0, probability of this prediction: 0.72308 and entropy: 0.59002\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 18\n",
      "Test Prediction: 1, probability of this prediction: 0.99377 and entropy: 0.03787\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 19\n",
      "Test Prediction: 0, probability of this prediction: 0.99920 and entropy: 0.00648\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 20\n",
      "Test Prediction: 1, probability of this prediction: 0.66107 and entropy: 0.64032\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 21\n",
      "Test Prediction: 0, probability of this prediction: 0.96482 and entropy: 0.15231\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 22\n",
      "Test Prediction: 1, probability of this prediction: 0.75433 and entropy: 0.55753\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 23\n",
      "Test Prediction: 1, probability of this prediction: 0.99997 and entropy: 0.00031\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 24\n",
      "Test Prediction: 1, probability of this prediction: 0.95375 and entropy: 0.18731\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 25\n",
      "Test Prediction: 0, probability of this prediction: 0.99510 and entropy: 0.03097\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 26\n",
      "Test Prediction: 0, probability of this prediction: 0.75348 and entropy: 0.55848\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 27\n",
      "Test Prediction: 0, probability of this prediction: 0.60012 and entropy: 0.67296\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 28\n",
      "Test Prediction: 1, probability of this prediction: 0.75336 and entropy: 0.55862\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 29\n",
      "Test Prediction: 0, probability of this prediction: 0.95776 and entropy: 0.17500\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 30\n",
      "Test Prediction: 0, probability of this prediction: 0.83658 and entropy: 0.44530\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 31\n",
      "Test Prediction: 1, probability of this prediction: 0.91126 and entropy: 0.29960\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 32\n",
      "Test Prediction: 1, probability of this prediction: 0.98900 and entropy: 0.06053\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 33\n",
      "Test Prediction: 1, probability of this prediction: 0.95126 and entropy: 0.19479\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 34\n",
      "Test Prediction: 1, probability of this prediction: 0.96717 and entropy: 0.14445\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 35\n",
      "Test Prediction: 0, probability of this prediction: 0.99956 and entropy: 0.00382\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 36\n",
      "Test Prediction: 0, probability of this prediction: 0.93636 and entropy: 0.23688\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 37\n",
      "Test Prediction: 1, probability of this prediction: 0.93353 and entropy: 0.24441\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 38\n",
      "Test Prediction: 1, probability of this prediction: 0.98899 and entropy: 0.06058\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 39\n",
      "Test Prediction: 0, probability of this prediction: 0.99941 and entropy: 0.00500\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 40\n",
      "Test Prediction: 1, probability of this prediction: 0.99998 and entropy: 0.00028\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 41\n",
      "Test Prediction: 0, probability of this prediction: 0.99611 and entropy: 0.02549\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 42\n",
      "Test Prediction: 1, probability of this prediction: 0.89322 and entropy: 0.33973\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 43\n",
      "Test Prediction: 1, probability of this prediction: 0.94396 and entropy: 0.21594\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 44\n",
      "Test Prediction: 0, probability of this prediction: 0.99994 and entropy: 0.00060\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 45\n",
      "Test Prediction: 1, probability of this prediction: 0.88437 and entropy: 0.35813\n",
      "True Label: 1\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels, probabilities, entropies = output_predictions_probabilities(bnn_model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:34.542186Z",
     "start_time": "2021-07-09T13:33:34.506332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>entropies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99903476</td>\n",
       "      <td>0.007667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7682066</td>\n",
       "      <td>0.541434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65211725</td>\n",
       "      <td>0.646126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99779236</td>\n",
       "      <td>0.015707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9520572</td>\n",
       "      <td>0.192413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.82645684</td>\n",
       "      <td>0.461460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87701285</td>\n",
       "      <td>0.372835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8842299</td>\n",
       "      <td>0.358412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999045</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999958</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999745</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99981326</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9172134</td>\n",
       "      <td>0.285523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7227866</td>\n",
       "      <td>0.590302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826214</td>\n",
       "      <td>0.461839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7230784</td>\n",
       "      <td>0.590022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99376535</td>\n",
       "      <td>0.037872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9992035</td>\n",
       "      <td>0.006480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661073</td>\n",
       "      <td>0.640321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96481895</td>\n",
       "      <td>0.152314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75433254</td>\n",
       "      <td>0.557525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9999727</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95375377</td>\n",
       "      <td>0.187310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99509674</td>\n",
       "      <td>0.030966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7534794</td>\n",
       "      <td>0.558480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6001232</td>\n",
       "      <td>0.672962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7533559</td>\n",
       "      <td>0.558618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9577581</td>\n",
       "      <td>0.175004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8365778</td>\n",
       "      <td>0.445301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9112635</td>\n",
       "      <td>0.299605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9890049</td>\n",
       "      <td>0.060526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95125794</td>\n",
       "      <td>0.194795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9671689</td>\n",
       "      <td>0.144450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9995623</td>\n",
       "      <td>0.003823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93635523</td>\n",
       "      <td>0.236881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9335312</td>\n",
       "      <td>0.244408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9889921</td>\n",
       "      <td>0.060584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9994074</td>\n",
       "      <td>0.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9999759</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99610645</td>\n",
       "      <td>0.025489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8932184</td>\n",
       "      <td>0.339733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9439571</td>\n",
       "      <td>0.215938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999442</td>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.88436717</td>\n",
       "      <td>0.358132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions  true_labels probabilities  entropies\n",
       "0             0            0    0.99903476   0.007667\n",
       "1             1            1     0.7682066   0.541434\n",
       "2             0            1    0.65211725   0.646126\n",
       "3             1            1    0.99779236   0.015707\n",
       "4             1            1     0.9520572   0.192413\n",
       "5             0            0    0.82645684   0.461460\n",
       "6             0            0    0.87701285   0.372835\n",
       "7             1            1     0.8842299   0.358412\n",
       "8             0            0     0.9999045   0.000979\n",
       "9             0            0     0.9999958   0.000056\n",
       "10            0            0     0.9999745   0.000295\n",
       "11            0            0    0.99981326   0.001790\n",
       "12            1            1     0.9172134   0.285523\n",
       "13            0            0     0.7227866   0.590302\n",
       "14            1            0      0.826214   0.461839\n",
       "15            0            0           1.0   0.000000\n",
       "16            0            1     0.7230784   0.590022\n",
       "17            1            1    0.99376535   0.037872\n",
       "18            0            0     0.9992035   0.006480\n",
       "19            1            1      0.661073   0.640321\n",
       "20            0            0    0.96481895   0.152314\n",
       "21            1            0    0.75433254   0.557525\n",
       "22            1            1     0.9999727   0.000314\n",
       "23            1            1    0.95375377   0.187310\n",
       "24            0            0    0.99509674   0.030966\n",
       "25            0            1     0.7534794   0.558480\n",
       "26            0            0     0.6001232   0.672962\n",
       "27            1            1     0.7533559   0.558618\n",
       "28            0            1     0.9577581   0.175004\n",
       "29            0            0     0.8365778   0.445301\n",
       "30            1            1     0.9112635   0.299605\n",
       "31            1            1     0.9890049   0.060526\n",
       "32            1            1    0.95125794   0.194795\n",
       "33            1            1     0.9671689   0.144450\n",
       "34            0            0     0.9995623   0.003823\n",
       "35            0            0    0.93635523   0.236881\n",
       "36            1            1     0.9335312   0.244408\n",
       "37            1            1     0.9889921   0.060584\n",
       "38            0            0     0.9994074   0.004996\n",
       "39            1            1     0.9999759   0.000280\n",
       "40            0            0    0.99610645   0.025489\n",
       "41            1            0     0.8932184   0.339733\n",
       "42            1            1     0.9439571   0.215938\n",
       "43            0            0     0.9999442   0.000602\n",
       "44            1            1    0.88436717   0.358132"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_result_dict = {k: v for k, v in zip(['predictions', 'true_labels', 'probabilities', 'entropies'],\n",
    "                                                [predictions, true_labels, probabilities, entropies])}\n",
    "\n",
    "test_dataset_result_df = pd.DataFrame(test_dataset_result_dict)\n",
    "test_dataset_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:35.936732Z",
     "start_time": "2021-07-09T13:33:35.374408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correctly Predicted')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_entropies = test_dataset_result_df[test_dataset_result_df.predictions == test_dataset_result_df.true_labels]['entropies']\n",
    "correct_density = gaussian_kde(correct_entropies.to_numpy())\n",
    "plt.plot(np.linspace(0,1,100), correct_density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Correctly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:36.417602Z",
     "start_time": "2021-07-09T13:33:36.021438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Wrongly Predicted')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_entropies = test_dataset_result_df[test_dataset_result_df.predictions != test_dataset_result_df.true_labels]['entropies']\n",
    "wrong_density = gaussian_kde(wrong_entropies.to_numpy())\n",
    "plt.plot(np.linspace(0,1,100), wrong_density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Wrongly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:33:37.426797Z",
     "start_time": "2021-07-09T13:33:36.777536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Wrongly Predicted')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1,2, figsize = (10, 6))\n",
    "ax = axes.flat\n",
    "\n",
    "ax[0].plot(np.linspace(0,1,100), correct_density(np.linspace(0,1,100)))\n",
    "ax[0].set_ylabel('Frequency', fontsize=10)\n",
    "ax[0].set_xlabel('Entropy', fontsize=10)\n",
    "ax[0].set_title('Correctly Predicted', fontsize=10)\n",
    "\n",
    "ax[1].plot(np.linspace(0,1,100), wrong_density(np.linspace(0,1,100)))\n",
    "ax[1].set_ylabel('Frequency', fontsize=10)\n",
    "ax[1].set_xlabel('Entropy', fontsize=10)\n",
    "ax[1].set_title('Wrongly Predicted', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
