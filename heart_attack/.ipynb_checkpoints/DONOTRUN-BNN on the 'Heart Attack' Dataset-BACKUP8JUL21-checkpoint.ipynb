{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/uriel-sc-11KDtiUWRq4-unsplash.jpg\" width=400 height=400 />\n",
    "\n",
    "<center> <a href=\"https://unsplash.com/photos/11KDtiUWRq4\">Source</a> </center>\n",
    "\n",
    "# Bayesian Neural Network on the 'Heart Disease' Dataset\n",
    "\n",
    "Author: CHNG Soon Siang ([LinkedIn](https://www.linkedin.com/in/soon-siang-chng/))<br>\n",
    "Dataset: [Heart Disease Dataset](https://www.kaggle.com/ronitf/heart-disease-uci)\n",
    "\n",
    "Date last updated: 21 June 2021\n",
    "\n",
    "_**Summary**_    \n",
    "In applications where the size of the data collected is small and the outcome to be predicted is of great importance, one would require a probabilistic model to quantify the uncertainty of its predictions. This is often encountered in healthcare, engineering, academia, and other industries. In this exercise, a deterministic neural network (DNN) (acting as a baseline model) and a Bayesian neural network (BNN) were trained separately on the preprocessed heart attack dataset. The objective is to predict if heart disease is present. The accuracies attained by both models are tabulated below. Both models attained similar accuracy on the test dataset, however, in this context, the BNN model is advantageous as it quantifies the uncertainty, via the calculation of entropy, associated with its prediction.\n",
    "\n",
    "\n",
    "|                   | Deterministic NN | Bayesian NN |\n",
    "|-------------------|------------------|-------------|\n",
    "| Training Accuracy |                  |             |\n",
    "| Test Accuracy     |                  |             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:32.596359Z",
     "start_time": "2021-07-04T15:40:21.401092Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cloudpickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:33.472020Z",
     "start_time": "2021-07-04T15:40:33.453071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:34.275869Z",
     "start_time": "2021-07-04T15:40:34.120285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole data size:  303\n",
      "Sizes for different datasets are: Train 212, Test 45 and Validation 45.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = os.path.join('.', 'data', 'heart.csv')\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "feature_names = df.columns.to_list()[:-1]\n",
    "\n",
    "print(\"Whole data size: \", len(df))\n",
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "val_size = int(0.15 * len(df))\n",
    "test_size = int(0.15 * len(df))\n",
    "\n",
    "print(f\"Sizes for different datasets are: Train {train_size}, Test {test_size} and Validation {val_size}.\")\n",
    "\n",
    "train_dataframe = df[:train_size]\n",
    "test_dataframe = df[train_size:]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The features of the dataset and its respective description\n",
    "\n",
    "| Feature  | Description                                                    |\n",
    "|----------|----------------------------------------------------------------|\n",
    "| age      | age in years                                                   |\n",
    "| sex      | (1 = male; 0 = female)                                         |\n",
    "| cp       | chest pain type                                                |\n",
    "| trtbps   | resting blood pressure (in mm Hg on admission to the hospital) |\n",
    "| chol     | serum cholestoral in mg/dl                                     |\n",
    "| fbs      | (fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)     |\n",
    "| restecg  | resting electrocardiographic results                           |\n",
    "| thalachh | maximum heart rate achieved                                    |\n",
    "| exng     | exercise induced angina (1 = yes; 0 = no)                      |\n",
    "| oldpeak  | ST depression induced by exercise relative to rest             |\n",
    "| slp      | the slope of the peak exercise ST segment                      |\n",
    "| caa      | number of major vessels (0-3) colored by flourosopy            |\n",
    "| thall    | 3 = normal; 6 = fixed defect; 7 = reversable defect            |\n",
    "| output   | 1 (heart disease) or 0                                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:36.034179Z",
     "start_time": "2021-07-04T15:40:35.481683Z"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = tf.data.Dataset.from_tensor_slices(dict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:36.234678Z",
     "start_time": "2021-07-04T15:40:36.202736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex :  [1 0]\n",
      "cp :  [3 2 1 0]\n",
      "fbs :  [1 0]\n",
      "restecg :  [0 1 2]\n",
      "exng :  [0 1]\n",
      "slp :  [0 2 1]\n",
      "caa :  [0 2 1 3 4]\n",
      "thall :  [1 2 3 0]\n",
      "output :  [1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sex': 2,\n",
       " 'cp': 4,\n",
       " 'fbs': 2,\n",
       " 'restecg': 3,\n",
       " 'exng': 2,\n",
       " 'slp': 3,\n",
       " 'caa': 5,\n",
       " 'thall': 4,\n",
       " 'output': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall', 'output']\n",
    "cat_feat_depth = {k:v for k, v in zip(categorical_features, map(lambda x: len(df[x].unique()), categorical_features))}\n",
    "\n",
    "for cat_feat in categorical_features:\n",
    "    print(cat_feat,': ', df[cat_feat].unique())\n",
    "    \n",
    "cat_feat_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:36.996606Z",
     "start_time": "2021-07-04T15:40:36.976658Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_x(x):\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        \n",
    "        if feature in categorical_features:\n",
    "            \n",
    "            x[feature] = tf.one_hot(x[feature], depth = cat_feat_depth[feature], dtype = tf.float32)\n",
    "            x[feature] = tf.cast(x[feature], dtype = tf.float32)\n",
    "        else:\n",
    "            x[feature] = tf.cast(x[feature], dtype = tf.float32)\n",
    "    \n",
    "    x['output'] = tf.one_hot(x['output'], depth = cat_feat_depth['output'], dtype = tf.int32)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:37.655840Z",
     "start_time": "2021-07-04T15:40:37.522200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function transform_x at 0x0000025CF85D8DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function transform_x at 0x0000025CF85D8DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "full_dataset = full_dataset.map(transform_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:38.123591Z",
     "start_time": "2021-07-04T15:40:38.110624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       " 'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " 'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       " 'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       " 'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'output': TensorSpec(shape=(2,), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:39.854961Z",
     "start_time": "2021-07-04T15:40:39.837009Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_feature_label(x):\n",
    "    features = {feature:x[feature] for feature in df.columns.to_list()[:-1]}\n",
    "    return (features, x['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:40.812399Z",
     "start_time": "2021-07-04T15:40:40.751563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function map_feature_label at 0x0000025CF86EF1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function map_feature_label at 0x0000025CF86EF1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "full_dataset = full_dataset.map(map_feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:43.868559Z",
     "start_time": "2021-07-04T15:40:43.776831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': {}, 'sex': {}, 'cp': {}, 'trtbps': {}, 'chol': {}, 'fbs': {}, 'restecg': {}, 'thalachh': {}, 'exng': {}, 'oldpeak': {}, 'slp': {}, 'caa': {}, 'thall': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': {'shape': 1, 'dtype': tf.float32},\n",
       " 'sex': {'shape': 2, 'dtype': tf.float32},\n",
       " 'cp': {'shape': 4, 'dtype': tf.float32},\n",
       " 'trtbps': {'shape': 1, 'dtype': tf.float32},\n",
       " 'chol': {'shape': 1, 'dtype': tf.float32},\n",
       " 'fbs': {'shape': 2, 'dtype': tf.float32},\n",
       " 'restecg': {'shape': 3, 'dtype': tf.float32},\n",
       " 'thalachh': {'shape': 1, 'dtype': tf.float32},\n",
       " 'exng': {'shape': 2, 'dtype': tf.float32},\n",
       " 'oldpeak': {'shape': 1, 'dtype': tf.float32},\n",
       " 'slp': {'shape': 3, 'dtype': tf.float32},\n",
       " 'caa': {'shape': 5, 'dtype': tf.float32},\n",
       " 'thall': {'shape': 4, 'dtype': tf.float32}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_shape_dtype = {feature: dict() for feature in feature_names}\n",
    "print(feature_shape_dtype)\n",
    "\n",
    "for x in full_dataset.take(1):\n",
    "    q = x[0]\n",
    "    for feature in feature_names:\n",
    "        feature_shape_dtype[feature]['shape'] = int(cat_feat_depth[feature]) if feature in cat_feat_depth.keys() else 1\n",
    "        feature_shape_dtype[feature]['dtype'] = q[feature].dtype\n",
    "        \n",
    "feature_shape_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:45.113230Z",
     "start_time": "2021-07-04T15:40:45.094281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(2,), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(3,), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(4,), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:46.501517Z",
     "start_time": "2021-07-04T15:40:45.856245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22169811320754718, 0.7783018867924528)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neg_proportion = len(train_dataframe[train_dataframe.output ==0])/len(train_dataframe)\n",
    "num_pos_proportion = len(train_dataframe[train_dataframe.output ==1])/len(train_dataframe)\n",
    "\n",
    "num_neg_proportion, num_pos_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:47.228574Z",
     "start_time": "2021-07-04T15:40:47.216605Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_to_train_val_test(dataset, train_size, val_size, test_size):\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size = len(df))\n",
    "    train_dataset = dataset.take(train_size).batch(train_size)\n",
    "    test_dataset = dataset.skip(train_size)\n",
    "    val_dataset = dataset.skip(val_size).batch(val_size)\n",
    "    test_dataset = dataset.take(test_size).batch(test_size)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:47.949644Z",
     "start_time": "2021-07-04T15:40:47.925710Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset_to_train_val_test(full_dataset,\n",
    "                                                                     train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:48.782419Z",
     "start_time": "2021-07-04T15:40:48.770485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'age': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'sex': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'cp': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None),\n",
       "  'trtbps': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'chol': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'fbs': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'restecg': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'thalachh': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'exng': TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
       "  'oldpeak': TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       "  'slp': TensorSpec(shape=(None, 3), dtype=tf.float32, name=None),\n",
       "  'caa': TensorSpec(shape=(None, 5), dtype=tf.float32, name=None),\n",
       "  'thall': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)},\n",
       " TensorSpec(shape=(None, 2), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:49.871503Z",
     "start_time": "2021-07-04T15:40:49.764789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([55., 56., 42., 49., 67., 51., 39., 48., 57., 57., 61., 67., 53.,\n",
      "       53., 46., 39., 45., 64., 41., 38., 42., 67., 69., 49., 59., 54.,\n",
      "       45., 46., 52., 60., 51., 57., 44., 54., 53., 67., 61., 48., 50.,\n",
      "       66., 47., 54., 56., 44., 44.], dtype=float32)>, 'sex': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.]], dtype=float32)>, 'cp': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]], dtype=float32)>, 'trtbps': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([132., 200., 140., 134., 106., 130.,  94., 130., 110., 120., 148.,\n",
      "       125., 130., 142., 142., 118., 130., 128., 112., 120., 130., 100.,\n",
      "       160., 130., 140., 120., 110., 105., 136., 150., 110., 154., 108.,\n",
      "       108., 138., 160., 134., 124., 150., 112., 130., 110., 130., 112.,\n",
      "       110.], dtype=float32)>, 'chol': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([353., 288., 226., 271., 223., 256., 199., 245., 201., 354., 203.,\n",
      "       254., 197., 226., 177., 219., 234., 263., 268., 231., 180., 299.,\n",
      "       234., 269., 177., 258., 264., 204., 196., 258., 175., 232., 141.,\n",
      "       267., 234., 286., 234., 255., 243., 212., 253., 239., 221., 290.,\n",
      "       197.], dtype=float32)>, 'fbs': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32)>, 'restecg': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.]], dtype=float32)>, 'thalachh': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([132., 133., 178., 162., 142., 149., 179., 180., 126., 163., 161.,\n",
      "       163., 152., 111., 160., 140., 175., 105., 172., 182., 150., 125.,\n",
      "       131., 163., 162., 147., 132., 172., 169., 157., 123., 164., 175.,\n",
      "       167., 160., 108., 145., 175., 128., 132., 179., 126., 163., 153.,\n",
      "       177.], dtype=float32)>, 'exng': <tf.Tensor: shape=(45, 2), dtype=float32, numpy=\n",
      "array([[0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32)>, 'oldpeak': <tf.Tensor: shape=(45,), dtype=float32, numpy=\n",
      "array([1.2, 4. , 0. , 0. , 0.3, 0.5, 0. , 0.2, 1.5, 0.6, 0. , 0.2, 1.2,\n",
      "       0. , 1.4, 1.2, 0.6, 0.2, 0. , 3.8, 0. , 0.9, 0.1, 0. , 0. , 0.4,\n",
      "       1.2, 0. , 0.1, 2.6, 0.6, 0. , 0.6, 0. , 0. , 1.5, 2.6, 0. , 2.6,\n",
      "       0.1, 0. , 2.8, 0. , 0. , 0. ], dtype=float32)>, 'slp': <tf.Tensor: shape=(45, 3), dtype=float32, numpy=\n",
      "array([[0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 0., 1.]], dtype=float32)>, 'caa': <tf.Tensor: shape=(45, 5), dtype=float32, numpy=\n",
      "array([[0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.]], dtype=float32)>, 'thall': <tf.Tensor: shape=(45, 4), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0.]], dtype=float32)>}\n",
      "---------------\n",
      "tf.Tensor(\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]], shape=(45, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_dataset.take(1):\n",
    "    print(x)\n",
    "    print('-'*15)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T16:04:26.577568Z",
     "start_time": "2021-07-04T16:04:26.565602Z"
    }
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "\n",
    "hidden_units = [32, 32, 32]\n",
    "feature_names = df.columns.to_list()[:-1]\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:51.436320Z",
     "start_time": "2021-07-04T15:40:51.405402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'sex': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'sex')>,\n",
       " 'cp': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'cp')>,\n",
       " 'trtbps': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'trtbps')>,\n",
       " 'chol': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'chol')>,\n",
       " 'fbs': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'fbs')>,\n",
       " 'restecg': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'restecg')>,\n",
       " 'thalachh': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'thalachh')>,\n",
       " 'exng': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'exng')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'oldpeak')>,\n",
       " 'slp': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'slp')>,\n",
       " 'caa': <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'caa')>,\n",
       " 'thall': <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'thall')>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model_inputs(feature_names = feature_names): \n",
    "    inputs = {}\n",
    "    for feature_name in feature_names:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(feature_shape_dtype[feature_name]['shape'],),\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n",
    "\n",
    "create_model_inputs(feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:52.336949Z",
     "start_time": "2021-07-04T15:40:52.319955Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bnn_model(train_size):\n",
    "    \n",
    "    divergence_fn = lambda q, p, _:tfd.kl_divergence(q, p) / train_size\n",
    "    \n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features_ = tfpl.DenseReparameterization(\n",
    "            units = units, activation = 'relu',\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "    \n",
    "    distribution_params = tfpl.DenseReparameterization(\n",
    "            units = tfp.layers.OneHotCategorical.params_size(2), activation = None,\n",
    "            kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            kernel_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            kernel_divergence_fn = divergence_fn,\n",
    "            bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "            bias_posterior_fn = tfpl.default_mean_field_normal_fn(is_singular = False),\n",
    "            bias_divergence_fn = divergence_fn\n",
    "        )(features_)\n",
    "\n",
    "    outputs = tfp.layers.OneHotCategorical(2,\n",
    "                                          convert_to_tensor_fn=tfd.Distribution.mode)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:53.125802Z",
     "start_time": "2021-07-04T15:40:53.110842Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_nn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features_ = keras.layers.concatenate(list(inputs.values()))\n",
    "    features_ = keras.layers.BatchNormalization()(features_)\n",
    "    \n",
    "    for units in hidden_units:\n",
    "        features_ = tf.keras.layers.Dense(\n",
    "            units=units,\n",
    "            activation = 'relu')(features_)\n",
    "        \n",
    "    outputs = tf.keras.layers.Dense(2,\n",
    "                                    activation = 'softmax')(features_)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T16:04:19.164200Z",
     "start_time": "2021-07-04T16:04:19.144253Z"
    }
   },
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "def run_experiment(model, loss, train_dataset,val_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics = ['accuracy'],\n",
    "        #experimental_run_tf_function=False\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=val_dataset\n",
    "             )\n",
    "    \n",
    "    print(\"Model training finished.\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(train_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Train loss: {round(loss, 3)}, train accuracy: {round(accuracy, 3)}.\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(test_dataset,\n",
    "                                              verbose=0)\n",
    "    \n",
    "    print(f\"Test loss: {round(loss, 3)}, test accuracy: {round(accuracy, 3)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:40:54.893073Z",
     "start_time": "2021-07-04T15:40:54.775388Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_model_full = create_nn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:44:47.624617Z",
     "start_time": "2021-07-04T15:40:55.550353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025CF9C825E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025CF9C825E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.5519WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025CFB64DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025CFB64DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6981 - accuracy: 0.5519 - val_loss: 0.7974 - val_accuracy: 0.4845\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6500 - accuracy: 0.5896 - val_loss: 0.8128 - val_accuracy: 0.4806\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6153 - accuracy: 0.6745 - val_loss: 0.8487 - val_accuracy: 0.4574\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.6040 - accuracy: 0.7123 - val_loss: 0.9308 - val_accuracy: 0.4457\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5796 - accuracy: 0.7547 - val_loss: 0.9130 - val_accuracy: 0.4690\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5521 - accuracy: 0.7547 - val_loss: 1.0875 - val_accuracy: 0.4690\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5378 - accuracy: 0.7830 - val_loss: 1.1372 - val_accuracy: 0.4419\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.5262 - accuracy: 0.7972 - val_loss: 0.9309 - val_accuracy: 0.4612\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.4983 - accuracy: 0.8160 - val_loss: 0.8709 - val_accuracy: 0.4806\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4845 - accuracy: 0.8255 - val_loss: 1.0216 - val_accuracy: 0.4651\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4581 - accuracy: 0.8255 - val_loss: 1.0275 - val_accuracy: 0.4651\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.4425 - accuracy: 0.8632 - val_loss: 1.0200 - val_accuracy: 0.4457\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.4408 - accuracy: 0.8208 - val_loss: 1.0557 - val_accuracy: 0.4612\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4277 - accuracy: 0.8396 - val_loss: 1.0447 - val_accuracy: 0.4806\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4194 - accuracy: 0.8396 - val_loss: 1.0371 - val_accuracy: 0.4922\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4099 - accuracy: 0.8396 - val_loss: 1.0622 - val_accuracy: 0.4845\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4105 - accuracy: 0.8208 - val_loss: 0.9166 - val_accuracy: 0.5039\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3940 - accuracy: 0.8443 - val_loss: 1.0067 - val_accuracy: 0.4845\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3988 - accuracy: 0.8302 - val_loss: 0.8796 - val_accuracy: 0.5388\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3793 - accuracy: 0.8302 - val_loss: 0.8482 - val_accuracy: 0.5543\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3434 - accuracy: 0.8774 - val_loss: 0.7780 - val_accuracy: 0.5659\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.4119 - accuracy: 0.8302 - val_loss: 0.9415 - val_accuracy: 0.5349\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3720 - accuracy: 0.8585 - val_loss: 0.9777 - val_accuracy: 0.5116\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3686 - accuracy: 0.8538 - val_loss: 0.9782 - val_accuracy: 0.5271\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3682 - accuracy: 0.8679 - val_loss: 1.0881 - val_accuracy: 0.4806\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3347 - accuracy: 0.8443 - val_loss: 0.9687 - val_accuracy: 0.5388\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3358 - accuracy: 0.8491 - val_loss: 0.9479 - val_accuracy: 0.5388\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3414 - accuracy: 0.8632 - val_loss: 0.9059 - val_accuracy: 0.5504\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3361 - accuracy: 0.8821 - val_loss: 1.1403 - val_accuracy: 0.4884\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3148 - accuracy: 0.8726 - val_loss: 0.9432 - val_accuracy: 0.5310\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3162 - accuracy: 0.8821 - val_loss: 1.0219 - val_accuracy: 0.5310\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3015 - accuracy: 0.8821 - val_loss: 1.0547 - val_accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3266 - accuracy: 0.8915 - val_loss: 0.8796 - val_accuracy: 0.5465\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2957 - accuracy: 0.8726 - val_loss: 0.8556 - val_accuracy: 0.5853\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2817 - accuracy: 0.8868 - val_loss: 0.7986 - val_accuracy: 0.5891\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.2848 - accuracy: 0.8962 - val_loss: 0.7126 - val_accuracy: 0.6434\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3002 - accuracy: 0.8821 - val_loss: 0.8088 - val_accuracy: 0.5969\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.2816 - accuracy: 0.9057 - val_loss: 0.9106 - val_accuracy: 0.5504\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2788 - accuracy: 0.8962 - val_loss: 0.7963 - val_accuracy: 0.6047\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2866 - accuracy: 0.9009 - val_loss: 0.7797 - val_accuracy: 0.6202\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2487 - accuracy: 0.9198 - val_loss: 0.7896 - val_accuracy: 0.6124\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2698 - accuracy: 0.8962 - val_loss: 0.7763 - val_accuracy: 0.6357\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2797 - accuracy: 0.9009 - val_loss: 0.8631 - val_accuracy: 0.5891\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2711 - accuracy: 0.9104 - val_loss: 0.9249 - val_accuracy: 0.5698\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2379 - accuracy: 0.9104 - val_loss: 0.9156 - val_accuracy: 0.5659\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2657 - accuracy: 0.9104 - val_loss: 0.7594 - val_accuracy: 0.6434\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2402 - accuracy: 0.9104 - val_loss: 0.7169 - val_accuracy: 0.6395\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2919 - accuracy: 0.8868 - val_loss: 0.7418 - val_accuracy: 0.6318\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2448 - accuracy: 0.9009 - val_loss: 0.6961 - val_accuracy: 0.6589\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2490 - accuracy: 0.9104 - val_loss: 0.6473 - val_accuracy: 0.6860\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2348 - accuracy: 0.9245 - val_loss: 0.7471 - val_accuracy: 0.6318\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2510 - accuracy: 0.9151 - val_loss: 0.7562 - val_accuracy: 0.6318\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2138 - accuracy: 0.9198 - val_loss: 0.7747 - val_accuracy: 0.6318\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2377 - accuracy: 0.9292 - val_loss: 0.8549 - val_accuracy: 0.5969\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2226 - accuracy: 0.9340 - val_loss: 0.8876 - val_accuracy: 0.5775\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2103 - accuracy: 0.9198 - val_loss: 0.8413 - val_accuracy: 0.6124\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.2245 - accuracy: 0.9245 - val_loss: 0.8046 - val_accuracy: 0.6047\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2628 - accuracy: 0.9057 - val_loss: 0.6923 - val_accuracy: 0.6628\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.2091 - accuracy: 0.9292 - val_loss: 0.7145 - val_accuracy: 0.6434\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2227 - accuracy: 0.9340 - val_loss: 0.7426 - val_accuracy: 0.6473\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2191 - accuracy: 0.9292 - val_loss: 0.7493 - val_accuracy: 0.6512\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2034 - accuracy: 0.9434 - val_loss: 0.6112 - val_accuracy: 0.6899\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.2033 - accuracy: 0.9387 - val_loss: 0.5698 - val_accuracy: 0.7209\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2051 - accuracy: 0.9198 - val_loss: 0.6904 - val_accuracy: 0.6550\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2108 - accuracy: 0.9292 - val_loss: 0.7270 - val_accuracy: 0.6473\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2037 - accuracy: 0.9292 - val_loss: 0.8725 - val_accuracy: 0.6163\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2079 - accuracy: 0.9387 - val_loss: 0.6327 - val_accuracy: 0.6783\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2037 - accuracy: 0.9292 - val_loss: 0.7092 - val_accuracy: 0.6589\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1730 - accuracy: 0.9434 - val_loss: 0.7056 - val_accuracy: 0.6395\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1727 - accuracy: 0.9528 - val_loss: 0.6543 - val_accuracy: 0.6860\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1731 - accuracy: 0.9481 - val_loss: 0.7445 - val_accuracy: 0.6550\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1905 - accuracy: 0.9434 - val_loss: 0.6659 - val_accuracy: 0.6705\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1891 - accuracy: 0.9387 - val_loss: 0.7484 - val_accuracy: 0.6395\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1874 - accuracy: 0.9434 - val_loss: 0.7968 - val_accuracy: 0.6395\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1775 - accuracy: 0.9528 - val_loss: 0.6268 - val_accuracy: 0.7093\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1732 - accuracy: 0.9434 - val_loss: 0.6473 - val_accuracy: 0.6977\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1728 - accuracy: 0.9481 - val_loss: 0.6822 - val_accuracy: 0.6589\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1911 - accuracy: 0.9387 - val_loss: 0.5844 - val_accuracy: 0.7287\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1787 - accuracy: 0.9481 - val_loss: 0.6101 - val_accuracy: 0.7132\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1898 - accuracy: 0.9292 - val_loss: 0.6541 - val_accuracy: 0.6899\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1682 - accuracy: 0.9481 - val_loss: 0.7227 - val_accuracy: 0.6667\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1694 - accuracy: 0.9481 - val_loss: 0.6070 - val_accuracy: 0.7093\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1936 - accuracy: 0.9387 - val_loss: 0.5515 - val_accuracy: 0.7442\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1617 - accuracy: 0.9528 - val_loss: 0.5434 - val_accuracy: 0.7403\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1549 - accuracy: 0.9623 - val_loss: 0.6094 - val_accuracy: 0.7209\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1526 - accuracy: 0.9623 - val_loss: 0.5223 - val_accuracy: 0.7636\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1655 - accuracy: 0.9528 - val_loss: 0.5005 - val_accuracy: 0.7829\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1902 - accuracy: 0.9292 - val_loss: 0.5102 - val_accuracy: 0.7636\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1590 - accuracy: 0.9623 - val_loss: 0.4929 - val_accuracy: 0.7752\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1361 - accuracy: 0.9623 - val_loss: 0.5846 - val_accuracy: 0.7326\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1471 - accuracy: 0.9670 - val_loss: 0.6642 - val_accuracy: 0.7093\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1537 - accuracy: 0.9575 - val_loss: 0.5742 - val_accuracy: 0.7442\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1296 - accuracy: 0.9764 - val_loss: 0.5374 - val_accuracy: 0.7558\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1401 - accuracy: 0.9575 - val_loss: 0.5081 - val_accuracy: 0.7752\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1441 - accuracy: 0.9623 - val_loss: 0.4469 - val_accuracy: 0.7984\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1285 - accuracy: 0.9575 - val_loss: 0.5144 - val_accuracy: 0.7558\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1609 - accuracy: 0.9481 - val_loss: 0.5136 - val_accuracy: 0.7752\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1293 - accuracy: 0.9623 - val_loss: 0.4864 - val_accuracy: 0.7907\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1487 - accuracy: 0.9575 - val_loss: 0.5134 - val_accuracy: 0.7597\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1465 - accuracy: 0.9623 - val_loss: 0.4301 - val_accuracy: 0.8023\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1389 - accuracy: 0.9575 - val_loss: 0.5209 - val_accuracy: 0.7558\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1154 - accuracy: 0.9623 - val_loss: 0.4804 - val_accuracy: 0.7868\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1237 - accuracy: 0.9717 - val_loss: 0.5146 - val_accuracy: 0.7597\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1349 - accuracy: 0.9717 - val_loss: 0.5075 - val_accuracy: 0.7713\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1342 - accuracy: 0.9717 - val_loss: 0.4777 - val_accuracy: 0.7984\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1133 - accuracy: 0.9717 - val_loss: 0.4809 - val_accuracy: 0.7752\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1197 - accuracy: 0.9670 - val_loss: 0.4899 - val_accuracy: 0.7713\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1198 - accuracy: 0.9811 - val_loss: 0.4445 - val_accuracy: 0.7946\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1053 - accuracy: 0.9764 - val_loss: 0.4426 - val_accuracy: 0.7868\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0894 - accuracy: 0.9858 - val_loss: 0.4716 - val_accuracy: 0.7984\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1250 - accuracy: 0.9717 - val_loss: 0.4131 - val_accuracy: 0.8023\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0952 - accuracy: 0.9811 - val_loss: 0.4740 - val_accuracy: 0.8023\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1058 - accuracy: 0.9764 - val_loss: 0.3944 - val_accuracy: 0.8140\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0906 - accuracy: 0.9811 - val_loss: 0.4048 - val_accuracy: 0.8140\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1288 - accuracy: 0.9811 - val_loss: 0.4399 - val_accuracy: 0.8256\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1087 - accuracy: 0.9764 - val_loss: 0.3764 - val_accuracy: 0.8333\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0953 - accuracy: 0.9811 - val_loss: 0.4082 - val_accuracy: 0.8140\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0902 - accuracy: 0.9906 - val_loss: 0.3625 - val_accuracy: 0.8333\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1044 - accuracy: 0.9717 - val_loss: 0.4593 - val_accuracy: 0.8140\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0992 - accuracy: 0.9811 - val_loss: 0.4448 - val_accuracy: 0.8178\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0797 - accuracy: 0.9811 - val_loss: 0.4407 - val_accuracy: 0.8101\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1107 - accuracy: 0.9764 - val_loss: 0.3986 - val_accuracy: 0.8295\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0746 - accuracy: 0.9953 - val_loss: 0.3999 - val_accuracy: 0.8295\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0703 - accuracy: 0.9906 - val_loss: 0.4172 - val_accuracy: 0.8140\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0879 - accuracy: 0.9858 - val_loss: 0.3994 - val_accuracy: 0.8295\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0930 - accuracy: 0.9811 - val_loss: 0.3391 - val_accuracy: 0.8450\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0669 - accuracy: 0.9906 - val_loss: 0.4139 - val_accuracy: 0.8295\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0729 - accuracy: 0.9858 - val_loss: 0.3826 - val_accuracy: 0.8101\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1002 - accuracy: 0.9764 - val_loss: 0.4080 - val_accuracy: 0.8140\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0877 - accuracy: 0.9811 - val_loss: 0.4399 - val_accuracy: 0.8062\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0734 - accuracy: 0.9858 - val_loss: 0.3238 - val_accuracy: 0.8450\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0897 - accuracy: 0.9811 - val_loss: 0.3731 - val_accuracy: 0.8372\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0899 - accuracy: 0.9811 - val_loss: 0.3829 - val_accuracy: 0.8372\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0748 - accuracy: 0.9811 - val_loss: 0.3384 - val_accuracy: 0.8488\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0556 - accuracy: 0.9906 - val_loss: 0.3771 - val_accuracy: 0.8295\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0772 - accuracy: 0.9906 - val_loss: 0.3383 - val_accuracy: 0.8450\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0619 - accuracy: 0.9906 - val_loss: 0.3351 - val_accuracy: 0.8605\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0713 - accuracy: 0.9858 - val_loss: 0.3021 - val_accuracy: 0.8605\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0725 - accuracy: 0.9858 - val_loss: 0.3101 - val_accuracy: 0.8488\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0874 - accuracy: 0.9764 - val_loss: 0.3573 - val_accuracy: 0.8411\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0733 - accuracy: 0.9858 - val_loss: 0.3323 - val_accuracy: 0.8450\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0558 - accuracy: 0.9906 - val_loss: 0.3263 - val_accuracy: 0.8643\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0539 - accuracy: 0.9906 - val_loss: 0.2984 - val_accuracy: 0.8721\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0770 - accuracy: 0.9811 - val_loss: 0.3337 - val_accuracy: 0.8411\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0472 - accuracy: 0.9953 - val_loss: 0.3073 - val_accuracy: 0.8605\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0754 - accuracy: 0.9811 - val_loss: 0.3098 - val_accuracy: 0.8566\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0497 - accuracy: 0.9953 - val_loss: 0.2986 - val_accuracy: 0.8682\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0525 - accuracy: 0.9906 - val_loss: 0.3061 - val_accuracy: 0.8566\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0479 - accuracy: 0.9953 - val_loss: 0.2668 - val_accuracy: 0.8876\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0637 - accuracy: 0.9906 - val_loss: 0.2964 - val_accuracy: 0.8605\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0643 - accuracy: 0.9858 - val_loss: 0.3046 - val_accuracy: 0.8643\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0554 - accuracy: 0.9906 - val_loss: 0.3018 - val_accuracy: 0.8605\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0617 - accuracy: 0.9811 - val_loss: 0.2849 - val_accuracy: 0.8760\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0501 - accuracy: 0.9906 - val_loss: 0.2743 - val_accuracy: 0.8760\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 0.2559 - val_accuracy: 0.8953\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0416 - accuracy: 0.9953 - val_loss: 0.2806 - val_accuracy: 0.8721\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0321 - accuracy: 0.9953 - val_loss: 0.2614 - val_accuracy: 0.8837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0515 - accuracy: 0.9906 - val_loss: 0.2542 - val_accuracy: 0.8837\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0536 - accuracy: 0.9811 - val_loss: 0.2579 - val_accuracy: 0.8876\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.8837\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0504 - accuracy: 0.9858 - val_loss: 0.2693 - val_accuracy: 0.8798\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0307 - accuracy: 0.9953 - val_loss: 0.2503 - val_accuracy: 0.8915\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.2676 - val_accuracy: 0.8721\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0428 - accuracy: 0.9858 - val_loss: 0.2648 - val_accuracy: 0.8837\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0383 - accuracy: 0.9906 - val_loss: 0.2505 - val_accuracy: 0.8915\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0464 - accuracy: 0.9906 - val_loss: 0.2803 - val_accuracy: 0.8643\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0536 - accuracy: 0.9858 - val_loss: 0.2387 - val_accuracy: 0.8837\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0403 - accuracy: 0.9906 - val_loss: 0.2347 - val_accuracy: 0.8992\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0338 - accuracy: 0.9953 - val_loss: 0.2123 - val_accuracy: 0.9109\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.2076 - val_accuracy: 0.9070\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 0.2427 - val_accuracy: 0.8953\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.2453 - val_accuracy: 0.8837\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.2292 - val_accuracy: 0.8953\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0341 - accuracy: 0.9953 - val_loss: 0.2187 - val_accuracy: 0.9070\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0289 - accuracy: 0.9953 - val_loss: 0.2063 - val_accuracy: 0.9031\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0306 - accuracy: 0.9953 - val_loss: 0.2281 - val_accuracy: 0.8915\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.8876\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0285 - accuracy: 0.9953 - val_loss: 0.2002 - val_accuracy: 0.9147\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0351 - accuracy: 0.9953 - val_loss: 0.2108 - val_accuracy: 0.9147\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0272 - accuracy: 0.9953 - val_loss: 0.1857 - val_accuracy: 0.9186\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.2107 - val_accuracy: 0.9070\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0274 - accuracy: 0.9953 - val_loss: 0.2296 - val_accuracy: 0.8953\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9147\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9186\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0275 - accuracy: 0.9953 - val_loss: 0.2103 - val_accuracy: 0.8953\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9264\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9186\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0299 - accuracy: 0.9906 - val_loss: 0.1841 - val_accuracy: 0.9109\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9186\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0239 - accuracy: 0.9953 - val_loss: 0.1730 - val_accuracy: 0.9186\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.1559 - val_accuracy: 0.9302\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9109\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9419\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0262 - accuracy: 0.9953 - val_loss: 0.1658 - val_accuracy: 0.9225\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9380\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9380\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.1619 - val_accuracy: 0.9302\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.1457 - val_accuracy: 0.9302\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.1365 - val_accuracy: 0.9380\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9419\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9380\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9457\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9496\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9535\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.1156 - val_accuracy: 0.9496\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9457\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9496\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9535\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9574\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0972 - val_accuracy: 0.9574\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9380\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9651\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.1147 - val_accuracy: 0.9496\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9767\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9574\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9496\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9651\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9496\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9612\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9612\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9651\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9651\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9767\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9806\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9651\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9690\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9767\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9767\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9806\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9806\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9767\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9806\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9767\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9729\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 0.9767\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9806\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9806\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9806\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9845\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9922\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9845\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9922\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9767\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9845\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9884\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9922\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9884\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9884\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9961\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9922\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9961\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9922\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9961\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9961\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9961\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9961\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9961\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9961\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9961\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9922\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9922\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9922\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9922\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0109 - accuracy: 0.9953 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 9.2455e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 7.4150e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 7.9842e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 8.7792e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 5.4121e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 7.5374e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 8.2206e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 7.4672e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 8.8453e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 7.7536e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 5.5663e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 7.2156e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 7.1653e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.5773e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.5486e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 8.3869e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5.5566e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 7.5350e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 5.0163e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 5.6752e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 6.4243e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 4.5937e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 4.9713e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 7.0028e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 5.9379e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 4.9868e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 5.7384e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 4.8699e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 8.9636e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5.3452e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 7.7056e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 5.7777e-04 - accuracy: 1.0000 - val_loss: 9.8183e-04 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.8177e-04 - accuracy: 1.0000 - val_loss: 9.9477e-04 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 4.8701e-04 - accuracy: 1.0000 - val_loss: 9.0230e-04 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.6633e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 7.2641e-04 - accuracy: 1.0000 - val_loss: 8.3959e-04 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.4366e-04 - accuracy: 1.0000 - val_loss: 8.2701e-04 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4.2287e-04 - accuracy: 1.0000 - val_loss: 8.3123e-04 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.2183e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.9116e-04 - accuracy: 1.0000 - val_loss: 7.7143e-04 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.7081e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.2107e-04 - accuracy: 1.0000 - val_loss: 8.5774e-04 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.9057e-04 - accuracy: 1.0000 - val_loss: 7.1893e-04 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.3000e-04 - accuracy: 1.0000 - val_loss: 4.8359e-04 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.0577e-04 - accuracy: 1.0000 - val_loss: 6.2877e-04 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 3.0318e-04 - accuracy: 1.0000 - val_loss: 7.0817e-04 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.7189e-04 - accuracy: 1.0000 - val_loss: 6.3305e-04 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 2.5706e-04 - accuracy: 1.0000 - val_loss: 5.9686e-04 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.9009e-04 - accuracy: 1.0000 - val_loss: 5.4256e-04 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.9781e-04 - accuracy: 1.0000 - val_loss: 4.3778e-04 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0039e-04 - accuracy: 1.0000 - val_loss: 6.2488e-04 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1839e-04 - accuracy: 1.0000 - val_loss: 5.3813e-04 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 2.8625e-04 - accuracy: 1.0000 - val_loss: 5.8026e-04 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.7573e-04 - accuracy: 1.0000 - val_loss: 4.6782e-04 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.5059e-04 - accuracy: 1.0000 - val_loss: 4.8958e-04 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.2046e-04 - accuracy: 1.0000 - val_loss: 4.3926e-04 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.6577e-04 - accuracy: 1.0000 - val_loss: 4.4144e-04 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.4755e-04 - accuracy: 1.0000 - val_loss: 5.7899e-04 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.1118e-04 - accuracy: 1.0000 - val_loss: 4.9987e-04 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.6692e-04 - accuracy: 1.0000 - val_loss: 3.2123e-04 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.7418e-04 - accuracy: 1.0000 - val_loss: 4.3240e-04 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.1725e-04 - accuracy: 1.0000 - val_loss: 7.7966e-04 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 4.7961e-04 - accuracy: 1.0000 - val_loss: 4.4425e-04 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.4762e-04 - accuracy: 1.0000 - val_loss: 4.3678e-04 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 4.6485e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.6355e-04 - accuracy: 1.0000 - val_loss: 5.4586e-04 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 5.4557e-04 - accuracy: 1.0000 - val_loss: 3.5808e-04 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.8343e-04 - accuracy: 1.0000 - val_loss: 2.8015e-04 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 3.4162e-04 - accuracy: 1.0000 - val_loss: 3.1793e-04 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.7652e-04 - accuracy: 1.0000 - val_loss: 2.6748e-04 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.6613e-04 - accuracy: 1.0000 - val_loss: 2.3248e-04 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.4095e-04 - accuracy: 1.0000 - val_loss: 3.1437e-04 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.1483e-04 - accuracy: 1.0000 - val_loss: 2.6062e-04 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 1.6032e-04 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step - loss: 1.7912e-04 - accuracy: 1.0000 - val_loss: 2.8463e-04 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.9347e-04 - accuracy: 1.0000 - val_loss: 3.3991e-04 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.6014e-04 - accuracy: 1.0000 - val_loss: 2.0343e-04 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.2039e-04 - accuracy: 1.0000 - val_loss: 1.8444e-04 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.9118e-04 - accuracy: 1.0000 - val_loss: 2.0340e-04 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.0820e-04 - accuracy: 1.0000 - val_loss: 1.6330e-04 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.0812e-04 - accuracy: 1.0000 - val_loss: 1.4276e-04 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.0277e-04 - accuracy: 1.0000 - val_loss: 1.3915e-04 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.2485e-04 - accuracy: 1.0000 - val_loss: 2.4590e-04 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 8.1573e-05 - accuracy: 1.0000 - val_loss: 1.9775e-04 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.6411e-04 - accuracy: 1.0000 - val_loss: 3.1855e-04 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 3.6335e-04 - accuracy: 1.0000 - val_loss: 2.3261e-04 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.7016e-04 - accuracy: 1.0000 - val_loss: 1.3597e-04 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.1942e-04 - accuracy: 1.0000 - val_loss: 1.2646e-04 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 6.8100e-05 - accuracy: 1.0000 - val_loss: 1.2426e-04 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 7.1871e-05 - accuracy: 1.0000 - val_loss: 1.2041e-04 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.1102e-04 - accuracy: 1.0000 - val_loss: 1.5139e-04 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.4578e-04 - accuracy: 1.0000 - val_loss: 1.6325e-04 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 9.8854e-05 - accuracy: 1.0000 - val_loss: 1.2220e-04 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.0189e-04 - accuracy: 1.0000 - val_loss: 1.0864e-04 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 6.7779e-05 - accuracy: 1.0000 - val_loss: 1.0304e-04 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 5.7096e-05 - accuracy: 1.0000 - val_loss: 1.0018e-04 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 7.6023e-05 - accuracy: 1.0000 - val_loss: 9.4916e-05 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.1416e-04 - accuracy: 1.0000 - val_loss: 1.7748e-04 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.2045e-04 - accuracy: 1.0000 - val_loss: 9.9593e-05 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 7.8622e-05 - accuracy: 1.0000 - val_loss: 8.0653e-05 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 7.1249e-05 - accuracy: 1.0000 - val_loss: 1.0718e-04 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 6.2519e-05 - accuracy: 1.0000 - val_loss: 8.2556e-05 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 5.8191e-05 - accuracy: 1.0000 - val_loss: 7.4775e-05 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.3913e-05 - accuracy: 1.0000 - val_loss: 5.4532e-05 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 5.3165e-05 - accuracy: 1.0000 - val_loss: 6.5508e-05 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.1464e-05 - accuracy: 1.0000 - val_loss: 6.3147e-05 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 8.0689e-05 - accuracy: 1.0000 - val_loss: 6.4554e-05 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.8172e-05 - accuracy: 1.0000 - val_loss: 6.7813e-05 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.6491e-05 - accuracy: 1.0000 - val_loss: 6.8620e-05 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 5.5910e-05 - accuracy: 1.0000 - val_loss: 6.0390e-05 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4.7822e-05 - accuracy: 1.0000 - val_loss: 4.1419e-05 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 7.0764e-05 - accuracy: 1.0000 - val_loss: 8.8363e-05 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 5.6452e-05 - accuracy: 1.0000 - val_loss: 5.4989e-05 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 6.3680e-05 - accuracy: 1.0000 - val_loss: 5.2067e-05 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.9279e-05 - accuracy: 1.0000 - val_loss: 4.4245e-05 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 4.6169e-05 - accuracy: 1.0000 - val_loss: 4.6787e-05 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 4.2790e-05 - accuracy: 1.0000 - val_loss: 5.0991e-05 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 4.6590e-05 - accuracy: 1.0000 - val_loss: 4.6932e-05 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.6076e-05 - accuracy: 1.0000 - val_loss: 2.7849e-05 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.6733e-05 - accuracy: 1.0000 - val_loss: 3.7331e-05 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.3300e-05 - accuracy: 1.0000 - val_loss: 4.0786e-05 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.7531e-05 - accuracy: 1.0000 - val_loss: 4.0357e-05 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 4.3734e-05 - accuracy: 1.0000 - val_loss: 3.6884e-05 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.8910e-05 - accuracy: 1.0000 - val_loss: 3.4484e-05 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.2457e-05 - accuracy: 1.0000 - val_loss: 4.6270e-05 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 4.3011e-05 - accuracy: 1.0000 - val_loss: 3.4967e-05 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.4779e-05 - accuracy: 1.0000 - val_loss: 3.1930e-05 - val_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 4.7066e-05 - accuracy: 1.0000 - val_loss: 8.2489e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 2.1419e-04 - accuracy: 1.0000 - val_loss: 2.1716e-04 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1018e-04 - accuracy: 1.0000 - val_loss: 2.8535e-05 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.9243e-05 - accuracy: 1.0000 - val_loss: 2.3915e-05 - val_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 4.5373e-05 - accuracy: 1.0000 - val_loss: 3.3499e-05 - val_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.2327e-05 - accuracy: 1.0000 - val_loss: 3.1855e-05 - val_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.7014e-05 - accuracy: 1.0000 - val_loss: 1.9960e-05 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.9933e-05 - accuracy: 1.0000 - val_loss: 2.3448e-05 - val_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.8516e-05 - accuracy: 1.0000 - val_loss: 2.3227e-05 - val_accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.2692e-05 - accuracy: 1.0000 - val_loss: 2.6415e-05 - val_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.2904e-05 - accuracy: 1.0000 - val_loss: 1.5029e-05 - val_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 4.0516e-05 - accuracy: 1.0000 - val_loss: 2.1278e-05 - val_accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.6462e-05 - accuracy: 1.0000 - val_loss: 2.0681e-05 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.6584e-05 - accuracy: 1.0000 - val_loss: 1.9090e-05 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.6898e-05 - accuracy: 1.0000 - val_loss: 1.5676e-05 - val_accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.7038e-05 - accuracy: 1.0000 - val_loss: 1.8403e-05 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 2.3275e-05 - accuracy: 1.0000 - val_loss: 1.6521e-05 - val_accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.5468e-05 - accuracy: 1.0000 - val_loss: 1.1587e-05 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.6414e-05 - accuracy: 1.0000 - val_loss: 1.5521e-05 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.5013e-05 - accuracy: 1.0000 - val_loss: 1.4826e-05 - val_accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.4612e-05 - accuracy: 1.0000 - val_loss: 1.4535e-05 - val_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.5106e-05 - accuracy: 1.0000 - val_loss: 1.4571e-05 - val_accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.3715e-05 - accuracy: 1.0000 - val_loss: 1.0430e-05 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.6751e-05 - accuracy: 1.0000 - val_loss: 1.3624e-05 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.0733e-05 - accuracy: 1.0000 - val_loss: 1.7032e-05 - val_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.5550e-04 - accuracy: 1.0000 - val_loss: 1.1789e-04 - val_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.8118e-04 - accuracy: 1.0000 - val_loss: 2.1660e-05 - val_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.7925e-05 - accuracy: 1.0000 - val_loss: 1.2547e-05 - val_accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 2.2482e-05 - accuracy: 1.0000 - val_loss: 9.2740e-06 - val_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.4283e-05 - accuracy: 1.0000 - val_loss: 8.4437e-06 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.4014e-05 - accuracy: 1.0000 - val_loss: 1.0491e-05 - val_accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.0942e-05 - accuracy: 1.0000 - val_loss: 8.0357e-06 - val_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.3538e-05 - accuracy: 1.0000 - val_loss: 1.0723e-05 - val_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.1311e-05 - accuracy: 1.0000 - val_loss: 1.0973e-05 - val_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 9.2707e-06 - accuracy: 1.0000 - val_loss: 1.1287e-05 - val_accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.1595e-05 - accuracy: 1.0000 - val_loss: 9.6030e-06 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 9.1538e-06 - accuracy: 1.0000 - val_loss: 9.5813e-06 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 8.7048e-06 - accuracy: 1.0000 - val_loss: 1.0085e-05 - val_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.4473e-05 - accuracy: 1.0000 - val_loss: 1.0500e-05 - val_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.0384e-05 - accuracy: 1.0000 - val_loss: 8.4658e-06 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.0505e-05 - accuracy: 1.0000 - val_loss: 8.8246e-06 - val_accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.0845e-05 - accuracy: 1.0000 - val_loss: 1.1362e-05 - val_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.0350e-05 - accuracy: 1.0000 - val_loss: 1.1490e-05 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.5170e-05 - accuracy: 1.0000 - val_loss: 1.4510e-05 - val_accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.3865e-05 - accuracy: 1.0000 - val_loss: 2.2284e-05 - val_accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.6990e-05 - accuracy: 1.0000 - val_loss: 7.0820e-05 - val_accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.3231e-05 - accuracy: 1.0000 - val_loss: 2.5508e-05 - val_accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.1916e-05 - accuracy: 1.0000 - val_loss: 2.2281e-05 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 6.8373e-05 - accuracy: 1.0000 - val_loss: 1.9853e-05 - val_accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.5856e-04 - accuracy: 1.0000 - val_loss: 2.4104e-05 - val_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5.6058e-05 - accuracy: 1.0000 - val_loss: 8.1389e-06 - val_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.1585e-05 - accuracy: 1.0000 - val_loss: 6.4522e-06 - val_accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.2835e-05 - accuracy: 1.0000 - val_loss: 7.3693e-06 - val_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.1824e-05 - accuracy: 1.0000 - val_loss: 4.8916e-06 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.1341e-05 - accuracy: 1.0000 - val_loss: 6.6273e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 8.0096e-06 - accuracy: 1.0000 - val_loss: 5.7642e-06 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.2214e-05 - accuracy: 1.0000 - val_loss: 6.5784e-06 - val_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.3290e-05 - accuracy: 1.0000 - val_loss: 5.7301e-06 - val_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.1397e-05 - accuracy: 1.0000 - val_loss: 5.8682e-06 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 8.4938e-06 - accuracy: 1.0000 - val_loss: 6.2984e-06 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 6.0061e-06 - accuracy: 1.0000 - val_loss: 6.1672e-06 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.4548e-05 - accuracy: 1.0000 - val_loss: 6.1939e-06 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 4.6895e-06 - accuracy: 1.0000 - val_loss: 6.2193e-06 - val_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.3975e-05 - accuracy: 1.0000 - val_loss: 4.9600e-06 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 9.1123e-06 - accuracy: 1.0000 - val_loss: 6.3496e-06 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.1224e-05 - accuracy: 1.0000 - val_loss: 5.3679e-06 - val_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 8.1455e-06 - accuracy: 1.0000 - val_loss: 5.4320e-06 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 5.4700e-06 - accuracy: 1.0000 - val_loss: 5.3049e-06 - val_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 9.0629e-06 - accuracy: 1.0000 - val_loss: 4.6402e-06 - val_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 5.0173e-06 - accuracy: 1.0000 - val_loss: 5.0690e-06 - val_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 4.8323e-06 - accuracy: 1.0000 - val_loss: 4.2716e-06 - val_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 7.1173e-06 - accuracy: 1.0000 - val_loss: 4.1953e-06 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.2095e-05 - accuracy: 1.0000 - val_loss: 4.2785e-06 - val_accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 5.6164e-06 - accuracy: 1.0000 - val_loss: 4.7050e-06 - val_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5.9067e-06 - accuracy: 1.0000 - val_loss: 5.1822e-06 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 2.2011e-05 - accuracy: 1.0000 - val_loss: 3.4367e-06 - val_accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 8.3081e-06 - accuracy: 1.0000 - val_loss: 5.5527e-06 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 6.0001e-06 - accuracy: 1.0000 - val_loss: 4.5774e-06 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 5.1455e-06 - accuracy: 1.0000 - val_loss: 4.0511e-06 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 6.4444e-06 - accuracy: 1.0000 - val_loss: 3.7675e-06 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 5.5829e-06 - accuracy: 1.0000 - val_loss: 3.4999e-06 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.7738e-06 - accuracy: 1.0000 - val_loss: 3.6898e-06 - val_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.0555e-05 - accuracy: 1.0000 - val_loss: 4.9817e-06 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 6.0872e-06 - accuracy: 1.0000 - val_loss: 3.9199e-06 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 5.0718e-06 - accuracy: 1.0000 - val_loss: 3.6732e-06 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 7.9053e-06 - accuracy: 1.0000 - val_loss: 3.5059e-06 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5.5737e-06 - accuracy: 1.0000 - val_loss: 4.1795e-06 - val_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 7.5795e-06 - accuracy: 1.0000 - val_loss: 3.4379e-06 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.3739e-05 - accuracy: 1.0000 - val_loss: 7.5450e-06 - val_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.6076e-05 - accuracy: 1.0000 - val_loss: 3.1654e-06 - val_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 4.1407e-06 - accuracy: 1.0000 - val_loss: 2.8831e-06 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 5.9214e-06 - accuracy: 1.0000 - val_loss: 3.2402e-06 - val_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.6167e-05 - accuracy: 1.0000 - val_loss: 5.7033e-06 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 9.2452e-06 - accuracy: 1.0000 - val_loss: 2.7436e-06 - val_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.2571e-06 - accuracy: 1.0000 - val_loss: 2.1869e-06 - val_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4.0226e-06 - accuracy: 1.0000 - val_loss: 2.4867e-06 - val_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 3.7313e-06 - accuracy: 1.0000 - val_loss: 2.4655e-06 - val_accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 4.8633e-06 - accuracy: 1.0000 - val_loss: 2.3906e-06 - val_accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.2478e-06 - accuracy: 1.0000 - val_loss: 1.6754e-06 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 8.7193e-06 - accuracy: 1.0000 - val_loss: 4.9455e-06 - val_accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 9.3985e-05 - accuracy: 1.0000 - val_loss: 2.8666e-05 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 2.5558e-04 - accuracy: 1.0000 - val_loss: 9.7867e-06 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 3.4732e-06 - accuracy: 1.0000 - val_loss: 4.6757e-06 - val_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 9.8307e-06 - accuracy: 1.0000 - val_loss: 3.1160e-06 - val_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.8602e-06 - accuracy: 1.0000 - val_loss: 2.7949e-06 - val_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.0538e-06 - accuracy: 1.0000 - val_loss: 2.6738e-06 - val_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 5.4066e-06 - accuracy: 1.0000 - val_loss: 2.5089e-06 - val_accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4.0754e-06 - accuracy: 1.0000 - val_loss: 2.4012e-06 - val_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0794e-06 - accuracy: 1.0000 - val_loss: 2.4257e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 5.3269e-06 - accuracy: 1.0000 - val_loss: 1.8787e-06 - val_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5.0442e-06 - accuracy: 1.0000 - val_loss: 2.2284e-06 - val_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 3.1865e-06 - accuracy: 1.0000 - val_loss: 2.2945e-06 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.6068e-06 - accuracy: 1.0000 - val_loss: 2.2367e-06 - val_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.8261e-06 - accuracy: 1.0000 - val_loss: 2.0395e-06 - val_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.3259e-06 - accuracy: 1.0000 - val_loss: 2.0242e-06 - val_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 7.8582e-06 - accuracy: 1.0000 - val_loss: 2.1952e-06 - val_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.8210e-06 - accuracy: 1.0000 - val_loss: 1.8764e-06 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 3.2814e-06 - accuracy: 1.0000 - val_loss: 1.9748e-06 - val_accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.4190e-05 - accuracy: 1.0000 - val_loss: 3.0915e-06 - val_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.6841e-06 - accuracy: 1.0000 - val_loss: 3.0555e-06 - val_accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.2669e-06 - accuracy: 1.0000 - val_loss: 2.3209e-06 - val_accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 5.9275e-06 - accuracy: 1.0000 - val_loss: 1.8089e-06 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.6852e-06 - accuracy: 1.0000 - val_loss: 1.8671e-06 - val_accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.4094e-06 - accuracy: 1.0000 - val_loss: 1.7220e-06 - val_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 3.2978e-06 - accuracy: 1.0000 - val_loss: 1.9309e-06 - val_accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.6806e-06 - accuracy: 1.0000 - val_loss: 2.0076e-06 - val_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.3227e-06 - accuracy: 1.0000 - val_loss: 1.6906e-06 - val_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 3.2488e-06 - accuracy: 1.0000 - val_loss: 1.3709e-06 - val_accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.5016e-06 - accuracy: 1.0000 - val_loss: 1.5742e-06 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.2096e-06 - accuracy: 1.0000 - val_loss: 1.6463e-06 - val_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.1845e-06 - accuracy: 1.0000 - val_loss: 1.0535e-06 - val_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 3.5658e-06 - accuracy: 1.0000 - val_loss: 1.7193e-06 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 6.7752e-06 - accuracy: 1.0000 - val_loss: 2.3162e-06 - val_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.6271e-06 - accuracy: 1.0000 - val_loss: 1.4139e-06 - val_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 4.9959e-06 - accuracy: 1.0000 - val_loss: 1.3972e-06 - val_accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 2.6484e-06 - accuracy: 1.0000 - val_loss: 1.2748e-06 - val_accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.0426e-06 - accuracy: 1.0000 - val_loss: 1.5959e-06 - val_accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.6686e-06 - accuracy: 1.0000 - val_loss: 9.8047e-07 - val_accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.9394e-06 - accuracy: 1.0000 - val_loss: 9.5690e-07 - val_accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.2241e-06 - accuracy: 1.0000 - val_loss: 1.0562e-06 - val_accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.9405e-06 - accuracy: 1.0000 - val_loss: 1.3760e-06 - val_accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.4547e-06 - accuracy: 1.0000 - val_loss: 1.2484e-06 - val_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.7448e-06 - accuracy: 1.0000 - val_loss: 1.2549e-06 - val_accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.8590e-06 - accuracy: 1.0000 - val_loss: 1.1648e-06 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.6785e-06 - accuracy: 1.0000 - val_loss: 1.2387e-06 - val_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.8879e-06 - accuracy: 1.0000 - val_loss: 1.1879e-06 - val_accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.3490e-06 - accuracy: 1.0000 - val_loss: 1.1459e-06 - val_accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 2.5652e-06 - accuracy: 1.0000 - val_loss: 8.8575e-07 - val_accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.5511e-06 - accuracy: 1.0000 - val_loss: 1.1135e-06 - val_accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 4.2772e-06 - accuracy: 1.0000 - val_loss: 1.8971e-06 - val_accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.5118e-06 - accuracy: 1.0000 - val_loss: 9.4535e-07 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.9993e-06 - accuracy: 1.0000 - val_loss: 1.4305e-06 - val_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.1502e-06 - accuracy: 1.0000 - val_loss: 8.8575e-07 - val_accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.1938e-06 - accuracy: 1.0000 - val_loss: 1.0502e-06 - val_accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 8.3559e-07 - accuracy: 1.0000 - val_loss: 9.1854e-07 - val_accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.5281e-06 - accuracy: 1.0000 - val_loss: 8.9453e-07 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.3000e-06 - accuracy: 1.0000 - val_loss: 8.8944e-07 - val_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 8.5358e-07 - accuracy: 1.0000 - val_loss: 9.2502e-07 - val_accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.2835e-06 - accuracy: 1.0000 - val_loss: 1.3404e-06 - val_accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 5.5492e-06 - accuracy: 1.0000 - val_loss: 1.7377e-06 - val_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 5.2839e-06 - accuracy: 1.0000 - val_loss: 1.3399e-06 - val_accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.5255e-06 - accuracy: 1.0000 - val_loss: 6.1083e-07 - val_accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.6390e-06 - accuracy: 1.0000 - val_loss: 7.4482e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 8.5077e-07 - accuracy: 1.0000 - val_loss: 5.7987e-07 - val_accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.3571e-06 - accuracy: 1.0000 - val_loss: 8.5433e-07 - val_accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.1314e-06 - accuracy: 1.0000 - val_loss: 8.4786e-07 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.0889e-06 - accuracy: 1.0000 - val_loss: 6.4872e-07 - val_accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.5708e-06 - accuracy: 1.0000 - val_loss: 1.6107e-06 - val_accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 6.4272e-07 - accuracy: 1.0000 - val_loss: 1.6023e-06 - val_accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.0796e-06 - accuracy: 1.0000 - val_loss: 1.5349e-06 - val_accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 6.6914e-07 - accuracy: 1.0000 - val_loss: 1.3228e-06 - val_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.8277e-06 - accuracy: 1.0000 - val_loss: 6.2561e-07 - val_accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.3023e-06 - accuracy: 1.0000 - val_loss: 6.4641e-07 - val_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.2809e-06 - accuracy: 1.0000 - val_loss: 5.4383e-07 - val_accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.0948e-06 - accuracy: 1.0000 - val_loss: 5.8495e-07 - val_accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.6577e-07 - accuracy: 1.0000 - val_loss: 5.3274e-07 - val_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.3461e-06 - accuracy: 1.0000 - val_loss: 7.1063e-07 - val_accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.3090e-06 - accuracy: 1.0000 - val_loss: 6.2931e-07 - val_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 7.7823e-07 - accuracy: 1.0000 - val_loss: 5.0687e-07 - val_accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 6.5790e-07 - accuracy: 1.0000 - val_loss: 5.0317e-07 - val_accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.3532e-07 - accuracy: 1.0000 - val_loss: 4.6575e-07 - val_accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 9.6378e-07 - accuracy: 1.0000 - val_loss: 3.9921e-07 - val_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 7.8891e-07 - accuracy: 1.0000 - val_loss: 6.0713e-07 - val_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.0150e-06 - accuracy: 1.0000 - val_loss: 4.5466e-07 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.0965e-06 - accuracy: 1.0000 - val_loss: 4.5651e-07 - val_accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.7060e-06 - accuracy: 1.0000 - val_loss: 5.0179e-07 - val_accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 9.5478e-07 - accuracy: 1.0000 - val_loss: 4.3063e-07 - val_accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 9.2665e-07 - accuracy: 1.0000 - val_loss: 5.0825e-07 - val_accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 5.6174e-07 - accuracy: 1.0000 - val_loss: 4.6344e-07 - val_accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 5.9154e-07 - accuracy: 1.0000 - val_loss: 4.2555e-07 - val_accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.8406e-07 - accuracy: 1.0000 - val_loss: 4.0198e-07 - val_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.4768e-07 - accuracy: 1.0000 - val_loss: 3.2205e-07 - val_accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5.1114e-07 - accuracy: 1.0000 - val_loss: 2.1716e-07 - val_accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 5.0551e-07 - accuracy: 1.0000 - val_loss: 2.9895e-07 - val_accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.2108e-07 - accuracy: 1.0000 - val_loss: 3.6548e-07 - val_accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.0934e-05 - accuracy: 1.0000 - val_loss: 3.4122e-04 - val_accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.8648e-05 - accuracy: 1.0000 - val_loss: 1.1052e-06 - val_accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.0414e-06 - accuracy: 1.0000 - val_loss: 9.8507e-07 - val_accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.5115e-06 - accuracy: 1.0000 - val_loss: 4.6667e-07 - val_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.8983e-06 - accuracy: 1.0000 - val_loss: 7.9054e-07 - val_accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 7.9733e-07 - accuracy: 1.0000 - val_loss: 6.1313e-07 - val_accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 8.8505e-07 - accuracy: 1.0000 - val_loss: 4.1862e-07 - val_accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 6.1593e-06 - accuracy: 1.0000 - val_loss: 1.3487e-06 - val_accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.8087e-06 - accuracy: 1.0000 - val_loss: 4.5512e-07 - val_accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.5902e-07 - accuracy: 1.0000 - val_loss: 4.4403e-07 - val_accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.0071e-06 - accuracy: 1.0000 - val_loss: 4.3386e-07 - val_accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 8.8675e-07 - accuracy: 1.0000 - val_loss: 3.9736e-07 - val_accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 6.3653e-07 - accuracy: 1.0000 - val_loss: 3.9921e-07 - val_accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 6.2129e-06 - accuracy: 1.0000 - val_loss: 1.8309e-06 - val_accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 5.9042e-07 - accuracy: 1.0000 - val_loss: 1.4719e-06 - val_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 4.3113e-06 - accuracy: 1.0000 - val_loss: 5.2627e-07 - val_accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 7.6355e-06 - accuracy: 1.0000 - val_loss: 1.1237e-06 - val_accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.1611e-06 - accuracy: 1.0000 - val_loss: 7.6467e-07 - val_accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.2567e-06 - accuracy: 1.0000 - val_loss: 2.7908e-07 - val_accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4.9989e-07 - accuracy: 1.0000 - val_loss: 4.0845e-07 - val_accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 8.5188e-07 - accuracy: 1.0000 - val_loss: 3.4238e-07 - val_accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 7.1806e-07 - accuracy: 1.0000 - val_loss: 3.0957e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 4.0992e-07 - accuracy: 1.0000 - val_loss: 2.5875e-07 - val_accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 4.2510e-07 - accuracy: 1.0000 - val_loss: 2.7677e-07 - val_accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.6372e-07 - accuracy: 1.0000 - val_loss: 2.9571e-07 - val_accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 4.1442e-07 - accuracy: 1.0000 - val_loss: 2.7815e-07 - val_accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 7.1355e-07 - accuracy: 1.0000 - val_loss: 2.4673e-07 - val_accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 5.5849e-06 - accuracy: 1.0000 - val_loss: 1.6762e-06 - val_accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 5.8027e-06 - accuracy: 1.0000 - val_loss: 3.6132e-07 - val_accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 2.1087e-07 - accuracy: 1.0000 - val_loss: 3.4654e-07 - val_accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 5.8592e-07 - accuracy: 1.0000 - val_loss: 2.9386e-07 - val_accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4.2060e-07 - accuracy: 1.0000 - val_loss: 2.8416e-07 - val_accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 5.0889e-07 - accuracy: 1.0000 - val_loss: 2.7723e-07 - val_accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.1368e-07 - accuracy: 1.0000 - val_loss: 2.2779e-07 - val_accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 7.0230e-07 - accuracy: 1.0000 - val_loss: 2.5089e-07 - val_accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.9568e-07 - accuracy: 1.0000 - val_loss: 1.5617e-07 - val_accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 5.4206e-07 - accuracy: 1.0000 - val_loss: 2.5967e-07 - val_accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.6485e-07 - accuracy: 1.0000 - val_loss: 2.2409e-07 - val_accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.8414e-07 - accuracy: 1.0000 - val_loss: 2.2594e-07 - val_accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 8.2771e-07 - accuracy: 1.0000 - val_loss: 1.8713e-07 - val_accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.6147e-07 - accuracy: 1.0000 - val_loss: 1.6449e-07 - val_accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4.1554e-07 - accuracy: 1.0000 - val_loss: 2.2502e-07 - val_accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 7.2312e-07 - accuracy: 1.0000 - val_loss: 1.4555e-07 - val_accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.0945e-07 - accuracy: 1.0000 - val_loss: 2.4350e-07 - val_accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 4.2398e-07 - accuracy: 1.0000 - val_loss: 1.9268e-07 - val_accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.1883e-07 - accuracy: 1.0000 - val_loss: 1.9730e-07 - val_accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.7375e-07 - accuracy: 1.0000 - val_loss: 1.9221e-07 - val_accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.9361e-07 - accuracy: 1.0000 - val_loss: 1.8251e-07 - val_accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.9231e-07 - accuracy: 1.0000 - val_loss: 1.6449e-07 - val_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.9530e-07 - accuracy: 1.0000 - val_loss: 1.7096e-07 - val_accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0805e-07 - accuracy: 1.0000 - val_loss: 1.4370e-07 - val_accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.7038e-07 - accuracy: 1.0000 - val_loss: 1.7050e-07 - val_accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.0214e-07 - accuracy: 1.0000 - val_loss: 1.8898e-07 - val_accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 3.9924e-07 - accuracy: 1.0000 - val_loss: 1.3908e-07 - val_accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.7843e-07 - accuracy: 1.0000 - val_loss: 1.7650e-07 - val_accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.1398e-06 - accuracy: 1.0000 - val_loss: 3.4238e-07 - val_accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.0382e-07 - accuracy: 1.0000 - val_loss: 1.4277e-07 - val_accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.5697e-07 - accuracy: 1.0000 - val_loss: 1.4924e-07 - val_accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.5069e-06 - accuracy: 1.0000 - val_loss: 4.2740e-07 - val_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.6728e-07 - accuracy: 1.0000 - val_loss: 1.7697e-07 - val_accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.6878e-07 - accuracy: 1.0000 - val_loss: 1.6726e-07 - val_accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.6822e-07 - accuracy: 1.0000 - val_loss: 1.1597e-07 - val_accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.8050e-07 - accuracy: 1.0000 - val_loss: 1.0119e-07 - val_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.1199e-07 - accuracy: 1.0000 - val_loss: 1.2984e-07 - val_accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.6082e-07 - accuracy: 1.0000 - val_loss: 9.5645e-08 - val_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.7938e-07 - accuracy: 1.0000 - val_loss: 8.8714e-08 - val_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 3.5256e-07 - accuracy: 1.0000 - val_loss: 1.1366e-07 - val_accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.0356e-07 - accuracy: 1.0000 - val_loss: 1.1597e-07 - val_accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.6766e-07 - accuracy: 1.0000 - val_loss: 1.1829e-07 - val_accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.3214e-07 - accuracy: 1.0000 - val_loss: 1.3168e-07 - val_accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.0637e-07 - accuracy: 1.0000 - val_loss: 1.1413e-07 - val_accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.6799e-06 - accuracy: 1.0000 - val_loss: 1.2396e-04 - val_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.1541e-04 - accuracy: 1.0000 - val_loss: 1.9175e-07 - val_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 3.9586e-07 - accuracy: 1.0000 - val_loss: 1.2337e-07 - val_accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 4.0092e-07 - accuracy: 1.0000 - val_loss: 1.8390e-07 - val_accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.5407e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.9512e-07 - accuracy: 1.0000 - val_loss: 1.6172e-07 - val_accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 2.3954e-07 - accuracy: 1.0000 - val_loss: 1.7234e-07 - val_accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.5763e-07 - accuracy: 1.0000 - val_loss: 1.7512e-07 - val_accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.1246e-07 - accuracy: 1.0000 - val_loss: 1.7465e-07 - val_accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.9080e-07 - accuracy: 1.0000 - val_loss: 1.5063e-07 - val_accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.6597e-07 - accuracy: 1.0000 - val_loss: 1.5895e-07 - val_accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.8612e-07 - accuracy: 1.0000 - val_loss: 8.1321e-08 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 8.2263e-07 - accuracy: 1.0000 - val_loss: 1.2984e-07 - val_accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.8219e-07 - accuracy: 1.0000 - val_loss: 1.4185e-07 - val_accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.8050e-07 - accuracy: 1.0000 - val_loss: 1.3030e-07 - val_accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 3.3738e-07 - accuracy: 1.0000 - val_loss: 1.2706e-07 - val_accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 7.2817e-07 - accuracy: 1.0000 - val_loss: 1.1828e-07 - val_accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.0243e-07 - accuracy: 1.0000 - val_loss: 1.2937e-07 - val_accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 3.9867e-07 - accuracy: 1.0000 - val_loss: 1.1690e-07 - val_accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.8275e-07 - accuracy: 1.0000 - val_loss: 1.2429e-07 - val_accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 1.3327e-07 - accuracy: 1.0000 - val_loss: 1.0904e-07 - val_accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 3.5931e-07 - accuracy: 1.0000 - val_loss: 1.0581e-07 - val_accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 4.9651e-07 - accuracy: 1.0000 - val_loss: 1.1551e-07 - val_accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.9062e-07 - accuracy: 1.0000 - val_loss: 1.0766e-07 - val_accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 2.5922e-07 - accuracy: 1.0000 - val_loss: 1.1782e-07 - val_accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.4685e-07 - accuracy: 1.0000 - val_loss: 5.9143e-08 - val_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 8.2151e-07 - accuracy: 1.0000 - val_loss: 1.2706e-07 - val_accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 3.3345e-07 - accuracy: 1.0000 - val_loss: 1.0997e-07 - val_accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 4.0204e-07 - accuracy: 1.0000 - val_loss: 1.0489e-07 - val_accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.0468e-07 - accuracy: 1.0000 - val_loss: 1.1644e-07 - val_accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.2652e-07 - accuracy: 1.0000 - val_loss: 1.1182e-07 - val_accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.7375e-07 - accuracy: 1.0000 - val_loss: 1.1274e-07 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 8.0578e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.7319e-07 - accuracy: 1.0000 - val_loss: 8.0397e-08 - val_accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.8444e-07 - accuracy: 1.0000 - val_loss: 8.1783e-08 - val_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.3495e-07 - accuracy: 1.0000 - val_loss: 1.0766e-07 - val_accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 9.5030e-08 - accuracy: 1.0000 - val_loss: 1.0442e-07 - val_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.8894e-07 - accuracy: 1.0000 - val_loss: 9.5183e-08 - val_accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.6822e-07 - accuracy: 1.0000 - val_loss: 1.0258e-07 - val_accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.4339e-07 - accuracy: 1.0000 - val_loss: 8.2707e-08 - val_accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.1415e-07 - accuracy: 1.0000 - val_loss: 1.0027e-07 - val_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 2.9521e-07 - accuracy: 1.0000 - val_loss: 1.0581e-07 - val_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.1865e-07 - accuracy: 1.0000 - val_loss: 7.1618e-08 - val_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 4.6221e-07 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 8.4346e-08 - accuracy: 1.0000 - val_loss: 1.0673e-07 - val_accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.3214e-07 - accuracy: 1.0000 - val_loss: 1.2244e-07 - val_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.1995e-07 - accuracy: 1.0000 - val_loss: 8.0859e-08 - val_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 8.5471e-08 - accuracy: 1.0000 - val_loss: 7.1156e-08 - val_accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.8500e-07 - accuracy: 1.0000 - val_loss: 8.5017e-08 - val_accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.3777e-07 - accuracy: 1.0000 - val_loss: 9.0562e-08 - val_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.0243e-07 - accuracy: 1.0000 - val_loss: 8.7790e-08 - val_accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.9343e-07 - accuracy: 1.0000 - val_loss: 7.8549e-08 - val_accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.3664e-07 - accuracy: 1.0000 - val_loss: 8.8252e-08 - val_accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.9690e-07 - accuracy: 1.0000 - val_loss: 7.5776e-08 - val_accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.8275e-07 - accuracy: 1.0000 - val_loss: 7.7625e-08 - val_accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 4.4478e-07 - accuracy: 1.0000 - val_loss: 6.9770e-08 - val_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.9681e-07 - accuracy: 1.0000 - val_loss: 9.1024e-08 - val_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 2.1649e-07 - accuracy: 1.0000 - val_loss: 6.6997e-08 - val_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.9370e-07 - accuracy: 1.0000 - val_loss: 1.4416e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 5.7355e-08 - accuracy: 1.0000 - val_loss: 1.4185e-07 - val_accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.0870e-07 - accuracy: 1.0000 - val_loss: 8.7328e-08 - val_accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.8781e-07 - accuracy: 1.0000 - val_loss: 1.0258e-07 - val_accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.6982e-07 - accuracy: 1.0000 - val_loss: 1.0304e-07 - val_accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.0131e-07 - accuracy: 1.0000 - val_loss: 1.1875e-07 - val_accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.1134e-07 - accuracy: 1.0000 - val_loss: 1.2152e-07 - val_accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.8855e-07 - accuracy: 1.0000 - val_loss: 6.8384e-08 - val_accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.3833e-07 - accuracy: 1.0000 - val_loss: 6.5611e-08 - val_accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 9.8404e-08 - accuracy: 1.0000 - val_loss: 6.0067e-08 - val_accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 9.5030e-08 - accuracy: 1.0000 - val_loss: 6.2377e-08 - val_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.3889e-07 - accuracy: 1.0000 - val_loss: 6.5149e-08 - val_accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.8725e-07 - accuracy: 1.0000 - val_loss: 6.3763e-08 - val_accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.2042e-07 - accuracy: 1.0000 - val_loss: 6.5611e-08 - val_accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.0065e-07 - accuracy: 1.0000 - val_loss: 6.3763e-08 - val_accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.6476e-07 - accuracy: 1.0000 - val_loss: 6.9770e-08 - val_accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.2258e-07 - accuracy: 1.0000 - val_loss: 6.5611e-08 - val_accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.5481e-07 - accuracy: 1.0000 - val_loss: 7.0694e-08 - val_accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.3383e-07 - accuracy: 1.0000 - val_loss: 6.0529e-08 - val_accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.3383e-07 - accuracy: 1.0000 - val_loss: 6.1915e-08 - val_accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.0628e-07 - accuracy: 1.0000 - val_loss: 5.1750e-08 - val_accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.0965e-07 - accuracy: 1.0000 - val_loss: 5.6832e-08 - val_accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.8387e-07 - accuracy: 1.0000 - val_loss: 6.5149e-08 - val_accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 4.3353e-07 - accuracy: 1.0000 - val_loss: 2.1162e-07 - val_accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.4901e-07 - accuracy: 1.0000 - val_loss: 6.7922e-08 - val_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.3383e-07 - accuracy: 1.0000 - val_loss: 1.5063e-07 - val_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 5.6003e-07 - accuracy: 1.0000 - val_loss: 9.0100e-08 - val_accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.7263e-07 - accuracy: 1.0000 - val_loss: 4.6205e-08 - val_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.2146e-07 - accuracy: 1.0000 - val_loss: 5.3136e-08 - val_accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.7825e-07 - accuracy: 1.0000 - val_loss: 8.3631e-08 - val_accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6.0110e-07 - accuracy: 1.0000 - val_loss: 6.2839e-08 - val_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.0065e-07 - accuracy: 1.0000 - val_loss: 3.6502e-08 - val_accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 5.1170e-08 - accuracy: 1.0000 - val_loss: 4.4357e-08 - val_accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 2.8902e-07 - accuracy: 1.0000 - val_loss: 4.4819e-08 - val_accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.0083e-07 - accuracy: 1.0000 - val_loss: 4.0661e-08 - val_accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.7675e-08 - accuracy: 1.0000 - val_loss: 4.0661e-08 - val_accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.4123e-07 - accuracy: 1.0000 - val_loss: 3.4192e-08 - val_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 6.5958e-07 - accuracy: 1.0000 - val_loss: 9.7955e-08 - val_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.0628e-07 - accuracy: 1.0000 - val_loss: 6.3763e-08 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.8845e-08 - accuracy: 1.0000 - val_loss: 4.7129e-08 - val_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.0065e-07 - accuracy: 1.0000 - val_loss: 4.2971e-08 - val_accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.8358e-08 - accuracy: 1.0000 - val_loss: 4.3433e-08 - val_accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 8.9969e-08 - accuracy: 1.0000 - val_loss: 3.6502e-08 - val_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.9343e-07 - accuracy: 1.0000 - val_loss: 3.6040e-08 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 6.7477e-08 - accuracy: 1.0000 - val_loss: 3.2806e-08 - val_accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 6.2416e-08 - accuracy: 1.0000 - val_loss: 3.2806e-08 - val_accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 9.8966e-08 - accuracy: 1.0000 - val_loss: 3.2344e-08 - val_accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 5.7355e-08 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 8.0410e-08 - accuracy: 1.0000 - val_loss: 2.7261e-08 - val_accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.2614e-08 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 4.3298e-08 - accuracy: 1.0000 - val_loss: 3.0033e-08 - val_accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 8.9969e-08 - accuracy: 1.0000 - val_loss: 2.9571e-08 - val_accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.0571e-07 - accuracy: 1.0000 - val_loss: 3.2344e-08 - val_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.7150e-07 - accuracy: 1.0000 - val_loss: 3.0957e-08 - val_accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 6.3541e-08 - accuracy: 1.0000 - val_loss: 2.9109e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.6203e-07 - accuracy: 1.0000 - val_loss: 5.9142e-08 - val_accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.0486e-08 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5.5668e-08 - accuracy: 1.0000 - val_loss: 5.4060e-08 - val_accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1359e-07 - accuracy: 1.0000 - val_loss: 5.1750e-08 - val_accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.4768e-07 - accuracy: 1.0000 - val_loss: 1.0627e-07 - val_accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 8.3222e-08 - accuracy: 1.0000 - val_loss: 5.6370e-08 - val_accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.3777e-07 - accuracy: 1.0000 - val_loss: 2.3103e-08 - val_accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 5.0608e-08 - accuracy: 1.0000 - val_loss: 3.3730e-08 - val_accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 7.8723e-08 - accuracy: 1.0000 - val_loss: 4.6667e-08 - val_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 4.9483e-08 - accuracy: 1.0000 - val_loss: 4.2509e-08 - val_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 3.8799e-08 - accuracy: 1.0000 - val_loss: 2.9571e-08 - val_accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 4.2173e-08 - accuracy: 1.0000 - val_loss: 3.6502e-08 - val_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 7.1975e-08 - accuracy: 1.0000 - val_loss: 2.4489e-08 - val_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 4.0486e-08 - accuracy: 1.0000 - val_loss: 2.5875e-08 - val_accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 4.2735e-08 - accuracy: 1.0000 - val_loss: 2.0330e-08 - val_accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 3.7675e-08 - accuracy: 1.0000 - val_loss: 2.0330e-08 - val_accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.8237e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.1048e-08 - accuracy: 1.0000 - val_loss: 1.8020e-08 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 6.0729e-08 - accuracy: 1.0000 - val_loss: 2.1254e-08 - val_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 3.3738e-08 - accuracy: 1.0000 - val_loss: 1.9406e-08 - val_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 6.5790e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 3.5425e-08 - accuracy: 1.0000 - val_loss: 1.6634e-08 - val_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 3.4301e-08 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.5988e-08 - accuracy: 1.0000 - val_loss: 1.5710e-08 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 5.7355e-08 - accuracy: 1.0000 - val_loss: 1.5248e-08 - val_accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.8678e-08 - accuracy: 1.0000 - val_loss: 1.4324e-08 - val_accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 3.2614e-08 - accuracy: 1.0000 - val_loss: 1.4324e-08 - val_accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 3.3738e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.0909e-07 - accuracy: 1.0000 - val_loss: 7.0232e-08 - val_accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 6.2581e-07 - accuracy: 1.0000 - val_loss: 2.7168e-07 - val_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5.4429e-07 - accuracy: 1.0000 - val_loss: 2.1716e-08 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.6925e-07 - accuracy: 1.0000 - val_loss: 1.5248e-08 - val_accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.7796e-08 - accuracy: 1.0000 - val_loss: 1.6172e-08 - val_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 4.2173e-08 - accuracy: 1.0000 - val_loss: 1.3862e-08 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 4.2173e-08 - accuracy: 1.0000 - val_loss: 1.4786e-08 - val_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.7158e-08 - accuracy: 1.0000 - val_loss: 2.1716e-08 - val_accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 8.4908e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 1.4324e-08 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 4.3860e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4.2735e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 3.9362e-08 - accuracy: 1.0000 - val_loss: 1.2475e-08 - val_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.1246e-07 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 2.2641e-08 - val_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 3.9924e-08 - accuracy: 1.0000 - val_loss: 1.3862e-08 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2652e-07 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 4.6672e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 5.4600e-07 - accuracy: 1.0000 - val_loss: 2.7815e-07 - val_accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 9.3171e-07 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 3.7112e-08 - accuracy: 1.0000 - val_loss: 2.2178e-08 - val_accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 2.0805e-08 - accuracy: 1.0000 - val_loss: 1.7558e-08 - val_accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 4.4985e-08 - accuracy: 1.0000 - val_loss: 1.2475e-08 - val_accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 3.7112e-08 - accuracy: 1.0000 - val_loss: 1.8482e-08 - val_accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 7.8161e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 1.5745e-08 - accuracy: 1.0000 - val_loss: 1.4786e-08 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.1489e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.7553e-08 - accuracy: 1.0000 - val_loss: 1.2475e-08 - val_accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 4.1048e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 1.7994e-08 - accuracy: 1.0000 - val_loss: 1.2013e-08 - val_accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 2.4179e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0243e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 2.9802e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.2492e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.5745e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 2.5866e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 5.3982e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.7994e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.5425e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 8.7720e-08 - accuracy: 1.0000 - val_loss: 1.8020e-08 - val_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.3495e-08 - accuracy: 1.0000 - val_loss: 1.6634e-08 - val_accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 1.0122e-07 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 6.6915e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 4.7234e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 8.3169e-09 - val_accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 2.6428e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 8.9969e-08 - accuracy: 1.0000 - val_loss: 1.2475e-08 - val_accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 5.6793e-08 - accuracy: 1.0000 - val_loss: 1.0627e-08 - val_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 4.7234e-08 - accuracy: 1.0000 - val_loss: 1.0165e-08 - val_accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.2492e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 3.0927e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 2.9240e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 3.8799e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.3495e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 3.8237e-08 - accuracy: 1.0000 - val_loss: 1.2475e-08 - val_accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 6.5790e-08 - accuracy: 1.0000 - val_loss: 2.7723e-08 - val_accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 2.9802e-08 - accuracy: 1.0000 - val_loss: 2.0330e-08 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 4.4985e-08 - accuracy: 1.0000 - val_loss: 1.2937e-08 - val_accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 1.1551e-08 - val_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 3.7112e-08 - accuracy: 1.0000 - val_loss: 6.9308e-09 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.9681e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 2.1930e-08 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 7.8723e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.1808e-08 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.9681e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 2.0805e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 9.7031e-09 - val_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 3.8799e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 6.7477e-09 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 2.5866e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 3.9362e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.7432e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.8556e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 7.3100e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 1.6869e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.9681e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.5182e-08 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.6869e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 3.9362e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 1.4058e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 3.0365e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 5.6231e-09 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 3.3738e-08 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.8781e-07 - accuracy: 1.0000 - val_loss: 3.8812e-08 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 5.2857e-08 - accuracy: 1.0000 - val_loss: 1.1089e-08 - val_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 9.9528e-08 - accuracy: 1.0000 - val_loss: 1.3862e-09 - val_accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 2.6428e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 7.3100e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 8.6033e-08 - accuracy: 1.0000 - val_loss: 8.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 7.3928e-09 - val_accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 2.8115e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.6869e-08 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 3.9361e-08 - accuracy: 1.0000 - val_loss: 7.8549e-09 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 3.8237e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.6869e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.8237e-08 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.4620e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.5182e-08 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 3.3738e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.7432e-08 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.2371e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 5.0045e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.5988e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.0684e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.2717e-07 - accuracy: 1.0000 - val_loss: 7.1012e-07 - val_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 7.9821e-06 - accuracy: 1.0000 - val_loss: 1.3587e-06 - val_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.5816e-05 - accuracy: 1.0000 - val_loss: 9.2410e-09 - val_accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 1.6869e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.1696e-07 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 8.4346e-09 - accuracy: 1.0000 - val_loss: 6.4687e-09 - val_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.0628e-07 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 1.5745e-08 - accuracy: 1.0000 - val_loss: 6.0067e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 4.8921e-08 - accuracy: 1.0000 - val_loss: 5.5446e-09 - val_accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.6307e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.2933e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.3495e-08 - accuracy: 1.0000 - val_loss: 4.6205e-09 - val_accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.0805e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 4.1585e-09 - val_accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 7.3100e-09 - accuracy: 1.0000 - val_loss: 5.0826e-09 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.8837e-07 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.3055e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.0122e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.7994e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 7.8723e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.3552e-07 - accuracy: 1.0000 - val_loss: 3.6964e-09 - val_accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 4.4985e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.6231e-09 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.1246e-08 - accuracy: 1.0000 - val_loss: 3.2344e-09 - val_accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 6.1854e-09 - accuracy: 1.0000 - val_loss: 1.8482e-09 - val_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 7.3100e-09 - accuracy: 1.0000 - val_loss: 2.3103e-09 - val_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.1808e-08 - accuracy: 1.0000 - val_loss: 9.2410e-10 - val_accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 3.3176e-08 - accuracy: 1.0000 - val_loss: 2.7723e-09 - val_accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 8.9969e-09 - accuracy: 1.0000 - val_loss: 1.3862e-09 - val_accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 9.5592e-09 - accuracy: 1.0000 - val_loss: 1.3862e-09 - val_accuracy: 1.0000\n",
      "Model training finished.\n",
      "Train loss: 0.0, train accuracy: 1.0.\n",
      "Evaluating model performance...\n",
      "Test loss: 0.0, test accuracy: 1.0.\n"
     ]
    }
   ],
   "source": [
    "run_experiment(nn_model_full, tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               train_dataset, val_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:44:53.534218Z",
     "start_time": "2021-07-04T15:44:52.932862Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jymch\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "bnn_model_full = create_bnn_model(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:48:53.606220Z",
     "start_time": "2021-07-04T15:44:55.526979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025CFC798048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025CFC798048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - ETA: 0s - loss: 38.5882 - accuracy: 0.5094WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025CFFD5BAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025CFFD5BAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.5882 - accuracy: 0.5094 - val_loss: 38.8259 - val_accuracy: 0.4496\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 38.5333 - accuracy: 0.6179 - val_loss: 38.5688 - val_accuracy: 0.4380\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 38.5015 - accuracy: 0.5189 - val_loss: 38.4985 - val_accuracy: 0.5155\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 38.4702 - accuracy: 0.5660 - val_loss: 38.4780 - val_accuracy: 0.4457\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 38.4496 - accuracy: 0.5094 - val_loss: 38.4697 - val_accuracy: 0.5271\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 38.4193 - accuracy: 0.5330 - val_loss: 38.3784 - val_accuracy: 0.6279\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 38.3801 - accuracy: 0.6321 - val_loss: 38.3993 - val_accuracy: 0.5581\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 38.3651 - accuracy: 0.6226 - val_loss: 38.4134 - val_accuracy: 0.4651\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 38.3400 - accuracy: 0.6509 - val_loss: 38.3685 - val_accuracy: 0.5039\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 38.3267 - accuracy: 0.7264 - val_loss: 38.3215 - val_accuracy: 0.5698\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 38.3063 - accuracy: 0.7311 - val_loss: 38.3269 - val_accuracy: 0.4961\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 38.2818 - accuracy: 0.7547 - val_loss: 38.3243 - val_accuracy: 0.5930\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 38.2586 - accuracy: 0.8019 - val_loss: 38.2712 - val_accuracy: 0.5581\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 38.2353 - accuracy: 0.6934 - val_loss: 38.2350 - val_accuracy: 0.5969\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 38.2085 - accuracy: 0.8019 - val_loss: 38.2352 - val_accuracy: 0.5620\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 38.2094 - accuracy: 0.7170 - val_loss: 38.2081 - val_accuracy: 0.5736\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 38.1826 - accuracy: 0.5330 - val_loss: 38.1815 - val_accuracy: 0.6085\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 38.1334 - accuracy: 0.7736 - val_loss: 38.1543 - val_accuracy: 0.5659\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 38.1331 - accuracy: 0.6226 - val_loss: 38.1272 - val_accuracy: 0.6240\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 38.0795 - accuracy: 0.8302 - val_loss: 38.1040 - val_accuracy: 0.6434\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 38.0749 - accuracy: 0.6462 - val_loss: 38.1083 - val_accuracy: 0.5853\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 38.0818 - accuracy: 0.6792 - val_loss: 38.0975 - val_accuracy: 0.5853\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 38.0370 - accuracy: 0.7736 - val_loss: 38.0678 - val_accuracy: 0.6202\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 38.0236 - accuracy: 0.7264 - val_loss: 38.0559 - val_accuracy: 0.6434\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 38.0098 - accuracy: 0.7925 - val_loss: 38.0437 - val_accuracy: 0.6357\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 37.9578 - accuracy: 0.8443 - val_loss: 37.9889 - val_accuracy: 0.7248\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 37.9182 - accuracy: 0.8538 - val_loss: 37.9411 - val_accuracy: 0.7636\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 37.9353 - accuracy: 0.8019 - val_loss: 37.9598 - val_accuracy: 0.6705\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 37.9051 - accuracy: 0.8443 - val_loss: 37.9618 - val_accuracy: 0.6395\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 37.8974 - accuracy: 0.8585 - val_loss: 37.9280 - val_accuracy: 0.7054\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 37.8776 - accuracy: 0.7264 - val_loss: 37.8929 - val_accuracy: 0.7364\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 37.8377 - accuracy: 0.8160 - val_loss: 37.8902 - val_accuracy: 0.6822\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 37.8411 - accuracy: 0.8538 - val_loss: 37.8794 - val_accuracy: 0.6899\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 37.7624 - accuracy: 0.8349 - val_loss: 37.8629 - val_accuracy: 0.6628\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 37.7787 - accuracy: 0.8113 - val_loss: 37.8170 - val_accuracy: 0.7209\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 37.7222 - accuracy: 0.8491 - val_loss: 37.7890 - val_accuracy: 0.6938\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 37.7047 - accuracy: 0.8443 - val_loss: 37.7682 - val_accuracy: 0.7713\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 37.7124 - accuracy: 0.8396 - val_loss: 37.7836 - val_accuracy: 0.7054\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 37.6911 - accuracy: 0.8113 - val_loss: 37.7090 - val_accuracy: 0.7442\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 37.6218 - accuracy: 0.8491 - val_loss: 37.7096 - val_accuracy: 0.7597\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 37.6303 - accuracy: 0.8538 - val_loss: 37.6648 - val_accuracy: 0.7946\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 37.6103 - accuracy: 0.8538 - val_loss: 37.6804 - val_accuracy: 0.7519\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 37.6053 - accuracy: 0.8585 - val_loss: 37.7018 - val_accuracy: 0.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 37.6035 - accuracy: 0.8491 - val_loss: 37.6468 - val_accuracy: 0.7481\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 37.5098 - accuracy: 0.8632 - val_loss: 37.6299 - val_accuracy: 0.7326\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 37.5540 - accuracy: 0.8396 - val_loss: 37.6108 - val_accuracy: 0.7558\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 37.5154 - accuracy: 0.8491 - val_loss: 37.5520 - val_accuracy: 0.7558\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 37.4637 - accuracy: 0.8396 - val_loss: 37.5650 - val_accuracy: 0.7713\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 37.4725 - accuracy: 0.8632 - val_loss: 37.6179 - val_accuracy: 0.7093\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 37.4431 - accuracy: 0.8585 - val_loss: 37.5105 - val_accuracy: 0.7868\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 37.4315 - accuracy: 0.8538 - val_loss: 37.4898 - val_accuracy: 0.7984\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 37.3640 - accuracy: 0.8679 - val_loss: 37.4912 - val_accuracy: 0.7481\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 37.3797 - accuracy: 0.8396 - val_loss: 37.4747 - val_accuracy: 0.7636\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 37.3851 - accuracy: 0.8538 - val_loss: 37.5307 - val_accuracy: 0.7209\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 37.3380 - accuracy: 0.8349 - val_loss: 37.4377 - val_accuracy: 0.7558\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 37.3150 - accuracy: 0.8726 - val_loss: 37.5299 - val_accuracy: 0.7209\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 37.3006 - accuracy: 0.8538 - val_loss: 37.3930 - val_accuracy: 0.7713\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 37.2845 - accuracy: 0.8349 - val_loss: 37.3505 - val_accuracy: 0.8140\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 37.2346 - accuracy: 0.8962 - val_loss: 37.4132 - val_accuracy: 0.7364\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 37.2572 - accuracy: 0.8396 - val_loss: 37.4323 - val_accuracy: 0.7132\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 37.2086 - accuracy: 0.8821 - val_loss: 37.3422 - val_accuracy: 0.7907\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 37.2216 - accuracy: 0.8538 - val_loss: 37.3331 - val_accuracy: 0.7791\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 37.2309 - accuracy: 0.8396 - val_loss: 37.3705 - val_accuracy: 0.7287\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 37.1928 - accuracy: 0.8632 - val_loss: 37.3388 - val_accuracy: 0.7442\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 37.1551 - accuracy: 0.8821 - val_loss: 37.2988 - val_accuracy: 0.7636\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 37.1819 - accuracy: 0.8585 - val_loss: 37.3460 - val_accuracy: 0.6899\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 37.1265 - accuracy: 0.8632 - val_loss: 37.2140 - val_accuracy: 0.7946\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 37.0972 - accuracy: 0.8538 - val_loss: 37.2984 - val_accuracy: 0.7248\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 37.0844 - accuracy: 0.8632 - val_loss: 37.2080 - val_accuracy: 0.7713\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 37.0883 - accuracy: 0.8443 - val_loss: 37.2522 - val_accuracy: 0.7442\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 37.0324 - accuracy: 0.9057 - val_loss: 37.3520 - val_accuracy: 0.6860\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 37.0282 - accuracy: 0.8632 - val_loss: 37.2310 - val_accuracy: 0.7636\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 37.0394 - accuracy: 0.8585 - val_loss: 37.1938 - val_accuracy: 0.7597\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 37.0349 - accuracy: 0.8585 - val_loss: 37.1085 - val_accuracy: 0.8023\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 36.9754 - accuracy: 0.8726 - val_loss: 37.1965 - val_accuracy: 0.7326\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 37.0104 - accuracy: 0.8774 - val_loss: 37.2859 - val_accuracy: 0.7209\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 36.9386 - accuracy: 0.8821 - val_loss: 37.1325 - val_accuracy: 0.7713\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 36.9161 - accuracy: 0.8821 - val_loss: 37.0935 - val_accuracy: 0.7558\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 36.9306 - accuracy: 0.8726 - val_loss: 37.1800 - val_accuracy: 0.7209\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 36.9418 - accuracy: 0.8538 - val_loss: 37.1742 - val_accuracy: 0.7209\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 36.9240 - accuracy: 0.8585 - val_loss: 37.0849 - val_accuracy: 0.7713\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 36.8736 - accuracy: 0.8585 - val_loss: 36.9926 - val_accuracy: 0.7946\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 36.8899 - accuracy: 0.8538 - val_loss: 36.9966 - val_accuracy: 0.7713\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 36.8465 - accuracy: 0.8868 - val_loss: 36.9215 - val_accuracy: 0.8295\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 36.8478 - accuracy: 0.8585 - val_loss: 36.9711 - val_accuracy: 0.7597\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 36.7939 - accuracy: 0.8821 - val_loss: 36.9021 - val_accuracy: 0.7984\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 36.8037 - accuracy: 0.8774 - val_loss: 36.9273 - val_accuracy: 0.7674\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 36.7652 - accuracy: 0.8962 - val_loss: 36.8641 - val_accuracy: 0.8140\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 36.8028 - accuracy: 0.8632 - val_loss: 36.9444 - val_accuracy: 0.7558\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 36.7632 - accuracy: 0.8726 - val_loss: 36.8771 - val_accuracy: 0.7868\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 36.8133 - accuracy: 0.8349 - val_loss: 36.8605 - val_accuracy: 0.8101\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 36.7086 - accuracy: 0.8915 - val_loss: 36.7945 - val_accuracy: 0.8333\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 36.7258 - accuracy: 0.8774 - val_loss: 36.8588 - val_accuracy: 0.7791\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 36.7124 - accuracy: 0.8491 - val_loss: 36.8785 - val_accuracy: 0.7791\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 36.6866 - accuracy: 0.8726 - val_loss: 36.7565 - val_accuracy: 0.8333\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 36.6305 - accuracy: 0.8868 - val_loss: 36.7307 - val_accuracy: 0.8411\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 36.6731 - accuracy: 0.8679 - val_loss: 36.7151 - val_accuracy: 0.8333\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 36.6263 - accuracy: 0.8774 - val_loss: 36.7205 - val_accuracy: 0.8217\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 36.6377 - accuracy: 0.8679 - val_loss: 36.7418 - val_accuracy: 0.7868\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 211ms/step - loss: 36.6014 - accuracy: 0.8868 - val_loss: 36.7140 - val_accuracy: 0.8140\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 36.6028 - accuracy: 0.8632 - val_loss: 36.6795 - val_accuracy: 0.8217\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 36.5707 - accuracy: 0.8868 - val_loss: 36.6721 - val_accuracy: 0.8140\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 36.5458 - accuracy: 0.8962 - val_loss: 36.6551 - val_accuracy: 0.8256\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 36.5198 - accuracy: 0.8915 - val_loss: 36.5885 - val_accuracy: 0.8450\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 36.5211 - accuracy: 0.8679 - val_loss: 36.6703 - val_accuracy: 0.7868\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 36.5514 - accuracy: 0.8491 - val_loss: 36.5689 - val_accuracy: 0.8256\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 36.4871 - accuracy: 0.8821 - val_loss: 36.6142 - val_accuracy: 0.8178\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 36.4535 - accuracy: 0.8915 - val_loss: 36.5658 - val_accuracy: 0.8256\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 36.4651 - accuracy: 0.8868 - val_loss: 36.5109 - val_accuracy: 0.8488\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 36.4671 - accuracy: 0.8915 - val_loss: 36.5073 - val_accuracy: 0.8256\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 36.4677 - accuracy: 0.8915 - val_loss: 36.5265 - val_accuracy: 0.8178\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 36.3923 - accuracy: 0.8915 - val_loss: 36.4922 - val_accuracy: 0.8372\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 36.3933 - accuracy: 0.8821 - val_loss: 36.5477 - val_accuracy: 0.7829\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 36.3888 - accuracy: 0.8915 - val_loss: 36.5112 - val_accuracy: 0.8140\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 36.3484 - accuracy: 0.8915 - val_loss: 36.4324 - val_accuracy: 0.8527\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 36.3585 - accuracy: 0.8726 - val_loss: 36.4547 - val_accuracy: 0.8101\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 36.3214 - accuracy: 0.9009 - val_loss: 36.4516 - val_accuracy: 0.8178\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 36.2921 - accuracy: 0.9104 - val_loss: 36.4326 - val_accuracy: 0.8411\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 36.3231 - accuracy: 0.8726 - val_loss: 36.4525 - val_accuracy: 0.8101\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 36.3132 - accuracy: 0.8821 - val_loss: 36.3793 - val_accuracy: 0.8333\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 36.2837 - accuracy: 0.8726 - val_loss: 36.3568 - val_accuracy: 0.8566\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 36.2786 - accuracy: 0.8868 - val_loss: 36.3423 - val_accuracy: 0.8450\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 36.2143 - accuracy: 0.8868 - val_loss: 36.3827 - val_accuracy: 0.8256\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 36.2976 - accuracy: 0.8585 - val_loss: 36.3163 - val_accuracy: 0.8295\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 36.2356 - accuracy: 0.9009 - val_loss: 36.3079 - val_accuracy: 0.8372\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 36.2224 - accuracy: 0.8868 - val_loss: 36.2624 - val_accuracy: 0.8527\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 36.1777 - accuracy: 0.8962 - val_loss: 36.2846 - val_accuracy: 0.8333\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 36.1608 - accuracy: 0.8962 - val_loss: 36.3143 - val_accuracy: 0.8256\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 36.1549 - accuracy: 0.9009 - val_loss: 36.2881 - val_accuracy: 0.8333\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 36.1233 - accuracy: 0.9151 - val_loss: 36.2384 - val_accuracy: 0.8372\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 36.0582 - accuracy: 0.9387 - val_loss: 36.2096 - val_accuracy: 0.8411\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 36.1008 - accuracy: 0.9009 - val_loss: 36.2056 - val_accuracy: 0.8411\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 36.0888 - accuracy: 0.9009 - val_loss: 36.1849 - val_accuracy: 0.8295\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 36.0828 - accuracy: 0.8962 - val_loss: 36.1476 - val_accuracy: 0.8450\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 36.0696 - accuracy: 0.9057 - val_loss: 36.1377 - val_accuracy: 0.8488\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 36.0830 - accuracy: 0.8632 - val_loss: 36.1291 - val_accuracy: 0.8450\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 36.0256 - accuracy: 0.9057 - val_loss: 36.0740 - val_accuracy: 0.8566\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 35.9708 - accuracy: 0.9198 - val_loss: 36.1053 - val_accuracy: 0.8333\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 35.9925 - accuracy: 0.8868 - val_loss: 36.0624 - val_accuracy: 0.8566\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 35.9755 - accuracy: 0.9198 - val_loss: 36.0582 - val_accuracy: 0.8527\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 35.9414 - accuracy: 0.9104 - val_loss: 36.0760 - val_accuracy: 0.8488\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 35.9651 - accuracy: 0.9057 - val_loss: 36.0288 - val_accuracy: 0.8488\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 35.9602 - accuracy: 0.8868 - val_loss: 35.9973 - val_accuracy: 0.8488\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 35.8953 - accuracy: 0.9292 - val_loss: 35.9951 - val_accuracy: 0.8450\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 35.9469 - accuracy: 0.8679 - val_loss: 35.9880 - val_accuracy: 0.8450\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 35.8698 - accuracy: 0.9104 - val_loss: 35.9703 - val_accuracy: 0.8411\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 35.9148 - accuracy: 0.8774 - val_loss: 36.0419 - val_accuracy: 0.8023\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 35.8868 - accuracy: 0.8821 - val_loss: 35.9116 - val_accuracy: 0.8643\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 35.8717 - accuracy: 0.8915 - val_loss: 35.9615 - val_accuracy: 0.8295\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 35.7986 - accuracy: 0.9292 - val_loss: 35.8628 - val_accuracy: 0.8798\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 35.8375 - accuracy: 0.9057 - val_loss: 35.9381 - val_accuracy: 0.8372\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 35.8186 - accuracy: 0.9104 - val_loss: 35.8386 - val_accuracy: 0.8605\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 35.7944 - accuracy: 0.9057 - val_loss: 35.8665 - val_accuracy: 0.8295\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 35.7628 - accuracy: 0.9009 - val_loss: 35.8350 - val_accuracy: 0.8566\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 35.7976 - accuracy: 0.8632 - val_loss: 35.8308 - val_accuracy: 0.8643\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step - loss: 35.7367 - accuracy: 0.9245 - val_loss: 35.8325 - val_accuracy: 0.8295\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 35.7351 - accuracy: 0.9104 - val_loss: 35.7845 - val_accuracy: 0.8682\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 35.7588 - accuracy: 0.8821 - val_loss: 35.7824 - val_accuracy: 0.8566\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 35.6933 - accuracy: 0.9057 - val_loss: 35.7471 - val_accuracy: 0.8837\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 35.7340 - accuracy: 0.8774 - val_loss: 35.7620 - val_accuracy: 0.8411\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 35.7115 - accuracy: 0.9009 - val_loss: 35.7320 - val_accuracy: 0.8488\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 35.6880 - accuracy: 0.8868 - val_loss: 35.6811 - val_accuracy: 0.8876\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 35.6509 - accuracy: 0.9009 - val_loss: 35.7517 - val_accuracy: 0.8450\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 35.6018 - accuracy: 0.9104 - val_loss: 35.6578 - val_accuracy: 0.8953\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 35.6709 - accuracy: 0.8962 - val_loss: 35.6196 - val_accuracy: 0.9109\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 35.5816 - accuracy: 0.9057 - val_loss: 35.6641 - val_accuracy: 0.8760\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 35.5909 - accuracy: 0.8915 - val_loss: 35.6414 - val_accuracy: 0.8643\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 35.5635 - accuracy: 0.9198 - val_loss: 35.5881 - val_accuracy: 0.8876\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 35.5714 - accuracy: 0.8868 - val_loss: 35.5625 - val_accuracy: 0.8915\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 35.5510 - accuracy: 0.9009 - val_loss: 35.5864 - val_accuracy: 0.8643\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 35.5334 - accuracy: 0.9057 - val_loss: 35.5945 - val_accuracy: 0.8605\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 35.5195 - accuracy: 0.9009 - val_loss: 35.5180 - val_accuracy: 0.8837\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 35.5241 - accuracy: 0.9057 - val_loss: 35.5429 - val_accuracy: 0.8527\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 35.4955 - accuracy: 0.9151 - val_loss: 35.5433 - val_accuracy: 0.8643\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 35.5003 - accuracy: 0.8915 - val_loss: 35.4837 - val_accuracy: 0.8760\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 35.4469 - accuracy: 0.9104 - val_loss: 35.4549 - val_accuracy: 0.9031\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 35.4422 - accuracy: 0.9057 - val_loss: 35.4546 - val_accuracy: 0.8798\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 35.4485 - accuracy: 0.8962 - val_loss: 35.4835 - val_accuracy: 0.8643\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 35.3979 - accuracy: 0.9104 - val_loss: 35.4771 - val_accuracy: 0.8566\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 35.3710 - accuracy: 0.9104 - val_loss: 35.4105 - val_accuracy: 0.8798\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 35.4156 - accuracy: 0.8962 - val_loss: 35.3867 - val_accuracy: 0.8876\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 35.3292 - accuracy: 0.9434 - val_loss: 35.3962 - val_accuracy: 0.8721\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 35.3470 - accuracy: 0.9057 - val_loss: 35.4232 - val_accuracy: 0.8643\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 35.3028 - accuracy: 0.9245 - val_loss: 35.3673 - val_accuracy: 0.8721\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 35.3219 - accuracy: 0.9009 - val_loss: 35.3655 - val_accuracy: 0.8760\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 35.2478 - accuracy: 0.9245 - val_loss: 35.3644 - val_accuracy: 0.8837\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 35.2800 - accuracy: 0.9151 - val_loss: 35.3393 - val_accuracy: 0.8992\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 35.2936 - accuracy: 0.9151 - val_loss: 35.2844 - val_accuracy: 0.9031\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 35.2453 - accuracy: 0.9151 - val_loss: 35.2832 - val_accuracy: 0.8837\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 35.2319 - accuracy: 0.9104 - val_loss: 35.3136 - val_accuracy: 0.8682\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 35.2451 - accuracy: 0.9104 - val_loss: 35.2493 - val_accuracy: 0.8915\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 35.2322 - accuracy: 0.8962 - val_loss: 35.2359 - val_accuracy: 0.8915\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 35.1767 - accuracy: 0.9198 - val_loss: 35.2638 - val_accuracy: 0.8721\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 35.1678 - accuracy: 0.9198 - val_loss: 35.2107 - val_accuracy: 0.8915\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 35.1529 - accuracy: 0.9387 - val_loss: 35.2184 - val_accuracy: 0.8760\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 35.1845 - accuracy: 0.8962 - val_loss: 35.1979 - val_accuracy: 0.8682\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 35.1343 - accuracy: 0.9245 - val_loss: 35.1604 - val_accuracy: 0.8992\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 35.1024 - accuracy: 0.9198 - val_loss: 35.1414 - val_accuracy: 0.8992\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 35.0929 - accuracy: 0.9151 - val_loss: 35.1511 - val_accuracy: 0.8837\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 35.0502 - accuracy: 0.9387 - val_loss: 35.0784 - val_accuracy: 0.9109\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 35.1023 - accuracy: 0.9104 - val_loss: 35.1037 - val_accuracy: 0.8915\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 35.0812 - accuracy: 0.9151 - val_loss: 35.0806 - val_accuracy: 0.8915\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 35.0457 - accuracy: 0.9198 - val_loss: 35.0768 - val_accuracy: 0.8992\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 35.0217 - accuracy: 0.9292 - val_loss: 35.0469 - val_accuracy: 0.9070\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 35.0674 - accuracy: 0.8821 - val_loss: 35.0544 - val_accuracy: 0.8643\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 35.0138 - accuracy: 0.9292 - val_loss: 35.0519 - val_accuracy: 0.8682\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 35.0194 - accuracy: 0.9057 - val_loss: 35.0134 - val_accuracy: 0.8915\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 34.9783 - accuracy: 0.9245 - val_loss: 35.0085 - val_accuracy: 0.8798\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 34.9377 - accuracy: 0.9245 - val_loss: 35.0165 - val_accuracy: 0.8760\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 34.9743 - accuracy: 0.9057 - val_loss: 34.9753 - val_accuracy: 0.8798\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 34.9619 - accuracy: 0.8962 - val_loss: 34.9170 - val_accuracy: 0.9109\n",
      "Epoch 212/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step - loss: 34.9083 - accuracy: 0.9387 - val_loss: 34.9168 - val_accuracy: 0.9031\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 34.9191 - accuracy: 0.9104 - val_loss: 34.9098 - val_accuracy: 0.9109\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 34.8550 - accuracy: 0.9198 - val_loss: 34.8873 - val_accuracy: 0.8953\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 34.9007 - accuracy: 0.9104 - val_loss: 34.8679 - val_accuracy: 0.9186\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 34.8724 - accuracy: 0.9198 - val_loss: 34.8517 - val_accuracy: 0.9186\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 34.8308 - accuracy: 0.9245 - val_loss: 34.8913 - val_accuracy: 0.8837\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 34.8034 - accuracy: 0.9387 - val_loss: 34.8634 - val_accuracy: 0.8953\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 34.8380 - accuracy: 0.9104 - val_loss: 34.8149 - val_accuracy: 0.8953\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 34.7932 - accuracy: 0.9057 - val_loss: 34.7986 - val_accuracy: 0.8915\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 34.8087 - accuracy: 0.9151 - val_loss: 34.8124 - val_accuracy: 0.8798\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 34.7961 - accuracy: 0.9057 - val_loss: 34.7714 - val_accuracy: 0.9147\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 34.7477 - accuracy: 0.9104 - val_loss: 34.7820 - val_accuracy: 0.9109\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 34.7609 - accuracy: 0.9104 - val_loss: 34.7358 - val_accuracy: 0.9147\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 34.7404 - accuracy: 0.9009 - val_loss: 34.7387 - val_accuracy: 0.8837\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 34.7066 - accuracy: 0.9057 - val_loss: 34.7133 - val_accuracy: 0.8992\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 34.7204 - accuracy: 0.8962 - val_loss: 34.7196 - val_accuracy: 0.8953\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 34.6850 - accuracy: 0.9151 - val_loss: 34.6873 - val_accuracy: 0.9031\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 34.6453 - accuracy: 0.9245 - val_loss: 34.6953 - val_accuracy: 0.8992\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 34.5889 - accuracy: 0.9528 - val_loss: 34.6478 - val_accuracy: 0.9109\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 34.6427 - accuracy: 0.9104 - val_loss: 34.6287 - val_accuracy: 0.9109\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 34.5962 - accuracy: 0.9292 - val_loss: 34.6295 - val_accuracy: 0.8953\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 34.6071 - accuracy: 0.9292 - val_loss: 34.6098 - val_accuracy: 0.9070\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 34.6029 - accuracy: 0.9245 - val_loss: 34.5686 - val_accuracy: 0.9147\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 34.5829 - accuracy: 0.9198 - val_loss: 34.5626 - val_accuracy: 0.9031\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 34.6045 - accuracy: 0.8868 - val_loss: 34.5668 - val_accuracy: 0.9070\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 34.5322 - accuracy: 0.9387 - val_loss: 34.5214 - val_accuracy: 0.9302\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 34.5179 - accuracy: 0.9104 - val_loss: 34.5054 - val_accuracy: 0.9380\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 34.5238 - accuracy: 0.9104 - val_loss: 34.5583 - val_accuracy: 0.8837\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 34.5442 - accuracy: 0.9009 - val_loss: 34.5466 - val_accuracy: 0.8837\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 34.4976 - accuracy: 0.8962 - val_loss: 34.5003 - val_accuracy: 0.8876\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 34.4879 - accuracy: 0.9198 - val_loss: 34.5069 - val_accuracy: 0.8798\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 34.4244 - accuracy: 0.9340 - val_loss: 34.4333 - val_accuracy: 0.9186\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 34.4395 - accuracy: 0.9151 - val_loss: 34.4441 - val_accuracy: 0.9109\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 34.4224 - accuracy: 0.9434 - val_loss: 34.4070 - val_accuracy: 0.9302\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 34.4223 - accuracy: 0.9198 - val_loss: 34.4178 - val_accuracy: 0.9070\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 34.3865 - accuracy: 0.9292 - val_loss: 34.4061 - val_accuracy: 0.8992\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 34.3995 - accuracy: 0.9009 - val_loss: 34.3592 - val_accuracy: 0.9147\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 34.3626 - accuracy: 0.9104 - val_loss: 34.3780 - val_accuracy: 0.9031\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 34.3597 - accuracy: 0.9292 - val_loss: 34.3368 - val_accuracy: 0.9225\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 34.3498 - accuracy: 0.8962 - val_loss: 34.3477 - val_accuracy: 0.9147\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 34.3388 - accuracy: 0.9009 - val_loss: 34.3329 - val_accuracy: 0.9109\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 34.3170 - accuracy: 0.9245 - val_loss: 34.3325 - val_accuracy: 0.9070\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 34.3265 - accuracy: 0.9009 - val_loss: 34.3093 - val_accuracy: 0.9070\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 34.2353 - accuracy: 0.9528 - val_loss: 34.2897 - val_accuracy: 0.8992\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 34.2499 - accuracy: 0.9387 - val_loss: 34.2797 - val_accuracy: 0.9147\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 34.2652 - accuracy: 0.9245 - val_loss: 34.2608 - val_accuracy: 0.9070\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 34.2124 - accuracy: 0.9292 - val_loss: 34.2514 - val_accuracy: 0.9031\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 34.2095 - accuracy: 0.9292 - val_loss: 34.2312 - val_accuracy: 0.9109\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 34.1983 - accuracy: 0.9198 - val_loss: 34.2277 - val_accuracy: 0.9147\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 34.1884 - accuracy: 0.9387 - val_loss: 34.1664 - val_accuracy: 0.9535\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 34.1680 - accuracy: 0.9387 - val_loss: 34.1817 - val_accuracy: 0.9147\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 34.1607 - accuracy: 0.9481 - val_loss: 34.1494 - val_accuracy: 0.9225\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 34.1305 - accuracy: 0.9434 - val_loss: 34.1705 - val_accuracy: 0.8992\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 34.1124 - accuracy: 0.9292 - val_loss: 34.1081 - val_accuracy: 0.9341\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 34.1288 - accuracy: 0.9151 - val_loss: 34.1227 - val_accuracy: 0.9070\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 34.0972 - accuracy: 0.9104 - val_loss: 34.1110 - val_accuracy: 0.9109\n",
      "Epoch 268/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step - loss: 34.0974 - accuracy: 0.9292 - val_loss: 34.0947 - val_accuracy: 0.9070\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 34.0651 - accuracy: 0.9481 - val_loss: 34.0890 - val_accuracy: 0.8837\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 34.1044 - accuracy: 0.9104 - val_loss: 34.0862 - val_accuracy: 0.9070\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 34.0667 - accuracy: 0.9104 - val_loss: 34.0435 - val_accuracy: 0.9186\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 34.0359 - accuracy: 0.9292 - val_loss: 34.0246 - val_accuracy: 0.9186\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 33.9922 - accuracy: 0.9434 - val_loss: 34.0441 - val_accuracy: 0.8992\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 33.9760 - accuracy: 0.9245 - val_loss: 34.0291 - val_accuracy: 0.9031\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 33.9967 - accuracy: 0.9245 - val_loss: 33.9865 - val_accuracy: 0.8992\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 33.9644 - accuracy: 0.9481 - val_loss: 33.9747 - val_accuracy: 0.9302\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 34.0005 - accuracy: 0.9104 - val_loss: 33.9461 - val_accuracy: 0.9302\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 33.9036 - accuracy: 0.9434 - val_loss: 33.9433 - val_accuracy: 0.9147\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 33.9467 - accuracy: 0.9104 - val_loss: 33.8890 - val_accuracy: 0.9302\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 33.8748 - accuracy: 0.9340 - val_loss: 33.9070 - val_accuracy: 0.9341\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 33.8660 - accuracy: 0.9387 - val_loss: 33.8813 - val_accuracy: 0.9031\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 33.9224 - accuracy: 0.9198 - val_loss: 33.8453 - val_accuracy: 0.9341\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 33.8667 - accuracy: 0.9245 - val_loss: 33.8582 - val_accuracy: 0.9419\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 33.8010 - accuracy: 0.9387 - val_loss: 33.8605 - val_accuracy: 0.9225\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 33.8529 - accuracy: 0.9198 - val_loss: 33.8428 - val_accuracy: 0.9186\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 33.8013 - accuracy: 0.9387 - val_loss: 33.7872 - val_accuracy: 0.9380\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 33.7818 - accuracy: 0.9387 - val_loss: 33.8020 - val_accuracy: 0.9109\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 33.7634 - accuracy: 0.9434 - val_loss: 33.7940 - val_accuracy: 0.9186\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 33.7793 - accuracy: 0.9198 - val_loss: 33.7615 - val_accuracy: 0.9419\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 33.7673 - accuracy: 0.9245 - val_loss: 33.7842 - val_accuracy: 0.9147\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 33.7403 - accuracy: 0.9245 - val_loss: 33.7616 - val_accuracy: 0.9147\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 33.7191 - accuracy: 0.9434 - val_loss: 33.7701 - val_accuracy: 0.8992\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 33.7241 - accuracy: 0.9245 - val_loss: 33.7167 - val_accuracy: 0.9264\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 33.7243 - accuracy: 0.9245 - val_loss: 33.6959 - val_accuracy: 0.9419\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 33.6875 - accuracy: 0.9292 - val_loss: 33.6882 - val_accuracy: 0.9264\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 33.6952 - accuracy: 0.9151 - val_loss: 33.6602 - val_accuracy: 0.9380\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 33.6815 - accuracy: 0.9151 - val_loss: 33.6686 - val_accuracy: 0.9225\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 33.5942 - accuracy: 0.9528 - val_loss: 33.6525 - val_accuracy: 0.9341\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 33.6523 - accuracy: 0.9151 - val_loss: 33.6252 - val_accuracy: 0.9264\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 33.6601 - accuracy: 0.9245 - val_loss: 33.5957 - val_accuracy: 0.9302\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 33.5899 - accuracy: 0.9245 - val_loss: 33.5644 - val_accuracy: 0.9574\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 33.5818 - accuracy: 0.9198 - val_loss: 33.5979 - val_accuracy: 0.9264\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 33.5842 - accuracy: 0.9151 - val_loss: 33.5841 - val_accuracy: 0.9109\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 33.6036 - accuracy: 0.9151 - val_loss: 33.5333 - val_accuracy: 0.9380\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 33.5569 - accuracy: 0.9340 - val_loss: 33.5458 - val_accuracy: 0.9264\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 33.5619 - accuracy: 0.9151 - val_loss: 33.5317 - val_accuracy: 0.9186\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 33.5100 - accuracy: 0.9528 - val_loss: 33.5528 - val_accuracy: 0.9264\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 33.5243 - accuracy: 0.9151 - val_loss: 33.4847 - val_accuracy: 0.9302\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 33.4960 - accuracy: 0.9151 - val_loss: 33.5113 - val_accuracy: 0.9186\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 33.4488 - accuracy: 0.9481 - val_loss: 33.5324 - val_accuracy: 0.9031\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 33.4135 - accuracy: 0.9481 - val_loss: 33.4467 - val_accuracy: 0.9341\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 33.4051 - accuracy: 0.9481 - val_loss: 33.4372 - val_accuracy: 0.9225\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 33.4345 - accuracy: 0.9340 - val_loss: 33.4319 - val_accuracy: 0.9186\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 33.3895 - accuracy: 0.9387 - val_loss: 33.4041 - val_accuracy: 0.9419\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 33.4425 - accuracy: 0.9198 - val_loss: 33.4062 - val_accuracy: 0.9109\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 33.3873 - accuracy: 0.9481 - val_loss: 33.4005 - val_accuracy: 0.9031\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 33.4216 - accuracy: 0.9245 - val_loss: 33.3796 - val_accuracy: 0.9109\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 33.3382 - accuracy: 0.9245 - val_loss: 33.3562 - val_accuracy: 0.9186\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 33.3565 - accuracy: 0.9104 - val_loss: 33.3267 - val_accuracy: 0.9302\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 33.3556 - accuracy: 0.9104 - val_loss: 33.3357 - val_accuracy: 0.9070\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 33.3741 - accuracy: 0.8868 - val_loss: 33.3198 - val_accuracy: 0.9302\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 33.2510 - accuracy: 0.9623 - val_loss: 33.3196 - val_accuracy: 0.9109\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 33.3104 - accuracy: 0.9057 - val_loss: 33.2614 - val_accuracy: 0.9380\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 191ms/step - loss: 33.2620 - accuracy: 0.9292 - val_loss: 33.2458 - val_accuracy: 0.9341\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 33.2878 - accuracy: 0.9151 - val_loss: 33.2511 - val_accuracy: 0.9225\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 33.2007 - accuracy: 0.9434 - val_loss: 33.2696 - val_accuracy: 0.9031\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 33.2126 - accuracy: 0.9528 - val_loss: 33.2028 - val_accuracy: 0.9225\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 33.1724 - accuracy: 0.9481 - val_loss: 33.2389 - val_accuracy: 0.8876\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 33.2266 - accuracy: 0.9198 - val_loss: 33.1589 - val_accuracy: 0.9574\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 33.1848 - accuracy: 0.9340 - val_loss: 33.1752 - val_accuracy: 0.9302\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 33.1688 - accuracy: 0.9292 - val_loss: 33.1479 - val_accuracy: 0.9457\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 33.1517 - accuracy: 0.9387 - val_loss: 33.1129 - val_accuracy: 0.9496\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 33.1415 - accuracy: 0.9245 - val_loss: 33.1331 - val_accuracy: 0.9264\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 33.1271 - accuracy: 0.9340 - val_loss: 33.1144 - val_accuracy: 0.9264\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 33.0913 - accuracy: 0.9481 - val_loss: 33.0780 - val_accuracy: 0.9419\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 33.1176 - accuracy: 0.9292 - val_loss: 33.1025 - val_accuracy: 0.9225\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 33.0712 - accuracy: 0.9340 - val_loss: 33.0333 - val_accuracy: 0.9574\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 33.0658 - accuracy: 0.9198 - val_loss: 33.0441 - val_accuracy: 0.9302\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 33.0720 - accuracy: 0.9151 - val_loss: 33.0497 - val_accuracy: 0.9264\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 33.0505 - accuracy: 0.9198 - val_loss: 33.0297 - val_accuracy: 0.9380\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 33.0161 - accuracy: 0.9198 - val_loss: 33.0189 - val_accuracy: 0.9225\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 33.0398 - accuracy: 0.9151 - val_loss: 32.9998 - val_accuracy: 0.9302\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 33.0028 - accuracy: 0.9292 - val_loss: 32.9884 - val_accuracy: 0.9380\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 33.0198 - accuracy: 0.9151 - val_loss: 32.9749 - val_accuracy: 0.9186\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 32.9454 - accuracy: 0.9387 - val_loss: 32.9740 - val_accuracy: 0.9147\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 32.9361 - accuracy: 0.9387 - val_loss: 32.9310 - val_accuracy: 0.9302\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 32.9581 - accuracy: 0.9245 - val_loss: 32.9500 - val_accuracy: 0.9264\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 32.9326 - accuracy: 0.9292 - val_loss: 32.9261 - val_accuracy: 0.9147\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 32.9029 - accuracy: 0.9292 - val_loss: 32.8871 - val_accuracy: 0.9380\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 32.9286 - accuracy: 0.9292 - val_loss: 32.8684 - val_accuracy: 0.9380\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 32.9154 - accuracy: 0.9104 - val_loss: 32.8660 - val_accuracy: 0.9225\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 32.8944 - accuracy: 0.9198 - val_loss: 32.8570 - val_accuracy: 0.9264\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 32.8494 - accuracy: 0.9340 - val_loss: 32.8314 - val_accuracy: 0.9341\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 32.8464 - accuracy: 0.9245 - val_loss: 32.8249 - val_accuracy: 0.9225\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 32.8171 - accuracy: 0.9198 - val_loss: 32.8314 - val_accuracy: 0.9147\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 32.8237 - accuracy: 0.9292 - val_loss: 32.8037 - val_accuracy: 0.9341\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 32.7532 - accuracy: 0.9292 - val_loss: 32.7879 - val_accuracy: 0.9109\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 32.7622 - accuracy: 0.9292 - val_loss: 32.7926 - val_accuracy: 0.9147\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 32.7635 - accuracy: 0.9245 - val_loss: 32.7549 - val_accuracy: 0.9341\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 32.7417 - accuracy: 0.9292 - val_loss: 32.7276 - val_accuracy: 0.9225\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 32.7219 - accuracy: 0.9387 - val_loss: 32.7348 - val_accuracy: 0.9147\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 32.7433 - accuracy: 0.9292 - val_loss: 32.6943 - val_accuracy: 0.9380\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 32.6706 - accuracy: 0.9434 - val_loss: 32.7140 - val_accuracy: 0.9225\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 32.6815 - accuracy: 0.9434 - val_loss: 32.6917 - val_accuracy: 0.9302\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 32.6552 - accuracy: 0.9528 - val_loss: 32.6677 - val_accuracy: 0.9341\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 32.6703 - accuracy: 0.9245 - val_loss: 32.6848 - val_accuracy: 0.9109\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 32.6824 - accuracy: 0.9151 - val_loss: 32.6334 - val_accuracy: 0.9419\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 32.6170 - accuracy: 0.9292 - val_loss: 32.6271 - val_accuracy: 0.9225\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 32.6262 - accuracy: 0.9245 - val_loss: 32.6217 - val_accuracy: 0.9264\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 32.5811 - accuracy: 0.9575 - val_loss: 32.5811 - val_accuracy: 0.9341\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 32.5941 - accuracy: 0.9481 - val_loss: 32.5608 - val_accuracy: 0.9419\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 32.5841 - accuracy: 0.9292 - val_loss: 32.5782 - val_accuracy: 0.9186\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 32.5669 - accuracy: 0.9292 - val_loss: 32.5413 - val_accuracy: 0.9264\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 32.5638 - accuracy: 0.9198 - val_loss: 32.5401 - val_accuracy: 0.9147\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 32.5225 - accuracy: 0.9481 - val_loss: 32.5001 - val_accuracy: 0.9380\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 32.5178 - accuracy: 0.9434 - val_loss: 32.5173 - val_accuracy: 0.9341\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 32.5481 - accuracy: 0.8962 - val_loss: 32.5175 - val_accuracy: 0.9225\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 32.4482 - accuracy: 0.9575 - val_loss: 32.4768 - val_accuracy: 0.9302\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 32.4688 - accuracy: 0.9387 - val_loss: 32.4530 - val_accuracy: 0.9302\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 219ms/step - loss: 32.4821 - accuracy: 0.9245 - val_loss: 32.4523 - val_accuracy: 0.9380\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 32.4767 - accuracy: 0.9245 - val_loss: 32.4386 - val_accuracy: 0.9264\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 32.4421 - accuracy: 0.9340 - val_loss: 32.4323 - val_accuracy: 0.9302\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 32.3989 - accuracy: 0.9387 - val_loss: 32.4141 - val_accuracy: 0.9302\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 32.4094 - accuracy: 0.9387 - val_loss: 32.3874 - val_accuracy: 0.9419\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 32.4277 - accuracy: 0.9057 - val_loss: 32.3939 - val_accuracy: 0.9186\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 32.3740 - accuracy: 0.9340 - val_loss: 32.3683 - val_accuracy: 0.9225\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 32.3600 - accuracy: 0.9340 - val_loss: 32.3865 - val_accuracy: 0.9186\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 32.3504 - accuracy: 0.9340 - val_loss: 32.3181 - val_accuracy: 0.9457\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 32.3324 - accuracy: 0.9245 - val_loss: 32.3196 - val_accuracy: 0.9419\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 32.3375 - accuracy: 0.9104 - val_loss: 32.3107 - val_accuracy: 0.9264\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 32.3184 - accuracy: 0.9245 - val_loss: 32.2908 - val_accuracy: 0.9264\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 32.2736 - accuracy: 0.9387 - val_loss: 32.3154 - val_accuracy: 0.9186\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 32.3082 - accuracy: 0.9292 - val_loss: 32.2473 - val_accuracy: 0.9302\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 32.2866 - accuracy: 0.8962 - val_loss: 32.2295 - val_accuracy: 0.9419\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 32.2202 - accuracy: 0.9245 - val_loss: 32.2094 - val_accuracy: 0.9419\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 32.3060 - accuracy: 0.8962 - val_loss: 32.2300 - val_accuracy: 0.9302\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 32.2610 - accuracy: 0.9151 - val_loss: 32.1983 - val_accuracy: 0.9341\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 32.2193 - accuracy: 0.9292 - val_loss: 32.1941 - val_accuracy: 0.9070\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 32.2244 - accuracy: 0.9057 - val_loss: 32.1578 - val_accuracy: 0.9457\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 32.1881 - accuracy: 0.9245 - val_loss: 32.1885 - val_accuracy: 0.9031\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 32.1683 - accuracy: 0.9387 - val_loss: 32.1355 - val_accuracy: 0.9380\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 32.1532 - accuracy: 0.9292 - val_loss: 32.1413 - val_accuracy: 0.9225\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 32.1492 - accuracy: 0.9340 - val_loss: 32.1174 - val_accuracy: 0.9302\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 32.0694 - accuracy: 0.9575 - val_loss: 32.1516 - val_accuracy: 0.9109\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 32.1136 - accuracy: 0.9340 - val_loss: 32.1110 - val_accuracy: 0.9264\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 32.0399 - accuracy: 0.9528 - val_loss: 32.1000 - val_accuracy: 0.9147\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 32.1020 - accuracy: 0.9245 - val_loss: 32.0453 - val_accuracy: 0.9380\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 32.0970 - accuracy: 0.9245 - val_loss: 32.0565 - val_accuracy: 0.9264\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 32.0398 - accuracy: 0.9387 - val_loss: 32.0289 - val_accuracy: 0.9380\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 32.0236 - accuracy: 0.9387 - val_loss: 32.0316 - val_accuracy: 0.9264\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 32.0344 - accuracy: 0.9245 - val_loss: 32.0585 - val_accuracy: 0.8992\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 31.9842 - accuracy: 0.9528 - val_loss: 32.0112 - val_accuracy: 0.9225\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 31.9969 - accuracy: 0.9340 - val_loss: 31.9727 - val_accuracy: 0.9341\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 32.0013 - accuracy: 0.9387 - val_loss: 31.9747 - val_accuracy: 0.9380\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 31.9921 - accuracy: 0.9198 - val_loss: 31.9495 - val_accuracy: 0.9264\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 31.9511 - accuracy: 0.9104 - val_loss: 31.9285 - val_accuracy: 0.9380\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 31.9122 - accuracy: 0.9481 - val_loss: 31.9299 - val_accuracy: 0.9225\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 32.0153 - accuracy: 0.8915 - val_loss: 31.8993 - val_accuracy: 0.9535\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 31.8721 - accuracy: 0.9575 - val_loss: 31.8836 - val_accuracy: 0.9380\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 31.9182 - accuracy: 0.9245 - val_loss: 31.8745 - val_accuracy: 0.9109\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 31.9137 - accuracy: 0.9198 - val_loss: 31.8291 - val_accuracy: 0.9457\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 31.8432 - accuracy: 0.9434 - val_loss: 31.8381 - val_accuracy: 0.9380\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 31.8655 - accuracy: 0.9340 - val_loss: 31.8399 - val_accuracy: 0.9302\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 31.9010 - accuracy: 0.9057 - val_loss: 31.8164 - val_accuracy: 0.9380\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 31.8903 - accuracy: 0.8868 - val_loss: 31.7820 - val_accuracy: 0.9496\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 31.7973 - accuracy: 0.9434 - val_loss: 31.7941 - val_accuracy: 0.9302\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 31.8010 - accuracy: 0.9245 - val_loss: 31.7682 - val_accuracy: 0.9419\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 31.7477 - accuracy: 0.9481 - val_loss: 31.7506 - val_accuracy: 0.9419\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 31.7802 - accuracy: 0.9387 - val_loss: 31.7520 - val_accuracy: 0.9341\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 31.7881 - accuracy: 0.9340 - val_loss: 31.7284 - val_accuracy: 0.9380\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 31.7919 - accuracy: 0.9009 - val_loss: 31.7134 - val_accuracy: 0.9341\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 31.7331 - accuracy: 0.9292 - val_loss: 31.7349 - val_accuracy: 0.9186\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 31.7062 - accuracy: 0.9387 - val_loss: 31.6639 - val_accuracy: 0.9535\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 31.7216 - accuracy: 0.9245 - val_loss: 31.7104 - val_accuracy: 0.9225\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 31.6633 - accuracy: 0.9434 - val_loss: 31.6749 - val_accuracy: 0.9302\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 296ms/step - loss: 31.6518 - accuracy: 0.9387 - val_loss: 31.6544 - val_accuracy: 0.9264\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 31.6821 - accuracy: 0.8915 - val_loss: 31.6563 - val_accuracy: 0.9109\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 31.6269 - accuracy: 0.9340 - val_loss: 31.6467 - val_accuracy: 0.9186\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 31.6578 - accuracy: 0.9245 - val_loss: 31.5981 - val_accuracy: 0.9419\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 31.5953 - accuracy: 0.9340 - val_loss: 31.5827 - val_accuracy: 0.9302\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 31.5975 - accuracy: 0.9292 - val_loss: 31.6080 - val_accuracy: 0.9225\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 31.5994 - accuracy: 0.9198 - val_loss: 31.5560 - val_accuracy: 0.9380\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 31.5657 - accuracy: 0.9434 - val_loss: 31.5767 - val_accuracy: 0.9186\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 31.5723 - accuracy: 0.9198 - val_loss: 31.5679 - val_accuracy: 0.9147\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 31.5795 - accuracy: 0.9151 - val_loss: 31.5155 - val_accuracy: 0.9225\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 31.5488 - accuracy: 0.9198 - val_loss: 31.4964 - val_accuracy: 0.9457\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 31.4778 - accuracy: 0.9340 - val_loss: 31.5290 - val_accuracy: 0.9225\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 31.4837 - accuracy: 0.9387 - val_loss: 31.4948 - val_accuracy: 0.9186\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 31.4790 - accuracy: 0.9292 - val_loss: 31.4274 - val_accuracy: 0.9574\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 31.4677 - accuracy: 0.9245 - val_loss: 31.4688 - val_accuracy: 0.9302\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 31.4664 - accuracy: 0.9292 - val_loss: 31.4408 - val_accuracy: 0.9225\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 31.4683 - accuracy: 0.9198 - val_loss: 31.4346 - val_accuracy: 0.9147\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 31.4396 - accuracy: 0.9245 - val_loss: 31.3916 - val_accuracy: 0.9341\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 31.4375 - accuracy: 0.9057 - val_loss: 31.3806 - val_accuracy: 0.9380\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 31.3878 - accuracy: 0.9340 - val_loss: 31.3953 - val_accuracy: 0.9225\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 31.3752 - accuracy: 0.9387 - val_loss: 31.3693 - val_accuracy: 0.9302\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 31.3986 - accuracy: 0.9151 - val_loss: 31.3455 - val_accuracy: 0.9457\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 31.3250 - accuracy: 0.9434 - val_loss: 31.3351 - val_accuracy: 0.9341\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 31.3599 - accuracy: 0.9057 - val_loss: 31.3194 - val_accuracy: 0.9302\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 31.3626 - accuracy: 0.9057 - val_loss: 31.3222 - val_accuracy: 0.9302\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 31.2931 - accuracy: 0.9340 - val_loss: 31.2685 - val_accuracy: 0.9457\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 31.2775 - accuracy: 0.9434 - val_loss: 31.2780 - val_accuracy: 0.9302\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 31.2905 - accuracy: 0.9387 - val_loss: 31.2633 - val_accuracy: 0.9302\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 31.2515 - accuracy: 0.9340 - val_loss: 31.2447 - val_accuracy: 0.9380\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 31.2693 - accuracy: 0.9245 - val_loss: 31.2284 - val_accuracy: 0.9496\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 31.2181 - accuracy: 0.9292 - val_loss: 31.2320 - val_accuracy: 0.9302\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 31.2316 - accuracy: 0.9340 - val_loss: 31.2176 - val_accuracy: 0.9109\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 31.1994 - accuracy: 0.9575 - val_loss: 31.2081 - val_accuracy: 0.9302\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 31.1861 - accuracy: 0.9292 - val_loss: 31.2064 - val_accuracy: 0.9264\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 31.2305 - accuracy: 0.9104 - val_loss: 31.1904 - val_accuracy: 0.9225\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 31.1591 - accuracy: 0.9340 - val_loss: 31.1751 - val_accuracy: 0.9302\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 31.0992 - accuracy: 0.9575 - val_loss: 31.1092 - val_accuracy: 0.9341\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 31.1617 - accuracy: 0.9151 - val_loss: 31.1333 - val_accuracy: 0.9264\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 31.1549 - accuracy: 0.8962 - val_loss: 31.1118 - val_accuracy: 0.9380\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 31.1602 - accuracy: 0.9104 - val_loss: 31.0934 - val_accuracy: 0.9302\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 31.1133 - accuracy: 0.9292 - val_loss: 31.1059 - val_accuracy: 0.9225\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 31.0910 - accuracy: 0.9292 - val_loss: 31.0742 - val_accuracy: 0.9147\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 31.0789 - accuracy: 0.9292 - val_loss: 31.0345 - val_accuracy: 0.9457\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 31.0709 - accuracy: 0.9198 - val_loss: 31.0391 - val_accuracy: 0.9264\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 30.9940 - accuracy: 0.9528 - val_loss: 31.0107 - val_accuracy: 0.9457\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 30.9980 - accuracy: 0.9434 - val_loss: 31.0285 - val_accuracy: 0.9225\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 31.0048 - accuracy: 0.9292 - val_loss: 30.9955 - val_accuracy: 0.9147\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 30.9713 - accuracy: 0.9340 - val_loss: 30.9884 - val_accuracy: 0.9302\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 31.0064 - accuracy: 0.9340 - val_loss: 30.9459 - val_accuracy: 0.9535\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 30.9958 - accuracy: 0.9245 - val_loss: 30.9804 - val_accuracy: 0.9302\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 30.9703 - accuracy: 0.9198 - val_loss: 30.9368 - val_accuracy: 0.9341\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 30.9585 - accuracy: 0.9198 - val_loss: 30.9501 - val_accuracy: 0.9147\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 30.9653 - accuracy: 0.9151 - val_loss: 30.9555 - val_accuracy: 0.8992\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 30.9424 - accuracy: 0.9198 - val_loss: 30.9048 - val_accuracy: 0.9341\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 30.8889 - accuracy: 0.9340 - val_loss: 30.9012 - val_accuracy: 0.9186\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 30.9033 - accuracy: 0.9057 - val_loss: 30.8762 - val_accuracy: 0.9264\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step - loss: 30.8862 - accuracy: 0.9198 - val_loss: 30.8442 - val_accuracy: 0.9419\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 30.8195 - accuracy: 0.9481 - val_loss: 30.9019 - val_accuracy: 0.9109\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 30.8272 - accuracy: 0.9245 - val_loss: 30.8159 - val_accuracy: 0.9380\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 30.7675 - accuracy: 0.9528 - val_loss: 30.8019 - val_accuracy: 0.9341\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 30.8193 - accuracy: 0.9151 - val_loss: 30.8101 - val_accuracy: 0.9186\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 30.8139 - accuracy: 0.9292 - val_loss: 30.8200 - val_accuracy: 0.9147\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 30.8052 - accuracy: 0.9245 - val_loss: 30.7789 - val_accuracy: 0.9225\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 30.7473 - accuracy: 0.9292 - val_loss: 30.7746 - val_accuracy: 0.9341\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 30.7526 - accuracy: 0.9292 - val_loss: 30.7340 - val_accuracy: 0.9341\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 30.7600 - accuracy: 0.9245 - val_loss: 30.6985 - val_accuracy: 0.9457\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 30.7675 - accuracy: 0.9151 - val_loss: 30.7264 - val_accuracy: 0.9186\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 30.6802 - accuracy: 0.9623 - val_loss: 30.6992 - val_accuracy: 0.9302\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 30.6732 - accuracy: 0.9387 - val_loss: 30.6903 - val_accuracy: 0.9147\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 30.7283 - accuracy: 0.9245 - val_loss: 30.6543 - val_accuracy: 0.9419\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 30.7129 - accuracy: 0.9009 - val_loss: 30.6654 - val_accuracy: 0.9380\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 30.6361 - accuracy: 0.9481 - val_loss: 30.6495 - val_accuracy: 0.9147\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 30.6925 - accuracy: 0.9198 - val_loss: 30.6103 - val_accuracy: 0.9457\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 30.6859 - accuracy: 0.9245 - val_loss: 30.6079 - val_accuracy: 0.9419\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 30.6336 - accuracy: 0.9245 - val_loss: 30.6067 - val_accuracy: 0.9341\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 30.6282 - accuracy: 0.9292 - val_loss: 30.5580 - val_accuracy: 0.9535\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 30.6395 - accuracy: 0.8962 - val_loss: 30.5570 - val_accuracy: 0.9496\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 30.5639 - accuracy: 0.9528 - val_loss: 30.5793 - val_accuracy: 0.9109\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 30.5369 - accuracy: 0.9340 - val_loss: 30.5254 - val_accuracy: 0.9341\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 30.5940 - accuracy: 0.9198 - val_loss: 30.5063 - val_accuracy: 0.9419\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 30.5270 - accuracy: 0.9340 - val_loss: 30.4976 - val_accuracy: 0.9419\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 30.5216 - accuracy: 0.9292 - val_loss: 30.5255 - val_accuracy: 0.9109\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 30.4785 - accuracy: 0.9434 - val_loss: 30.4855 - val_accuracy: 0.9186\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 30.6242 - accuracy: 0.8774 - val_loss: 30.4900 - val_accuracy: 0.9419\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 30.4478 - accuracy: 0.9245 - val_loss: 30.4868 - val_accuracy: 0.9147\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 30.4705 - accuracy: 0.9198 - val_loss: 30.4510 - val_accuracy: 0.9380\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 30.4687 - accuracy: 0.9151 - val_loss: 30.4446 - val_accuracy: 0.9225\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 30.4114 - accuracy: 0.9387 - val_loss: 30.4386 - val_accuracy: 0.9302\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 30.4107 - accuracy: 0.9340 - val_loss: 30.3831 - val_accuracy: 0.9457\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 30.4742 - accuracy: 0.9009 - val_loss: 30.4270 - val_accuracy: 0.8992\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 30.3848 - accuracy: 0.9481 - val_loss: 30.4126 - val_accuracy: 0.9070\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 30.3581 - accuracy: 0.9387 - val_loss: 30.3311 - val_accuracy: 0.9496\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 30.3375 - accuracy: 0.9245 - val_loss: 30.3692 - val_accuracy: 0.9186\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 30.3681 - accuracy: 0.9292 - val_loss: 30.3523 - val_accuracy: 0.9341\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 30.3626 - accuracy: 0.9104 - val_loss: 30.3233 - val_accuracy: 0.9225\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 30.3985 - accuracy: 0.8821 - val_loss: 30.2927 - val_accuracy: 0.9419\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 30.3540 - accuracy: 0.9198 - val_loss: 30.3017 - val_accuracy: 0.9147\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 30.2551 - accuracy: 0.9481 - val_loss: 30.2865 - val_accuracy: 0.9302\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 30.3253 - accuracy: 0.9151 - val_loss: 30.3006 - val_accuracy: 0.9186\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 30.2700 - accuracy: 0.9387 - val_loss: 30.2263 - val_accuracy: 0.9419\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 30.1959 - accuracy: 0.9575 - val_loss: 30.2375 - val_accuracy: 0.9380\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 30.2802 - accuracy: 0.9198 - val_loss: 30.2605 - val_accuracy: 0.9302\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 30.1847 - accuracy: 0.9481 - val_loss: 30.1940 - val_accuracy: 0.9380\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 30.1770 - accuracy: 0.9623 - val_loss: 30.2116 - val_accuracy: 0.9302\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 30.1705 - accuracy: 0.9434 - val_loss: 30.2081 - val_accuracy: 0.9109\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 30.1842 - accuracy: 0.9292 - val_loss: 30.1627 - val_accuracy: 0.9147\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 30.1987 - accuracy: 0.9198 - val_loss: 30.1633 - val_accuracy: 0.9031\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 30.1086 - accuracy: 0.9623 - val_loss: 30.1191 - val_accuracy: 0.9302\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 30.1095 - accuracy: 0.9340 - val_loss: 30.1561 - val_accuracy: 0.9109\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 30.0752 - accuracy: 0.9434 - val_loss: 30.0833 - val_accuracy: 0.9535\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 30.0910 - accuracy: 0.9528 - val_loss: 30.0915 - val_accuracy: 0.9380\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 30.1036 - accuracy: 0.9340 - val_loss: 30.1004 - val_accuracy: 0.9070\n",
      "Epoch 548/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step - loss: 30.0950 - accuracy: 0.9198 - val_loss: 30.0922 - val_accuracy: 0.9225\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 30.0564 - accuracy: 0.9340 - val_loss: 30.0778 - val_accuracy: 0.9341\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 30.0823 - accuracy: 0.9057 - val_loss: 30.0007 - val_accuracy: 0.9496\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 30.0775 - accuracy: 0.9057 - val_loss: 30.0426 - val_accuracy: 0.9186\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 29.9981 - accuracy: 0.9387 - val_loss: 30.0201 - val_accuracy: 0.9147\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 30.0092 - accuracy: 0.9292 - val_loss: 29.9975 - val_accuracy: 0.9380\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 30.0107 - accuracy: 0.9340 - val_loss: 30.0139 - val_accuracy: 0.9264\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 30.0087 - accuracy: 0.9151 - val_loss: 29.9987 - val_accuracy: 0.9147\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 29.9638 - accuracy: 0.9292 - val_loss: 29.9616 - val_accuracy: 0.9380\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 29.9064 - accuracy: 0.9528 - val_loss: 29.8994 - val_accuracy: 0.9496\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 29.9224 - accuracy: 0.9387 - val_loss: 29.9156 - val_accuracy: 0.9225\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 29.8998 - accuracy: 0.9387 - val_loss: 29.9083 - val_accuracy: 0.9419\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 29.9297 - accuracy: 0.9340 - val_loss: 29.9168 - val_accuracy: 0.9302\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 29.8792 - accuracy: 0.9528 - val_loss: 29.8765 - val_accuracy: 0.9302\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 29.9011 - accuracy: 0.9198 - val_loss: 29.9030 - val_accuracy: 0.9225\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 29.8849 - accuracy: 0.9387 - val_loss: 29.8706 - val_accuracy: 0.9380\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 29.8418 - accuracy: 0.9340 - val_loss: 29.8346 - val_accuracy: 0.9225\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 29.8615 - accuracy: 0.9198 - val_loss: 29.8528 - val_accuracy: 0.9186\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 29.8130 - accuracy: 0.9434 - val_loss: 29.7924 - val_accuracy: 0.9341\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 29.8436 - accuracy: 0.9104 - val_loss: 29.7691 - val_accuracy: 0.9419\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 29.8242 - accuracy: 0.9104 - val_loss: 29.7671 - val_accuracy: 0.9302\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 29.8087 - accuracy: 0.9151 - val_loss: 29.8121 - val_accuracy: 0.9109\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 29.7769 - accuracy: 0.9151 - val_loss: 29.7734 - val_accuracy: 0.9302\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 29.7556 - accuracy: 0.9387 - val_loss: 29.7201 - val_accuracy: 0.9457\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 29.7315 - accuracy: 0.9198 - val_loss: 29.7442 - val_accuracy: 0.9186\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 29.7163 - accuracy: 0.9387 - val_loss: 29.6775 - val_accuracy: 0.9380\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 29.6942 - accuracy: 0.9434 - val_loss: 29.7509 - val_accuracy: 0.9186\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 29.6925 - accuracy: 0.9340 - val_loss: 29.6902 - val_accuracy: 0.9264\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 29.6691 - accuracy: 0.9387 - val_loss: 29.6342 - val_accuracy: 0.9496\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 29.6721 - accuracy: 0.9198 - val_loss: 29.6762 - val_accuracy: 0.9225\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 29.6694 - accuracy: 0.9198 - val_loss: 29.6450 - val_accuracy: 0.9341\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 29.6180 - accuracy: 0.9434 - val_loss: 29.6294 - val_accuracy: 0.9147\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 29.6232 - accuracy: 0.9245 - val_loss: 29.6070 - val_accuracy: 0.9264\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 29.6019 - accuracy: 0.9340 - val_loss: 29.5964 - val_accuracy: 0.9380\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 29.5840 - accuracy: 0.9387 - val_loss: 29.5965 - val_accuracy: 0.9264\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 29.6085 - accuracy: 0.9104 - val_loss: 29.5810 - val_accuracy: 0.9225\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 29.5833 - accuracy: 0.9245 - val_loss: 29.5934 - val_accuracy: 0.9225\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 29.5725 - accuracy: 0.9198 - val_loss: 29.5632 - val_accuracy: 0.9341\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 29.6494 - accuracy: 0.9009 - val_loss: 29.5405 - val_accuracy: 0.9225\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 29.5688 - accuracy: 0.9057 - val_loss: 29.5150 - val_accuracy: 0.9264\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 29.5254 - accuracy: 0.9340 - val_loss: 29.4881 - val_accuracy: 0.9457\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 29.4799 - accuracy: 0.9528 - val_loss: 29.4632 - val_accuracy: 0.9225\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 29.4708 - accuracy: 0.9387 - val_loss: 29.4483 - val_accuracy: 0.9574\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 29.4549 - accuracy: 0.9387 - val_loss: 29.4802 - val_accuracy: 0.9341\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 29.4508 - accuracy: 0.9481 - val_loss: 29.4309 - val_accuracy: 0.9535\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 29.4052 - accuracy: 0.9670 - val_loss: 29.4319 - val_accuracy: 0.9302\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 29.4463 - accuracy: 0.9292 - val_loss: 29.4308 - val_accuracy: 0.9186\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 29.4438 - accuracy: 0.9198 - val_loss: 29.3915 - val_accuracy: 0.9380\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 29.4016 - accuracy: 0.9434 - val_loss: 29.3959 - val_accuracy: 0.9225\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 29.3947 - accuracy: 0.9481 - val_loss: 29.3737 - val_accuracy: 0.9109\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 29.3831 - accuracy: 0.9245 - val_loss: 29.3655 - val_accuracy: 0.9302\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 29.3421 - accuracy: 0.9292 - val_loss: 29.3794 - val_accuracy: 0.9070\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 29.3294 - accuracy: 0.9434 - val_loss: 29.3267 - val_accuracy: 0.9380\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 29.3685 - accuracy: 0.9198 - val_loss: 29.3240 - val_accuracy: 0.9264\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 29.2946 - accuracy: 0.9670 - val_loss: 29.3052 - val_accuracy: 0.9302\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 29.3334 - accuracy: 0.9292 - val_loss: 29.3134 - val_accuracy: 0.9264\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 207ms/step - loss: 29.3120 - accuracy: 0.9245 - val_loss: 29.2806 - val_accuracy: 0.9225\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 29.2879 - accuracy: 0.9198 - val_loss: 29.2516 - val_accuracy: 0.9264\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 29.2756 - accuracy: 0.9104 - val_loss: 29.3006 - val_accuracy: 0.9225\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 29.2881 - accuracy: 0.9057 - val_loss: 29.2379 - val_accuracy: 0.9380\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 29.2281 - accuracy: 0.9434 - val_loss: 29.2130 - val_accuracy: 0.9341\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 29.2596 - accuracy: 0.9057 - val_loss: 29.2207 - val_accuracy: 0.9419\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 29.2269 - accuracy: 0.9245 - val_loss: 29.1879 - val_accuracy: 0.9341\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 29.1915 - accuracy: 0.9292 - val_loss: 29.2036 - val_accuracy: 0.9147\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 29.2031 - accuracy: 0.9340 - val_loss: 29.1848 - val_accuracy: 0.9147\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 29.1750 - accuracy: 0.9057 - val_loss: 29.1461 - val_accuracy: 0.9264\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 29.1780 - accuracy: 0.9198 - val_loss: 29.1149 - val_accuracy: 0.9496\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 29.1214 - accuracy: 0.9434 - val_loss: 29.1151 - val_accuracy: 0.9419\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 29.1006 - accuracy: 0.9387 - val_loss: 29.0952 - val_accuracy: 0.9457\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 29.1206 - accuracy: 0.9292 - val_loss: 29.1346 - val_accuracy: 0.9341\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 29.0857 - accuracy: 0.9340 - val_loss: 29.1031 - val_accuracy: 0.9070\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 29.0948 - accuracy: 0.9340 - val_loss: 29.0294 - val_accuracy: 0.9457\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 29.0409 - accuracy: 0.9387 - val_loss: 29.0535 - val_accuracy: 0.9380\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 29.0479 - accuracy: 0.9434 - val_loss: 29.0457 - val_accuracy: 0.9109\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 29.0245 - accuracy: 0.9481 - val_loss: 29.0207 - val_accuracy: 0.9341\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 29.0033 - accuracy: 0.9340 - val_loss: 29.0601 - val_accuracy: 0.9186\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 29.0798 - accuracy: 0.9198 - val_loss: 29.0350 - val_accuracy: 0.9186\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 28.9607 - accuracy: 0.9575 - val_loss: 28.9914 - val_accuracy: 0.9070\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 28.9734 - accuracy: 0.9198 - val_loss: 28.9478 - val_accuracy: 0.9341\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 29.0126 - accuracy: 0.9245 - val_loss: 28.9707 - val_accuracy: 0.9302\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 28.9610 - accuracy: 0.9292 - val_loss: 28.9681 - val_accuracy: 0.9225\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 29.0114 - accuracy: 0.9151 - val_loss: 28.9100 - val_accuracy: 0.9341\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 28.9354 - accuracy: 0.9245 - val_loss: 28.9358 - val_accuracy: 0.9070\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 28.9133 - accuracy: 0.9198 - val_loss: 28.9125 - val_accuracy: 0.9419\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 28.9032 - accuracy: 0.9198 - val_loss: 28.8688 - val_accuracy: 0.9341\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 28.8851 - accuracy: 0.9340 - val_loss: 28.8651 - val_accuracy: 0.9457\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 28.8846 - accuracy: 0.9245 - val_loss: 28.8376 - val_accuracy: 0.9380\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 28.8950 - accuracy: 0.9057 - val_loss: 28.8506 - val_accuracy: 0.9302\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 28.8452 - accuracy: 0.9198 - val_loss: 28.8265 - val_accuracy: 0.9341\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 28.8268 - accuracy: 0.9245 - val_loss: 28.8548 - val_accuracy: 0.9070\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 28.8251 - accuracy: 0.9104 - val_loss: 28.8136 - val_accuracy: 0.9302\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 28.8235 - accuracy: 0.9104 - val_loss: 28.7769 - val_accuracy: 0.9535\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 28.8339 - accuracy: 0.9104 - val_loss: 28.7699 - val_accuracy: 0.9302\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 28.7630 - accuracy: 0.9340 - val_loss: 28.7659 - val_accuracy: 0.9225\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 28.7599 - accuracy: 0.9340 - val_loss: 28.7682 - val_accuracy: 0.9186\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 28.8151 - accuracy: 0.8868 - val_loss: 28.7227 - val_accuracy: 0.9225\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 28.7455 - accuracy: 0.9057 - val_loss: 28.7116 - val_accuracy: 0.9264\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 28.7488 - accuracy: 0.9198 - val_loss: 28.7044 - val_accuracy: 0.9302\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 28.6793 - accuracy: 0.9575 - val_loss: 28.7266 - val_accuracy: 0.9147\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 28.6712 - accuracy: 0.9528 - val_loss: 28.6719 - val_accuracy: 0.9419\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 28.6756 - accuracy: 0.9434 - val_loss: 28.6259 - val_accuracy: 0.9535\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 28.6906 - accuracy: 0.9151 - val_loss: 28.6512 - val_accuracy: 0.9225\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 28.6651 - accuracy: 0.8962 - val_loss: 28.6499 - val_accuracy: 0.9302\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 28.6438 - accuracy: 0.9057 - val_loss: 28.6349 - val_accuracy: 0.9302\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 28.6539 - accuracy: 0.9340 - val_loss: 28.6078 - val_accuracy: 0.9302\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 28.7203 - accuracy: 0.8868 - val_loss: 28.6055 - val_accuracy: 0.9302\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 28.6228 - accuracy: 0.9151 - val_loss: 28.6672 - val_accuracy: 0.8837\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 28.6124 - accuracy: 0.9151 - val_loss: 28.5531 - val_accuracy: 0.9341\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 28.6013 - accuracy: 0.9104 - val_loss: 28.5799 - val_accuracy: 0.9147\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 28.5119 - accuracy: 0.9434 - val_loss: 28.5867 - val_accuracy: 0.9186\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 28.5157 - accuracy: 0.9387 - val_loss: 28.5007 - val_accuracy: 0.9341\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 28.4995 - accuracy: 0.9292 - val_loss: 28.5117 - val_accuracy: 0.9186\n",
      "Epoch 660/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step - loss: 28.4980 - accuracy: 0.9481 - val_loss: 28.4513 - val_accuracy: 0.9574\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 28.5459 - accuracy: 0.8915 - val_loss: 28.4837 - val_accuracy: 0.9380\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 28.4941 - accuracy: 0.9198 - val_loss: 28.4985 - val_accuracy: 0.9109\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 28.4665 - accuracy: 0.9292 - val_loss: 28.4760 - val_accuracy: 0.9186\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 28.4742 - accuracy: 0.9198 - val_loss: 28.4737 - val_accuracy: 0.9109\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 28.4200 - accuracy: 0.9387 - val_loss: 28.4502 - val_accuracy: 0.9147\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 28.4331 - accuracy: 0.9198 - val_loss: 28.4652 - val_accuracy: 0.9225\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 28.4389 - accuracy: 0.9387 - val_loss: 28.3874 - val_accuracy: 0.9457\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 28.4301 - accuracy: 0.9151 - val_loss: 28.4195 - val_accuracy: 0.9186\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 28.3827 - accuracy: 0.9245 - val_loss: 28.3728 - val_accuracy: 0.9380\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 28.3179 - accuracy: 0.9623 - val_loss: 28.4083 - val_accuracy: 0.9031\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 28.3098 - accuracy: 0.9434 - val_loss: 28.3312 - val_accuracy: 0.9341\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 28.3298 - accuracy: 0.9434 - val_loss: 28.3399 - val_accuracy: 0.9147\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 28.3270 - accuracy: 0.9151 - val_loss: 28.2920 - val_accuracy: 0.9419\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 28.3192 - accuracy: 0.9387 - val_loss: 28.3142 - val_accuracy: 0.9302\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 28.3074 - accuracy: 0.9151 - val_loss: 28.3089 - val_accuracy: 0.9264\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 28.3218 - accuracy: 0.9292 - val_loss: 28.2765 - val_accuracy: 0.9186\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 28.3187 - accuracy: 0.9151 - val_loss: 28.2782 - val_accuracy: 0.9225\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 28.2847 - accuracy: 0.9151 - val_loss: 28.2754 - val_accuracy: 0.9225\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 28.2129 - accuracy: 0.9340 - val_loss: 28.2415 - val_accuracy: 0.9302\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 28.2629 - accuracy: 0.9151 - val_loss: 28.2141 - val_accuracy: 0.9380\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 28.2344 - accuracy: 0.9434 - val_loss: 28.1807 - val_accuracy: 0.9457\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 28.2093 - accuracy: 0.9198 - val_loss: 28.1784 - val_accuracy: 0.9380\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 28.2180 - accuracy: 0.9104 - val_loss: 28.1537 - val_accuracy: 0.9496\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 28.1838 - accuracy: 0.9198 - val_loss: 28.2024 - val_accuracy: 0.9147\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 28.1944 - accuracy: 0.9057 - val_loss: 28.1240 - val_accuracy: 0.9341\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 28.1234 - accuracy: 0.9528 - val_loss: 28.1312 - val_accuracy: 0.9264\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 28.1481 - accuracy: 0.9057 - val_loss: 28.1149 - val_accuracy: 0.9264\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 28.1843 - accuracy: 0.9104 - val_loss: 28.1293 - val_accuracy: 0.9147\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 28.1031 - accuracy: 0.9340 - val_loss: 28.0963 - val_accuracy: 0.9264\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 28.0715 - accuracy: 0.9387 - val_loss: 28.0777 - val_accuracy: 0.9186\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 28.0890 - accuracy: 0.9151 - val_loss: 28.0913 - val_accuracy: 0.9109\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 28.0601 - accuracy: 0.9340 - val_loss: 28.0976 - val_accuracy: 0.9109\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 28.0249 - accuracy: 0.9575 - val_loss: 28.0366 - val_accuracy: 0.9264\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 28.0319 - accuracy: 0.9245 - val_loss: 28.0458 - val_accuracy: 0.9109\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 28.0780 - accuracy: 0.9104 - val_loss: 28.0366 - val_accuracy: 0.9109\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 27.9998 - accuracy: 0.9481 - val_loss: 28.0062 - val_accuracy: 0.9147\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 28.0001 - accuracy: 0.9340 - val_loss: 27.9684 - val_accuracy: 0.9264\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 27.9720 - accuracy: 0.9387 - val_loss: 27.9650 - val_accuracy: 0.9341\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 27.9909 - accuracy: 0.9151 - val_loss: 27.9520 - val_accuracy: 0.9264\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 27.9658 - accuracy: 0.9340 - val_loss: 27.9854 - val_accuracy: 0.8992\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 27.9718 - accuracy: 0.9057 - val_loss: 27.9486 - val_accuracy: 0.9264\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 27.9333 - accuracy: 0.9245 - val_loss: 27.9594 - val_accuracy: 0.9186\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 27.9077 - accuracy: 0.9151 - val_loss: 27.8980 - val_accuracy: 0.9302\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 27.8983 - accuracy: 0.9198 - val_loss: 27.9033 - val_accuracy: 0.9186\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 27.9287 - accuracy: 0.9009 - val_loss: 27.8943 - val_accuracy: 0.9031\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 27.8195 - accuracy: 0.9575 - val_loss: 27.8807 - val_accuracy: 0.9341\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 27.9290 - accuracy: 0.8915 - val_loss: 27.8397 - val_accuracy: 0.9225\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 27.8595 - accuracy: 0.9151 - val_loss: 27.8691 - val_accuracy: 0.8992\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 27.8435 - accuracy: 0.9104 - val_loss: 27.8154 - val_accuracy: 0.9302\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 27.8353 - accuracy: 0.9198 - val_loss: 27.8106 - val_accuracy: 0.9186\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 27.7728 - accuracy: 0.9481 - val_loss: 27.8112 - val_accuracy: 0.9264\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 27.7944 - accuracy: 0.9292 - val_loss: 27.8069 - val_accuracy: 0.9109\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 27.8045 - accuracy: 0.9057 - val_loss: 27.7961 - val_accuracy: 0.9225\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 27.7800 - accuracy: 0.9387 - val_loss: 27.7461 - val_accuracy: 0.9186\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 27.7507 - accuracy: 0.9340 - val_loss: 27.7639 - val_accuracy: 0.9070\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 260ms/step - loss: 27.7522 - accuracy: 0.9340 - val_loss: 27.7500 - val_accuracy: 0.9225\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 27.6987 - accuracy: 0.9292 - val_loss: 27.7090 - val_accuracy: 0.9186\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 27.7125 - accuracy: 0.9151 - val_loss: 27.6883 - val_accuracy: 0.9264\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 27.6620 - accuracy: 0.9575 - val_loss: 27.6998 - val_accuracy: 0.9225\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 27.6538 - accuracy: 0.9528 - val_loss: 27.6359 - val_accuracy: 0.9574\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 27.6820 - accuracy: 0.9057 - val_loss: 27.6202 - val_accuracy: 0.9186\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 27.6654 - accuracy: 0.9340 - val_loss: 27.6828 - val_accuracy: 0.9070\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 27.6178 - accuracy: 0.9292 - val_loss: 27.6332 - val_accuracy: 0.9147\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 27.6277 - accuracy: 0.9387 - val_loss: 27.6267 - val_accuracy: 0.9302\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 27.6381 - accuracy: 0.9104 - val_loss: 27.5623 - val_accuracy: 0.9419\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 27.6277 - accuracy: 0.8962 - val_loss: 27.5395 - val_accuracy: 0.9419\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 27.6222 - accuracy: 0.9009 - val_loss: 27.5586 - val_accuracy: 0.9341\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 27.5729 - accuracy: 0.9151 - val_loss: 27.5939 - val_accuracy: 0.9186\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 27.5903 - accuracy: 0.9292 - val_loss: 27.5686 - val_accuracy: 0.9031\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 27.5312 - accuracy: 0.9387 - val_loss: 27.5341 - val_accuracy: 0.9225\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 27.5338 - accuracy: 0.9198 - val_loss: 27.5136 - val_accuracy: 0.9225\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 27.5355 - accuracy: 0.9198 - val_loss: 27.4993 - val_accuracy: 0.9341\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 27.5367 - accuracy: 0.9104 - val_loss: 27.4879 - val_accuracy: 0.9264\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 27.5096 - accuracy: 0.9198 - val_loss: 27.4968 - val_accuracy: 0.9225\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 27.4762 - accuracy: 0.9104 - val_loss: 27.4315 - val_accuracy: 0.9264\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 27.4714 - accuracy: 0.9245 - val_loss: 27.4304 - val_accuracy: 0.9419\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 27.4568 - accuracy: 0.9387 - val_loss: 27.4392 - val_accuracy: 0.9225\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 27.3737 - accuracy: 0.9481 - val_loss: 27.4020 - val_accuracy: 0.9225\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 27.4223 - accuracy: 0.9245 - val_loss: 27.3803 - val_accuracy: 0.9302\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 27.3818 - accuracy: 0.9434 - val_loss: 27.3958 - val_accuracy: 0.9070\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 27.3574 - accuracy: 0.9434 - val_loss: 27.3607 - val_accuracy: 0.9380\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 27.3488 - accuracy: 0.9292 - val_loss: 27.4011 - val_accuracy: 0.9109\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 27.3302 - accuracy: 0.9340 - val_loss: 27.3436 - val_accuracy: 0.9264\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 27.3410 - accuracy: 0.9434 - val_loss: 27.3240 - val_accuracy: 0.9264\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 27.3429 - accuracy: 0.9151 - val_loss: 27.3182 - val_accuracy: 0.9419\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 27.3213 - accuracy: 0.9292 - val_loss: 27.3108 - val_accuracy: 0.9264\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 27.3210 - accuracy: 0.9245 - val_loss: 27.3126 - val_accuracy: 0.9186\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 27.3197 - accuracy: 0.9292 - val_loss: 27.3184 - val_accuracy: 0.9147\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 27.2643 - accuracy: 0.9198 - val_loss: 27.2984 - val_accuracy: 0.9341\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 27.2738 - accuracy: 0.9198 - val_loss: 27.2579 - val_accuracy: 0.9109\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 27.1791 - accuracy: 0.9623 - val_loss: 27.2621 - val_accuracy: 0.8992\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 27.2926 - accuracy: 0.9009 - val_loss: 27.2219 - val_accuracy: 0.9341\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 27.2403 - accuracy: 0.9151 - val_loss: 27.2098 - val_accuracy: 0.9186\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 27.2328 - accuracy: 0.8962 - val_loss: 27.1955 - val_accuracy: 0.9186\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 27.2063 - accuracy: 0.9151 - val_loss: 27.1804 - val_accuracy: 0.9380\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 27.1415 - accuracy: 0.9387 - val_loss: 27.1327 - val_accuracy: 0.9535\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 27.1773 - accuracy: 0.9340 - val_loss: 27.1286 - val_accuracy: 0.9419\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 27.2167 - accuracy: 0.8962 - val_loss: 27.1247 - val_accuracy: 0.9225\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 27.1111 - accuracy: 0.9575 - val_loss: 27.1503 - val_accuracy: 0.9264\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 27.0912 - accuracy: 0.9387 - val_loss: 27.1104 - val_accuracy: 0.9341\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 27.1100 - accuracy: 0.9340 - val_loss: 27.1059 - val_accuracy: 0.9419\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 27.0997 - accuracy: 0.9245 - val_loss: 27.0767 - val_accuracy: 0.9419\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 27.1100 - accuracy: 0.9292 - val_loss: 27.1113 - val_accuracy: 0.8953\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 27.0163 - accuracy: 0.9623 - val_loss: 27.0456 - val_accuracy: 0.9186\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 27.0797 - accuracy: 0.9198 - val_loss: 27.0280 - val_accuracy: 0.9302\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 26.9960 - accuracy: 0.9387 - val_loss: 27.0167 - val_accuracy: 0.9302\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 27.0384 - accuracy: 0.9292 - val_loss: 27.0119 - val_accuracy: 0.9186\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 27.0441 - accuracy: 0.8962 - val_loss: 27.0073 - val_accuracy: 0.9186\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 27.0437 - accuracy: 0.8962 - val_loss: 26.9970 - val_accuracy: 0.9225\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 26.9972 - accuracy: 0.9340 - val_loss: 27.0027 - val_accuracy: 0.9109\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 27.0427 - accuracy: 0.8821 - val_loss: 26.9364 - val_accuracy: 0.9419\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 217ms/step - loss: 26.9786 - accuracy: 0.9387 - val_loss: 26.9454 - val_accuracy: 0.9109\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 26.9944 - accuracy: 0.9104 - val_loss: 26.9399 - val_accuracy: 0.9302\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 26.8713 - accuracy: 0.9623 - val_loss: 26.9252 - val_accuracy: 0.9264\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 26.9293 - accuracy: 0.9151 - val_loss: 26.9199 - val_accuracy: 0.9186\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 26.9670 - accuracy: 0.9009 - val_loss: 26.8792 - val_accuracy: 0.9225\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 26.8451 - accuracy: 0.9434 - val_loss: 26.8690 - val_accuracy: 0.9380\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 26.8506 - accuracy: 0.9340 - val_loss: 26.8487 - val_accuracy: 0.9302\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 26.9236 - accuracy: 0.8821 - val_loss: 26.8847 - val_accuracy: 0.9031\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 26.8333 - accuracy: 0.9481 - val_loss: 26.8545 - val_accuracy: 0.9264\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 26.8561 - accuracy: 0.9198 - val_loss: 26.8121 - val_accuracy: 0.9302\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 26.8004 - accuracy: 0.9292 - val_loss: 26.7925 - val_accuracy: 0.9264\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 26.8384 - accuracy: 0.9104 - val_loss: 26.8571 - val_accuracy: 0.9031\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 26.7969 - accuracy: 0.9481 - val_loss: 26.8212 - val_accuracy: 0.9070\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 26.7742 - accuracy: 0.9387 - val_loss: 26.7698 - val_accuracy: 0.9341\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 26.7798 - accuracy: 0.9151 - val_loss: 26.7711 - val_accuracy: 0.9302\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 26.7576 - accuracy: 0.9340 - val_loss: 26.7354 - val_accuracy: 0.9225\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 26.7413 - accuracy: 0.9198 - val_loss: 26.7468 - val_accuracy: 0.9264\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 26.7257 - accuracy: 0.9434 - val_loss: 26.7199 - val_accuracy: 0.9225\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 26.7077 - accuracy: 0.9434 - val_loss: 26.7148 - val_accuracy: 0.9186\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 26.6821 - accuracy: 0.9481 - val_loss: 26.7340 - val_accuracy: 0.9147\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 26.7075 - accuracy: 0.9151 - val_loss: 26.6863 - val_accuracy: 0.9264\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 26.6899 - accuracy: 0.9151 - val_loss: 26.6372 - val_accuracy: 0.9302\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 26.6552 - accuracy: 0.9340 - val_loss: 26.6234 - val_accuracy: 0.9302\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 26.7032 - accuracy: 0.9245 - val_loss: 26.6302 - val_accuracy: 0.9302\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 26.5909 - accuracy: 0.9481 - val_loss: 26.6580 - val_accuracy: 0.8953\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 26.6177 - accuracy: 0.9104 - val_loss: 26.6608 - val_accuracy: 0.9109\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 26.5744 - accuracy: 0.9340 - val_loss: 26.5965 - val_accuracy: 0.9302\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 26.6233 - accuracy: 0.9198 - val_loss: 26.5930 - val_accuracy: 0.9186\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 26.5915 - accuracy: 0.9340 - val_loss: 26.5489 - val_accuracy: 0.9302\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 26.5312 - accuracy: 0.9434 - val_loss: 26.5393 - val_accuracy: 0.9109\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 26.6133 - accuracy: 0.8821 - val_loss: 26.5218 - val_accuracy: 0.9302\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 26.5292 - accuracy: 0.9528 - val_loss: 26.5677 - val_accuracy: 0.9031\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 26.5443 - accuracy: 0.9104 - val_loss: 26.4601 - val_accuracy: 0.9457\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 26.5030 - accuracy: 0.9340 - val_loss: 26.4963 - val_accuracy: 0.9147\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 26.5086 - accuracy: 0.9245 - val_loss: 26.4530 - val_accuracy: 0.9341\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 26.4963 - accuracy: 0.9198 - val_loss: 26.4608 - val_accuracy: 0.9186\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 26.4615 - accuracy: 0.9434 - val_loss: 26.4586 - val_accuracy: 0.9302\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 26.4977 - accuracy: 0.9198 - val_loss: 26.4216 - val_accuracy: 0.9380\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 26.4143 - accuracy: 0.9387 - val_loss: 26.4403 - val_accuracy: 0.9070\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 26.4299 - accuracy: 0.9528 - val_loss: 26.3841 - val_accuracy: 0.9380\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 26.3970 - accuracy: 0.9434 - val_loss: 26.4108 - val_accuracy: 0.9147\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 26.3814 - accuracy: 0.9292 - val_loss: 26.3667 - val_accuracy: 0.9380\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 26.3871 - accuracy: 0.9292 - val_loss: 26.3796 - val_accuracy: 0.9264\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 26.3298 - accuracy: 0.9340 - val_loss: 26.3740 - val_accuracy: 0.9031\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 26.3666 - accuracy: 0.9198 - val_loss: 26.3974 - val_accuracy: 0.9070\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 26.3821 - accuracy: 0.9009 - val_loss: 26.3242 - val_accuracy: 0.9264\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 26.3224 - accuracy: 0.9292 - val_loss: 26.3132 - val_accuracy: 0.9186\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 26.3267 - accuracy: 0.9198 - val_loss: 26.3281 - val_accuracy: 0.9109\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 26.2708 - accuracy: 0.9434 - val_loss: 26.2591 - val_accuracy: 0.9264\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 26.3125 - accuracy: 0.9340 - val_loss: 26.3005 - val_accuracy: 0.9264\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 26.2671 - accuracy: 0.9198 - val_loss: 26.2769 - val_accuracy: 0.9186\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 26.2802 - accuracy: 0.9104 - val_loss: 26.2227 - val_accuracy: 0.9457\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 26.3102 - accuracy: 0.8868 - val_loss: 26.2587 - val_accuracy: 0.9109\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 26.2809 - accuracy: 0.8962 - val_loss: 26.2159 - val_accuracy: 0.9186\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 26.1849 - accuracy: 0.9387 - val_loss: 26.2362 - val_accuracy: 0.9070\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 26.1930 - accuracy: 0.9198 - val_loss: 26.1994 - val_accuracy: 0.9147\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 210ms/step - loss: 26.1903 - accuracy: 0.9245 - val_loss: 26.2067 - val_accuracy: 0.8992\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 26.1358 - accuracy: 0.9387 - val_loss: 26.2068 - val_accuracy: 0.9031\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 26.1972 - accuracy: 0.8962 - val_loss: 26.1629 - val_accuracy: 0.9264\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 26.1208 - accuracy: 0.9292 - val_loss: 26.1728 - val_accuracy: 0.9264\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 26.1328 - accuracy: 0.9387 - val_loss: 26.0970 - val_accuracy: 0.9380\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 26.1371 - accuracy: 0.9292 - val_loss: 26.1346 - val_accuracy: 0.9070\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 26.0724 - accuracy: 0.9387 - val_loss: 26.0940 - val_accuracy: 0.9419\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 26.1544 - accuracy: 0.8915 - val_loss: 26.0505 - val_accuracy: 0.9302\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 26.0797 - accuracy: 0.9340 - val_loss: 26.0908 - val_accuracy: 0.9186\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 26.0644 - accuracy: 0.9104 - val_loss: 26.0281 - val_accuracy: 0.9419\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 26.1031 - accuracy: 0.9151 - val_loss: 26.0351 - val_accuracy: 0.9302\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 26.0379 - accuracy: 0.9245 - val_loss: 26.0411 - val_accuracy: 0.9070\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 26.0215 - accuracy: 0.9151 - val_loss: 25.9924 - val_accuracy: 0.9264\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 26.0063 - accuracy: 0.9151 - val_loss: 26.0247 - val_accuracy: 0.9225\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 26.0524 - accuracy: 0.9151 - val_loss: 25.9872 - val_accuracy: 0.9341\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 25.9751 - accuracy: 0.9245 - val_loss: 25.9505 - val_accuracy: 0.9302\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 26.0222 - accuracy: 0.8868 - val_loss: 25.9694 - val_accuracy: 0.9147\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 25.9220 - accuracy: 0.9340 - val_loss: 25.9410 - val_accuracy: 0.9264\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 26.0703 - accuracy: 0.9009 - val_loss: 25.9713 - val_accuracy: 0.9186\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 25.9055 - accuracy: 0.9623 - val_loss: 25.9893 - val_accuracy: 0.8837\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 25.9497 - accuracy: 0.9104 - val_loss: 25.8735 - val_accuracy: 0.9264\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 25.8832 - accuracy: 0.9434 - val_loss: 25.9236 - val_accuracy: 0.9109\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 25.8542 - accuracy: 0.9387 - val_loss: 25.8684 - val_accuracy: 0.9264\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 25.8988 - accuracy: 0.9009 - val_loss: 25.8821 - val_accuracy: 0.9225\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 25.9013 - accuracy: 0.9009 - val_loss: 25.8543 - val_accuracy: 0.9186\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 25.8906 - accuracy: 0.8915 - val_loss: 25.8266 - val_accuracy: 0.9264\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 25.8305 - accuracy: 0.9292 - val_loss: 25.8223 - val_accuracy: 0.9341\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 25.8170 - accuracy: 0.9292 - val_loss: 25.8498 - val_accuracy: 0.9225\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 25.8086 - accuracy: 0.9387 - val_loss: 25.8119 - val_accuracy: 0.9109\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 25.8127 - accuracy: 0.9340 - val_loss: 25.8069 - val_accuracy: 0.9225\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 25.7755 - accuracy: 0.9245 - val_loss: 25.7575 - val_accuracy: 0.9302\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 25.7694 - accuracy: 0.9151 - val_loss: 25.7574 - val_accuracy: 0.9070\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 25.7947 - accuracy: 0.8915 - val_loss: 25.7661 - val_accuracy: 0.9147\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 25.8207 - accuracy: 0.8915 - val_loss: 25.7488 - val_accuracy: 0.9109\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 25.7450 - accuracy: 0.9245 - val_loss: 25.7277 - val_accuracy: 0.9264\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 25.6814 - accuracy: 0.9434 - val_loss: 25.6693 - val_accuracy: 0.9496\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 25.6647 - accuracy: 0.9575 - val_loss: 25.7429 - val_accuracy: 0.9186\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 25.7019 - accuracy: 0.9198 - val_loss: 25.6954 - val_accuracy: 0.9225\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 25.6694 - accuracy: 0.9198 - val_loss: 25.6744 - val_accuracy: 0.9031\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 25.6845 - accuracy: 0.9198 - val_loss: 25.6586 - val_accuracy: 0.8876\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 25.7302 - accuracy: 0.9151 - val_loss: 25.5959 - val_accuracy: 0.9380\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 25.5944 - accuracy: 0.9481 - val_loss: 25.5796 - val_accuracy: 0.9380\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 25.6482 - accuracy: 0.9245 - val_loss: 25.6388 - val_accuracy: 0.9031\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 25.6000 - accuracy: 0.9340 - val_loss: 25.5665 - val_accuracy: 0.9225\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 25.6899 - accuracy: 0.8774 - val_loss: 25.5484 - val_accuracy: 0.9225\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 25.5638 - accuracy: 0.9292 - val_loss: 25.6034 - val_accuracy: 0.9264\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 25.5855 - accuracy: 0.9104 - val_loss: 25.5546 - val_accuracy: 0.9264\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 25.5040 - accuracy: 0.9481 - val_loss: 25.5622 - val_accuracy: 0.9147\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 25.5387 - accuracy: 0.9151 - val_loss: 25.4892 - val_accuracy: 0.9380\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 25.5340 - accuracy: 0.9245 - val_loss: 25.4965 - val_accuracy: 0.9302\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 25.5475 - accuracy: 0.9104 - val_loss: 25.5091 - val_accuracy: 0.9109\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 25.5531 - accuracy: 0.9151 - val_loss: 25.4885 - val_accuracy: 0.9302\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 25.4713 - accuracy: 0.9245 - val_loss: 25.4789 - val_accuracy: 0.9302\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 25.4608 - accuracy: 0.9198 - val_loss: 25.4649 - val_accuracy: 0.9225\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 25.4873 - accuracy: 0.9292 - val_loss: 25.4748 - val_accuracy: 0.8992\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 25.5008 - accuracy: 0.8962 - val_loss: 25.4465 - val_accuracy: 0.9380\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 201ms/step - loss: 25.4770 - accuracy: 0.8915 - val_loss: 25.4190 - val_accuracy: 0.9380\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 25.4678 - accuracy: 0.8915 - val_loss: 25.3925 - val_accuracy: 0.9419\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 25.4410 - accuracy: 0.9151 - val_loss: 25.3923 - val_accuracy: 0.9302\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 25.3398 - accuracy: 0.9387 - val_loss: 25.3647 - val_accuracy: 0.9341\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 25.4586 - accuracy: 0.8868 - val_loss: 25.4192 - val_accuracy: 0.9031\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 25.3958 - accuracy: 0.9104 - val_loss: 25.3624 - val_accuracy: 0.9186\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 25.3815 - accuracy: 0.9009 - val_loss: 25.3063 - val_accuracy: 0.9341\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 25.2999 - accuracy: 0.9481 - val_loss: 25.3209 - val_accuracy: 0.9147\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 25.4398 - accuracy: 0.8679 - val_loss: 25.3053 - val_accuracy: 0.9264\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 25.4763 - accuracy: 0.8679 - val_loss: 25.2745 - val_accuracy: 0.9264\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 25.3066 - accuracy: 0.9151 - val_loss: 25.3150 - val_accuracy: 0.9109\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 25.2940 - accuracy: 0.9009 - val_loss: 25.2853 - val_accuracy: 0.9147\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 25.2715 - accuracy: 0.9245 - val_loss: 25.3010 - val_accuracy: 0.8953\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 25.2273 - accuracy: 0.9434 - val_loss: 25.3266 - val_accuracy: 0.8876\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 25.2456 - accuracy: 0.9151 - val_loss: 25.2852 - val_accuracy: 0.8953\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 25.2092 - accuracy: 0.9292 - val_loss: 25.2381 - val_accuracy: 0.9070\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 25.1870 - accuracy: 0.9292 - val_loss: 25.1702 - val_accuracy: 0.9302\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 25.1750 - accuracy: 0.9245 - val_loss: 25.2490 - val_accuracy: 0.9031\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 25.1952 - accuracy: 0.9151 - val_loss: 25.2230 - val_accuracy: 0.9031\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 25.2451 - accuracy: 0.8915 - val_loss: 25.1506 - val_accuracy: 0.9419\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 25.2008 - accuracy: 0.9009 - val_loss: 25.1236 - val_accuracy: 0.9380\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 25.1357 - accuracy: 0.9481 - val_loss: 25.1896 - val_accuracy: 0.8798\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 25.1187 - accuracy: 0.9292 - val_loss: 25.1239 - val_accuracy: 0.9147\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 25.1057 - accuracy: 0.9292 - val_loss: 25.1235 - val_accuracy: 0.9186\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 25.1051 - accuracy: 0.9387 - val_loss: 25.1279 - val_accuracy: 0.8992\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 25.0586 - accuracy: 0.9387 - val_loss: 25.1850 - val_accuracy: 0.8798\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 25.0824 - accuracy: 0.9245 - val_loss: 25.0985 - val_accuracy: 0.9070\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 25.0839 - accuracy: 0.9104 - val_loss: 25.0062 - val_accuracy: 0.9457\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 25.0388 - accuracy: 0.9292 - val_loss: 25.0333 - val_accuracy: 0.9341\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 25.0885 - accuracy: 0.9009 - val_loss: 25.1016 - val_accuracy: 0.8876\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 24.9767 - accuracy: 0.9575 - val_loss: 25.0058 - val_accuracy: 0.9264\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 25.0246 - accuracy: 0.9009 - val_loss: 25.0354 - val_accuracy: 0.9070\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 25.0377 - accuracy: 0.8962 - val_loss: 24.9835 - val_accuracy: 0.9225\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 25.0034 - accuracy: 0.9198 - val_loss: 24.9310 - val_accuracy: 0.9341\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 25.0072 - accuracy: 0.9009 - val_loss: 24.9974 - val_accuracy: 0.9031\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 24.9396 - accuracy: 0.9198 - val_loss: 24.9468 - val_accuracy: 0.9147\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 24.9558 - accuracy: 0.9151 - val_loss: 24.9525 - val_accuracy: 0.8953\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 24.9223 - accuracy: 0.9340 - val_loss: 24.9552 - val_accuracy: 0.8953\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 24.8848 - accuracy: 0.9245 - val_loss: 24.9276 - val_accuracy: 0.8953\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 24.8675 - accuracy: 0.9387 - val_loss: 24.8909 - val_accuracy: 0.9225\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 24.9283 - accuracy: 0.8915 - val_loss: 24.8739 - val_accuracy: 0.9147\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 24.9037 - accuracy: 0.9151 - val_loss: 24.8477 - val_accuracy: 0.9109\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 24.9298 - accuracy: 0.9104 - val_loss: 24.8880 - val_accuracy: 0.8876\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 24.9315 - accuracy: 0.9009 - val_loss: 24.8236 - val_accuracy: 0.9264\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 24.8408 - accuracy: 0.9198 - val_loss: 24.8398 - val_accuracy: 0.9070\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 24.8309 - accuracy: 0.9151 - val_loss: 24.8585 - val_accuracy: 0.9031\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 24.8276 - accuracy: 0.9198 - val_loss: 24.8014 - val_accuracy: 0.9070\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 24.7647 - accuracy: 0.9292 - val_loss: 24.8060 - val_accuracy: 0.9031\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 24.8662 - accuracy: 0.8915 - val_loss: 24.7825 - val_accuracy: 0.9031\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 24.7564 - accuracy: 0.9434 - val_loss: 24.7541 - val_accuracy: 0.9225\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 24.7369 - accuracy: 0.9387 - val_loss: 24.7371 - val_accuracy: 0.9186\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 24.8225 - accuracy: 0.8821 - val_loss: 24.8012 - val_accuracy: 0.9186\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 24.8603 - accuracy: 0.8679 - val_loss: 24.7497 - val_accuracy: 0.8915\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 24.7927 - accuracy: 0.8679 - val_loss: 24.7305 - val_accuracy: 0.9109\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 24.6958 - accuracy: 0.9340 - val_loss: 24.6805 - val_accuracy: 0.9264\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 24.6792 - accuracy: 0.9387 - val_loss: 24.7190 - val_accuracy: 0.8992\n",
      "Epoch 940/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step - loss: 24.6675 - accuracy: 0.9292 - val_loss: 24.6847 - val_accuracy: 0.9031\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 24.6444 - accuracy: 0.9387 - val_loss: 24.6687 - val_accuracy: 0.9341\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 24.6415 - accuracy: 0.9198 - val_loss: 24.6223 - val_accuracy: 0.9302\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 24.6620 - accuracy: 0.8915 - val_loss: 24.6698 - val_accuracy: 0.9070\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 24.5977 - accuracy: 0.9387 - val_loss: 24.6261 - val_accuracy: 0.9264\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 24.6225 - accuracy: 0.9104 - val_loss: 24.6340 - val_accuracy: 0.9186\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 24.6228 - accuracy: 0.8962 - val_loss: 24.5862 - val_accuracy: 0.9264\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 24.6259 - accuracy: 0.9104 - val_loss: 24.5466 - val_accuracy: 0.9341\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 24.6222 - accuracy: 0.9057 - val_loss: 24.5656 - val_accuracy: 0.9186\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 24.5459 - accuracy: 0.9104 - val_loss: 24.5340 - val_accuracy: 0.9302\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 24.5454 - accuracy: 0.9198 - val_loss: 24.5195 - val_accuracy: 0.9302\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 24.5573 - accuracy: 0.9198 - val_loss: 24.5321 - val_accuracy: 0.9031\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 24.5163 - accuracy: 0.9292 - val_loss: 24.5167 - val_accuracy: 0.9302\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 24.5479 - accuracy: 0.9151 - val_loss: 24.5284 - val_accuracy: 0.8992\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 24.4825 - accuracy: 0.9104 - val_loss: 24.5117 - val_accuracy: 0.9147\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 24.4466 - accuracy: 0.9292 - val_loss: 24.4962 - val_accuracy: 0.9186\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 24.5159 - accuracy: 0.8962 - val_loss: 24.4623 - val_accuracy: 0.9186\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 24.4398 - accuracy: 0.9387 - val_loss: 24.4302 - val_accuracy: 0.9225\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 24.4044 - accuracy: 0.9481 - val_loss: 24.4122 - val_accuracy: 0.9264\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 24.4463 - accuracy: 0.9245 - val_loss: 24.4459 - val_accuracy: 0.8915\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 24.3853 - accuracy: 0.8962 - val_loss: 24.3861 - val_accuracy: 0.9341\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 24.4092 - accuracy: 0.9340 - val_loss: 24.3920 - val_accuracy: 0.9070\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 24.3854 - accuracy: 0.9198 - val_loss: 24.4030 - val_accuracy: 0.9031\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 24.4389 - accuracy: 0.8679 - val_loss: 24.3961 - val_accuracy: 0.9031\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 24.3571 - accuracy: 0.9387 - val_loss: 24.3504 - val_accuracy: 0.9225\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 24.2921 - accuracy: 0.9481 - val_loss: 24.3035 - val_accuracy: 0.9302\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 24.4342 - accuracy: 0.8726 - val_loss: 24.3729 - val_accuracy: 0.8798\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 24.3068 - accuracy: 0.9198 - val_loss: 24.3431 - val_accuracy: 0.9070\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 24.5064 - accuracy: 0.8349 - val_loss: 24.3238 - val_accuracy: 0.9186\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 24.2917 - accuracy: 0.9245 - val_loss: 24.3318 - val_accuracy: 0.9031\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 24.2845 - accuracy: 0.9104 - val_loss: 24.2905 - val_accuracy: 0.9109\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 24.2569 - accuracy: 0.9292 - val_loss: 24.2606 - val_accuracy: 0.9070\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 24.2418 - accuracy: 0.9292 - val_loss: 24.2475 - val_accuracy: 0.9186\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 24.2536 - accuracy: 0.9198 - val_loss: 24.2378 - val_accuracy: 0.9380\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 24.2781 - accuracy: 0.8962 - val_loss: 24.2328 - val_accuracy: 0.9031\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 24.2338 - accuracy: 0.9198 - val_loss: 24.2453 - val_accuracy: 0.9031\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 24.2016 - accuracy: 0.9104 - val_loss: 24.2299 - val_accuracy: 0.9109\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 24.2516 - accuracy: 0.8962 - val_loss: 24.2309 - val_accuracy: 0.8682\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 24.2741 - accuracy: 0.9057 - val_loss: 24.1055 - val_accuracy: 0.9457\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 24.1660 - accuracy: 0.9151 - val_loss: 24.1716 - val_accuracy: 0.9147\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 24.1497 - accuracy: 0.9151 - val_loss: 24.1389 - val_accuracy: 0.9109\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 24.1086 - accuracy: 0.9245 - val_loss: 24.1680 - val_accuracy: 0.9186\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 24.1773 - accuracy: 0.8962 - val_loss: 24.1129 - val_accuracy: 0.9070\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 24.1649 - accuracy: 0.9057 - val_loss: 24.0922 - val_accuracy: 0.9264\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 24.1653 - accuracy: 0.8774 - val_loss: 24.0609 - val_accuracy: 0.9147\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 24.2527 - accuracy: 0.8491 - val_loss: 24.0926 - val_accuracy: 0.9070\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 24.0245 - accuracy: 0.9245 - val_loss: 24.0075 - val_accuracy: 0.9457\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 24.1163 - accuracy: 0.8962 - val_loss: 24.0299 - val_accuracy: 0.9147\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 24.0548 - accuracy: 0.9009 - val_loss: 24.0989 - val_accuracy: 0.8798\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 24.0079 - accuracy: 0.9151 - val_loss: 24.0128 - val_accuracy: 0.9070\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 24.0224 - accuracy: 0.9151 - val_loss: 23.9860 - val_accuracy: 0.9147\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 23.9537 - accuracy: 0.9387 - val_loss: 23.9623 - val_accuracy: 0.9302\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 23.9884 - accuracy: 0.9151 - val_loss: 23.9614 - val_accuracy: 0.9302\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 23.9728 - accuracy: 0.9151 - val_loss: 23.9603 - val_accuracy: 0.9186\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 23.9571 - accuracy: 0.9434 - val_loss: 23.9767 - val_accuracy: 0.9031\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 23.9703 - accuracy: 0.9057 - val_loss: 23.9791 - val_accuracy: 0.8915\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 199ms/step - loss: 23.9919 - accuracy: 0.9009 - val_loss: 23.9805 - val_accuracy: 0.8992\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 23.9496 - accuracy: 0.9151 - val_loss: 23.9622 - val_accuracy: 0.8915\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 23.9238 - accuracy: 0.9057 - val_loss: 23.8834 - val_accuracy: 0.9264\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 23.8751 - accuracy: 0.9387 - val_loss: 23.8967 - val_accuracy: 0.8992\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 23.9100 - accuracy: 0.9104 - val_loss: 23.8923 - val_accuracy: 0.8953\n",
      "Model training finished.\n",
      "Train loss: 23.883, train accuracy: 0.934.\n",
      "Evaluating model performance...\n",
      "Test loss: 23.902, test accuracy: 0.867.\n"
     ]
    }
   ],
   "source": [
    "run_experiment(bnn_model_full,\n",
    "               nll,\n",
    "               train_dataset,\n",
    "               val_dataset,\n",
    "               test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:56:20.625206Z",
     "start_time": "2021-07-04T15:56:13.002384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000025C84379C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000025C84379C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: .\\bnn_model_saved\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(\n",
    "    bnn_model_full,\n",
    "    os.path.join('.','bnn_model_saved')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T15:51:37.777155Z",
     "start_time": "2021-07-04T15:51:37.755212Z"
    }
   },
   "outputs": [],
   "source": [
    "bnn_model_full_config = bnn_model_full.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T16:03:21.446641Z",
     "start_time": "2021-07-04T16:03:14.877212Z"
    }
   },
   "outputs": [],
   "source": [
    "bnn_model_loaded = tf.keras.models.load_model(os.path.join('.','bnn_model_saved'), custom_objects={'nll': nll})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T16:03:24.561310Z",
     "start_time": "2021-07-04T16:03:24.316964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025C82E7A948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025C82E7A948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    <ipython-input-22-c4739803df1b>:2 nll  *\n        return -y_pred.log_prob(y_true)\n\n    AttributeError: 'Tensor' object has no attribute 'log_prob'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-bd1c990a3379>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbnn_model_loaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 726\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-22-c4739803df1b>:2 nll  *\n        return -y_pred.log_prob(y_true)\n\n    AttributeError: 'Tensor' object has no attribute 'log_prob'\n"
     ]
    }
   ],
   "source": [
    "bnn_model_loaded.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_bnn = bnn_model_full.predict(test_dataset)\n",
    "test_predictions_nn = nn_model_full.predict(test_dataset)\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\bnn_model_full\\assets\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join('.','bnn_model_full')\n",
    "\n",
    "tf.saved_model.save(\n",
    "    bnn_model_full, export_dir = save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predictions_probabilities(model, test_dataset = test_dataset):\n",
    "    \n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    probabilities = []\n",
    "    entropies = []\n",
    "    i = 1\n",
    "\n",
    "    for x, y in test_dataset.unbatch().batch(1).take(-1):\n",
    "        \n",
    "        output_dist = model(x)\n",
    "        \n",
    "        # prediction\n",
    "        [prediction] = highest_prob = output_dist.mode()\n",
    "        prediction = np.argmax(prediction)\n",
    "        \n",
    "        # probability of this prediction\n",
    "        probability = output_dist.prob(highest_prob).numpy().squeeze()\n",
    "        \n",
    "        # true label of test example\n",
    "        true_label = np.argmax(y.numpy().squeeze())\n",
    "        \n",
    "        # entropy\n",
    "        [entropy] = output_dist.entropy().numpy()\n",
    "        \n",
    "        print(f\"Test Example: {i}\")\n",
    "        print(f\"Test Prediction: {prediction}, probability of this prediction: {probability} and entropy: {entropy}\")\n",
    "        print(f\"True Label: {true_label}\")\n",
    "        print(\"=\"*15)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        predictions.append(prediction)\n",
    "        true_labels.append(true_label)\n",
    "        probabilities.append(probability)\n",
    "        entropies.append(entropy)\n",
    "        \n",
    "    return predictions, true_labels, probabilities, entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Example: 1\n",
      "Test Prediction: 0, probability of this prediction: 0.9999985694885254 and entropy: 2.0503997802734375e-05\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 2\n",
      "Test Prediction: 0, probability of this prediction: 0.9990960359573364 and entropy: 0.007239341735839844\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 3\n",
      "Test Prediction: 1, probability of this prediction: 0.9970126152038574 and entropy: 0.020349740982055664\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 4\n",
      "Test Prediction: 1, probability of this prediction: 0.9680721759796143 and entropy: 0.1413809061050415\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 5\n",
      "Test Prediction: 1, probability of this prediction: 0.9757798910140991 and entropy: 0.11403703689575195\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 6\n",
      "Test Prediction: 0, probability of this prediction: 0.9998941421508789 and entropy: 0.0010747909545898438\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 7\n",
      "Test Prediction: 1, probability of this prediction: 0.963542103767395 and entropy: 0.15651893615722656\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 8\n",
      "Test Prediction: 0, probability of this prediction: 0.9986703395843506 and entropy: 0.010135173797607422\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 9\n",
      "Test Prediction: 0, probability of this prediction: 0.992324709892273 and entropy: 0.04502248764038086\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 10\n",
      "Test Prediction: 1, probability of this prediction: 0.7264497876167297 and entropy: 0.586758017539978\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 11\n",
      "Test Prediction: 1, probability of this prediction: 0.9999027252197266 and entropy: 0.0009961128234863281\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 12\n",
      "Test Prediction: 1, probability of this prediction: 0.5873917937278748 and entropy: 0.6777938008308411\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 13\n",
      "Test Prediction: 1, probability of this prediction: 0.9909391403198242 and entropy: 0.05164003372192383\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 14\n",
      "Test Prediction: 1, probability of this prediction: 0.8725292682647705 and entropy: 0.3815501928329468\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 15\n",
      "Test Prediction: 1, probability of this prediction: 0.9882144927978516 and entropy: 0.06405377388000488\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 16\n",
      "Test Prediction: 0, probability of this prediction: 0.5763184428215027 and entropy: 0.6814525723457336\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 17\n",
      "Test Prediction: 1, probability of this prediction: 0.9994145631790161 and entropy: 0.004942893981933594\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 18\n",
      "Test Prediction: 1, probability of this prediction: 0.8878713846206665 and entropy: 0.3509427011013031\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 19\n",
      "Test Prediction: 0, probability of this prediction: 0.5213857293128967 and entropy: 0.6922322511672974\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 20\n",
      "Test Prediction: 1, probability of this prediction: 0.9994937181472778 and entropy: 0.004348039627075195\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 21\n",
      "Test Prediction: 1, probability of this prediction: 0.9969050288200378 and entropy: 0.020972490310668945\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 22\n",
      "Test Prediction: 0, probability of this prediction: 0.9839308857917786 and entropy: 0.08231854438781738\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 23\n",
      "Test Prediction: 1, probability of this prediction: 0.9999114274978638 and entropy: 0.0009150505065917969\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 24\n",
      "Test Prediction: 1, probability of this prediction: 0.5748827457427979 and entropy: 0.681890070438385\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 25\n",
      "Test Prediction: 1, probability of this prediction: 0.9789485335350037 and entropy: 0.102103590965271\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 26\n",
      "Test Prediction: 1, probability of this prediction: 0.9986371397972107 and entropy: 0.010354280471801758\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 27\n",
      "Test Prediction: 0, probability of this prediction: 0.9998201727867126 and entropy: 0.0017304420471191406\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 28\n",
      "Test Prediction: 0, probability of this prediction: 0.9965057373046875 and entropy: 0.0232541561126709\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 29\n",
      "Test Prediction: 1, probability of this prediction: 0.986949622631073 and entropy: 0.06958949565887451\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 30\n",
      "Test Prediction: 0, probability of this prediction: 0.8754270672798157 and entropy: 0.37593841552734375\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 31\n",
      "Test Prediction: 0, probability of this prediction: 0.6349270343780518 and entropy: 0.6562812328338623\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 32\n",
      "Test Prediction: 0, probability of this prediction: 0.9137623310089111 and entropy: 0.2937455177307129\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 33\n",
      "Test Prediction: 0, probability of this prediction: 0.6425970196723938 and entropy: 0.651909351348877\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 34\n",
      "Test Prediction: 1, probability of this prediction: 0.845264196395874 and entropy: 0.43083667755126953\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 35\n",
      "Test Prediction: 0, probability of this prediction: 0.5336083173751831 and entropy: 0.6908864974975586\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 36\n",
      "Test Prediction: 1, probability of this prediction: 0.999830961227417 and entropy: 0.0016369819641113281\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 37\n",
      "Test Prediction: 0, probability of this prediction: 0.7683412432670593 and entropy: 0.5412728786468506\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 38\n",
      "Test Prediction: 0, probability of this prediction: 0.9937404990196228 and entropy: 0.03799843788146973\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 39\n",
      "Test Prediction: 0, probability of this prediction: 0.9557240605354309 and entropy: 0.18130290508270264\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 40\n",
      "Test Prediction: 1, probability of this prediction: 0.9381832480430603 and entropy: 0.23193734884262085\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 41\n",
      "Test Prediction: 0, probability of this prediction: 0.9939736723899841 and entropy: 0.03681230545043945\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 42\n",
      "Test Prediction: 1, probability of this prediction: 0.7171197533607483 and entropy: 0.5956530570983887\n",
      "True Label: 1\n",
      "===============\n",
      "Test Example: 43\n",
      "Test Prediction: 0, probability of this prediction: 0.9999951124191284 and entropy: 6.4849853515625e-05\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 44\n",
      "Test Prediction: 0, probability of this prediction: 0.7768283486366272 and entropy: 0.5308930277824402\n",
      "True Label: 0\n",
      "===============\n",
      "Test Example: 45\n",
      "Test Prediction: 0, probability of this prediction: 0.9694585204124451 and entropy: 0.13661956787109375\n",
      "True Label: 0\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels, probabilities, entropies = output_predictions_probabilities(bnn_model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>entropies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99999857</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99909604</td>\n",
       "      <td>0.007239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9970126</td>\n",
       "      <td>0.020350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9680722</td>\n",
       "      <td>0.141381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9757799</td>\n",
       "      <td>0.114037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99989414</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9635421</td>\n",
       "      <td>0.156519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99867034</td>\n",
       "      <td>0.010135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9923247</td>\n",
       "      <td>0.045022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7264498</td>\n",
       "      <td>0.586758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9999027</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5873918</td>\n",
       "      <td>0.677794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99093914</td>\n",
       "      <td>0.051640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87252927</td>\n",
       "      <td>0.381550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9882145</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.57631844</td>\n",
       "      <td>0.681453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99941456</td>\n",
       "      <td>0.004943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8878714</td>\n",
       "      <td>0.350943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5213857</td>\n",
       "      <td>0.692232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9994937</td>\n",
       "      <td>0.004348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996905</td>\n",
       "      <td>0.020972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9839309</td>\n",
       "      <td>0.082319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9999114</td>\n",
       "      <td>0.000915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57488275</td>\n",
       "      <td>0.681890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97894853</td>\n",
       "      <td>0.102104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99863714</td>\n",
       "      <td>0.010354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9998202</td>\n",
       "      <td>0.001730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99650574</td>\n",
       "      <td>0.023254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9869496</td>\n",
       "      <td>0.069589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87542707</td>\n",
       "      <td>0.375938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63492703</td>\n",
       "      <td>0.656281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91376233</td>\n",
       "      <td>0.293746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.642597</td>\n",
       "      <td>0.651909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8452642</td>\n",
       "      <td>0.430837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5336083</td>\n",
       "      <td>0.690886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99983096</td>\n",
       "      <td>0.001637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76834124</td>\n",
       "      <td>0.541273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9937405</td>\n",
       "      <td>0.037998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95572406</td>\n",
       "      <td>0.181303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93818325</td>\n",
       "      <td>0.231937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9939737</td>\n",
       "      <td>0.036812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71711975</td>\n",
       "      <td>0.595653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9999951</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77682835</td>\n",
       "      <td>0.530893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9694585</td>\n",
       "      <td>0.136620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictions  true_labels probabilities  entropies\n",
       "0             0            0    0.99999857   0.000021\n",
       "1             0            0    0.99909604   0.007239\n",
       "2             1            1     0.9970126   0.020350\n",
       "3             1            1     0.9680722   0.141381\n",
       "4             1            1     0.9757799   0.114037\n",
       "5             0            0    0.99989414   0.001075\n",
       "6             1            1     0.9635421   0.156519\n",
       "7             0            0    0.99867034   0.010135\n",
       "8             0            0     0.9923247   0.045022\n",
       "9             1            1     0.7264498   0.586758\n",
       "10            1            1     0.9999027   0.000996\n",
       "11            1            0     0.5873918   0.677794\n",
       "12            1            1    0.99093914   0.051640\n",
       "13            1            1    0.87252927   0.381550\n",
       "14            1            1     0.9882145   0.064054\n",
       "15            0            0    0.57631844   0.681453\n",
       "16            1            1    0.99941456   0.004943\n",
       "17            1            1     0.8878714   0.350943\n",
       "18            0            0     0.5213857   0.692232\n",
       "19            1            1     0.9994937   0.004348\n",
       "20            1            1      0.996905   0.020972\n",
       "21            0            0     0.9839309   0.082319\n",
       "22            1            1     0.9999114   0.000915\n",
       "23            1            1    0.57488275   0.681890\n",
       "24            1            1    0.97894853   0.102104\n",
       "25            1            1    0.99863714   0.010354\n",
       "26            0            0     0.9998202   0.001730\n",
       "27            0            0    0.99650574   0.023254\n",
       "28            1            1     0.9869496   0.069589\n",
       "29            0            1    0.87542707   0.375938\n",
       "30            0            1    0.63492703   0.656281\n",
       "31            0            0    0.91376233   0.293746\n",
       "32            0            1      0.642597   0.651909\n",
       "33            1            1     0.8452642   0.430837\n",
       "34            0            0     0.5336083   0.690886\n",
       "35            1            1    0.99983096   0.001637\n",
       "36            0            0    0.76834124   0.541273\n",
       "37            0            0     0.9937405   0.037998\n",
       "38            0            0    0.95572406   0.181303\n",
       "39            1            1    0.93818325   0.231937\n",
       "40            0            0     0.9939737   0.036812\n",
       "41            1            1    0.71711975   0.595653\n",
       "42            0            0     0.9999951   0.000065\n",
       "43            0            0    0.77682835   0.530893\n",
       "44            0            0     0.9694585   0.136620"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_result_dict = {k: v for k, v in zip(['predictions', 'true_labels', 'probabilities', 'entropies'],\n",
    "                                                [predictions, true_labels, probabilities, entropies])}\n",
    "\n",
    "test_dataset_result_df = pd.DataFrame(test_dataset_result_dict)\n",
    "test_dataset_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Correctly Predicted')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_entropies = test_dataset_result_df[test_dataset_result_df.predictions == test_dataset_result_df.true_labels]['entropies']\n",
    "density = gaussian_kde(correct_entropies.to_numpy())\n",
    "plt.plot(np.linspace(0,1,100), density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Correctly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Wrongly Predicted')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_entropies = test_dataset_result_df[test_dataset_result_df.predictions != test_dataset_result_df.true_labels]['entropies']\n",
    "density = gaussian_kde(wrong_entropies.to_numpy())\n",
    "plt.plot(np.linspace(0,1,100), density(np.linspace(0,1,100)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Entropy')\n",
    "plt.title('Wrongly Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
